{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuntherFrager/fuzzy-carnival/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inicio"
      ],
      "metadata": {
        "id": "0JhlSJgUuTS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUG8qtpVN5rV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFaPaOHIQUg-"
      },
      "outputs": [],
      "source": [
        "df_completo = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Notebookfinal/usdt-btc2.csv', index_col='Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "IdCHiSA3UMG4",
        "outputId": "c091289a-8892-4504-9631-226b692e5883"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Open     High      Low    Close    Volume\n",
              "Time                                                             \n",
              "2017-08-18 00:00:00  4244.77  4267.59  4244.77  4244.77  0.657267\n",
              "2017-08-18 00:01:00  4267.59  4278.05  4267.59  4278.05  0.643297\n",
              "2017-08-18 00:02:00  4244.77  4244.77  4244.77  4244.77  0.216000\n",
              "2017-08-18 00:03:00  4278.05  4278.05  4278.05  4278.05  0.456560\n",
              "2017-08-18 00:04:00  4278.05  4278.05  4278.05  4278.05  0.055644"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50003ffb-fc14-48e7-b63f-8fbafe39c3d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:00:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>0.657267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:01:00</th>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.643297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:02:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>0.216000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:03:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.456560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:04:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.055644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50003ffb-fc14-48e7-b63f-8fbafe39c3d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50003ffb-fc14-48e7-b63f-8fbafe39c3d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50003ffb-fc14-48e7-b63f-8fbafe39c3d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e9899f5b-9570-4ce1-8bc9-64bbf88ccd05\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9899f5b-9570-4ce1-8bc9-64bbf88ccd05')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e9899f5b-9570-4ce1-8bc9-64bbf88ccd05 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ_UZXSPUjAm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f53def93-be48-4e7a-e803-5254c85c2eaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close       Volume\n",
              "count  1440.000000  1440.000000  1440.000000  1440.000000  1440.000000\n",
              "mean   4215.451375  4218.256854  4213.974792  4216.858924     0.747635\n",
              "std     104.165440   103.839755   104.408027   104.167140     1.152575\n",
              "min    3949.360000  3956.300000  3938.770000  3938.770000     0.000000\n",
              "25%    4135.470000  4136.430000  4135.470000  4135.470000     0.035113\n",
              "50%    4251.735000  4254.280000  4249.510000  4252.630000     0.300000\n",
              "75%    4296.732500  4300.000000  4294.842500  4298.000000     0.863444\n",
              "max    4371.420000  4371.520000  4371.400000  4371.520000     8.619423"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0b2b6f0-19b1-41fe-aa5a-3be34a971645\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4215.451375</td>\n",
              "      <td>4218.256854</td>\n",
              "      <td>4213.974792</td>\n",
              "      <td>4216.858924</td>\n",
              "      <td>0.747635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104.165440</td>\n",
              "      <td>103.839755</td>\n",
              "      <td>104.408027</td>\n",
              "      <td>104.167140</td>\n",
              "      <td>1.152575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3949.360000</td>\n",
              "      <td>3956.300000</td>\n",
              "      <td>3938.770000</td>\n",
              "      <td>3938.770000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4135.470000</td>\n",
              "      <td>4136.430000</td>\n",
              "      <td>4135.470000</td>\n",
              "      <td>4135.470000</td>\n",
              "      <td>0.035113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4251.735000</td>\n",
              "      <td>4254.280000</td>\n",
              "      <td>4249.510000</td>\n",
              "      <td>4252.630000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4296.732500</td>\n",
              "      <td>4300.000000</td>\n",
              "      <td>4294.842500</td>\n",
              "      <td>4298.000000</td>\n",
              "      <td>0.863444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4371.420000</td>\n",
              "      <td>4371.520000</td>\n",
              "      <td>4371.400000</td>\n",
              "      <td>4371.520000</td>\n",
              "      <td>8.619423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0b2b6f0-19b1-41fe-aa5a-3be34a971645')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0b2b6f0-19b1-41fe-aa5a-3be34a971645 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0b2b6f0-19b1-41fe-aa5a-3be34a971645');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f34a7513-76cf-41d9-b2f6-aecc373e9c95\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f34a7513-76cf-41d9-b2f6-aecc373e9c95')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f34a7513-76cf-41d9-b2f6-aecc373e9c95 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[:1440]\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1632.758920674063,\n        \"min\": 104.16544009874012,\n        \"max\": 4371.42,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4215.451375000001,\n          4251.735000000001,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1633.9818432223815,\n        \"min\": 103.83975512777414,\n        \"max\": 4371.52,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4218.256854166667,\n          4254.28,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1631.6863905647667,\n        \"min\": 104.40802715412487,\n        \"max\": 4371.4,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4213.9747916666665,\n          4249.51,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1632.4963328123038,\n        \"min\": 104.1671398651228,\n        \"max\": 4371.52,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4216.858923611111,\n          4252.63,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 508.53308719397137,\n        \"min\": 0.0,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7476354847222221,\n          0.3,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df[:1440].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentando con candlesticks"
      ],
      "metadata": {
        "id": "6gQ8azQ_2IGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mplfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzg00nQr2OcY",
        "outputId": "11626310-f700-44ed-f547-94e41019d339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.10b0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/75.0 kB\u001b[0m \u001b[31m990.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mplfinance) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mplfinance) (1.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mplfinance) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.16.0)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.10b0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df[160:185]\n",
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "eANCt8BX2xST",
        "outputId": "b7cf7182-5ed6-4c87-df8f-22c67f1585c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Open     High      Low    Close    Volume\n",
              "Time                                                             \n",
              "2017-08-18 02:40:00  4291.47  4291.47  4291.47  4291.47  0.432000\n",
              "2017-08-18 02:41:00  4291.47  4295.40  4291.47  4295.40  0.706374\n",
              "2017-08-18 02:42:00  4291.47  4295.40  4291.47  4295.40  1.833000\n",
              "2017-08-18 02:43:00  4340.62  4340.62  4291.17  4291.17  0.795313\n",
              "2017-08-18 02:44:00  4340.00  4340.00  4290.55  4340.00  3.448118"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-133f9e8c-db8b-4be3-8da0-389f20c04e9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:40:00</th>\n",
              "      <td>4291.47</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>0.432000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:41:00</th>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>0.706374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:42:00</th>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>1.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:43:00</th>\n",
              "      <td>4340.62</td>\n",
              "      <td>4340.62</td>\n",
              "      <td>4291.17</td>\n",
              "      <td>4291.17</td>\n",
              "      <td>0.795313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:44:00</th>\n",
              "      <td>4340.00</td>\n",
              "      <td>4340.00</td>\n",
              "      <td>4290.55</td>\n",
              "      <td>4340.00</td>\n",
              "      <td>3.448118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-133f9e8c-db8b-4be3-8da0-389f20c04e9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-133f9e8c-db8b-4be3-8da0-389f20c04e9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-133f9e8c-db8b-4be3-8da0-389f20c04e9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87ebd5f7-eaed-43c2-ad7d-987d654c59ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87ebd5f7-eaed-43c2-ad7d-987d654c59ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87ebd5f7-eaed-43c2-ad7d-987d654c59ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"2017-08-18 02:48:00\",\n          \"2017-08-18 02:56:00\",\n          \"2017-08-18 02:40:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.473557718259123,\n        \"min\": 4274.16,\n        \"max\": 4340.62,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          4274.16,\n          4291.47,\n          4313.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.014063173764914,\n        \"min\": 4289.88,\n        \"max\": 4340.62,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          4294.5,\n          4291.47,\n          4321.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.091027135354349,\n        \"min\": 4274.16,\n        \"max\": 4325.38,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          4274.16,\n          4291.47,\n          4313.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.630501415571786,\n        \"min\": 4274.16,\n        \"max\": 4340.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          4289.88,\n          4291.47,\n          4321.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9474897015462315,\n        \"min\": 0.040636,\n        \"max\": 3.800029,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.39336,\n          0.063676,\n          0.432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mplfinance.original_flavor import candlestick_ohlc\n",
        "import matplotlib.dates as mdates\n",
        "import pandas as pd\n",
        "\n",
        "# Supongamos que tienes un DataFrame de pandas llamado df que contiene tus datos\n",
        "\n",
        "# Convertir el índice a un formato de fecha\n",
        "df2['Time'] = pd.to_datetime(df2.index)\n",
        "\n",
        "# Crear la figura y los ejes del gráfico\n",
        "fig, ax = plt.subplots(figsize=(12, 6))  # Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "# Crear una nueva columna 'Color' que determine el color de la vela (verde para subida, rojo para bajada)\n",
        "df2['Color'] = 'g'  # Inicialmente, establecemos todas las velas en verde\n",
        "df2.loc[df2['Close'] < df2['Open'], 'Color'] = 'r'  # Cambiamos el color a rojo para las velas bajistas\n",
        "\n",
        "# Dibujar el gráfico de velas con colores personalizados\n",
        "candlestick_ohlc(ax, df2[['Time','Open', 'High', 'Low', 'Close']].values, width=0.0005, colorup='g', colordown='r', alpha=0.75)\n",
        "\n",
        "# Ajustar el formato de las fechas en el eje x para que se muestren correctamente\n",
        "ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=30))  # Configura el intervalo de 30 minutos\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))  # Formato de las horas:minutos\n",
        "\n",
        "# Rotar las fechas para que sean legibles\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Etiquetas y título del gráfico\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Candlestick Chart')\n",
        "\n",
        "# Añadir cuadrícula\n",
        "plt.grid(True)\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N9_HF4MG2TDT",
        "outputId": "c5e17230-007a-4b0b-c7b8-ab50377b161c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-312e55990266>:9: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df2.Time = pd.to_datetime(df2.index)\n",
            "<ipython-input-35-312e55990266>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['Color'] = 'g'  # Inicialmente, establecemos todas las velas en verde\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Time'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-312e55990266>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Dibujar el gráfico de velas con colores personalizados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcandlestick_ohlc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolordown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Ajustar el formato de las fechas en el eje x para que se muestren correctamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Time'] not in index\""
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[160:250]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Tg119maS4pkh",
        "outputId": "2c72d0fe-1a7c-4f15-f1b6-6bb63397066a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Open     High      Low    Close    Volume\n",
              "Time                                                             \n",
              "2017-08-18 02:40:00  4291.47  4291.47  4291.47  4291.47  0.432000\n",
              "2017-08-18 02:41:00  4291.47  4295.40  4291.47  4295.40  0.706374\n",
              "2017-08-18 02:42:00  4291.47  4295.40  4291.47  4295.40  1.833000\n",
              "2017-08-18 02:43:00  4340.62  4340.62  4291.17  4291.17  0.795313\n",
              "2017-08-18 02:44:00  4340.00  4340.00  4290.55  4340.00  3.448118\n",
              "...                      ...      ...      ...      ...       ...\n",
              "2017-08-18 04:05:00  4290.75  4290.75  4290.75  4290.75  0.050936\n",
              "2017-08-18 04:06:00  4290.75  4290.75  4290.75  4290.75  0.000000\n",
              "2017-08-18 04:07:00  4290.75  4290.75  4290.75  4290.75  0.389475\n",
              "2017-08-18 04:08:00  4270.50  4286.09  4270.50  4286.09  3.893273\n",
              "2017-08-18 04:09:00  4286.09  4286.09  4286.09  4286.09  0.953845\n",
              "\n",
              "[90 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8c7346a-c042-4f2e-b5c3-a21f9d448ddb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:40:00</th>\n",
              "      <td>4291.47</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>0.432000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:41:00</th>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>0.706374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:42:00</th>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>4291.47</td>\n",
              "      <td>4295.40</td>\n",
              "      <td>1.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:43:00</th>\n",
              "      <td>4340.62</td>\n",
              "      <td>4340.62</td>\n",
              "      <td>4291.17</td>\n",
              "      <td>4291.17</td>\n",
              "      <td>0.795313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 02:44:00</th>\n",
              "      <td>4340.00</td>\n",
              "      <td>4340.00</td>\n",
              "      <td>4290.55</td>\n",
              "      <td>4340.00</td>\n",
              "      <td>3.448118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 04:05:00</th>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>0.050936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 04:06:00</th>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 04:07:00</th>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>4290.75</td>\n",
              "      <td>0.389475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 04:08:00</th>\n",
              "      <td>4270.50</td>\n",
              "      <td>4286.09</td>\n",
              "      <td>4270.50</td>\n",
              "      <td>4286.09</td>\n",
              "      <td>3.893273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 04:09:00</th>\n",
              "      <td>4286.09</td>\n",
              "      <td>4286.09</td>\n",
              "      <td>4286.09</td>\n",
              "      <td>4286.09</td>\n",
              "      <td>0.953845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8c7346a-c042-4f2e-b5c3-a21f9d448ddb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8c7346a-c042-4f2e-b5c3-a21f9d448ddb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8c7346a-c042-4f2e-b5c3-a21f9d448ddb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b5cec016-b04a-459c-b8d0-c5e927b8bb02\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5cec016-b04a-459c-b8d0-c5e927b8bb02')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b5cec016-b04a-459c-b8d0-c5e927b8bb02 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[160:250]\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"2017-08-18 03:20:00\",\n          \"2017-08-18 03:02:00\",\n          \"2017-08-18 03:35:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.574851767771438,\n        \"min\": 4261.41,\n        \"max\": 4340.62,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          4270.5,\n          4262.32,\n          4288.03\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.28326573733513,\n        \"min\": 4261.41,\n        \"max\": 4340.62,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          4290.75,\n          4290.1,\n          4295.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.651580646668574,\n        \"min\": 4247.75,\n        \"max\": 4325.38,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          4290.75,\n          4297.13,\n          4254.92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.233787088844757,\n        \"min\": 4247.75,\n        \"max\": 4340.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          4304.66,\n          4304.67,\n          4291.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1678314002453298,\n        \"min\": 0.0,\n        \"max\": 4.201553,\n        \"num_unique_values\": 86,\n        \"samples\": [\n          3.398982,\n          0.432,\n          0.131808\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vuelvo a la normalidad"
      ],
      "metadata": {
        "id": "XtucIAQ92LoW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6EmRKOR03GC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "bcbc55ef-acb3-484f-dc5b-221acb9d2a62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close\n",
              "count  1440.000000  1440.000000  1440.000000  1440.000000\n",
              "mean   4062.759597  4064.447153  4062.262396  4063.774993\n",
              "std      54.944692    53.465466    55.325712    54.251404\n",
              "min    3870.620000  3882.590000  3850.000000  3850.000000\n",
              "25%    4023.880000  4027.370000  4023.872500  4027.370000\n",
              "50%    4068.230000  4069.660000  4068.200000  4068.285000\n",
              "75%    4096.330000  4096.330000  4096.330000  4096.330000\n",
              "max    4180.000000  4180.000000  4180.000000  4180.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91e429bf-c617-48d8-9d27-7210f993bc90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4062.759597</td>\n",
              "      <td>4064.447153</td>\n",
              "      <td>4062.262396</td>\n",
              "      <td>4063.774993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>54.944692</td>\n",
              "      <td>53.465466</td>\n",
              "      <td>55.325712</td>\n",
              "      <td>54.251404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3870.620000</td>\n",
              "      <td>3882.590000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4023.880000</td>\n",
              "      <td>4027.370000</td>\n",
              "      <td>4023.872500</td>\n",
              "      <td>4027.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4068.230000</td>\n",
              "      <td>4069.660000</td>\n",
              "      <td>4068.200000</td>\n",
              "      <td>4068.285000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4096.330000</td>\n",
              "      <td>4096.330000</td>\n",
              "      <td>4096.330000</td>\n",
              "      <td>4096.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4180.000000</td>\n",
              "      <td>4180.000000</td>\n",
              "      <td>4180.000000</td>\n",
              "      <td>4180.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91e429bf-c617-48d8-9d27-7210f993bc90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91e429bf-c617-48d8-9d27-7210f993bc90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91e429bf-c617-48d8-9d27-7210f993bc90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c746a820-3c06-4971-a92d-53d79b1f2bda\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c746a820-3c06-4971-a92d-53d79b1f2bda')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c746a820-3c06-4971-a92d-53d79b1f2bda button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[1440:2880]\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1575.4649078609903,\n        \"min\": 54.9446918546871,\n        \"max\": 4180.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4062.7595972222225,\n          4068.23,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1577.0867134902098,\n        \"min\": 53.465465616315456,\n        \"max\": 4180.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4064.4471527777782,\n          4069.66,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1574.1231497599613,\n        \"min\": 55.325712158770884,\n        \"max\": 4180.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4062.262395833333,\n          4068.2,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1574.808758412489,\n        \"min\": 54.25140447290541,\n        \"max\": 4180.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4063.7749930555556,\n          4068.285,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df[1440:2880].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4vayiQWWUxS"
      },
      "outputs": [],
      "source": [
        "df_final = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gGHL1OZumyR"
      },
      "outputs": [],
      "source": [
        "def normalizar(dataframe, dia):\n",
        "  i = dia * 1440\n",
        "  df_final_dia1 = df[:][i:i+1440]\n",
        "  df_final_dia2 = df[:][i+1440:i+2880]\n",
        "\n",
        "  nuevo_min = 0.25\n",
        "  nuevo_max = 0.75\n",
        "\n",
        "\n",
        "  df_final_dia2['Open'] = ((df_final_dia2['Open'] - df_final_dia1['Open'].min()) / (df_final_dia1['Open'].max() - df_final_dia1['Open'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "  df_final_dia2['High'] = ((df_final_dia2['High'] - df_final_dia1['High'].min()) / (df_final_dia1['High'].max() - df_final_dia1['High'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "  df_final_dia2['Low'] = ((df_final_dia2['Low'] - df_final_dia1['Low'].min()) / (df_final_dia1['Low'].max() - df_final_dia1['Low'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "  df_final_dia2['Close'] = ((df_final_dia2['Close'] - df_final_dia1['Close'].min()) / (df_final_dia1['Close'].max() - df_final_dia1['Close'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "\n",
        "\n",
        "  global df_final\n",
        "  global df_normal\n",
        "  df_normal = df_final_dia2\n",
        "  df_final = df[:][i:i+1440]\n",
        "  return df_final\n",
        "  return df_normal\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "iwBRBSy7zVa2",
        "outputId": "1dd44022-1f4a-4bd2-b7d7-89d9ee7e48ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Open     High      Low    Close\n",
              "Time                                                   \n",
              "2017-08-18 00:00:00  4244.77  4267.59  4244.77  4244.77\n",
              "2017-08-18 00:01:00  4267.59  4278.05  4267.59  4278.05\n",
              "2017-08-18 00:02:00  4244.77  4244.77  4244.77  4244.77\n",
              "2017-08-18 00:03:00  4278.05  4278.05  4278.05  4278.05\n",
              "2017-08-18 00:04:00  4278.05  4278.05  4278.05  4278.05\n",
              "...                      ...      ...      ...      ...\n",
              "2017-08-18 23:55:00  4156.39  4156.39  4156.39  4156.39\n",
              "2017-08-18 23:56:00  4156.39  4156.39  4156.39  4156.39\n",
              "2017-08-18 23:57:00  4156.39  4156.39  4156.39  4156.39\n",
              "2017-08-18 23:58:00  4156.39  4156.39  4156.39  4156.39\n",
              "2017-08-18 23:59:00  4156.39  4156.39  4156.39  4156.39\n",
              "\n",
              "[1440 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c62c6c5-6d4a-4be9-b08d-539db01a6187\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:00:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:01:00</th>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:02:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:03:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:04:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:55:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:56:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:57:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:58:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:59:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c62c6c5-6d4a-4be9-b08d-539db01a6187')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c62c6c5-6d4a-4be9-b08d-539db01a6187 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c62c6c5-6d4a-4be9-b08d-539db01a6187');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-147447ac-dcc8-4d3b-afa2-e09bbda60eeb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-147447ac-dcc8-4d3b-afa2-e09bbda60eeb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-147447ac-dcc8-4d3b-afa2-e09bbda60eeb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9edda115-9f69-493d-80ed-26bd4cc85f9d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9edda115-9f69-493d-80ed-26bd4cc85f9d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.16544009874012,\n        \"min\": 3949.36,\n        \"max\": 4371.42,\n        \"num_unique_values\": 476,\n        \"samples\": [\n          4152.55,\n          4245.0,\n          4307.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 103.83975512777414,\n        \"min\": 3956.3,\n        \"max\": 4371.52,\n        \"num_unique_values\": 381,\n        \"samples\": [\n          4015.7,\n          4225.84,\n          4330.82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.40802715412487,\n        \"min\": 3938.77,\n        \"max\": 4371.4,\n        \"num_unique_values\": 478,\n        \"samples\": [\n          4152.55,\n          4234.43,\n          4283.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.1671398651228,\n        \"min\": 3938.77,\n        \"max\": 4371.52,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          4063.13,\n          4330.82,\n          4286.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "normalizar(df,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kWepC1S_WMkm",
        "outputId": "5f77923f-11d8-4db7-8251-b943b35de34b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close\n",
              "count  1440.000000  1440.000000  1440.000000  1440.000000\n",
              "mean   4215.451375  4218.256854  4213.974792  4216.858924\n",
              "std     104.165440   103.839755   104.408027   104.167140\n",
              "min    3949.360000  3956.300000  3938.770000  3938.770000\n",
              "25%    4135.470000  4136.430000  4135.470000  4135.470000\n",
              "50%    4251.735000  4254.280000  4249.510000  4252.630000\n",
              "75%    4296.732500  4300.000000  4294.842500  4298.000000\n",
              "max    4371.420000  4371.520000  4371.400000  4371.520000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d734279d-4826-435f-8468-48aff7683df7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4215.451375</td>\n",
              "      <td>4218.256854</td>\n",
              "      <td>4213.974792</td>\n",
              "      <td>4216.858924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104.165440</td>\n",
              "      <td>103.839755</td>\n",
              "      <td>104.408027</td>\n",
              "      <td>104.167140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3949.360000</td>\n",
              "      <td>3956.300000</td>\n",
              "      <td>3938.770000</td>\n",
              "      <td>3938.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4135.470000</td>\n",
              "      <td>4136.430000</td>\n",
              "      <td>4135.470000</td>\n",
              "      <td>4135.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4251.735000</td>\n",
              "      <td>4254.280000</td>\n",
              "      <td>4249.510000</td>\n",
              "      <td>4252.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4296.732500</td>\n",
              "      <td>4300.000000</td>\n",
              "      <td>4294.842500</td>\n",
              "      <td>4298.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4371.420000</td>\n",
              "      <td>4371.520000</td>\n",
              "      <td>4371.400000</td>\n",
              "      <td>4371.520000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d734279d-4826-435f-8468-48aff7683df7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d734279d-4826-435f-8468-48aff7683df7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d734279d-4826-435f-8468-48aff7683df7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34f8cc47-88ba-4221-abad-8224ed54da67\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34f8cc47-88ba-4221-abad-8224ed54da67')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34f8cc47-88ba-4221-abad-8224ed54da67 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1632.758920674063,\n        \"min\": 104.16544009874012,\n        \"max\": 4371.42,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4215.451375000001,\n          4251.735000000001,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1633.9818432223815,\n        \"min\": 103.83975512777414,\n        \"max\": 4371.52,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4218.256854166667,\n          4254.28,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1631.6863905647667,\n        \"min\": 104.40802715412487,\n        \"max\": 4371.4,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4213.9747916666665,\n          4249.51,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1632.4963328123038,\n        \"min\": 104.1671398651228,\n        \"max\": 4371.52,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4216.858923611111,\n          4252.63,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_final.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "N69umnzKpg9n",
        "outputId": "1d2fa1d7-24e5-4c5f-f669-5faee5985579"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close\n",
              "count  1440.000000  1440.000000  1440.000000  1440.000000\n",
              "mean      0.384341     0.380229     0.392723     0.394431\n",
              "std       0.065091     0.064382     0.063941     0.062682\n",
              "min       0.156719     0.161240     0.147407     0.147435\n",
              "25%       0.338281     0.335581     0.348355     0.352369\n",
              "50%       0.390821     0.386506     0.399585     0.399642\n",
              "75%       0.424110     0.418621     0.432096     0.432045\n",
              "max       0.523231     0.519375     0.528795     0.528718"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5e0ce96-4e80-4e2b-aaad-98f24bd8dbd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.384341</td>\n",
              "      <td>0.380229</td>\n",
              "      <td>0.392723</td>\n",
              "      <td>0.394431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.065091</td>\n",
              "      <td>0.064382</td>\n",
              "      <td>0.063941</td>\n",
              "      <td>0.062682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.156719</td>\n",
              "      <td>0.161240</td>\n",
              "      <td>0.147407</td>\n",
              "      <td>0.147435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.338281</td>\n",
              "      <td>0.335581</td>\n",
              "      <td>0.348355</td>\n",
              "      <td>0.352369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.390821</td>\n",
              "      <td>0.386506</td>\n",
              "      <td>0.399585</td>\n",
              "      <td>0.399642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.424110</td>\n",
              "      <td>0.418621</td>\n",
              "      <td>0.432096</td>\n",
              "      <td>0.432045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.523231</td>\n",
              "      <td>0.519375</td>\n",
              "      <td>0.528795</td>\n",
              "      <td>0.528718</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5e0ce96-4e80-4e2b-aaad-98f24bd8dbd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5e0ce96-4e80-4e2b-aaad-98f24bd8dbd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5e0ce96-4e80-4e2b-aaad-98f24bd8dbd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-63a08b6b-d1cc-4e53-bde7-9e1c42af102c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63a08b6b-d1cc-4e53-bde7-9e1c42af102c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-63a08b6b-d1cc-4e53-bde7-9e1c42af102c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_normal\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 509.0016154573155,\n        \"min\": 0.06509109114188398,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.38434061178768664,\n          0.3908212102544661,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 509.00245628063516,\n        \"min\": 0.06438209336775133,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3802287375099676,\n          0.38650594865372523,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 509.0000862188769,\n        \"min\": 0.06394114157452202,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.39272287616824236,\n          0.39958509580935203,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 508.99986310511247,\n        \"min\": 0.06268215421479532,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3944309567366324,\n          0.3996418255343731,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_normal.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYZrtajnBrvW"
      },
      "source": [
        "### Training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFyU497lxvQL"
      },
      "outputs": [],
      "source": [
        "def accionar(df_normal):\n",
        "\n",
        "  lista = []\n",
        "\n",
        "  for i in range(len(df_normal.Open)):\n",
        "\n",
        "    if df_normal.Open[i] / df_normal[:][i+1:i+8].describe().Open['max'] >= 1.002:\n",
        "      lista.append('V')\n",
        "    elif df_normal.Open[i] / df_normal[:][i+1:i+8].describe().Open['min'] <= 0.998:\n",
        "      lista.append('C')\n",
        "    else:\n",
        "      lista.append('P')\n",
        "\n",
        "\n",
        "  df_final['Accion'] = lista\n",
        "  df_normal['Accion'] = lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf90v585qM2x"
      },
      "outputs": [],
      "source": [
        "dfaux1 = df_normal.copy(deep = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y27rXqWxGQA",
        "outputId": "9d082171-52c2-48c9-dd9b-09175c909919"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Open      High       Low     Close\n",
              "Time                                                       \n",
              "2017-08-19 00:00:00  0.495261  0.490945  0.501508  0.501438\n",
              "2017-08-19 00:01:00  0.495261  0.490945  0.501508  0.501438\n",
              "2017-08-19 00:02:00  0.495261  0.490945  0.501508  0.501438\n",
              "2017-08-19 00:03:00  0.495261  0.490945  0.501508  0.501438\n",
              "2017-08-19 00:04:00  0.495261  0.490945  0.501508  0.501438"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a11916d-2112-4895-ae60-b19045f14d9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:00:00</th>\n",
              "      <td>0.495261</td>\n",
              "      <td>0.490945</td>\n",
              "      <td>0.501508</td>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:01:00</th>\n",
              "      <td>0.495261</td>\n",
              "      <td>0.490945</td>\n",
              "      <td>0.501508</td>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:02:00</th>\n",
              "      <td>0.495261</td>\n",
              "      <td>0.490945</td>\n",
              "      <td>0.501508</td>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:03:00</th>\n",
              "      <td>0.495261</td>\n",
              "      <td>0.490945</td>\n",
              "      <td>0.501508</td>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:04:00</th>\n",
              "      <td>0.495261</td>\n",
              "      <td>0.490945</td>\n",
              "      <td>0.501508</td>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a11916d-2112-4895-ae60-b19045f14d9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a11916d-2112-4895-ae60-b19045f14d9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a11916d-2112-4895-ae60-b19045f14d9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cea6f3d6-75d0-48ad-9e0e-6554dd33fbf4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cea6f3d6-75d0-48ad-9e0e-6554dd33fbf4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cea6f3d6-75d0-48ad-9e0e-6554dd33fbf4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfaux1",
              "summary": "{\n  \"name\": \"dfaux1\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06509109114188398,\n        \"min\": 0.15671942377860937,\n        \"max\": 0.5232312941287968,\n        \"num_unique_values\": 318,\n        \"samples\": [\n          0.29443680993223686,\n          0.42599393451168077,\n          0.4007724020281477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06438209336775133,\n        \"min\": 0.16123982467125864,\n        \"max\": 0.5193752709407058,\n        \"num_unique_values\": 265,\n        \"samples\": [\n          0.3790159433553295,\n          0.31052213284523833,\n          0.3279586725109577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06394114157452202,\n        \"min\": 0.1474065598779557,\n        \"max\": 0.5287948131197562,\n        \"num_unique_values\": 309,\n        \"samples\": [\n          0.48254281949934097,\n          0.4802544899798906,\n          0.3672826664817513\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06268215421479532,\n        \"min\": 0.1474350086655114,\n        \"max\": 0.5287175043327554,\n        \"num_unique_values\": 259,\n        \"samples\": [\n          0.3197515886770651,\n          0.4131773541305602,\n          0.44035239745811705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dfaux1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_zN8cLeN7dI"
      },
      "outputs": [],
      "source": [
        "accionar(dfaux1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg-__UZ_qV94"
      },
      "outputs": [],
      "source": [
        "dfaux1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VcBTP3fxcj9"
      },
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1UA9XQs_EFne",
        "outputId": "2a34b3d7-12d3-47eb-d18f-6bd8f1d382c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Filtrar las compras y ventas\n",
        "compras = df_final[df_final['Accion'] == 'C']\n",
        "ventas  = df_final[df_final['Accion'] == 'V']\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "plt.plot(df_final['Open'], color='lightgray', label='Precio')\n",
        "plt.scatter(compras.index, compras['Open'], color='green', marker='^', label='Compra')\n",
        "plt.scatter(ventas.index, ventas['Open'], color='red', marker='v', label='Venta')\n",
        "\n",
        "# Configuración adicional\n",
        "plt.xlabel('Precio')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Histograma de Compras y Ventas')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el histograma\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq3HSOO5Jy9o"
      },
      "outputs": [],
      "source": [
        "def simulacion(df):\n",
        "  BTC = 0.01\n",
        "  USDT = 100\n",
        "  total = USDT + (BTC * df['Open'][-1])\n",
        "  print('Comienza simulacion con', total, 'USD')\n",
        "\n",
        "  for i in range(len(df['Accion'])):\n",
        "    if USDT > 5:\n",
        "      if df['Accion'][i] == 'C':\n",
        "        monto = USDT * 0.02\n",
        "        USDT = USDT - monto\n",
        "        BTC = BTC + (monto / df['Open'][i])\n",
        "\n",
        "      elif BTC > 0.01:\n",
        "        if df['Accion'][i] == 'V':\n",
        "          monto = BTC * 0.02\n",
        "          BTC = BTC - monto\n",
        "          USDT = USDT + (monto * df['Open'][i])\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    elif BTC > 0.01:\n",
        "      if df['Accion'][i] == 'V':\n",
        "        monto = BTC * 0.02\n",
        "        BTC = BTC - monto\n",
        "        USDT = USDT + (monto * df['Open'][i])\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "\n",
        "  totalaux = total\n",
        "  total = USDT + (BTC * df['Open'][-1])\n",
        "  print('Finaliza simulacion con', total, 'USD')\n",
        "  global ganancia\n",
        "  ganancia = float(total - totalaux)\n",
        "  return total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ewaHJEBvR4J",
        "outputId": "3bbe2832-8410-4e54-d4b6-dcefe7021df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comienza simulacion con 141.5639 USD\n",
            "Finaliza simulacion con 140.81767789961006 USD\n",
            "ganancia acumulada: -0.7462221003899288\n",
            "Comienza simulacion con 141.24689999999998 USD\n",
            "Finaliza simulacion con 142.13631953192737 USD\n",
            "ganancia acumulada: 0.1431974315374589\n",
            "Comienza simulacion con 140.7994 USD\n",
            "Finaliza simulacion con 140.57396489857464 USD\n",
            "ganancia acumulada: -0.08223766988788839\n",
            "Comienza simulacion con 138.2249 USD\n",
            "Finaliza simulacion con 136.8627391974718 USD\n",
            "ganancia acumulada: -1.4443984724160828\n",
            "Comienza simulacion con 140.8372 USD\n",
            "Finaliza simulacion con 142.5847717969359 USD\n",
            "ganancia acumulada: 0.3031733245198325\n",
            "Comienza simulacion con 141.3192 USD\n",
            "Finaliza simulacion con 141.4643567048363 USD\n",
            "ganancia acumulada: 0.44833002935612853\n",
            "Comienza simulacion con 143.4678 USD\n",
            "Finaliza simulacion con 144.3178503886229 USD\n",
            "ganancia acumulada: 1.2983804179790184\n",
            "Comienza simulacion con 142.6604 USD\n",
            "Finaliza simulacion con 142.26896957435872 USD\n",
            "ganancia acumulada: 0.9069499923377293\n",
            "Comienza simulacion con 143.681 USD\n",
            "Finaliza simulacion con 144.11371296804 USD\n",
            "ganancia acumulada: 1.3396629603777228\n",
            "Comienza simulacion con 142.95 USD\n",
            "Finaliza simulacion con 142.82742989215228 USD\n",
            "ganancia acumulada: 1.2170928525300155\n"
          ]
        }
      ],
      "source": [
        "gananciaacumulada = 0\n",
        "dias_buenos = []\n",
        "for i in range(10):\n",
        "  normalizar(df, i)\n",
        "  accionar(df_normal)\n",
        "  simulacion(df_final)\n",
        "  gananciaacumulada = gananciaacumulada + ganancia\n",
        "  print('ganancia acumulada:', gananciaacumulada)\n",
        "  if ganancia > 0:\n",
        "    dias_buenos.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb2a0C5fOrZV",
        "outputId": "d1c22445-6cf6-4065-9e64-11d59bc14e19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 4, 5, 6, 8]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dias_buenos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "06BRaef0zfTb",
        "outputId": "ec2a9d9f-ce5e-47ec-8aae-e9cbd1b158f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7873bbf-bea7-4355-9347-e9a001b748ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>Accion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-28 00:19:00</th>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-28 00:20:00</th>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>0.491249</td>\n",
              "      <td>0.491248</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-28 00:21:00</th>\n",
              "      <td>0.486522</td>\n",
              "      <td>0.486521</td>\n",
              "      <td>0.486392</td>\n",
              "      <td>0.486394</td>\n",
              "      <td>0.486522</td>\n",
              "      <td>0.486521</td>\n",
              "      <td>0.486392</td>\n",
              "      <td>0.486394</td>\n",
              "      <td>0.486522</td>\n",
              "      <td>0.486521</td>\n",
              "      <td>...</td>\n",
              "      <td>0.486394</td>\n",
              "      <td>0.486522</td>\n",
              "      <td>0.486521</td>\n",
              "      <td>0.486392</td>\n",
              "      <td>0.486394</td>\n",
              "      <td>0.486522</td>\n",
              "      <td>0.486521</td>\n",
              "      <td>0.486392</td>\n",
              "      <td>0.486394</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-28 00:22:00</th>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486395</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-28 00:23:00</th>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>0.486398</td>\n",
              "      <td>0.486397</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7873bbf-bea7-4355-9347-e9a001b748ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7873bbf-bea7-4355-9347-e9a001b748ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7873bbf-bea7-4355-9347-e9a001b748ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a4e62f1c-9987-4c40-99ce-56b7800b3639\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4e62f1c-9987-4c40-99ce-56b7800b3639')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a4e62f1c-9987-4c40-99ce-56b7800b3639 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                            1         2         3         4         5  \\\n",
              "Time                                                                    \n",
              "2017-08-28 00:19:00  0.491249  0.491248  0.491249  0.491248  0.491249   \n",
              "2017-08-28 00:20:00  0.491249  0.491248  0.491249  0.491248  0.491249   \n",
              "2017-08-28 00:21:00  0.486522  0.486521  0.486392  0.486394  0.486522   \n",
              "2017-08-28 00:22:00  0.486395  0.486397  0.486395  0.486397  0.486395   \n",
              "2017-08-28 00:23:00  0.486398  0.486397  0.486398  0.486397  0.486398   \n",
              "\n",
              "                            6         7         8         9        10  ...  \\\n",
              "Time                                                                   ...   \n",
              "2017-08-28 00:19:00  0.491248  0.491249  0.491248  0.491249  0.491248  ...   \n",
              "2017-08-28 00:20:00  0.491248  0.491249  0.491248  0.491249  0.491248  ...   \n",
              "2017-08-28 00:21:00  0.486521  0.486392  0.486394  0.486522  0.486521  ...   \n",
              "2017-08-28 00:22:00  0.486397  0.486395  0.486397  0.486395  0.486397  ...   \n",
              "2017-08-28 00:23:00  0.486397  0.486398  0.486397  0.486398  0.486397  ...   \n",
              "\n",
              "                           72        73        74        75        76  \\\n",
              "Time                                                                    \n",
              "2017-08-28 00:19:00  0.491248  0.491249  0.491248  0.491249  0.491248   \n",
              "2017-08-28 00:20:00  0.491248  0.491249  0.491248  0.491249  0.491248   \n",
              "2017-08-28 00:21:00  0.486394  0.486522  0.486521  0.486392  0.486394   \n",
              "2017-08-28 00:22:00  0.486397  0.486395  0.486397  0.486395  0.486397   \n",
              "2017-08-28 00:23:00  0.486397  0.486398  0.486397  0.486398  0.486397   \n",
              "\n",
              "                           77        78        79        80  Accion  \n",
              "Time                                                                 \n",
              "2017-08-28 00:19:00  0.491249  0.491248  0.491249  0.491248       P  \n",
              "2017-08-28 00:20:00  0.491249  0.491248  0.491249  0.491248       V  \n",
              "2017-08-28 00:21:00  0.486522  0.486521  0.486392  0.486394       P  \n",
              "2017-08-28 00:22:00  0.486395  0.486397  0.486395  0.486397       P  \n",
              "2017-08-28 00:23:00  0.486398  0.486397  0.486398  0.486397       P  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "for i in range(20):\n",
        "    j = i\n",
        "    k = 0 - (20 - i)\n",
        "    df_aux1[str(i*4+1)] = df_normal.Open[j:k]\n",
        "    df_aux1[str(i*4+2)] = df_normal.High[j:k]\n",
        "    df_aux1[str(i*4+3)] = df_normal.Low[j:k]\n",
        "    df_aux1[str(i*4+4)] = df_normal.Close[j:k]\n",
        "df_aux1[\"Accion\"] = df_normal.Accion\n",
        "\n",
        "df_aux1 = df_aux1.dropna()\n",
        "df_aux1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuTtC6qI3Yp9",
        "outputId": "7880ff70-d2b4-4687-d8b7-a76c20b622cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1401, 81)"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_aux1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMvFxUUQDdZ2",
        "outputId": "871b82e8-88ed-4e12-9741-d811f24fb527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5, 0, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1]\n"
          ]
        }
      ],
      "source": [
        "lista = []\n",
        "for i in range(len(df_aux1['Accion'])):\n",
        "  if df_aux1.Accion[i] == 'C':\n",
        "    lista.append(1)\n",
        "  elif df_aux1.Accion[i] == \"V\":\n",
        "    lista.append(0)\n",
        "  else:\n",
        "    lista.append(0.5)\n",
        "\n",
        "print(lista)\n",
        "df_aux1['Accion'] = lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQRTRZHk32JY",
        "outputId": "52db3287-488c-46cb-af7f-8014ab71dd8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1401 entries, 2017-08-28 00:19:00 to 2017-08-28 23:39:00\n",
            "Data columns (total 81 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   1       1401 non-null   float64\n",
            " 1   2       1401 non-null   float64\n",
            " 2   3       1401 non-null   float64\n",
            " 3   4       1401 non-null   float64\n",
            " 4   5       1401 non-null   float64\n",
            " 5   6       1401 non-null   float64\n",
            " 6   7       1401 non-null   float64\n",
            " 7   8       1401 non-null   float64\n",
            " 8   9       1401 non-null   float64\n",
            " 9   10      1401 non-null   float64\n",
            " 10  11      1401 non-null   float64\n",
            " 11  12      1401 non-null   float64\n",
            " 12  13      1401 non-null   float64\n",
            " 13  14      1401 non-null   float64\n",
            " 14  15      1401 non-null   float64\n",
            " 15  16      1401 non-null   float64\n",
            " 16  17      1401 non-null   float64\n",
            " 17  18      1401 non-null   float64\n",
            " 18  19      1401 non-null   float64\n",
            " 19  20      1401 non-null   float64\n",
            " 20  21      1401 non-null   float64\n",
            " 21  22      1401 non-null   float64\n",
            " 22  23      1401 non-null   float64\n",
            " 23  24      1401 non-null   float64\n",
            " 24  25      1401 non-null   float64\n",
            " 25  26      1401 non-null   float64\n",
            " 26  27      1401 non-null   float64\n",
            " 27  28      1401 non-null   float64\n",
            " 28  29      1401 non-null   float64\n",
            " 29  30      1401 non-null   float64\n",
            " 30  31      1401 non-null   float64\n",
            " 31  32      1401 non-null   float64\n",
            " 32  33      1401 non-null   float64\n",
            " 33  34      1401 non-null   float64\n",
            " 34  35      1401 non-null   float64\n",
            " 35  36      1401 non-null   float64\n",
            " 36  37      1401 non-null   float64\n",
            " 37  38      1401 non-null   float64\n",
            " 38  39      1401 non-null   float64\n",
            " 39  40      1401 non-null   float64\n",
            " 40  41      1401 non-null   float64\n",
            " 41  42      1401 non-null   float64\n",
            " 42  43      1401 non-null   float64\n",
            " 43  44      1401 non-null   float64\n",
            " 44  45      1401 non-null   float64\n",
            " 45  46      1401 non-null   float64\n",
            " 46  47      1401 non-null   float64\n",
            " 47  48      1401 non-null   float64\n",
            " 48  49      1401 non-null   float64\n",
            " 49  50      1401 non-null   float64\n",
            " 50  51      1401 non-null   float64\n",
            " 51  52      1401 non-null   float64\n",
            " 52  53      1401 non-null   float64\n",
            " 53  54      1401 non-null   float64\n",
            " 54  55      1401 non-null   float64\n",
            " 55  56      1401 non-null   float64\n",
            " 56  57      1401 non-null   float64\n",
            " 57  58      1401 non-null   float64\n",
            " 58  59      1401 non-null   float64\n",
            " 59  60      1401 non-null   float64\n",
            " 60  61      1401 non-null   float64\n",
            " 61  62      1401 non-null   float64\n",
            " 62  63      1401 non-null   float64\n",
            " 63  64      1401 non-null   float64\n",
            " 64  65      1401 non-null   float64\n",
            " 65  66      1401 non-null   float64\n",
            " 66  67      1401 non-null   float64\n",
            " 67  68      1401 non-null   float64\n",
            " 68  69      1401 non-null   float64\n",
            " 69  70      1401 non-null   float64\n",
            " 70  71      1401 non-null   float64\n",
            " 71  72      1401 non-null   float64\n",
            " 72  73      1401 non-null   float64\n",
            " 73  74      1401 non-null   float64\n",
            " 74  75      1401 non-null   float64\n",
            " 75  76      1401 non-null   float64\n",
            " 76  77      1401 non-null   float64\n",
            " 77  78      1401 non-null   float64\n",
            " 78  79      1401 non-null   float64\n",
            " 79  80      1401 non-null   float64\n",
            " 80  Accion  1401 non-null   float64\n",
            "dtypes: float64(81)\n",
            "memory usage: 897.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df_aux1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY1jqm_Fd7nE"
      },
      "source": [
        "### Red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "DzEnkBbvJLIj",
        "outputId": "768d8eed-55e5-47f2-b3f9-f646c493ff8a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_aux1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d3c27265dc1b>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Dividir el conjunto de datos en características (X) y variable de salida (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_aux1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_aux1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_aux1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_aux1' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar tus datos, asumiendo que 'df' es tu DataFrame\n",
        "# Asegúrate de que tu DataFrame tenga una columna llamada 'target' para la variable de salida\n",
        "# y otras características necesarias.\n",
        "# Puedes ajustar esto según tu conjunto de datos real.\n",
        "\n",
        "# Supongamos que tienes un DataFrame 'df' con características y una columna 'target' para la variable de salida.\n",
        "# Asegúrate de ajustar esto según tus datos reales.\n",
        "\n",
        "# Ejemplo de cómo cargar datos:\n",
        "# df = pd.read_csv('tu_archivo.csv')\n",
        "\n",
        "# Dividir el conjunto de datos en características (X) y variable de salida (y)\n",
        "X = df_aux1.drop('Accion', axis=1)\n",
        "y = df_aux1[df_aux1.columns[:-1]]\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Construir el modelo de red neuronal en TensorFlow\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(80,)),  # Capa de entrada con 80 neuronas\n",
        "    tf.keras.layers.Dense(60, activation='relu'),   # Capa oculta con 60 neuronas y activación ReLU\n",
        "    tf.keras.layers.Dense(1)                        # Capa de salida con 1 neurona para problemas de regresión\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Loss en el conjunto de prueba: {loss}')\n",
        "print(f'MAE en el conjunto de prueba: {mae}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "xDfKcAXSruTB",
        "outputId": "9e9376c9-fc3d-4ba5-e3cc-24b01ce05fcc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x1200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comienza simulacion con 142.95 USD\n",
            "Finaliza simulacion con 142.95 USD\n",
            "142.95\n"
          ]
        }
      ],
      "source": [
        "# Filtrar las compras y ventas\n",
        "compras = df_final[df_final['Accion'] == 'C']\n",
        "ventas  = df_final[df_final['Accion'] == 'V']\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "plt.plot(df_final['Open'], color='lightgray', label='Precio')\n",
        "plt.scatter(compras.index, compras['Open'], color='green', marker='^', label='Compra')\n",
        "plt.scatter(ventas.index, ventas['Open'], color='red', marker='v', label='Venta')\n",
        "\n",
        "# Configuración adicional\n",
        "plt.xlabel('Precio')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Histograma de Compras y Ventas')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el histograma\n",
        "plt.show()\n",
        "\n",
        "print(simulacion(df_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ebDEhnMBq6",
        "outputId": "1f20efe9-826f-47ae-ca7f-042704783384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "lista = model.predict(df_aux1.drop('Accion', axis = 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCCaH2x6MpFQ"
      },
      "outputs": [],
      "source": [
        "lista = [i[0] for i in lista.tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "WoivexbJPs-Z",
        "outputId": "8a57b95a-4c97-4e94-9573-68ca55209e6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fb18ff01-cf93-461f-9d24-cff8cd61b043\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1401.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.489939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.005884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.469862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.486825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.490776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.493937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.500109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb18ff01-cf93-461f-9d24-cff8cd61b043')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb18ff01-cf93-461f-9d24-cff8cd61b043 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb18ff01-cf93-461f-9d24-cff8cd61b043');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88ae9715-c6a6-457f-94cb-d5a556e7f93c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88ae9715-c6a6-457f-94cb-d5a556e7f93c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88ae9715-c6a6-457f-94cb-d5a556e7f93c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 0\n",
              "count  1401.000000\n",
              "mean      0.489939\n",
              "std       0.005884\n",
              "min       0.469862\n",
              "25%       0.486825\n",
              "50%       0.490776\n",
              "75%       0.493937\n",
              "max       0.500109"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(lista).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEZyr-G7Odu7"
      },
      "outputs": [],
      "source": [
        "lista2 = []\n",
        "for i in range(18):\n",
        "  lista2.append(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_jAmzxsOVbK"
      },
      "outputs": [],
      "source": [
        "lista.append()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW4EvxA1N-KF"
      },
      "outputs": [],
      "source": [
        "df_final['Accion'] = lista2+lista+lista2+[0.5,0.5,0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "-r6CKbJgPEHI",
        "outputId": "35135632-5d64-437c-8ad4-cff36c8ed96c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x1200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comienza simulacion con 142.95 USD\n",
            "Finaliza simulacion con 142.95 USD\n",
            "142.95\n"
          ]
        }
      ],
      "source": [
        "# Filtrar las compras y ventas\n",
        "compras = df_final[df_final['Accion'] < 0.484825]\n",
        "ventas  = df_final[df_final['Accion'] > 0.495937]\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "plt.plot(df_final['Open'], color='lightgray', label='Precio')\n",
        "plt.scatter(compras.index, compras['Open'], color='green', marker='^', label='Compra')\n",
        "plt.scatter(ventas.index, ventas['Open'], color='red', marker='v', label='Venta')\n",
        "\n",
        "# Configuración adicional\n",
        "plt.xlabel('Precio')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Histograma de Compras y Ventas')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el histograma\n",
        "plt.show()\n",
        "\n",
        "print(simulacion(df_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "YauxtYgkQ5Bq",
        "outputId": "0651e12f-b2f3-43c0-8265-b93ea50bd098"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0efc14ee-e166-40d0-8e85-d5ed286281c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Accion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-27 00:00:00</th>\n",
              "      <td>4368.10</td>\n",
              "      <td>4368.10</td>\n",
              "      <td>4368.10</td>\n",
              "      <td>4368.10</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-27 00:01:00</th>\n",
              "      <td>4379.24</td>\n",
              "      <td>4379.24</td>\n",
              "      <td>4379.24</td>\n",
              "      <td>4379.24</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-27 00:02:00</th>\n",
              "      <td>4373.50</td>\n",
              "      <td>4373.50</td>\n",
              "      <td>4372.00</td>\n",
              "      <td>4372.00</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-27 00:03:00</th>\n",
              "      <td>4358.79</td>\n",
              "      <td>4358.79</td>\n",
              "      <td>4342.58</td>\n",
              "      <td>4342.58</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-27 00:04:00</th>\n",
              "      <td>4355.80</td>\n",
              "      <td>4375.00</td>\n",
              "      <td>4355.80</td>\n",
              "      <td>4375.00</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0efc14ee-e166-40d0-8e85-d5ed286281c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0efc14ee-e166-40d0-8e85-d5ed286281c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0efc14ee-e166-40d0-8e85-d5ed286281c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-607bac20-f35e-4934-b7d2-52ce836254d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-607bac20-f35e-4934-b7d2-52ce836254d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-607bac20-f35e-4934-b7d2-52ce836254d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                        Open     High      Low    Close  Accion\n",
              "Time                                                           \n",
              "2017-08-27 00:00:00  4368.10  4368.10  4368.10  4368.10     0.5\n",
              "2017-08-27 00:01:00  4379.24  4379.24  4379.24  4379.24     0.5\n",
              "2017-08-27 00:02:00  4373.50  4373.50  4372.00  4372.00     0.5\n",
              "2017-08-27 00:03:00  4358.79  4358.79  4342.58  4342.58     0.5\n",
              "2017-08-27 00:04:00  4355.80  4375.00  4355.80  4375.00     0.5"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iic3zc8Y5auM"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11-At7O4S2H8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78dc81f2-7163-4a67-906a-8944c68b024c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "# First we will import the necessary Library\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For Evalution we will use these library\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# For model building we will use these library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "# For PLotting we will use these library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(5))\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalizar(df,1)"
      ],
      "metadata": {
        "id": "uiFcDHrcp66N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2f3a4843-dce3-4ccf-a2e6-05f084c8dbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'normalizar' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f49849b5b0b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalizar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'normalizar' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "5xlg-z0MSJhl",
        "outputId": "731292ee-24de-4354-c7be-9a02952d5ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Close\n",
              "Time                         \n",
              "2017-08-19 00:00:00  0.501438\n",
              "2017-08-19 00:01:00  0.501438\n",
              "2017-08-19 00:02:00  0.501438\n",
              "2017-08-19 00:03:00  0.501438\n",
              "2017-08-19 00:04:00  0.501438\n",
              "2017-08-19 00:05:00  0.528718\n",
              "2017-08-19 00:06:00  0.515072\n",
              "2017-08-19 00:07:00  0.501438\n",
              "2017-08-19 00:08:00  0.501438\n",
              "2017-08-19 00:09:00  0.501438"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-343ac773-cc20-4998-b318-1feecf540c7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:00:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:01:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:02:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:03:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:04:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:05:00</th>\n",
              "      <td>0.528718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:06:00</th>\n",
              "      <td>0.515072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:07:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:08:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:09:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-343ac773-cc20-4998-b318-1feecf540c7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-343ac773-cc20-4998-b318-1feecf540c7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-343ac773-cc20-4998-b318-1feecf540c7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b00ac6ab-2b2c-406b-9f9b-c16fea6e65a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b00ac6ab-2b2c-406b-9f9b-c16fea6e65a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b00ac6ab-2b2c-406b-9f9b-c16fea6e65a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_normal[['Close']][0:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009205305238861004,\n        \"min\": 0.5014384748700175,\n        \"max\": 0.5287175043327554,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5014384748700175,\n          0.5287175043327554,\n          0.5150722125938756\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df_normal[['Close']][0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqW1431F6BBA",
        "outputId": "9688d742-6a3a-429b-8bca-76b5fcef2a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n"
          ]
        }
      ],
      "source": [
        "training_size = int(len(df_normal.Open)*0.60)\n",
        "test_size=len(df_normal.Open)-training_size\n",
        "train_data,test_data=df_normal[['Close']][0:training_size],df_normal[['Close']][training_size:]\n",
        "print(\"train_data: \", train_data.shape)\n",
        "print(\"test_data: \", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "D_Mkr7XzWEng",
        "outputId": "147334ac-f100-4ffe-c712-a933ef190ff4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Close\n",
              "Time                         \n",
              "2017-08-19 00:00:00  0.501438\n",
              "2017-08-19 00:01:00  0.501438\n",
              "2017-08-19 00:02:00  0.501438\n",
              "2017-08-19 00:03:00  0.501438\n",
              "2017-08-19 00:04:00  0.501438"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24c81719-52ab-4b62-ba9f-e77510fb13a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:00:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:01:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:02:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:03:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:04:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24c81719-52ab-4b62-ba9f-e77510fb13a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24c81719-52ab-4b62-ba9f-e77510fb13a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24c81719-52ab-4b62-ba9f-e77510fb13a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9718a5ea-c8d3-42e2-9b5a-0aab13c06a73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9718a5ea-c8d3-42e2-9b5a-0aab13c06a73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9718a5ea-c8d3-42e2-9b5a-0aab13c06a73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 864,\n  \"fields\": [\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06331640944049542,\n        \"min\": 0.1474350086655114,\n        \"max\": 0.5287175043327554,\n        \"num_unique_values\": 205,\n        \"samples\": [\n          0.48082611207394566,\n          0.44035239745811705,\n          0.32141536683997673\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B63fDjFhhmL"
      },
      "outputs": [],
      "source": [
        "scaler=MinMaxScaler(feature_range=(0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYIsWvBhP5f",
        "outputId": "b7f84296-0a4b-414c-b6bb-5f9d9e6ffd41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(864, 1)\n"
          ]
        }
      ],
      "source": [
        "train_data=scaler.fit_transform(np.array(train_data).reshape(-1,1))\n",
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLnrHqmCh9Jz",
        "outputId": "9135aa00-79c0-4986-928f-370d8a64ac2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(576, 1)\n"
          ]
        }
      ],
      "source": [
        "test_data=scaler.fit_transform(np.array(test_data).reshape(-1,1))\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX_yLWPPSjGT"
      },
      "outputs": [],
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "\n",
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-time_step-1):\n",
        "        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + time_step, 0])\n",
        "\n",
        "    dataY2 = []\n",
        "    for i in range(len(dataY)-5):\n",
        "      dataY2.append(dataY[i:i+5])\n",
        "\n",
        "    #return np.array(dataX), np.array(dataY)\n",
        "    return np.array(dataX[:-5]), np.array(dataY2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL7QbuYgUEyH",
        "outputId": "6cf069e8-b225-497e-ba8c-d2294a54f99f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n"
          ]
        }
      ],
      "source": [
        "time_step = 15\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8ipxp_bT3HU"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(5))\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu6GLB7XT7ZN",
        "outputId": "6641add5-73cc-4df7-ea81-8cfe5160a43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "27/27 [==============================] - 2s 27ms/step - loss: 0.2576 - val_loss: 0.2453\n",
            "Epoch 2/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.1171 - val_loss: 0.0859\n",
            "Epoch 3/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0287 - val_loss: 0.0195\n",
            "Epoch 4/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0134\n",
            "Epoch 5/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0127\n",
            "Epoch 6/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0122\n",
            "Epoch 7/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0121\n",
            "Epoch 8/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0119\n",
            "Epoch 9/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0118\n",
            "Epoch 10/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0117\n",
            "Epoch 11/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0116\n",
            "Epoch 12/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0116\n",
            "Epoch 13/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0114\n",
            "Epoch 14/200\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0114\n",
            "Epoch 15/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0114\n",
            "Epoch 16/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0113\n",
            "Epoch 17/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0114\n",
            "Epoch 18/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0114\n",
            "Epoch 19/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0112\n",
            "Epoch 20/200\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0113\n",
            "Epoch 21/200\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0051 - val_loss: 0.0113\n",
            "Epoch 22/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0110\n",
            "Epoch 23/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0110\n",
            "Epoch 24/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0112\n",
            "Epoch 25/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0109\n",
            "Epoch 26/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0108\n",
            "Epoch 27/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0108\n",
            "Epoch 28/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0112\n",
            "Epoch 29/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0107\n",
            "Epoch 30/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0107\n",
            "Epoch 31/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0106\n",
            "Epoch 32/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0107\n",
            "Epoch 33/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0107\n",
            "Epoch 34/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0106\n",
            "Epoch 35/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0104\n",
            "Epoch 36/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0103\n",
            "Epoch 37/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0104\n",
            "Epoch 38/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0103\n",
            "Epoch 39/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0102\n",
            "Epoch 40/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0104\n",
            "Epoch 41/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0107\n",
            "Epoch 42/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0103\n",
            "Epoch 43/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0100\n",
            "Epoch 44/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0100\n",
            "Epoch 45/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0099\n",
            "Epoch 46/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0098\n",
            "Epoch 47/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0098\n",
            "Epoch 48/200\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0101\n",
            "Epoch 49/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0097\n",
            "Epoch 50/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0097\n",
            "Epoch 51/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0096\n",
            "Epoch 52/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.0098\n",
            "Epoch 53/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0095\n",
            "Epoch 54/200\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0095\n",
            "Epoch 55/200\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0094\n",
            "Epoch 56/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0094\n",
            "Epoch 57/200\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0093\n",
            "Epoch 58/200\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0095\n",
            "Epoch 59/200\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0092\n",
            "Epoch 60/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0091\n",
            "Epoch 61/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0094\n",
            "Epoch 62/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0092\n",
            "Epoch 63/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0092\n",
            "Epoch 64/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0090\n",
            "Epoch 65/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0089\n",
            "Epoch 66/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0089\n",
            "Epoch 67/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0090\n",
            "Epoch 68/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0087\n",
            "Epoch 69/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0087\n",
            "Epoch 70/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0088\n",
            "Epoch 71/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0086\n",
            "Epoch 72/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0085\n",
            "Epoch 73/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0086\n",
            "Epoch 74/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0085\n",
            "Epoch 75/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0084\n",
            "Epoch 76/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0087\n",
            "Epoch 77/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0083\n",
            "Epoch 78/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0084\n",
            "Epoch 79/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0082\n",
            "Epoch 80/200\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0083\n",
            "Epoch 81/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0082\n",
            "Epoch 82/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0082\n",
            "Epoch 83/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0082\n",
            "Epoch 84/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0081\n",
            "Epoch 85/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0084\n",
            "Epoch 86/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0081\n",
            "Epoch 87/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0080\n",
            "Epoch 88/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0081\n",
            "Epoch 89/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0081\n",
            "Epoch 90/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0079\n",
            "Epoch 91/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0080\n",
            "Epoch 92/200\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0079\n",
            "Epoch 93/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0079\n",
            "Epoch 94/200\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0079\n",
            "Epoch 95/200\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0084\n",
            "Epoch 96/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0041 - val_loss: 0.0078\n",
            "Epoch 97/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0078\n",
            "Epoch 98/200\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0040 - val_loss: 0.0080\n",
            "Epoch 99/200\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0040 - val_loss: 0.0082\n",
            "Epoch 100/200\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.0040 - val_loss: 0.0078\n",
            "Epoch 101/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0079\n",
            "Epoch 102/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0078\n",
            "Epoch 103/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0077\n",
            "Epoch 104/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0079\n",
            "Epoch 105/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0078\n",
            "Epoch 106/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0077\n",
            "Epoch 107/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0078\n",
            "Epoch 108/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0079\n",
            "Epoch 109/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0077\n",
            "Epoch 110/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0077\n",
            "Epoch 111/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0077\n",
            "Epoch 112/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0079\n",
            "Epoch 113/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0079\n",
            "Epoch 114/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0076\n",
            "Epoch 115/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0076\n",
            "Epoch 116/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0075\n",
            "Epoch 117/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0078\n",
            "Epoch 118/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0077\n",
            "Epoch 119/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0079\n",
            "Epoch 120/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0076\n",
            "Epoch 121/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0077\n",
            "Epoch 122/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0076\n",
            "Epoch 123/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0076\n",
            "Epoch 124/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0075\n",
            "Epoch 125/200\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0075\n",
            "Epoch 126/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0075\n",
            "Epoch 127/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0076\n",
            "Epoch 128/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0076\n",
            "Epoch 129/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 130/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0075\n",
            "Epoch 131/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0079\n",
            "Epoch 132/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 133/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0038 - val_loss: 0.0076\n",
            "Epoch 134/200\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 135/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 136/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0079\n",
            "Epoch 137/200\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0075\n",
            "Epoch 138/200\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 139/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 140/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0077\n",
            "Epoch 141/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0079\n",
            "Epoch 142/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0073\n",
            "Epoch 143/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 144/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 145/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 146/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 147/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 148/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0073\n",
            "Epoch 149/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 150/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 151/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 152/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 153/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 154/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 155/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 156/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 157/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 158/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0073\n",
            "Epoch 159/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0075\n",
            "Epoch 160/200\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0071\n",
            "Epoch 161/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 162/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 163/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0073\n",
            "Epoch 164/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 165/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 166/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 167/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 168/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 169/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0070\n",
            "Epoch 170/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 171/200\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 172/200\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 173/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 174/200\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 175/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 176/200\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0072\n",
            "Epoch 177/200\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 178/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 179/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 180/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0070\n",
            "Epoch 181/200\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 182/200\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 183/200\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.0036 - val_loss: 0.0072\n",
            "Epoch 184/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 185/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 186/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0072\n",
            "Epoch 187/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 188/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 189/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 190/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 191/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 192/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 193/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 194/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0075\n",
            "Epoch 195/200\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0070\n",
            "Epoch 196/200\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 197/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 198/200\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 199/200\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 200/200\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0070\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=30,batch_size=32,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "Bb4H0jGBiPLh",
        "outputId": "fc4554f6-cc78-45ec-e7fa-856472cde3dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWHebwW9iQga",
        "outputId": "626bc753-ef2e-40a3-9da8-6b07471ca59c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 4ms/step\n",
            "18/18 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((843, 5), (555, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)\n",
        "train_predict.shape, test_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [train_predict[i][4] for i in range(len(train_predict))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "train_predict = np.array(lista2)"
      ],
      "metadata": {
        "id": "wc9V_jLyYLj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [test_predict[i][4] for i in range(len(test_predict))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "test_predict = np.array(lista2)"
      ],
      "metadata": {
        "id": "nmHkpADwbp60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [y_train[i][4] for i in range(len(y_train))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "y_train = np.array(lista2)"
      ],
      "metadata": {
        "id": "aFdTNN-QijA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [y_test[i][4] for i in range(len(y_test))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "y_test = np.array(lista2)"
      ],
      "metadata": {
        "id": "6mGNzNutimmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict.shape, test_predict.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUavQQVhiUfy",
        "outputId": "ade3c052-e7f2-453e-d67d-1a3f8cbd1a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((843, 1), (555, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwJ5IXiWi1W3"
      },
      "outputs": [],
      "source": [
        "# Transform back to original form\n",
        "\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1))\n",
        "original_ytest = scaler.inverse_transform(y_test.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suEx33WNi4px",
        "outputId": "28028e7a-62f9-4cd0-faff-a3a082fd3df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data RMSE:  0.012104921391724836\n",
            "Train data MSE:  0.00014652912189983756\n",
            "Train data MAE:  0.008582752398558114\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.017037829655800838\n",
            "Test data MSE:  0.0002902876393800865\n",
            "Test data MAE:  0.010859940325736974\n"
          ]
        }
      ],
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_ytest,test_predict)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_ytest,test_predict))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_ytest,test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hMgDbx1i9tU",
        "outputId": "dff935b0-81b4-4b22-ee1f-b48257960504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data explained variance regression score: 0.8059813174760692\n",
            "Test data explained variance regression score: 0.7973598908567816\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"Train data explained variance regression score:\",\n",
        "      explained_variance_score(original_ytrain, train_predict))\n",
        "print(\"Test data explained variance regression score:\",\n",
        "      explained_variance_score(original_ytest, test_predict))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "tvH4Ji6njYlc",
        "outputId": "711b97c0-2380-44fe-b0a2-ac7761e6e534"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Close\n",
              "Time                         \n",
              "2017-08-19 00:00:00  0.501438\n",
              "2017-08-19 00:01:00  0.501438\n",
              "2017-08-19 00:02:00  0.501438\n",
              "2017-08-19 00:03:00  0.501438\n",
              "2017-08-19 00:04:00  0.501438"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a527ddd4-fa4f-4671-9d0f-f6fcd70b1bb2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:00:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:01:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:02:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:03:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:04:00</th>\n",
              "      <td>0.501438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a527ddd4-fa4f-4671-9d0f-f6fcd70b1bb2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a527ddd4-fa4f-4671-9d0f-f6fcd70b1bb2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a527ddd4-fa4f-4671-9d0f-f6fcd70b1bb2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf28f32d-496f-4105-b5e2-968be1c01524\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf28f32d-496f-4105-b5e2-968be1c01524')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf28f32d-496f-4105-b5e2-968be1c01524 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "closedf",
              "summary": "{\n  \"name\": \"closedf\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06268215421479532,\n        \"min\": 0.1474350086655114,\n        \"max\": 0.5287175043327554,\n        \"num_unique_values\": 259,\n        \"samples\": [\n          0.3197515886770651,\n          0.4131773541305602,\n          0.44035239745811705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "closedf = df_normal[['Close']].copy(deep=True)\n",
        "closedf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ19aiH9jdo7",
        "outputId": "40133337-d265-43ec-d05e-2954a375d4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1440, 1)\n"
          ]
        }
      ],
      "source": [
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "closedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))\n",
        "print(closedf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y0pEPQ02YYD",
        "outputId": "95796368-accc-41e2-c08b-5840bbb2fe75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92845455],\n",
              "       [0.92845455],\n",
              "       [0.92845455],\n",
              "       ...,\n",
              "       [0.83239394],\n",
              "       [0.83239394],\n",
              "       [0.83239394]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "closedf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w8vxjgAZh0V",
        "outputId": "f5c8ca77-68bf-4dce-94ba-ea66bd3fbfb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(843, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAhQDKIgb7mc",
        "outputId": "0abace35-b43a-4f3e-e991-c0cf8ce997ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(555, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "9aBj2g6OjESO",
        "outputId": "e5d7226f-f1ad-4faa-c905-d280d353c583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train predicted data:  (1440, 1)\n",
            "Test predicted data:  (1440, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"bf3d5138-9ba9-4118-829d-30a9a54803c7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bf3d5138-9ba9-4118-829d-30a9a54803c7\")) {                    Plotly.newPlot(                        \"bf3d5138-9ba9-4118-829d-30a9a54803c7\",                        [{\"hovertemplate\":\"variable=original_close\\u003cbr\\u003eDate=%{x}\\u003cbr\\u003eStock price=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"original_close\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Original close price\",\"showlegend\":true,\"x\":[\"2017-08-19 00:00:00\",\"2017-08-19 00:01:00\",\"2017-08-19 00:02:00\",\"2017-08-19 00:03:00\",\"2017-08-19 00:04:00\",\"2017-08-19 00:05:00\",\"2017-08-19 00:06:00\",\"2017-08-19 00:07:00\",\"2017-08-19 00:08:00\",\"2017-08-19 00:09:00\",\"2017-08-19 00:10:00\",\"2017-08-19 00:11:00\",\"2017-08-19 00:12:00\",\"2017-08-19 00:13:00\",\"2017-08-19 00:14:00\",\"2017-08-19 00:15:00\",\"2017-08-19 00:16:00\",\"2017-08-19 00:17:00\",\"2017-08-19 00:18:00\",\"2017-08-19 00:19:00\",\"2017-08-19 00:20:00\",\"2017-08-19 00:21:00\",\"2017-08-19 00:22:00\",\"2017-08-19 00:23:00\",\"2017-08-19 00:24:00\",\"2017-08-19 00:25:00\",\"2017-08-19 00:26:00\",\"2017-08-19 00:27:00\",\"2017-08-19 00:28:00\",\"2017-08-19 00:29:00\",\"2017-08-19 00:30:00\",\"2017-08-19 00:31:00\",\"2017-08-19 00:32:00\",\"2017-08-19 00:33:00\",\"2017-08-19 00:34:00\",\"2017-08-19 00:35:00\",\"2017-08-19 00:36:00\",\"2017-08-19 00:37:00\",\"2017-08-19 00:38:00\",\"2017-08-19 00:39:00\",\"2017-08-19 00:40:00\",\"2017-08-19 00:41:00\",\"2017-08-19 00:42:00\",\"2017-08-19 00:43:00\",\"2017-08-19 00:44:00\",\"2017-08-19 00:45:00\",\"2017-08-19 00:46:00\",\"2017-08-19 00:47:00\",\"2017-08-19 00:48:00\",\"2017-08-19 00:49:00\",\"2017-08-19 00:50:00\",\"2017-08-19 00:51:00\",\"2017-08-19 00:52:00\",\"2017-08-19 00:53:00\",\"2017-08-19 00:54:00\",\"2017-08-19 00:55:00\",\"2017-08-19 00:56:00\",\"2017-08-19 00:57:00\",\"2017-08-19 00:58:00\",\"2017-08-19 00:59:00\",\"2017-08-19 01:00:00\",\"2017-08-19 01:01:00\",\"2017-08-19 01:02:00\",\"2017-08-19 01:03:00\",\"2017-08-19 01:04:00\",\"2017-08-19 01:05:00\",\"2017-08-19 01:06:00\",\"2017-08-19 01:07:00\",\"2017-08-19 01:08:00\",\"2017-08-19 01:09:00\",\"2017-08-19 01:10:00\",\"2017-08-19 01:11:00\",\"2017-08-19 01:12:00\",\"2017-08-19 01:13:00\",\"2017-08-19 01:14:00\",\"2017-08-19 01:15:00\",\"2017-08-19 01:16:00\",\"2017-08-19 01:17:00\",\"2017-08-19 01:18:00\",\"2017-08-19 01:19:00\",\"2017-08-19 01:20:00\",\"2017-08-19 01:21:00\",\"2017-08-19 01:22:00\",\"2017-08-19 01:23:00\",\"2017-08-19 01:24:00\",\"2017-08-19 01:25:00\",\"2017-08-19 01:26:00\",\"2017-08-19 01:27:00\",\"2017-08-19 01:28:00\",\"2017-08-19 01:29:00\",\"2017-08-19 01:30:00\",\"2017-08-19 01:31:00\",\"2017-08-19 01:32:00\",\"2017-08-19 01:33:00\",\"2017-08-19 01:34:00\",\"2017-08-19 01:35:00\",\"2017-08-19 01:36:00\",\"2017-08-19 01:37:00\",\"2017-08-19 01:38:00\",\"2017-08-19 01:39:00\",\"2017-08-19 01:40:00\",\"2017-08-19 01:41:00\",\"2017-08-19 01:42:00\",\"2017-08-19 01:43:00\",\"2017-08-19 01:44:00\",\"2017-08-19 01:45:00\",\"2017-08-19 01:46:00\",\"2017-08-19 01:47:00\",\"2017-08-19 01:48:00\",\"2017-08-19 01:49:00\",\"2017-08-19 01:50:00\",\"2017-08-19 01:51:00\",\"2017-08-19 01:52:00\",\"2017-08-19 01:53:00\",\"2017-08-19 01:54:00\",\"2017-08-19 01:55:00\",\"2017-08-19 01:56:00\",\"2017-08-19 01:57:00\",\"2017-08-19 01:58:00\",\"2017-08-19 01:59:00\",\"2017-08-19 02:00:00\",\"2017-08-19 02:01:00\",\"2017-08-19 02:02:00\",\"2017-08-19 02:03:00\",\"2017-08-19 02:04:00\",\"2017-08-19 02:05:00\",\"2017-08-19 02:06:00\",\"2017-08-19 02:07:00\",\"2017-08-19 02:08:00\",\"2017-08-19 02:09:00\",\"2017-08-19 02:10:00\",\"2017-08-19 02:11:00\",\"2017-08-19 02:12:00\",\"2017-08-19 02:13:00\",\"2017-08-19 02:14:00\",\"2017-08-19 02:15:00\",\"2017-08-19 02:16:00\",\"2017-08-19 02:17:00\",\"2017-08-19 02:18:00\",\"2017-08-19 02:19:00\",\"2017-08-19 02:20:00\",\"2017-08-19 02:21:00\",\"2017-08-19 02:22:00\",\"2017-08-19 02:23:00\",\"2017-08-19 02:24:00\",\"2017-08-19 02:25:00\",\"2017-08-19 02:26:00\",\"2017-08-19 02:27:00\",\"2017-08-19 02:28:00\",\"2017-08-19 02:29:00\",\"2017-08-19 02:30:00\",\"2017-08-19 02:31:00\",\"2017-08-19 02:32:00\",\"2017-08-19 02:33:00\",\"2017-08-19 02:34:00\",\"2017-08-19 02:35:00\",\"2017-08-19 02:36:00\",\"2017-08-19 02:37:00\",\"2017-08-19 02:38:00\",\"2017-08-19 02:39:00\",\"2017-08-19 02:40:00\",\"2017-08-19 02:41:00\",\"2017-08-19 02:42:00\",\"2017-08-19 02:43:00\",\"2017-08-19 02:44:00\",\"2017-08-19 02:45:00\",\"2017-08-19 02:46:00\",\"2017-08-19 02:47:00\",\"2017-08-19 02:48:00\",\"2017-08-19 02:49:00\",\"2017-08-19 02:50:00\",\"2017-08-19 02:51:00\",\"2017-08-19 02:52:00\",\"2017-08-19 02:53:00\",\"2017-08-19 02:54:00\",\"2017-08-19 02:55:00\",\"2017-08-19 02:56:00\",\"2017-08-19 02:57:00\",\"2017-08-19 02:58:00\",\"2017-08-19 02:59:00\",\"2017-08-19 03:00:00\",\"2017-08-19 03:01:00\",\"2017-08-19 03:02:00\",\"2017-08-19 03:03:00\",\"2017-08-19 03:04:00\",\"2017-08-19 03:05:00\",\"2017-08-19 03:06:00\",\"2017-08-19 03:07:00\",\"2017-08-19 03:08:00\",\"2017-08-19 03:09:00\",\"2017-08-19 03:10:00\",\"2017-08-19 03:11:00\",\"2017-08-19 03:12:00\",\"2017-08-19 03:13:00\",\"2017-08-19 03:14:00\",\"2017-08-19 03:15:00\",\"2017-08-19 03:16:00\",\"2017-08-19 03:17:00\",\"2017-08-19 03:18:00\",\"2017-08-19 03:19:00\",\"2017-08-19 03:20:00\",\"2017-08-19 03:21:00\",\"2017-08-19 03:22:00\",\"2017-08-19 03:23:00\",\"2017-08-19 03:24:00\",\"2017-08-19 03:25:00\",\"2017-08-19 03:26:00\",\"2017-08-19 03:27:00\",\"2017-08-19 03:28:00\",\"2017-08-19 03:29:00\",\"2017-08-19 03:30:00\",\"2017-08-19 03:31:00\",\"2017-08-19 03:32:00\",\"2017-08-19 03:33:00\",\"2017-08-19 03:34:00\",\"2017-08-19 03:35:00\",\"2017-08-19 03:36:00\",\"2017-08-19 03:37:00\",\"2017-08-19 03:38:00\",\"2017-08-19 03:39:00\",\"2017-08-19 03:40:00\",\"2017-08-19 03:41:00\",\"2017-08-19 03:42:00\",\"2017-08-19 03:43:00\",\"2017-08-19 03:44:00\",\"2017-08-19 03:45:00\",\"2017-08-19 03:46:00\",\"2017-08-19 03:47:00\",\"2017-08-19 03:48:00\",\"2017-08-19 03:49:00\",\"2017-08-19 03:50:00\",\"2017-08-19 03:51:00\",\"2017-08-19 03:52:00\",\"2017-08-19 03:53:00\",\"2017-08-19 03:54:00\",\"2017-08-19 03:55:00\",\"2017-08-19 03:56:00\",\"2017-08-19 03:57:00\",\"2017-08-19 03:58:00\",\"2017-08-19 03:59:00\",\"2017-08-19 04:00:00\",\"2017-08-19 04:01:00\",\"2017-08-19 04:02:00\",\"2017-08-19 04:03:00\",\"2017-08-19 04:04:00\",\"2017-08-19 04:05:00\",\"2017-08-19 04:06:00\",\"2017-08-19 04:07:00\",\"2017-08-19 04:08:00\",\"2017-08-19 04:09:00\",\"2017-08-19 04:10:00\",\"2017-08-19 04:11:00\",\"2017-08-19 04:12:00\",\"2017-08-19 04:13:00\",\"2017-08-19 04:14:00\",\"2017-08-19 04:15:00\",\"2017-08-19 04:16:00\",\"2017-08-19 04:17:00\",\"2017-08-19 04:18:00\",\"2017-08-19 04:19:00\",\"2017-08-19 04:20:00\",\"2017-08-19 04:21:00\",\"2017-08-19 04:22:00\",\"2017-08-19 04:23:00\",\"2017-08-19 04:24:00\",\"2017-08-19 04:25:00\",\"2017-08-19 04:26:00\",\"2017-08-19 04:27:00\",\"2017-08-19 04:28:00\",\"2017-08-19 04:29:00\",\"2017-08-19 04:30:00\",\"2017-08-19 04:31:00\",\"2017-08-19 04:32:00\",\"2017-08-19 04:33:00\",\"2017-08-19 04:34:00\",\"2017-08-19 04:35:00\",\"2017-08-19 04:36:00\",\"2017-08-19 04:37:00\",\"2017-08-19 04:38:00\",\"2017-08-19 04:39:00\",\"2017-08-19 04:40:00\",\"2017-08-19 04:41:00\",\"2017-08-19 04:42:00\",\"2017-08-19 04:43:00\",\"2017-08-19 04:44:00\",\"2017-08-19 04:45:00\",\"2017-08-19 04:46:00\",\"2017-08-19 04:47:00\",\"2017-08-19 04:48:00\",\"2017-08-19 04:49:00\",\"2017-08-19 04:50:00\",\"2017-08-19 04:51:00\",\"2017-08-19 04:52:00\",\"2017-08-19 04:53:00\",\"2017-08-19 04:54:00\",\"2017-08-19 04:55:00\",\"2017-08-19 04:56:00\",\"2017-08-19 04:57:00\",\"2017-08-19 04:58:00\",\"2017-08-19 04:59:00\",\"2017-08-19 05:00:00\",\"2017-08-19 05:01:00\",\"2017-08-19 05:02:00\",\"2017-08-19 05:03:00\",\"2017-08-19 05:04:00\",\"2017-08-19 05:05:00\",\"2017-08-19 05:06:00\",\"2017-08-19 05:07:00\",\"2017-08-19 05:08:00\",\"2017-08-19 05:09:00\",\"2017-08-19 05:10:00\",\"2017-08-19 05:11:00\",\"2017-08-19 05:12:00\",\"2017-08-19 05:13:00\",\"2017-08-19 05:14:00\",\"2017-08-19 05:15:00\",\"2017-08-19 05:16:00\",\"2017-08-19 05:17:00\",\"2017-08-19 05:18:00\",\"2017-08-19 05:19:00\",\"2017-08-19 05:20:00\",\"2017-08-19 05:21:00\",\"2017-08-19 05:22:00\",\"2017-08-19 05:23:00\",\"2017-08-19 05:24:00\",\"2017-08-19 05:25:00\",\"2017-08-19 05:26:00\",\"2017-08-19 05:27:00\",\"2017-08-19 05:28:00\",\"2017-08-19 05:29:00\",\"2017-08-19 05:30:00\",\"2017-08-19 05:31:00\",\"2017-08-19 05:32:00\",\"2017-08-19 05:33:00\",\"2017-08-19 05:34:00\",\"2017-08-19 05:35:00\",\"2017-08-19 05:36:00\",\"2017-08-19 05:37:00\",\"2017-08-19 05:38:00\",\"2017-08-19 05:39:00\",\"2017-08-19 05:40:00\",\"2017-08-19 05:41:00\",\"2017-08-19 05:42:00\",\"2017-08-19 05:43:00\",\"2017-08-19 05:44:00\",\"2017-08-19 05:45:00\",\"2017-08-19 05:46:00\",\"2017-08-19 05:47:00\",\"2017-08-19 05:48:00\",\"2017-08-19 05:49:00\",\"2017-08-19 05:50:00\",\"2017-08-19 05:51:00\",\"2017-08-19 05:52:00\",\"2017-08-19 05:53:00\",\"2017-08-19 05:54:00\",\"2017-08-19 05:55:00\",\"2017-08-19 05:56:00\",\"2017-08-19 05:57:00\",\"2017-08-19 05:58:00\",\"2017-08-19 05:59:00\",\"2017-08-19 06:00:00\",\"2017-08-19 06:01:00\",\"2017-08-19 06:02:00\",\"2017-08-19 06:03:00\",\"2017-08-19 06:04:00\",\"2017-08-19 06:05:00\",\"2017-08-19 06:06:00\",\"2017-08-19 06:07:00\",\"2017-08-19 06:08:00\",\"2017-08-19 06:09:00\",\"2017-08-19 06:10:00\",\"2017-08-19 06:11:00\",\"2017-08-19 06:12:00\",\"2017-08-19 06:13:00\",\"2017-08-19 06:14:00\",\"2017-08-19 06:15:00\",\"2017-08-19 06:16:00\",\"2017-08-19 06:17:00\",\"2017-08-19 06:18:00\",\"2017-08-19 06:19:00\",\"2017-08-19 06:20:00\",\"2017-08-19 06:21:00\",\"2017-08-19 06:22:00\",\"2017-08-19 06:23:00\",\"2017-08-19 06:24:00\",\"2017-08-19 06:25:00\",\"2017-08-19 06:26:00\",\"2017-08-19 06:27:00\",\"2017-08-19 06:28:00\",\"2017-08-19 06:29:00\",\"2017-08-19 06:30:00\",\"2017-08-19 06:31:00\",\"2017-08-19 06:32:00\",\"2017-08-19 06:33:00\",\"2017-08-19 06:34:00\",\"2017-08-19 06:35:00\",\"2017-08-19 06:36:00\",\"2017-08-19 06:37:00\",\"2017-08-19 06:38:00\",\"2017-08-19 06:39:00\",\"2017-08-19 06:40:00\",\"2017-08-19 06:41:00\",\"2017-08-19 06:42:00\",\"2017-08-19 06:43:00\",\"2017-08-19 06:44:00\",\"2017-08-19 06:45:00\",\"2017-08-19 06:46:00\",\"2017-08-19 06:47:00\",\"2017-08-19 06:48:00\",\"2017-08-19 06:49:00\",\"2017-08-19 06:50:00\",\"2017-08-19 06:51:00\",\"2017-08-19 06:52:00\",\"2017-08-19 06:53:00\",\"2017-08-19 06:54:00\",\"2017-08-19 06:55:00\",\"2017-08-19 06:56:00\",\"2017-08-19 06:57:00\",\"2017-08-19 06:58:00\",\"2017-08-19 06:59:00\",\"2017-08-19 07:00:00\",\"2017-08-19 07:01:00\",\"2017-08-19 07:02:00\",\"2017-08-19 07:03:00\",\"2017-08-19 07:04:00\",\"2017-08-19 07:05:00\",\"2017-08-19 07:06:00\",\"2017-08-19 07:07:00\",\"2017-08-19 07:08:00\",\"2017-08-19 07:09:00\",\"2017-08-19 07:10:00\",\"2017-08-19 07:11:00\",\"2017-08-19 07:12:00\",\"2017-08-19 07:13:00\",\"2017-08-19 07:14:00\",\"2017-08-19 07:15:00\",\"2017-08-19 07:16:00\",\"2017-08-19 07:17:00\",\"2017-08-19 07:18:00\",\"2017-08-19 07:19:00\",\"2017-08-19 07:20:00\",\"2017-08-19 07:21:00\",\"2017-08-19 07:22:00\",\"2017-08-19 07:23:00\",\"2017-08-19 07:24:00\",\"2017-08-19 07:25:00\",\"2017-08-19 07:26:00\",\"2017-08-19 07:27:00\",\"2017-08-19 07:28:00\",\"2017-08-19 07:29:00\",\"2017-08-19 07:30:00\",\"2017-08-19 07:31:00\",\"2017-08-19 07:32:00\",\"2017-08-19 07:33:00\",\"2017-08-19 07:34:00\",\"2017-08-19 07:35:00\",\"2017-08-19 07:36:00\",\"2017-08-19 07:37:00\",\"2017-08-19 07:38:00\",\"2017-08-19 07:39:00\",\"2017-08-19 07:40:00\",\"2017-08-19 07:41:00\",\"2017-08-19 07:42:00\",\"2017-08-19 07:43:00\",\"2017-08-19 07:44:00\",\"2017-08-19 07:45:00\",\"2017-08-19 07:46:00\",\"2017-08-19 07:47:00\",\"2017-08-19 07:48:00\",\"2017-08-19 07:49:00\",\"2017-08-19 07:50:00\",\"2017-08-19 07:51:00\",\"2017-08-19 07:52:00\",\"2017-08-19 07:53:00\",\"2017-08-19 07:54:00\",\"2017-08-19 07:55:00\",\"2017-08-19 07:56:00\",\"2017-08-19 07:57:00\",\"2017-08-19 07:58:00\",\"2017-08-19 07:59:00\",\"2017-08-19 08:00:00\",\"2017-08-19 08:01:00\",\"2017-08-19 08:02:00\",\"2017-08-19 08:03:00\",\"2017-08-19 08:04:00\",\"2017-08-19 08:05:00\",\"2017-08-19 08:06:00\",\"2017-08-19 08:07:00\",\"2017-08-19 08:08:00\",\"2017-08-19 08:09:00\",\"2017-08-19 08:10:00\",\"2017-08-19 08:11:00\",\"2017-08-19 08:12:00\",\"2017-08-19 08:13:00\",\"2017-08-19 08:14:00\",\"2017-08-19 08:15:00\",\"2017-08-19 08:16:00\",\"2017-08-19 08:17:00\",\"2017-08-19 08:18:00\",\"2017-08-19 08:19:00\",\"2017-08-19 08:20:00\",\"2017-08-19 08:21:00\",\"2017-08-19 08:22:00\",\"2017-08-19 08:23:00\",\"2017-08-19 08:24:00\",\"2017-08-19 08:25:00\",\"2017-08-19 08:26:00\",\"2017-08-19 08:27:00\",\"2017-08-19 08:28:00\",\"2017-08-19 08:29:00\",\"2017-08-19 08:30:00\",\"2017-08-19 08:31:00\",\"2017-08-19 08:32:00\",\"2017-08-19 08:33:00\",\"2017-08-19 08:34:00\",\"2017-08-19 08:35:00\",\"2017-08-19 08:36:00\",\"2017-08-19 08:37:00\",\"2017-08-19 08:38:00\",\"2017-08-19 08:39:00\",\"2017-08-19 08:40:00\",\"2017-08-19 08:41:00\",\"2017-08-19 08:42:00\",\"2017-08-19 08:43:00\",\"2017-08-19 08:44:00\",\"2017-08-19 08:45:00\",\"2017-08-19 08:46:00\",\"2017-08-19 08:47:00\",\"2017-08-19 08:48:00\",\"2017-08-19 08:49:00\",\"2017-08-19 08:50:00\",\"2017-08-19 08:51:00\",\"2017-08-19 08:52:00\",\"2017-08-19 08:53:00\",\"2017-08-19 08:54:00\",\"2017-08-19 08:55:00\",\"2017-08-19 08:56:00\",\"2017-08-19 08:57:00\",\"2017-08-19 08:58:00\",\"2017-08-19 08:59:00\",\"2017-08-19 09:00:00\",\"2017-08-19 09:01:00\",\"2017-08-19 09:02:00\",\"2017-08-19 09:03:00\",\"2017-08-19 09:04:00\",\"2017-08-19 09:05:00\",\"2017-08-19 09:06:00\",\"2017-08-19 09:07:00\",\"2017-08-19 09:08:00\",\"2017-08-19 09:09:00\",\"2017-08-19 09:10:00\",\"2017-08-19 09:11:00\",\"2017-08-19 09:12:00\",\"2017-08-19 09:13:00\",\"2017-08-19 09:14:00\",\"2017-08-19 09:15:00\",\"2017-08-19 09:16:00\",\"2017-08-19 09:17:00\",\"2017-08-19 09:18:00\",\"2017-08-19 09:19:00\",\"2017-08-19 09:20:00\",\"2017-08-19 09:21:00\",\"2017-08-19 09:22:00\",\"2017-08-19 09:23:00\",\"2017-08-19 09:24:00\",\"2017-08-19 09:25:00\",\"2017-08-19 09:26:00\",\"2017-08-19 09:27:00\",\"2017-08-19 09:28:00\",\"2017-08-19 09:29:00\",\"2017-08-19 09:30:00\",\"2017-08-19 09:31:00\",\"2017-08-19 09:32:00\",\"2017-08-19 09:33:00\",\"2017-08-19 09:34:00\",\"2017-08-19 09:35:00\",\"2017-08-19 09:36:00\",\"2017-08-19 09:37:00\",\"2017-08-19 09:38:00\",\"2017-08-19 09:39:00\",\"2017-08-19 09:40:00\",\"2017-08-19 09:41:00\",\"2017-08-19 09:42:00\",\"2017-08-19 09:43:00\",\"2017-08-19 09:44:00\",\"2017-08-19 09:45:00\",\"2017-08-19 09:46:00\",\"2017-08-19 09:47:00\",\"2017-08-19 09:48:00\",\"2017-08-19 09:49:00\",\"2017-08-19 09:50:00\",\"2017-08-19 09:51:00\",\"2017-08-19 09:52:00\",\"2017-08-19 09:53:00\",\"2017-08-19 09:54:00\",\"2017-08-19 09:55:00\",\"2017-08-19 09:56:00\",\"2017-08-19 09:57:00\",\"2017-08-19 09:58:00\",\"2017-08-19 09:59:00\",\"2017-08-19 10:00:00\",\"2017-08-19 10:01:00\",\"2017-08-19 10:02:00\",\"2017-08-19 10:03:00\",\"2017-08-19 10:04:00\",\"2017-08-19 10:05:00\",\"2017-08-19 10:06:00\",\"2017-08-19 10:07:00\",\"2017-08-19 10:08:00\",\"2017-08-19 10:09:00\",\"2017-08-19 10:10:00\",\"2017-08-19 10:11:00\",\"2017-08-19 10:12:00\",\"2017-08-19 10:13:00\",\"2017-08-19 10:14:00\",\"2017-08-19 10:15:00\",\"2017-08-19 10:16:00\",\"2017-08-19 10:17:00\",\"2017-08-19 10:18:00\",\"2017-08-19 10:19:00\",\"2017-08-19 10:20:00\",\"2017-08-19 10:21:00\",\"2017-08-19 10:22:00\",\"2017-08-19 10:23:00\",\"2017-08-19 10:24:00\",\"2017-08-19 10:25:00\",\"2017-08-19 10:26:00\",\"2017-08-19 10:27:00\",\"2017-08-19 10:28:00\",\"2017-08-19 10:29:00\",\"2017-08-19 10:30:00\",\"2017-08-19 10:31:00\",\"2017-08-19 10:32:00\",\"2017-08-19 10:33:00\",\"2017-08-19 10:34:00\",\"2017-08-19 10:35:00\",\"2017-08-19 10:36:00\",\"2017-08-19 10:37:00\",\"2017-08-19 10:38:00\",\"2017-08-19 10:39:00\",\"2017-08-19 10:40:00\",\"2017-08-19 10:41:00\",\"2017-08-19 10:42:00\",\"2017-08-19 10:43:00\",\"2017-08-19 10:44:00\",\"2017-08-19 10:45:00\",\"2017-08-19 10:46:00\",\"2017-08-19 10:47:00\",\"2017-08-19 10:48:00\",\"2017-08-19 10:49:00\",\"2017-08-19 10:50:00\",\"2017-08-19 10:51:00\",\"2017-08-19 10:52:00\",\"2017-08-19 10:53:00\",\"2017-08-19 10:54:00\",\"2017-08-19 10:55:00\",\"2017-08-19 10:56:00\",\"2017-08-19 10:57:00\",\"2017-08-19 10:58:00\",\"2017-08-19 10:59:00\",\"2017-08-19 11:00:00\",\"2017-08-19 11:01:00\",\"2017-08-19 11:02:00\",\"2017-08-19 11:03:00\",\"2017-08-19 11:04:00\",\"2017-08-19 11:05:00\",\"2017-08-19 11:06:00\",\"2017-08-19 11:07:00\",\"2017-08-19 11:08:00\",\"2017-08-19 11:09:00\",\"2017-08-19 11:10:00\",\"2017-08-19 11:11:00\",\"2017-08-19 11:12:00\",\"2017-08-19 11:13:00\",\"2017-08-19 11:14:00\",\"2017-08-19 11:15:00\",\"2017-08-19 11:16:00\",\"2017-08-19 11:17:00\",\"2017-08-19 11:18:00\",\"2017-08-19 11:19:00\",\"2017-08-19 11:20:00\",\"2017-08-19 11:21:00\",\"2017-08-19 11:22:00\",\"2017-08-19 11:23:00\",\"2017-08-19 11:24:00\",\"2017-08-19 11:25:00\",\"2017-08-19 11:26:00\",\"2017-08-19 11:27:00\",\"2017-08-19 11:28:00\",\"2017-08-19 11:29:00\",\"2017-08-19 11:30:00\",\"2017-08-19 11:31:00\",\"2017-08-19 11:32:00\",\"2017-08-19 11:33:00\",\"2017-08-19 11:34:00\",\"2017-08-19 11:35:00\",\"2017-08-19 11:36:00\",\"2017-08-19 11:37:00\",\"2017-08-19 11:38:00\",\"2017-08-19 11:39:00\",\"2017-08-19 11:40:00\",\"2017-08-19 11:41:00\",\"2017-08-19 11:42:00\",\"2017-08-19 11:43:00\",\"2017-08-19 11:44:00\",\"2017-08-19 11:45:00\",\"2017-08-19 11:46:00\",\"2017-08-19 11:47:00\",\"2017-08-19 11:48:00\",\"2017-08-19 11:49:00\",\"2017-08-19 11:50:00\",\"2017-08-19 11:51:00\",\"2017-08-19 11:52:00\",\"2017-08-19 11:53:00\",\"2017-08-19 11:54:00\",\"2017-08-19 11:55:00\",\"2017-08-19 11:56:00\",\"2017-08-19 11:57:00\",\"2017-08-19 11:58:00\",\"2017-08-19 11:59:00\",\"2017-08-19 12:00:00\",\"2017-08-19 12:01:00\",\"2017-08-19 12:02:00\",\"2017-08-19 12:03:00\",\"2017-08-19 12:04:00\",\"2017-08-19 12:05:00\",\"2017-08-19 12:06:00\",\"2017-08-19 12:07:00\",\"2017-08-19 12:08:00\",\"2017-08-19 12:09:00\",\"2017-08-19 12:10:00\",\"2017-08-19 12:11:00\",\"2017-08-19 12:12:00\",\"2017-08-19 12:13:00\",\"2017-08-19 12:14:00\",\"2017-08-19 12:15:00\",\"2017-08-19 12:16:00\",\"2017-08-19 12:17:00\",\"2017-08-19 12:18:00\",\"2017-08-19 12:19:00\",\"2017-08-19 12:20:00\",\"2017-08-19 12:21:00\",\"2017-08-19 12:22:00\",\"2017-08-19 12:23:00\",\"2017-08-19 12:24:00\",\"2017-08-19 12:25:00\",\"2017-08-19 12:26:00\",\"2017-08-19 12:27:00\",\"2017-08-19 12:28:00\",\"2017-08-19 12:29:00\",\"2017-08-19 12:30:00\",\"2017-08-19 12:31:00\",\"2017-08-19 12:32:00\",\"2017-08-19 12:33:00\",\"2017-08-19 12:34:00\",\"2017-08-19 12:35:00\",\"2017-08-19 12:36:00\",\"2017-08-19 12:37:00\",\"2017-08-19 12:38:00\",\"2017-08-19 12:39:00\",\"2017-08-19 12:40:00\",\"2017-08-19 12:41:00\",\"2017-08-19 12:42:00\",\"2017-08-19 12:43:00\",\"2017-08-19 12:44:00\",\"2017-08-19 12:45:00\",\"2017-08-19 12:46:00\",\"2017-08-19 12:47:00\",\"2017-08-19 12:48:00\",\"2017-08-19 12:49:00\",\"2017-08-19 12:50:00\",\"2017-08-19 12:51:00\",\"2017-08-19 12:52:00\",\"2017-08-19 12:53:00\",\"2017-08-19 12:54:00\",\"2017-08-19 12:55:00\",\"2017-08-19 12:56:00\",\"2017-08-19 12:57:00\",\"2017-08-19 12:58:00\",\"2017-08-19 12:59:00\",\"2017-08-19 13:00:00\",\"2017-08-19 13:01:00\",\"2017-08-19 13:02:00\",\"2017-08-19 13:03:00\",\"2017-08-19 13:04:00\",\"2017-08-19 13:05:00\",\"2017-08-19 13:06:00\",\"2017-08-19 13:07:00\",\"2017-08-19 13:08:00\",\"2017-08-19 13:09:00\",\"2017-08-19 13:10:00\",\"2017-08-19 13:11:00\",\"2017-08-19 13:12:00\",\"2017-08-19 13:13:00\",\"2017-08-19 13:14:00\",\"2017-08-19 13:15:00\",\"2017-08-19 13:16:00\",\"2017-08-19 13:17:00\",\"2017-08-19 13:18:00\",\"2017-08-19 13:19:00\",\"2017-08-19 13:20:00\",\"2017-08-19 13:21:00\",\"2017-08-19 13:22:00\",\"2017-08-19 13:23:00\",\"2017-08-19 13:24:00\",\"2017-08-19 13:25:00\",\"2017-08-19 13:26:00\",\"2017-08-19 13:27:00\",\"2017-08-19 13:28:00\",\"2017-08-19 13:29:00\",\"2017-08-19 13:30:00\",\"2017-08-19 13:31:00\",\"2017-08-19 13:32:00\",\"2017-08-19 13:33:00\",\"2017-08-19 13:34:00\",\"2017-08-19 13:35:00\",\"2017-08-19 13:36:00\",\"2017-08-19 13:37:00\",\"2017-08-19 13:38:00\",\"2017-08-19 13:39:00\",\"2017-08-19 13:40:00\",\"2017-08-19 13:41:00\",\"2017-08-19 13:42:00\",\"2017-08-19 13:43:00\",\"2017-08-19 13:44:00\",\"2017-08-19 13:45:00\",\"2017-08-19 13:46:00\",\"2017-08-19 13:47:00\",\"2017-08-19 13:48:00\",\"2017-08-19 13:49:00\",\"2017-08-19 13:50:00\",\"2017-08-19 13:51:00\",\"2017-08-19 13:52:00\",\"2017-08-19 13:53:00\",\"2017-08-19 13:54:00\",\"2017-08-19 13:55:00\",\"2017-08-19 13:56:00\",\"2017-08-19 13:57:00\",\"2017-08-19 13:58:00\",\"2017-08-19 13:59:00\",\"2017-08-19 14:00:00\",\"2017-08-19 14:01:00\",\"2017-08-19 14:02:00\",\"2017-08-19 14:03:00\",\"2017-08-19 14:04:00\",\"2017-08-19 14:05:00\",\"2017-08-19 14:06:00\",\"2017-08-19 14:07:00\",\"2017-08-19 14:08:00\",\"2017-08-19 14:09:00\",\"2017-08-19 14:10:00\",\"2017-08-19 14:11:00\",\"2017-08-19 14:12:00\",\"2017-08-19 14:13:00\",\"2017-08-19 14:14:00\",\"2017-08-19 14:15:00\",\"2017-08-19 14:16:00\",\"2017-08-19 14:17:00\",\"2017-08-19 14:18:00\",\"2017-08-19 14:19:00\",\"2017-08-19 14:20:00\",\"2017-08-19 14:21:00\",\"2017-08-19 14:22:00\",\"2017-08-19 14:23:00\",\"2017-08-19 14:24:00\",\"2017-08-19 14:25:00\",\"2017-08-19 14:26:00\",\"2017-08-19 14:27:00\",\"2017-08-19 14:28:00\",\"2017-08-19 14:29:00\",\"2017-08-19 14:30:00\",\"2017-08-19 14:31:00\",\"2017-08-19 14:32:00\",\"2017-08-19 14:33:00\",\"2017-08-19 14:34:00\",\"2017-08-19 14:35:00\",\"2017-08-19 14:36:00\",\"2017-08-19 14:37:00\",\"2017-08-19 14:38:00\",\"2017-08-19 14:39:00\",\"2017-08-19 14:40:00\",\"2017-08-19 14:41:00\",\"2017-08-19 14:42:00\",\"2017-08-19 14:43:00\",\"2017-08-19 14:44:00\",\"2017-08-19 14:45:00\",\"2017-08-19 14:46:00\",\"2017-08-19 14:47:00\",\"2017-08-19 14:48:00\",\"2017-08-19 14:49:00\",\"2017-08-19 14:50:00\",\"2017-08-19 14:51:00\",\"2017-08-19 14:52:00\",\"2017-08-19 14:53:00\",\"2017-08-19 14:54:00\",\"2017-08-19 14:55:00\",\"2017-08-19 14:56:00\",\"2017-08-19 14:57:00\",\"2017-08-19 14:58:00\",\"2017-08-19 14:59:00\",\"2017-08-19 15:00:00\",\"2017-08-19 15:01:00\",\"2017-08-19 15:02:00\",\"2017-08-19 15:03:00\",\"2017-08-19 15:04:00\",\"2017-08-19 15:05:00\",\"2017-08-19 15:06:00\",\"2017-08-19 15:07:00\",\"2017-08-19 15:08:00\",\"2017-08-19 15:09:00\",\"2017-08-19 15:10:00\",\"2017-08-19 15:11:00\",\"2017-08-19 15:12:00\",\"2017-08-19 15:13:00\",\"2017-08-19 15:14:00\",\"2017-08-19 15:15:00\",\"2017-08-19 15:16:00\",\"2017-08-19 15:17:00\",\"2017-08-19 15:18:00\",\"2017-08-19 15:19:00\",\"2017-08-19 15:20:00\",\"2017-08-19 15:21:00\",\"2017-08-19 15:22:00\",\"2017-08-19 15:23:00\",\"2017-08-19 15:24:00\",\"2017-08-19 15:25:00\",\"2017-08-19 15:26:00\",\"2017-08-19 15:27:00\",\"2017-08-19 15:28:00\",\"2017-08-19 15:29:00\",\"2017-08-19 15:30:00\",\"2017-08-19 15:31:00\",\"2017-08-19 15:32:00\",\"2017-08-19 15:33:00\",\"2017-08-19 15:34:00\",\"2017-08-19 15:35:00\",\"2017-08-19 15:36:00\",\"2017-08-19 15:37:00\",\"2017-08-19 15:38:00\",\"2017-08-19 15:39:00\",\"2017-08-19 15:40:00\",\"2017-08-19 15:41:00\",\"2017-08-19 15:42:00\",\"2017-08-19 15:43:00\",\"2017-08-19 15:44:00\",\"2017-08-19 15:45:00\",\"2017-08-19 15:46:00\",\"2017-08-19 15:47:00\",\"2017-08-19 15:48:00\",\"2017-08-19 15:49:00\",\"2017-08-19 15:50:00\",\"2017-08-19 15:51:00\",\"2017-08-19 15:52:00\",\"2017-08-19 15:53:00\",\"2017-08-19 15:54:00\",\"2017-08-19 15:55:00\",\"2017-08-19 15:56:00\",\"2017-08-19 15:57:00\",\"2017-08-19 15:58:00\",\"2017-08-19 15:59:00\",\"2017-08-19 16:00:00\",\"2017-08-19 16:01:00\",\"2017-08-19 16:02:00\",\"2017-08-19 16:03:00\",\"2017-08-19 16:04:00\",\"2017-08-19 16:05:00\",\"2017-08-19 16:06:00\",\"2017-08-19 16:07:00\",\"2017-08-19 16:08:00\",\"2017-08-19 16:09:00\",\"2017-08-19 16:10:00\",\"2017-08-19 16:11:00\",\"2017-08-19 16:12:00\",\"2017-08-19 16:13:00\",\"2017-08-19 16:14:00\",\"2017-08-19 16:15:00\",\"2017-08-19 16:16:00\",\"2017-08-19 16:17:00\",\"2017-08-19 16:18:00\",\"2017-08-19 16:19:00\",\"2017-08-19 16:20:00\",\"2017-08-19 16:21:00\",\"2017-08-19 16:22:00\",\"2017-08-19 16:23:00\",\"2017-08-19 16:24:00\",\"2017-08-19 16:25:00\",\"2017-08-19 16:26:00\",\"2017-08-19 16:27:00\",\"2017-08-19 16:28:00\",\"2017-08-19 16:29:00\",\"2017-08-19 16:30:00\",\"2017-08-19 16:31:00\",\"2017-08-19 16:32:00\",\"2017-08-19 16:33:00\",\"2017-08-19 16:34:00\",\"2017-08-19 16:35:00\",\"2017-08-19 16:36:00\",\"2017-08-19 16:37:00\",\"2017-08-19 16:38:00\",\"2017-08-19 16:39:00\",\"2017-08-19 16:40:00\",\"2017-08-19 16:41:00\",\"2017-08-19 16:42:00\",\"2017-08-19 16:43:00\",\"2017-08-19 16:44:00\",\"2017-08-19 16:45:00\",\"2017-08-19 16:46:00\",\"2017-08-19 16:47:00\",\"2017-08-19 16:48:00\",\"2017-08-19 16:49:00\",\"2017-08-19 16:50:00\",\"2017-08-19 16:51:00\",\"2017-08-19 16:52:00\",\"2017-08-19 16:53:00\",\"2017-08-19 16:54:00\",\"2017-08-19 16:55:00\",\"2017-08-19 16:56:00\",\"2017-08-19 16:57:00\",\"2017-08-19 16:58:00\",\"2017-08-19 16:59:00\",\"2017-08-19 17:00:00\",\"2017-08-19 17:01:00\",\"2017-08-19 17:02:00\",\"2017-08-19 17:03:00\",\"2017-08-19 17:04:00\",\"2017-08-19 17:05:00\",\"2017-08-19 17:06:00\",\"2017-08-19 17:07:00\",\"2017-08-19 17:08:00\",\"2017-08-19 17:09:00\",\"2017-08-19 17:10:00\",\"2017-08-19 17:11:00\",\"2017-08-19 17:12:00\",\"2017-08-19 17:13:00\",\"2017-08-19 17:14:00\",\"2017-08-19 17:15:00\",\"2017-08-19 17:16:00\",\"2017-08-19 17:17:00\",\"2017-08-19 17:18:00\",\"2017-08-19 17:19:00\",\"2017-08-19 17:20:00\",\"2017-08-19 17:21:00\",\"2017-08-19 17:22:00\",\"2017-08-19 17:23:00\",\"2017-08-19 17:24:00\",\"2017-08-19 17:25:00\",\"2017-08-19 17:26:00\",\"2017-08-19 17:27:00\",\"2017-08-19 17:28:00\",\"2017-08-19 17:29:00\",\"2017-08-19 17:30:00\",\"2017-08-19 17:31:00\",\"2017-08-19 17:32:00\",\"2017-08-19 17:33:00\",\"2017-08-19 17:34:00\",\"2017-08-19 17:35:00\",\"2017-08-19 17:36:00\",\"2017-08-19 17:37:00\",\"2017-08-19 17:38:00\",\"2017-08-19 17:39:00\",\"2017-08-19 17:40:00\",\"2017-08-19 17:41:00\",\"2017-08-19 17:42:00\",\"2017-08-19 17:43:00\",\"2017-08-19 17:44:00\",\"2017-08-19 17:45:00\",\"2017-08-19 17:46:00\",\"2017-08-19 17:47:00\",\"2017-08-19 17:48:00\",\"2017-08-19 17:49:00\",\"2017-08-19 17:50:00\",\"2017-08-19 17:51:00\",\"2017-08-19 17:52:00\",\"2017-08-19 17:53:00\",\"2017-08-19 17:54:00\",\"2017-08-19 17:55:00\",\"2017-08-19 17:56:00\",\"2017-08-19 17:57:00\",\"2017-08-19 17:58:00\",\"2017-08-19 17:59:00\",\"2017-08-19 18:00:00\",\"2017-08-19 18:01:00\",\"2017-08-19 18:02:00\",\"2017-08-19 18:03:00\",\"2017-08-19 18:04:00\",\"2017-08-19 18:05:00\",\"2017-08-19 18:06:00\",\"2017-08-19 18:07:00\",\"2017-08-19 18:08:00\",\"2017-08-19 18:09:00\",\"2017-08-19 18:10:00\",\"2017-08-19 18:11:00\",\"2017-08-19 18:12:00\",\"2017-08-19 18:13:00\",\"2017-08-19 18:14:00\",\"2017-08-19 18:15:00\",\"2017-08-19 18:16:00\",\"2017-08-19 18:17:00\",\"2017-08-19 18:18:00\",\"2017-08-19 18:19:00\",\"2017-08-19 18:20:00\",\"2017-08-19 18:21:00\",\"2017-08-19 18:22:00\",\"2017-08-19 18:23:00\",\"2017-08-19 18:24:00\",\"2017-08-19 18:25:00\",\"2017-08-19 18:26:00\",\"2017-08-19 18:27:00\",\"2017-08-19 18:28:00\",\"2017-08-19 18:29:00\",\"2017-08-19 18:30:00\",\"2017-08-19 18:31:00\",\"2017-08-19 18:32:00\",\"2017-08-19 18:33:00\",\"2017-08-19 18:34:00\",\"2017-08-19 18:35:00\",\"2017-08-19 18:36:00\",\"2017-08-19 18:37:00\",\"2017-08-19 18:38:00\",\"2017-08-19 18:39:00\",\"2017-08-19 18:40:00\",\"2017-08-19 18:41:00\",\"2017-08-19 18:42:00\",\"2017-08-19 18:43:00\",\"2017-08-19 18:44:00\",\"2017-08-19 18:45:00\",\"2017-08-19 18:46:00\",\"2017-08-19 18:47:00\",\"2017-08-19 18:48:00\",\"2017-08-19 18:49:00\",\"2017-08-19 18:50:00\",\"2017-08-19 18:51:00\",\"2017-08-19 18:52:00\",\"2017-08-19 18:53:00\",\"2017-08-19 18:54:00\",\"2017-08-19 18:55:00\",\"2017-08-19 18:56:00\",\"2017-08-19 18:57:00\",\"2017-08-19 18:58:00\",\"2017-08-19 18:59:00\",\"2017-08-19 19:00:00\",\"2017-08-19 19:01:00\",\"2017-08-19 19:02:00\",\"2017-08-19 19:03:00\",\"2017-08-19 19:04:00\",\"2017-08-19 19:05:00\",\"2017-08-19 19:06:00\",\"2017-08-19 19:07:00\",\"2017-08-19 19:08:00\",\"2017-08-19 19:09:00\",\"2017-08-19 19:10:00\",\"2017-08-19 19:11:00\",\"2017-08-19 19:12:00\",\"2017-08-19 19:13:00\",\"2017-08-19 19:14:00\",\"2017-08-19 19:15:00\",\"2017-08-19 19:16:00\",\"2017-08-19 19:17:00\",\"2017-08-19 19:18:00\",\"2017-08-19 19:19:00\",\"2017-08-19 19:20:00\",\"2017-08-19 19:21:00\",\"2017-08-19 19:22:00\",\"2017-08-19 19:23:00\",\"2017-08-19 19:24:00\",\"2017-08-19 19:25:00\",\"2017-08-19 19:26:00\",\"2017-08-19 19:27:00\",\"2017-08-19 19:28:00\",\"2017-08-19 19:29:00\",\"2017-08-19 19:30:00\",\"2017-08-19 19:31:00\",\"2017-08-19 19:32:00\",\"2017-08-19 19:33:00\",\"2017-08-19 19:34:00\",\"2017-08-19 19:35:00\",\"2017-08-19 19:36:00\",\"2017-08-19 19:37:00\",\"2017-08-19 19:38:00\",\"2017-08-19 19:39:00\",\"2017-08-19 19:40:00\",\"2017-08-19 19:41:00\",\"2017-08-19 19:42:00\",\"2017-08-19 19:43:00\",\"2017-08-19 19:44:00\",\"2017-08-19 19:45:00\",\"2017-08-19 19:46:00\",\"2017-08-19 19:47:00\",\"2017-08-19 19:48:00\",\"2017-08-19 19:49:00\",\"2017-08-19 19:50:00\",\"2017-08-19 19:51:00\",\"2017-08-19 19:52:00\",\"2017-08-19 19:53:00\",\"2017-08-19 19:54:00\",\"2017-08-19 19:55:00\",\"2017-08-19 19:56:00\",\"2017-08-19 19:57:00\",\"2017-08-19 19:58:00\",\"2017-08-19 19:59:00\",\"2017-08-19 20:00:00\",\"2017-08-19 20:01:00\",\"2017-08-19 20:02:00\",\"2017-08-19 20:03:00\",\"2017-08-19 20:04:00\",\"2017-08-19 20:05:00\",\"2017-08-19 20:06:00\",\"2017-08-19 20:07:00\",\"2017-08-19 20:08:00\",\"2017-08-19 20:09:00\",\"2017-08-19 20:10:00\",\"2017-08-19 20:11:00\",\"2017-08-19 20:12:00\",\"2017-08-19 20:13:00\",\"2017-08-19 20:14:00\",\"2017-08-19 20:15:00\",\"2017-08-19 20:16:00\",\"2017-08-19 20:17:00\",\"2017-08-19 20:18:00\",\"2017-08-19 20:19:00\",\"2017-08-19 20:20:00\",\"2017-08-19 20:21:00\",\"2017-08-19 20:22:00\",\"2017-08-19 20:23:00\",\"2017-08-19 20:24:00\",\"2017-08-19 20:25:00\",\"2017-08-19 20:26:00\",\"2017-08-19 20:27:00\",\"2017-08-19 20:28:00\",\"2017-08-19 20:29:00\",\"2017-08-19 20:30:00\",\"2017-08-19 20:31:00\",\"2017-08-19 20:32:00\",\"2017-08-19 20:33:00\",\"2017-08-19 20:34:00\",\"2017-08-19 20:35:00\",\"2017-08-19 20:36:00\",\"2017-08-19 20:37:00\",\"2017-08-19 20:38:00\",\"2017-08-19 20:39:00\",\"2017-08-19 20:40:00\",\"2017-08-19 20:41:00\",\"2017-08-19 20:42:00\",\"2017-08-19 20:43:00\",\"2017-08-19 20:44:00\",\"2017-08-19 20:45:00\",\"2017-08-19 20:46:00\",\"2017-08-19 20:47:00\",\"2017-08-19 20:48:00\",\"2017-08-19 20:49:00\",\"2017-08-19 20:50:00\",\"2017-08-19 20:51:00\",\"2017-08-19 20:52:00\",\"2017-08-19 20:53:00\",\"2017-08-19 20:54:00\",\"2017-08-19 20:55:00\",\"2017-08-19 20:56:00\",\"2017-08-19 20:57:00\",\"2017-08-19 20:58:00\",\"2017-08-19 20:59:00\",\"2017-08-19 21:00:00\",\"2017-08-19 21:01:00\",\"2017-08-19 21:02:00\",\"2017-08-19 21:03:00\",\"2017-08-19 21:04:00\",\"2017-08-19 21:05:00\",\"2017-08-19 21:06:00\",\"2017-08-19 21:07:00\",\"2017-08-19 21:08:00\",\"2017-08-19 21:09:00\",\"2017-08-19 21:10:00\",\"2017-08-19 21:11:00\",\"2017-08-19 21:12:00\",\"2017-08-19 21:13:00\",\"2017-08-19 21:14:00\",\"2017-08-19 21:15:00\",\"2017-08-19 21:16:00\",\"2017-08-19 21:17:00\",\"2017-08-19 21:18:00\",\"2017-08-19 21:19:00\",\"2017-08-19 21:20:00\",\"2017-08-19 21:21:00\",\"2017-08-19 21:22:00\",\"2017-08-19 21:23:00\",\"2017-08-19 21:24:00\",\"2017-08-19 21:25:00\",\"2017-08-19 21:26:00\",\"2017-08-19 21:27:00\",\"2017-08-19 21:28:00\",\"2017-08-19 21:29:00\",\"2017-08-19 21:30:00\",\"2017-08-19 21:31:00\",\"2017-08-19 21:32:00\",\"2017-08-19 21:33:00\",\"2017-08-19 21:34:00\",\"2017-08-19 21:35:00\",\"2017-08-19 21:36:00\",\"2017-08-19 21:37:00\",\"2017-08-19 21:38:00\",\"2017-08-19 21:39:00\",\"2017-08-19 21:40:00\",\"2017-08-19 21:41:00\",\"2017-08-19 21:42:00\",\"2017-08-19 21:43:00\",\"2017-08-19 21:44:00\",\"2017-08-19 21:45:00\",\"2017-08-19 21:46:00\",\"2017-08-19 21:47:00\",\"2017-08-19 21:48:00\",\"2017-08-19 21:49:00\",\"2017-08-19 21:50:00\",\"2017-08-19 21:51:00\",\"2017-08-19 21:52:00\",\"2017-08-19 21:53:00\",\"2017-08-19 21:54:00\",\"2017-08-19 21:55:00\",\"2017-08-19 21:56:00\",\"2017-08-19 21:57:00\",\"2017-08-19 21:58:00\",\"2017-08-19 21:59:00\",\"2017-08-19 22:00:00\",\"2017-08-19 22:01:00\",\"2017-08-19 22:02:00\",\"2017-08-19 22:03:00\",\"2017-08-19 22:04:00\",\"2017-08-19 22:05:00\",\"2017-08-19 22:06:00\",\"2017-08-19 22:07:00\",\"2017-08-19 22:08:00\",\"2017-08-19 22:09:00\",\"2017-08-19 22:10:00\",\"2017-08-19 22:11:00\",\"2017-08-19 22:12:00\",\"2017-08-19 22:13:00\",\"2017-08-19 22:14:00\",\"2017-08-19 22:15:00\",\"2017-08-19 22:16:00\",\"2017-08-19 22:17:00\",\"2017-08-19 22:18:00\",\"2017-08-19 22:19:00\",\"2017-08-19 22:20:00\",\"2017-08-19 22:21:00\",\"2017-08-19 22:22:00\",\"2017-08-19 22:23:00\",\"2017-08-19 22:24:00\",\"2017-08-19 22:25:00\",\"2017-08-19 22:26:00\",\"2017-08-19 22:27:00\",\"2017-08-19 22:28:00\",\"2017-08-19 22:29:00\",\"2017-08-19 22:30:00\",\"2017-08-19 22:31:00\",\"2017-08-19 22:32:00\",\"2017-08-19 22:33:00\",\"2017-08-19 22:34:00\",\"2017-08-19 22:35:00\",\"2017-08-19 22:36:00\",\"2017-08-19 22:37:00\",\"2017-08-19 22:38:00\",\"2017-08-19 22:39:00\",\"2017-08-19 22:40:00\",\"2017-08-19 22:41:00\",\"2017-08-19 22:42:00\",\"2017-08-19 22:43:00\",\"2017-08-19 22:44:00\",\"2017-08-19 22:45:00\",\"2017-08-19 22:46:00\",\"2017-08-19 22:47:00\",\"2017-08-19 22:48:00\",\"2017-08-19 22:49:00\",\"2017-08-19 22:50:00\",\"2017-08-19 22:51:00\",\"2017-08-19 22:52:00\",\"2017-08-19 22:53:00\",\"2017-08-19 22:54:00\",\"2017-08-19 22:55:00\",\"2017-08-19 22:56:00\",\"2017-08-19 22:57:00\",\"2017-08-19 22:58:00\",\"2017-08-19 22:59:00\",\"2017-08-19 23:00:00\",\"2017-08-19 23:01:00\",\"2017-08-19 23:02:00\",\"2017-08-19 23:03:00\",\"2017-08-19 23:04:00\",\"2017-08-19 23:05:00\",\"2017-08-19 23:06:00\",\"2017-08-19 23:07:00\",\"2017-08-19 23:08:00\",\"2017-08-19 23:09:00\",\"2017-08-19 23:10:00\",\"2017-08-19 23:11:00\",\"2017-08-19 23:12:00\",\"2017-08-19 23:13:00\",\"2017-08-19 23:14:00\",\"2017-08-19 23:15:00\",\"2017-08-19 23:16:00\",\"2017-08-19 23:17:00\",\"2017-08-19 23:18:00\",\"2017-08-19 23:19:00\",\"2017-08-19 23:20:00\",\"2017-08-19 23:21:00\",\"2017-08-19 23:22:00\",\"2017-08-19 23:23:00\",\"2017-08-19 23:24:00\",\"2017-08-19 23:25:00\",\"2017-08-19 23:26:00\",\"2017-08-19 23:27:00\",\"2017-08-19 23:28:00\",\"2017-08-19 23:29:00\",\"2017-08-19 23:30:00\",\"2017-08-19 23:31:00\",\"2017-08-19 23:32:00\",\"2017-08-19 23:33:00\",\"2017-08-19 23:34:00\",\"2017-08-19 23:35:00\",\"2017-08-19 23:36:00\",\"2017-08-19 23:37:00\",\"2017-08-19 23:38:00\",\"2017-08-19 23:39:00\",\"2017-08-19 23:40:00\",\"2017-08-19 23:41:00\",\"2017-08-19 23:42:00\",\"2017-08-19 23:43:00\",\"2017-08-19 23:44:00\",\"2017-08-19 23:45:00\",\"2017-08-19 23:46:00\",\"2017-08-19 23:47:00\",\"2017-08-19 23:48:00\",\"2017-08-19 23:49:00\",\"2017-08-19 23:50:00\",\"2017-08-19 23:51:00\",\"2017-08-19 23:52:00\",\"2017-08-19 23:53:00\",\"2017-08-19 23:54:00\",\"2017-08-19 23:55:00\",\"2017-08-19 23:56:00\",\"2017-08-19 23:57:00\",\"2017-08-19 23:58:00\",\"2017-08-19 23:59:00\"],\"xaxis\":\"x\",\"y\":[0.5014384748700175,0.5014384748700175,0.5014384748700175,0.5014384748700175,0.5014384748700175,0.5287175043327554,0.5150722125938756,0.5014384748700175,0.5014384748700175,0.5014384748700175,0.5014384748700175,0.5014384748700175,0.5014384748700175,0.485713460427498,0.5004794916233393,0.5004794916233393,0.5004794916233393,0.485713460427498,0.485713460427498,0.4825014442518773,0.4825014442518773,0.4801906412478334,0.4801906412478334,0.4801906412478334,0.5028942807625643,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.44035239745811705,0.44035239745811705,0.47134026574234544,0.4552455228191793,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.4547718082033505,0.48625649913344865,0.48625649913344865,0.48625649913344865,0.48625649913344865,0.48625649913344865,0.48771230502599655,0.48771230502599655,0.48771230502599655,0.48082611207394566,0.4656787983824372,0.4656787983824372,0.4656787983824372,0.48082611207394566,0.48082611207394566,0.48082611207394566,0.4807683419988444,0.4807683419988444,0.4807683419988444,0.48082611207394566,0.48082611207394566,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.5009878682842286,0.489433853264009,0.489433853264009,0.489433853264009,0.489433853264009,0.489433853264009,0.40928365106874637,0.40928365106874637,0.5009878682842286,0.5009878682842286,0.4709474292316578,0.4709474292316578,0.4709474292316578,0.4709474292316578,0.4709474292316578,0.4709474292316578,0.38771230502599646,0.38771230502599646,0.38771230502599646,0.38771230502599646,0.38771230502599646,0.38771230502599646,0.38771230502599646,0.4277700751010976,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.42708838821490447,0.42708838821490447,0.42708838821490447,0.37419410745233983,0.40004043905257075,0.3996129404968227,0.3996129404968227,0.4639572501444248,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.4639572501444248,0.46170421721548216,0.46170421721548216,0.46170421721548216,0.4639572501444248,0.4494338532640092,0.4494338532640092,0.4342980935875212,0.4342980935875212,0.4179260543038706,0.4179260543038706,0.4179260543038706,0.4179260543038706,0.4179260543038706,0.3758694396302714,0.37303870595031785,0.3616926632004621,0.3616926632004621,0.3616926632004621,0.35290005777007494,0.36662622761409586,0.36662622761409586,0.36662622761409586,0.41580011554015006,0.3769555170421721,0.41548815713460413,0.41548815713460413,0.41548815713460413,0.41548815713460413,0.41548815713460413,0.41548815713460413,0.41548815713460413,0.41548815713460413,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097111496244944,0.4097227036395148,0.3996129404968227,0.3996129404968227,0.3953495089543617,0.3953495089543617,0.3953495089543617,0.39259965337954933,0.39259965337954933,0.39259965337954933,0.39122472559214316,0.4131773541305602,0.4131773541305602,0.4131773541305602,0.4131773541305602,0.41548815713460413,0.41548815713460413,0.3833217793183128,0.3833217793183128,0.3833217793183128,0.3785153090699017,0.3833217793183128,0.3833217793183128,0.39826112073945696,0.39567302137492755,0.373419988445985,0.39567302137492755,0.39567302137492755,0.3815077989601387,0.3815077989601387,0.3815077989601387,0.3764702484113228,0.3764702484113228,0.37403235124205636,0.37403235124205636,0.37403235124205636,0.37400924321201595,0.37400924321201595,0.37273830155979193,0.3594165222414786,0.3594165222414786,0.3554072790294627,0.3554072790294627,0.3594165222414786,0.34383015597920275,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.3206065857885616,0.3206065857885616,0.30557481224725574,0.2870421721548237,0.2870421721548237,0.2715713460427499,0.25202195262853844,0.24357596764875802,0.24357596764875802,0.25142114384748704,0.2870421721548237,0.30557481224725574,0.30557481224725574,0.30557481224725574,0.30557481224725574,0.30557481224725574,0.30557481224725574,0.3197515886770651,0.3195667244367417,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.31976314269208556,0.31976314269208556,0.28608318890814555,0.28608318890814555,0.31976314269208556,0.31976314269208556,0.31976314269208556,0.31976314269208556,0.31976314269208556,0.31976314269208556,0.31976314269208556,0.34270941652224163,0.32295205083766587,0.32295205083766587,0.32295205083766587,0.326476025418833,0.326476025418833,0.326476025418833,0.326476025418833,0.326476025418833,0.326476025418833,0.326476025418833,0.326476025418833,0.32532062391681105,0.3276429809358749,0.3276429809358749,0.3276429809358749,0.3276429809358749,0.3276429809358749,0.3276429809358749,0.3276429809358749,0.33896591565569023,0.3594049682264586,0.345043327556326,0.345043327556326,0.345043327556326,0.345043327556326,0.345043327556326,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.3594165222414786,0.37354708261120706,0.37354708261120706,0.37354708261120706,0.37354708261120706,0.34833622183708846,0.3956614673599076,0.3763547082611207,0.3763547082611207,0.3763547082611207,0.3763084922010399,0.3763084922010399,0.3763084922010399,0.3763547082611207,0.3763547082611207,0.36678798382437877,0.36678798382437877,0.36678798382437877,0.36678798382437877,0.36678798382437877,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.3612767186597341,0.33679376083188883,0.33679376083188883,0.33679376083188883,0.33679376083188883,0.33679376083188883,0.33679376083188883,0.33679376083188883,0.33679376083188883,0.33679376083188883,0.3374638937030615,0.3374638937030615,0.3374638937030615,0.3374638937030615,0.3374638937030615,0.3374638937030615,0.3207452339688041,0.3207452339688041,0.3207452339688041,0.3207452339688041,0.2803986135181975,0.2803986135181975,0.2803986135181975,0.2803986135181975,0.2803986135181975,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3195898324667822,0.3207452339688041,0.32909878682842286,0.32909878682842286,0.3374638937030615,0.3374638937030615,0.34387637203928356,0.34387637203928356,0.34387637203928356,0.34387637203928356,0.34387637203928356,0.34387637203928356,0.3611842865395724,0.3611842865395724,0.3611842865395724,0.3611842865395724,0.3611842865395724,0.3611842865395724,0.3611842865395724,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.3450548815713459,0.38396880415944507,0.38396880415944507,0.38396880415944507,0.41548815713460413,0.4157770075101096,0.4157770075101096,0.4157770075101096,0.4157770075101096,0.4157770075101096,0.4157770075101096,0.4157770075101096,0.4157770075101096,0.399543616406701,0.399543616406701,0.399543616406701,0.399543616406701,0.399543616406701,0.399543616406701,0.399543616406701,0.399543616406701,0.399543616406701,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.3385037550548814,0.38313691507798947,0.38313691507798947,0.38313691507798947,0.35946273830155995,0.35946273830155995,0.35946273830155995,0.35946273830155995,0.35946273830155995,0.35946273830155995,0.35946273830155995,0.35946273830155995,0.35946273830155995,0.32141536683997673,0.32141536683997673,0.32141536683997673,0.32141536683997673,0.32141536683997673,0.32141536683997673,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.32141536683997673,0.30004043905257066,0.30004043905257066,0.30004043905257066,0.30004043905257066,0.30004043905257066,0.3208607741190062,0.3208607741190062,0.3208607741190062,0.3208607741190062,0.3208607741190062,0.3208607741190062,0.3208607741190062,0.3208607741190062,0.32141536683997673,0.32141536683997673,0.32141536683997673,0.32141536683997673,0.33923165800115535,0.3588734835355285,0.3588734835355285,0.3392432120161758,0.3392432120161758,0.326476025418833,0.326476025418833,0.3057365684575392,0.3126574234546504,0.28500866551126536,0.28500866551126536,0.3160311958405546,0.3299537839399188,0.3299537839399188,0.31953206239168086,0.31953206239168086,0.32832466782206804,0.32832466782206804,0.32832466782206804,0.265413056036973,0.3090756787983825,0.3090756787983825,0.3090756787983825,0.31001155401502023,0.31001155401502023,0.31001155401502023,0.32532062391681105,0.324061236279607,0.324061236279607,0.275407279029463,0.275407279029463,0.269838243789717,0.324061236279607,0.24357596764875802,0.28853264009243196,0.24042172154823807,0.21389370306181402,0.245574812247256,0.2871808203350662,0.28714615829000584,0.28714615829000584,0.18508954361640695,0.18508954361640695,0.2867533217793182,0.2867533217793182,0.28673021374927776,0.28673021374927776,0.1474350086655114,0.27174465626805333,0.2095840554592721,0.2537897169266322,0.20061813980358206,0.25377816291161176,0.25377816291161176,0.25377816291161176,0.25377816291161176,0.25377816291161176,0.2717562102830733,0.2717562102830733,0.2717562102830733,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.25229924898902395,0.28737723859041003,0.28737723859041003,0.28737723859041003,0.2841767764298092,0.2841767764298092,0.30654534950895435,0.2573367995378393,0.2573367995378393,0.2573367995378393,0.2618197573656846,0.2618197573656846,0.26183131138070503,0.32407279029462743,0.32407279029462743,0.3450202195262856,0.3588734835355285,0.3588734835355285,0.3577180820335065,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.3588734835355285,0.38752744078567314,0.38752744078567314,0.38752744078567314,0.374852686308492,0.38752744078567314,0.37222992489890216,0.41548815713460413,0.4305083766608895,0.41548815713460413,0.4305083766608895,0.4250202195262852,0.4250202195262852,0.4250202195262852,0.4305083766608895,0.4250202195262852,0.4305083766608895,0.4305083766608895,0.4305083766608895,0.4081398035817444,0.4305083766608895,0.4305083766608895,0.4193240901213172,0.4305083766608895,0.4305083766608895,0.4305083766608895,0.4305083766608895,0.4305083766608895,0.43628538417099927,0.43628538417099927,0.43628538417099927,0.43628538417099927,0.43628538417099927,0.4226169844020796,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.38997689196995955,0.4328191796649334,0.43628538417099927,0.43628538417099927,0.3899884459849795,0.38997689196995955,0.3899884459849795,0.3899884459849795,0.3899884459849795,0.43603119584055416,0.43137492778740594,0.43135181975736553,0.43137492778740594,0.4313633737723855,0.4313633737723855,0.416955517042172,0.416955517042172,0.416955517042172,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.39724436741767755,0.3617504332755629,0.3667764298093588,0.3667764298093588,0.3970017331022529,0.3970017331022529,0.3970017331022529,0.37355863662622757,0.33657423454650465,0.33657423454650465,0.33657423454650465,0.33657423454650465,0.35573079145002906,0.35573079145002906,0.3970017331022529,0.3970017331022529,0.3970017331022529,0.3970017331022529,0.36373772385904096,0.39967071057192355,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37273830155979193,0.37273830155979193,0.37273830155979193,0.35218370883882144,0.35218370883882144,0.35218370883882144,0.35218370883882144,0.37273830155979193,0.37273830155979193,0.37273830155979193,0.37273830155979193,0.37273830155979193,0.37273830155979193,0.37273830155979193,0.3667071057192376,0.3667071057192376,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.37292316580011525,0.3667071057192376,0.3667071057192376,0.3667071057192376,0.3667071057192376,0.3667071057192376,0.3667071057192376,0.3667071057192376,0.3667071057192376,0.3667071057192376,0.3697458116695549,0.3697458116695549,0.3623859041016752,0.3697458116695549,0.3697458116695549,0.37295782784517617,0.37295782784517617,0.37295782784517617,0.3940439052570768,0.3940439052570768,0.3940439052570768,0.3940439052570768,0.39403235124205627,0.3940439052570768,0.3940439052570768,0.3731773541305604,0.3731773541305604,0.3672270363951472,0.37816868861929487,0.37816868861929487,0.37816868861929487,0.37816868861929487,0.3777411900635469,0.3672270363951472,0.3672270363951472,0.3672270363951472,0.3566320046216058,0.3566320046216058,0.3566320046216058,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.34034084344309645,0.3156845753899478,0.3156845753899478,0.3156961294049683,0.3156961294049683,0.3156961294049683,0.3156961294049683,0.3156961294049683,0.310935875216638,0.310935875216638,0.310935875216638,0.310935875216638,0.310935875216638,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2951530906990178,0.2884517619872908,0.2884517619872908,0.2884517619872908,0.2884517619872908,0.2884517619872908,0.2884517619872908,0.2884517619872908,0.2884517619872908,0.2884517619872908,0.3625592143269786,0.3625592143269786,0.34736568457538985,0.34736568457538985,0.34736568457538985,0.34736568457538985,0.3781571346042749,0.3781571346042749,0.31419410745233955,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.34385326400924315,0.34385326400924315,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.3781571346042749,0.34830155979202754,0.33220681686886194,0.34830155979202754,0.34830155979202754,0.34830155979202754,0.34830155979202754,0.34830155979202754,0.3218775274407856,0.2669035239745813,0.2669035239745813,0.26691507798960123,0.26691507798960123,0.26691507798960123,0.30917966493356414,0.30917966493356414,0.30917966493356414,0.30917966493356414,0.30917966493356414,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3075621028307338,0.3075621028307338,0.3207452339688041,0.3207452339688041,0.3207452339688041,0.29382437897169245,0.3207452339688041,0.3207452339688041,0.30341421143847486,0.30341421143847486,0.30341421143847486,0.30341421143847486,0.30341421143847486,0.30341421143847486,0.30341421143847486,0.29417099942229924,0.29417099942229924,0.29417099942229924,0.29417099942229924,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.3218775274407856,0.37734835355285923,0.37734835355285923,0.37734835355285923,0.37734835355285923,0.37734835355285923,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3371172732524552,0.3371172732524552,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.3523685730791448,0.37403235124205636,0.37403235124205636,0.37403235124205636,0.37403235124205636,0.37404390525707687,0.37404390525707687,0.37404390525707687,0.3785153090699017,0.3785153090699017,0.3972328134026571,0.3972328134026571,0.379844020797227,0.379844020797227,0.379844020797227,0.38022530329289417,0.38022530329289417,0.38022530329289417,0.41202195262853825,0.41202195262853825,0.41202195262853825,0.41202195262853825,0.41202195262853825,0.41202195262853825,0.41202195262853825,0.41202195262853825,0.4108665511265163,0.4108665511265163,0.4108665511265163,0.43166377816291146,0.43166377816291146,0.43166377816291146,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4113980358174465,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4204448295782782,0.4235759676487578,0.4235759676487578,0.4235759676487578,0.4235759676487578,0.4235759676487578,0.4408145580589254,0.4408145580589254,0.4408145580589254,0.4408145580589254,0.4408145580589254,0.4408145580589254,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4232409012131715,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4086943963027149,0.4232409012131715,0.4232409012131715,0.3802137492778737,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4235875216637782,0.4408145580589254,0.4338821490467937,0.4338821490467937,0.4338821490467937,0.4338821490467937,0.4338821490467937,0.4338821490467937,0.4338821490467937,0.4408145580589254,0.4408145580589254,0.4054477180820333,0.4054477180820333,0.3802137492778737,0.3802137492778737,0.3802137492778737,0.3802137492778737,0.3802137492778737,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4012305025996531,0.4054477180820333,0.4054477180820333,0.4006759098786825,0.4054477180820333,0.4351299826689773,0.408532640092432,0.38193529751588673,0.38348353552859626,0.408532640092432,0.3900462160600808,0.3900462160600808,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.408532640092432,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.42473136915077975,0.4940323512420559,0.4940323512420559,0.4940323512420559,0.4940323512420559,0.4940323512420559,0.4940323512420559,0.4940323512420559,0.4940323512420559,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.4940439052570763,0.48424610051993067,0.48424610051993067,0.48424610051993067,0.48424610051993067,0.48424610051993067,0.40740034662045044,0.42473136915077975,0.40651068746389357,0.40651068746389357,0.40651068746389357,0.40651068746389357,0.40651068746389357,0.40651068746389357,0.42473136915077975,0.4836568457538992,0.4836568457538992,0.4836452917388788,0.43870017331022526,0.43870017331022526,0.4825014442518773,0.4825014442518773,0.4825014442518773,0.48248989023685684,0.48248989023685684,0.48248989023685684,0.48248989023685684,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.4381224725592143,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.4602946273830151,0.4602946273830151,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.4602946273830151,0.4602946273830151,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.4602946273830151,0.4602946273830151,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.4819237435008663,0.4819237435008663,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.48247833622183633,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.4381224725592143,0.42473136915077975,0.42473136915077975,0.37158290005776995,0.4320450606585786,0.4320450606585786,0.40180820335066403,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.43088965915655664,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4202137492778741,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.4013460427498557,0.3975678798382434,0.4202137492778741,0.4202137492778741,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.4016002310803003,0.38177354130560376,0.38177354130560376,0.38177354130560376,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.416100519930676,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.4320450606585786,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.450184864240323,0.41620450606585757,0.41620450606585757,0.41620450606585757,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074,0.46481224725592074],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"variable=train_predicted_close\\u003cbr\\u003eDate=%{x}\\u003cbr\\u003eStock price=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"train_predicted_close\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Train predicted close price\",\"showlegend\":true,\"x\":[\"2017-08-19 00:00:00\",\"2017-08-19 00:01:00\",\"2017-08-19 00:02:00\",\"2017-08-19 00:03:00\",\"2017-08-19 00:04:00\",\"2017-08-19 00:05:00\",\"2017-08-19 00:06:00\",\"2017-08-19 00:07:00\",\"2017-08-19 00:08:00\",\"2017-08-19 00:09:00\",\"2017-08-19 00:10:00\",\"2017-08-19 00:11:00\",\"2017-08-19 00:12:00\",\"2017-08-19 00:13:00\",\"2017-08-19 00:14:00\",\"2017-08-19 00:15:00\",\"2017-08-19 00:16:00\",\"2017-08-19 00:17:00\",\"2017-08-19 00:18:00\",\"2017-08-19 00:19:00\",\"2017-08-19 00:20:00\",\"2017-08-19 00:21:00\",\"2017-08-19 00:22:00\",\"2017-08-19 00:23:00\",\"2017-08-19 00:24:00\",\"2017-08-19 00:25:00\",\"2017-08-19 00:26:00\",\"2017-08-19 00:27:00\",\"2017-08-19 00:28:00\",\"2017-08-19 00:29:00\",\"2017-08-19 00:30:00\",\"2017-08-19 00:31:00\",\"2017-08-19 00:32:00\",\"2017-08-19 00:33:00\",\"2017-08-19 00:34:00\",\"2017-08-19 00:35:00\",\"2017-08-19 00:36:00\",\"2017-08-19 00:37:00\",\"2017-08-19 00:38:00\",\"2017-08-19 00:39:00\",\"2017-08-19 00:40:00\",\"2017-08-19 00:41:00\",\"2017-08-19 00:42:00\",\"2017-08-19 00:43:00\",\"2017-08-19 00:44:00\",\"2017-08-19 00:45:00\",\"2017-08-19 00:46:00\",\"2017-08-19 00:47:00\",\"2017-08-19 00:48:00\",\"2017-08-19 00:49:00\",\"2017-08-19 00:50:00\",\"2017-08-19 00:51:00\",\"2017-08-19 00:52:00\",\"2017-08-19 00:53:00\",\"2017-08-19 00:54:00\",\"2017-08-19 00:55:00\",\"2017-08-19 00:56:00\",\"2017-08-19 00:57:00\",\"2017-08-19 00:58:00\",\"2017-08-19 00:59:00\",\"2017-08-19 01:00:00\",\"2017-08-19 01:01:00\",\"2017-08-19 01:02:00\",\"2017-08-19 01:03:00\",\"2017-08-19 01:04:00\",\"2017-08-19 01:05:00\",\"2017-08-19 01:06:00\",\"2017-08-19 01:07:00\",\"2017-08-19 01:08:00\",\"2017-08-19 01:09:00\",\"2017-08-19 01:10:00\",\"2017-08-19 01:11:00\",\"2017-08-19 01:12:00\",\"2017-08-19 01:13:00\",\"2017-08-19 01:14:00\",\"2017-08-19 01:15:00\",\"2017-08-19 01:16:00\",\"2017-08-19 01:17:00\",\"2017-08-19 01:18:00\",\"2017-08-19 01:19:00\",\"2017-08-19 01:20:00\",\"2017-08-19 01:21:00\",\"2017-08-19 01:22:00\",\"2017-08-19 01:23:00\",\"2017-08-19 01:24:00\",\"2017-08-19 01:25:00\",\"2017-08-19 01:26:00\",\"2017-08-19 01:27:00\",\"2017-08-19 01:28:00\",\"2017-08-19 01:29:00\",\"2017-08-19 01:30:00\",\"2017-08-19 01:31:00\",\"2017-08-19 01:32:00\",\"2017-08-19 01:33:00\",\"2017-08-19 01:34:00\",\"2017-08-19 01:35:00\",\"2017-08-19 01:36:00\",\"2017-08-19 01:37:00\",\"2017-08-19 01:38:00\",\"2017-08-19 01:39:00\",\"2017-08-19 01:40:00\",\"2017-08-19 01:41:00\",\"2017-08-19 01:42:00\",\"2017-08-19 01:43:00\",\"2017-08-19 01:44:00\",\"2017-08-19 01:45:00\",\"2017-08-19 01:46:00\",\"2017-08-19 01:47:00\",\"2017-08-19 01:48:00\",\"2017-08-19 01:49:00\",\"2017-08-19 01:50:00\",\"2017-08-19 01:51:00\",\"2017-08-19 01:52:00\",\"2017-08-19 01:53:00\",\"2017-08-19 01:54:00\",\"2017-08-19 01:55:00\",\"2017-08-19 01:56:00\",\"2017-08-19 01:57:00\",\"2017-08-19 01:58:00\",\"2017-08-19 01:59:00\",\"2017-08-19 02:00:00\",\"2017-08-19 02:01:00\",\"2017-08-19 02:02:00\",\"2017-08-19 02:03:00\",\"2017-08-19 02:04:00\",\"2017-08-19 02:05:00\",\"2017-08-19 02:06:00\",\"2017-08-19 02:07:00\",\"2017-08-19 02:08:00\",\"2017-08-19 02:09:00\",\"2017-08-19 02:10:00\",\"2017-08-19 02:11:00\",\"2017-08-19 02:12:00\",\"2017-08-19 02:13:00\",\"2017-08-19 02:14:00\",\"2017-08-19 02:15:00\",\"2017-08-19 02:16:00\",\"2017-08-19 02:17:00\",\"2017-08-19 02:18:00\",\"2017-08-19 02:19:00\",\"2017-08-19 02:20:00\",\"2017-08-19 02:21:00\",\"2017-08-19 02:22:00\",\"2017-08-19 02:23:00\",\"2017-08-19 02:24:00\",\"2017-08-19 02:25:00\",\"2017-08-19 02:26:00\",\"2017-08-19 02:27:00\",\"2017-08-19 02:28:00\",\"2017-08-19 02:29:00\",\"2017-08-19 02:30:00\",\"2017-08-19 02:31:00\",\"2017-08-19 02:32:00\",\"2017-08-19 02:33:00\",\"2017-08-19 02:34:00\",\"2017-08-19 02:35:00\",\"2017-08-19 02:36:00\",\"2017-08-19 02:37:00\",\"2017-08-19 02:38:00\",\"2017-08-19 02:39:00\",\"2017-08-19 02:40:00\",\"2017-08-19 02:41:00\",\"2017-08-19 02:42:00\",\"2017-08-19 02:43:00\",\"2017-08-19 02:44:00\",\"2017-08-19 02:45:00\",\"2017-08-19 02:46:00\",\"2017-08-19 02:47:00\",\"2017-08-19 02:48:00\",\"2017-08-19 02:49:00\",\"2017-08-19 02:50:00\",\"2017-08-19 02:51:00\",\"2017-08-19 02:52:00\",\"2017-08-19 02:53:00\",\"2017-08-19 02:54:00\",\"2017-08-19 02:55:00\",\"2017-08-19 02:56:00\",\"2017-08-19 02:57:00\",\"2017-08-19 02:58:00\",\"2017-08-19 02:59:00\",\"2017-08-19 03:00:00\",\"2017-08-19 03:01:00\",\"2017-08-19 03:02:00\",\"2017-08-19 03:03:00\",\"2017-08-19 03:04:00\",\"2017-08-19 03:05:00\",\"2017-08-19 03:06:00\",\"2017-08-19 03:07:00\",\"2017-08-19 03:08:00\",\"2017-08-19 03:09:00\",\"2017-08-19 03:10:00\",\"2017-08-19 03:11:00\",\"2017-08-19 03:12:00\",\"2017-08-19 03:13:00\",\"2017-08-19 03:14:00\",\"2017-08-19 03:15:00\",\"2017-08-19 03:16:00\",\"2017-08-19 03:17:00\",\"2017-08-19 03:18:00\",\"2017-08-19 03:19:00\",\"2017-08-19 03:20:00\",\"2017-08-19 03:21:00\",\"2017-08-19 03:22:00\",\"2017-08-19 03:23:00\",\"2017-08-19 03:24:00\",\"2017-08-19 03:25:00\",\"2017-08-19 03:26:00\",\"2017-08-19 03:27:00\",\"2017-08-19 03:28:00\",\"2017-08-19 03:29:00\",\"2017-08-19 03:30:00\",\"2017-08-19 03:31:00\",\"2017-08-19 03:32:00\",\"2017-08-19 03:33:00\",\"2017-08-19 03:34:00\",\"2017-08-19 03:35:00\",\"2017-08-19 03:36:00\",\"2017-08-19 03:37:00\",\"2017-08-19 03:38:00\",\"2017-08-19 03:39:00\",\"2017-08-19 03:40:00\",\"2017-08-19 03:41:00\",\"2017-08-19 03:42:00\",\"2017-08-19 03:43:00\",\"2017-08-19 03:44:00\",\"2017-08-19 03:45:00\",\"2017-08-19 03:46:00\",\"2017-08-19 03:47:00\",\"2017-08-19 03:48:00\",\"2017-08-19 03:49:00\",\"2017-08-19 03:50:00\",\"2017-08-19 03:51:00\",\"2017-08-19 03:52:00\",\"2017-08-19 03:53:00\",\"2017-08-19 03:54:00\",\"2017-08-19 03:55:00\",\"2017-08-19 03:56:00\",\"2017-08-19 03:57:00\",\"2017-08-19 03:58:00\",\"2017-08-19 03:59:00\",\"2017-08-19 04:00:00\",\"2017-08-19 04:01:00\",\"2017-08-19 04:02:00\",\"2017-08-19 04:03:00\",\"2017-08-19 04:04:00\",\"2017-08-19 04:05:00\",\"2017-08-19 04:06:00\",\"2017-08-19 04:07:00\",\"2017-08-19 04:08:00\",\"2017-08-19 04:09:00\",\"2017-08-19 04:10:00\",\"2017-08-19 04:11:00\",\"2017-08-19 04:12:00\",\"2017-08-19 04:13:00\",\"2017-08-19 04:14:00\",\"2017-08-19 04:15:00\",\"2017-08-19 04:16:00\",\"2017-08-19 04:17:00\",\"2017-08-19 04:18:00\",\"2017-08-19 04:19:00\",\"2017-08-19 04:20:00\",\"2017-08-19 04:21:00\",\"2017-08-19 04:22:00\",\"2017-08-19 04:23:00\",\"2017-08-19 04:24:00\",\"2017-08-19 04:25:00\",\"2017-08-19 04:26:00\",\"2017-08-19 04:27:00\",\"2017-08-19 04:28:00\",\"2017-08-19 04:29:00\",\"2017-08-19 04:30:00\",\"2017-08-19 04:31:00\",\"2017-08-19 04:32:00\",\"2017-08-19 04:33:00\",\"2017-08-19 04:34:00\",\"2017-08-19 04:35:00\",\"2017-08-19 04:36:00\",\"2017-08-19 04:37:00\",\"2017-08-19 04:38:00\",\"2017-08-19 04:39:00\",\"2017-08-19 04:40:00\",\"2017-08-19 04:41:00\",\"2017-08-19 04:42:00\",\"2017-08-19 04:43:00\",\"2017-08-19 04:44:00\",\"2017-08-19 04:45:00\",\"2017-08-19 04:46:00\",\"2017-08-19 04:47:00\",\"2017-08-19 04:48:00\",\"2017-08-19 04:49:00\",\"2017-08-19 04:50:00\",\"2017-08-19 04:51:00\",\"2017-08-19 04:52:00\",\"2017-08-19 04:53:00\",\"2017-08-19 04:54:00\",\"2017-08-19 04:55:00\",\"2017-08-19 04:56:00\",\"2017-08-19 04:57:00\",\"2017-08-19 04:58:00\",\"2017-08-19 04:59:00\",\"2017-08-19 05:00:00\",\"2017-08-19 05:01:00\",\"2017-08-19 05:02:00\",\"2017-08-19 05:03:00\",\"2017-08-19 05:04:00\",\"2017-08-19 05:05:00\",\"2017-08-19 05:06:00\",\"2017-08-19 05:07:00\",\"2017-08-19 05:08:00\",\"2017-08-19 05:09:00\",\"2017-08-19 05:10:00\",\"2017-08-19 05:11:00\",\"2017-08-19 05:12:00\",\"2017-08-19 05:13:00\",\"2017-08-19 05:14:00\",\"2017-08-19 05:15:00\",\"2017-08-19 05:16:00\",\"2017-08-19 05:17:00\",\"2017-08-19 05:18:00\",\"2017-08-19 05:19:00\",\"2017-08-19 05:20:00\",\"2017-08-19 05:21:00\",\"2017-08-19 05:22:00\",\"2017-08-19 05:23:00\",\"2017-08-19 05:24:00\",\"2017-08-19 05:25:00\",\"2017-08-19 05:26:00\",\"2017-08-19 05:27:00\",\"2017-08-19 05:28:00\",\"2017-08-19 05:29:00\",\"2017-08-19 05:30:00\",\"2017-08-19 05:31:00\",\"2017-08-19 05:32:00\",\"2017-08-19 05:33:00\",\"2017-08-19 05:34:00\",\"2017-08-19 05:35:00\",\"2017-08-19 05:36:00\",\"2017-08-19 05:37:00\",\"2017-08-19 05:38:00\",\"2017-08-19 05:39:00\",\"2017-08-19 05:40:00\",\"2017-08-19 05:41:00\",\"2017-08-19 05:42:00\",\"2017-08-19 05:43:00\",\"2017-08-19 05:44:00\",\"2017-08-19 05:45:00\",\"2017-08-19 05:46:00\",\"2017-08-19 05:47:00\",\"2017-08-19 05:48:00\",\"2017-08-19 05:49:00\",\"2017-08-19 05:50:00\",\"2017-08-19 05:51:00\",\"2017-08-19 05:52:00\",\"2017-08-19 05:53:00\",\"2017-08-19 05:54:00\",\"2017-08-19 05:55:00\",\"2017-08-19 05:56:00\",\"2017-08-19 05:57:00\",\"2017-08-19 05:58:00\",\"2017-08-19 05:59:00\",\"2017-08-19 06:00:00\",\"2017-08-19 06:01:00\",\"2017-08-19 06:02:00\",\"2017-08-19 06:03:00\",\"2017-08-19 06:04:00\",\"2017-08-19 06:05:00\",\"2017-08-19 06:06:00\",\"2017-08-19 06:07:00\",\"2017-08-19 06:08:00\",\"2017-08-19 06:09:00\",\"2017-08-19 06:10:00\",\"2017-08-19 06:11:00\",\"2017-08-19 06:12:00\",\"2017-08-19 06:13:00\",\"2017-08-19 06:14:00\",\"2017-08-19 06:15:00\",\"2017-08-19 06:16:00\",\"2017-08-19 06:17:00\",\"2017-08-19 06:18:00\",\"2017-08-19 06:19:00\",\"2017-08-19 06:20:00\",\"2017-08-19 06:21:00\",\"2017-08-19 06:22:00\",\"2017-08-19 06:23:00\",\"2017-08-19 06:24:00\",\"2017-08-19 06:25:00\",\"2017-08-19 06:26:00\",\"2017-08-19 06:27:00\",\"2017-08-19 06:28:00\",\"2017-08-19 06:29:00\",\"2017-08-19 06:30:00\",\"2017-08-19 06:31:00\",\"2017-08-19 06:32:00\",\"2017-08-19 06:33:00\",\"2017-08-19 06:34:00\",\"2017-08-19 06:35:00\",\"2017-08-19 06:36:00\",\"2017-08-19 06:37:00\",\"2017-08-19 06:38:00\",\"2017-08-19 06:39:00\",\"2017-08-19 06:40:00\",\"2017-08-19 06:41:00\",\"2017-08-19 06:42:00\",\"2017-08-19 06:43:00\",\"2017-08-19 06:44:00\",\"2017-08-19 06:45:00\",\"2017-08-19 06:46:00\",\"2017-08-19 06:47:00\",\"2017-08-19 06:48:00\",\"2017-08-19 06:49:00\",\"2017-08-19 06:50:00\",\"2017-08-19 06:51:00\",\"2017-08-19 06:52:00\",\"2017-08-19 06:53:00\",\"2017-08-19 06:54:00\",\"2017-08-19 06:55:00\",\"2017-08-19 06:56:00\",\"2017-08-19 06:57:00\",\"2017-08-19 06:58:00\",\"2017-08-19 06:59:00\",\"2017-08-19 07:00:00\",\"2017-08-19 07:01:00\",\"2017-08-19 07:02:00\",\"2017-08-19 07:03:00\",\"2017-08-19 07:04:00\",\"2017-08-19 07:05:00\",\"2017-08-19 07:06:00\",\"2017-08-19 07:07:00\",\"2017-08-19 07:08:00\",\"2017-08-19 07:09:00\",\"2017-08-19 07:10:00\",\"2017-08-19 07:11:00\",\"2017-08-19 07:12:00\",\"2017-08-19 07:13:00\",\"2017-08-19 07:14:00\",\"2017-08-19 07:15:00\",\"2017-08-19 07:16:00\",\"2017-08-19 07:17:00\",\"2017-08-19 07:18:00\",\"2017-08-19 07:19:00\",\"2017-08-19 07:20:00\",\"2017-08-19 07:21:00\",\"2017-08-19 07:22:00\",\"2017-08-19 07:23:00\",\"2017-08-19 07:24:00\",\"2017-08-19 07:25:00\",\"2017-08-19 07:26:00\",\"2017-08-19 07:27:00\",\"2017-08-19 07:28:00\",\"2017-08-19 07:29:00\",\"2017-08-19 07:30:00\",\"2017-08-19 07:31:00\",\"2017-08-19 07:32:00\",\"2017-08-19 07:33:00\",\"2017-08-19 07:34:00\",\"2017-08-19 07:35:00\",\"2017-08-19 07:36:00\",\"2017-08-19 07:37:00\",\"2017-08-19 07:38:00\",\"2017-08-19 07:39:00\",\"2017-08-19 07:40:00\",\"2017-08-19 07:41:00\",\"2017-08-19 07:42:00\",\"2017-08-19 07:43:00\",\"2017-08-19 07:44:00\",\"2017-08-19 07:45:00\",\"2017-08-19 07:46:00\",\"2017-08-19 07:47:00\",\"2017-08-19 07:48:00\",\"2017-08-19 07:49:00\",\"2017-08-19 07:50:00\",\"2017-08-19 07:51:00\",\"2017-08-19 07:52:00\",\"2017-08-19 07:53:00\",\"2017-08-19 07:54:00\",\"2017-08-19 07:55:00\",\"2017-08-19 07:56:00\",\"2017-08-19 07:57:00\",\"2017-08-19 07:58:00\",\"2017-08-19 07:59:00\",\"2017-08-19 08:00:00\",\"2017-08-19 08:01:00\",\"2017-08-19 08:02:00\",\"2017-08-19 08:03:00\",\"2017-08-19 08:04:00\",\"2017-08-19 08:05:00\",\"2017-08-19 08:06:00\",\"2017-08-19 08:07:00\",\"2017-08-19 08:08:00\",\"2017-08-19 08:09:00\",\"2017-08-19 08:10:00\",\"2017-08-19 08:11:00\",\"2017-08-19 08:12:00\",\"2017-08-19 08:13:00\",\"2017-08-19 08:14:00\",\"2017-08-19 08:15:00\",\"2017-08-19 08:16:00\",\"2017-08-19 08:17:00\",\"2017-08-19 08:18:00\",\"2017-08-19 08:19:00\",\"2017-08-19 08:20:00\",\"2017-08-19 08:21:00\",\"2017-08-19 08:22:00\",\"2017-08-19 08:23:00\",\"2017-08-19 08:24:00\",\"2017-08-19 08:25:00\",\"2017-08-19 08:26:00\",\"2017-08-19 08:27:00\",\"2017-08-19 08:28:00\",\"2017-08-19 08:29:00\",\"2017-08-19 08:30:00\",\"2017-08-19 08:31:00\",\"2017-08-19 08:32:00\",\"2017-08-19 08:33:00\",\"2017-08-19 08:34:00\",\"2017-08-19 08:35:00\",\"2017-08-19 08:36:00\",\"2017-08-19 08:37:00\",\"2017-08-19 08:38:00\",\"2017-08-19 08:39:00\",\"2017-08-19 08:40:00\",\"2017-08-19 08:41:00\",\"2017-08-19 08:42:00\",\"2017-08-19 08:43:00\",\"2017-08-19 08:44:00\",\"2017-08-19 08:45:00\",\"2017-08-19 08:46:00\",\"2017-08-19 08:47:00\",\"2017-08-19 08:48:00\",\"2017-08-19 08:49:00\",\"2017-08-19 08:50:00\",\"2017-08-19 08:51:00\",\"2017-08-19 08:52:00\",\"2017-08-19 08:53:00\",\"2017-08-19 08:54:00\",\"2017-08-19 08:55:00\",\"2017-08-19 08:56:00\",\"2017-08-19 08:57:00\",\"2017-08-19 08:58:00\",\"2017-08-19 08:59:00\",\"2017-08-19 09:00:00\",\"2017-08-19 09:01:00\",\"2017-08-19 09:02:00\",\"2017-08-19 09:03:00\",\"2017-08-19 09:04:00\",\"2017-08-19 09:05:00\",\"2017-08-19 09:06:00\",\"2017-08-19 09:07:00\",\"2017-08-19 09:08:00\",\"2017-08-19 09:09:00\",\"2017-08-19 09:10:00\",\"2017-08-19 09:11:00\",\"2017-08-19 09:12:00\",\"2017-08-19 09:13:00\",\"2017-08-19 09:14:00\",\"2017-08-19 09:15:00\",\"2017-08-19 09:16:00\",\"2017-08-19 09:17:00\",\"2017-08-19 09:18:00\",\"2017-08-19 09:19:00\",\"2017-08-19 09:20:00\",\"2017-08-19 09:21:00\",\"2017-08-19 09:22:00\",\"2017-08-19 09:23:00\",\"2017-08-19 09:24:00\",\"2017-08-19 09:25:00\",\"2017-08-19 09:26:00\",\"2017-08-19 09:27:00\",\"2017-08-19 09:28:00\",\"2017-08-19 09:29:00\",\"2017-08-19 09:30:00\",\"2017-08-19 09:31:00\",\"2017-08-19 09:32:00\",\"2017-08-19 09:33:00\",\"2017-08-19 09:34:00\",\"2017-08-19 09:35:00\",\"2017-08-19 09:36:00\",\"2017-08-19 09:37:00\",\"2017-08-19 09:38:00\",\"2017-08-19 09:39:00\",\"2017-08-19 09:40:00\",\"2017-08-19 09:41:00\",\"2017-08-19 09:42:00\",\"2017-08-19 09:43:00\",\"2017-08-19 09:44:00\",\"2017-08-19 09:45:00\",\"2017-08-19 09:46:00\",\"2017-08-19 09:47:00\",\"2017-08-19 09:48:00\",\"2017-08-19 09:49:00\",\"2017-08-19 09:50:00\",\"2017-08-19 09:51:00\",\"2017-08-19 09:52:00\",\"2017-08-19 09:53:00\",\"2017-08-19 09:54:00\",\"2017-08-19 09:55:00\",\"2017-08-19 09:56:00\",\"2017-08-19 09:57:00\",\"2017-08-19 09:58:00\",\"2017-08-19 09:59:00\",\"2017-08-19 10:00:00\",\"2017-08-19 10:01:00\",\"2017-08-19 10:02:00\",\"2017-08-19 10:03:00\",\"2017-08-19 10:04:00\",\"2017-08-19 10:05:00\",\"2017-08-19 10:06:00\",\"2017-08-19 10:07:00\",\"2017-08-19 10:08:00\",\"2017-08-19 10:09:00\",\"2017-08-19 10:10:00\",\"2017-08-19 10:11:00\",\"2017-08-19 10:12:00\",\"2017-08-19 10:13:00\",\"2017-08-19 10:14:00\",\"2017-08-19 10:15:00\",\"2017-08-19 10:16:00\",\"2017-08-19 10:17:00\",\"2017-08-19 10:18:00\",\"2017-08-19 10:19:00\",\"2017-08-19 10:20:00\",\"2017-08-19 10:21:00\",\"2017-08-19 10:22:00\",\"2017-08-19 10:23:00\",\"2017-08-19 10:24:00\",\"2017-08-19 10:25:00\",\"2017-08-19 10:26:00\",\"2017-08-19 10:27:00\",\"2017-08-19 10:28:00\",\"2017-08-19 10:29:00\",\"2017-08-19 10:30:00\",\"2017-08-19 10:31:00\",\"2017-08-19 10:32:00\",\"2017-08-19 10:33:00\",\"2017-08-19 10:34:00\",\"2017-08-19 10:35:00\",\"2017-08-19 10:36:00\",\"2017-08-19 10:37:00\",\"2017-08-19 10:38:00\",\"2017-08-19 10:39:00\",\"2017-08-19 10:40:00\",\"2017-08-19 10:41:00\",\"2017-08-19 10:42:00\",\"2017-08-19 10:43:00\",\"2017-08-19 10:44:00\",\"2017-08-19 10:45:00\",\"2017-08-19 10:46:00\",\"2017-08-19 10:47:00\",\"2017-08-19 10:48:00\",\"2017-08-19 10:49:00\",\"2017-08-19 10:50:00\",\"2017-08-19 10:51:00\",\"2017-08-19 10:52:00\",\"2017-08-19 10:53:00\",\"2017-08-19 10:54:00\",\"2017-08-19 10:55:00\",\"2017-08-19 10:56:00\",\"2017-08-19 10:57:00\",\"2017-08-19 10:58:00\",\"2017-08-19 10:59:00\",\"2017-08-19 11:00:00\",\"2017-08-19 11:01:00\",\"2017-08-19 11:02:00\",\"2017-08-19 11:03:00\",\"2017-08-19 11:04:00\",\"2017-08-19 11:05:00\",\"2017-08-19 11:06:00\",\"2017-08-19 11:07:00\",\"2017-08-19 11:08:00\",\"2017-08-19 11:09:00\",\"2017-08-19 11:10:00\",\"2017-08-19 11:11:00\",\"2017-08-19 11:12:00\",\"2017-08-19 11:13:00\",\"2017-08-19 11:14:00\",\"2017-08-19 11:15:00\",\"2017-08-19 11:16:00\",\"2017-08-19 11:17:00\",\"2017-08-19 11:18:00\",\"2017-08-19 11:19:00\",\"2017-08-19 11:20:00\",\"2017-08-19 11:21:00\",\"2017-08-19 11:22:00\",\"2017-08-19 11:23:00\",\"2017-08-19 11:24:00\",\"2017-08-19 11:25:00\",\"2017-08-19 11:26:00\",\"2017-08-19 11:27:00\",\"2017-08-19 11:28:00\",\"2017-08-19 11:29:00\",\"2017-08-19 11:30:00\",\"2017-08-19 11:31:00\",\"2017-08-19 11:32:00\",\"2017-08-19 11:33:00\",\"2017-08-19 11:34:00\",\"2017-08-19 11:35:00\",\"2017-08-19 11:36:00\",\"2017-08-19 11:37:00\",\"2017-08-19 11:38:00\",\"2017-08-19 11:39:00\",\"2017-08-19 11:40:00\",\"2017-08-19 11:41:00\",\"2017-08-19 11:42:00\",\"2017-08-19 11:43:00\",\"2017-08-19 11:44:00\",\"2017-08-19 11:45:00\",\"2017-08-19 11:46:00\",\"2017-08-19 11:47:00\",\"2017-08-19 11:48:00\",\"2017-08-19 11:49:00\",\"2017-08-19 11:50:00\",\"2017-08-19 11:51:00\",\"2017-08-19 11:52:00\",\"2017-08-19 11:53:00\",\"2017-08-19 11:54:00\",\"2017-08-19 11:55:00\",\"2017-08-19 11:56:00\",\"2017-08-19 11:57:00\",\"2017-08-19 11:58:00\",\"2017-08-19 11:59:00\",\"2017-08-19 12:00:00\",\"2017-08-19 12:01:00\",\"2017-08-19 12:02:00\",\"2017-08-19 12:03:00\",\"2017-08-19 12:04:00\",\"2017-08-19 12:05:00\",\"2017-08-19 12:06:00\",\"2017-08-19 12:07:00\",\"2017-08-19 12:08:00\",\"2017-08-19 12:09:00\",\"2017-08-19 12:10:00\",\"2017-08-19 12:11:00\",\"2017-08-19 12:12:00\",\"2017-08-19 12:13:00\",\"2017-08-19 12:14:00\",\"2017-08-19 12:15:00\",\"2017-08-19 12:16:00\",\"2017-08-19 12:17:00\",\"2017-08-19 12:18:00\",\"2017-08-19 12:19:00\",\"2017-08-19 12:20:00\",\"2017-08-19 12:21:00\",\"2017-08-19 12:22:00\",\"2017-08-19 12:23:00\",\"2017-08-19 12:24:00\",\"2017-08-19 12:25:00\",\"2017-08-19 12:26:00\",\"2017-08-19 12:27:00\",\"2017-08-19 12:28:00\",\"2017-08-19 12:29:00\",\"2017-08-19 12:30:00\",\"2017-08-19 12:31:00\",\"2017-08-19 12:32:00\",\"2017-08-19 12:33:00\",\"2017-08-19 12:34:00\",\"2017-08-19 12:35:00\",\"2017-08-19 12:36:00\",\"2017-08-19 12:37:00\",\"2017-08-19 12:38:00\",\"2017-08-19 12:39:00\",\"2017-08-19 12:40:00\",\"2017-08-19 12:41:00\",\"2017-08-19 12:42:00\",\"2017-08-19 12:43:00\",\"2017-08-19 12:44:00\",\"2017-08-19 12:45:00\",\"2017-08-19 12:46:00\",\"2017-08-19 12:47:00\",\"2017-08-19 12:48:00\",\"2017-08-19 12:49:00\",\"2017-08-19 12:50:00\",\"2017-08-19 12:51:00\",\"2017-08-19 12:52:00\",\"2017-08-19 12:53:00\",\"2017-08-19 12:54:00\",\"2017-08-19 12:55:00\",\"2017-08-19 12:56:00\",\"2017-08-19 12:57:00\",\"2017-08-19 12:58:00\",\"2017-08-19 12:59:00\",\"2017-08-19 13:00:00\",\"2017-08-19 13:01:00\",\"2017-08-19 13:02:00\",\"2017-08-19 13:03:00\",\"2017-08-19 13:04:00\",\"2017-08-19 13:05:00\",\"2017-08-19 13:06:00\",\"2017-08-19 13:07:00\",\"2017-08-19 13:08:00\",\"2017-08-19 13:09:00\",\"2017-08-19 13:10:00\",\"2017-08-19 13:11:00\",\"2017-08-19 13:12:00\",\"2017-08-19 13:13:00\",\"2017-08-19 13:14:00\",\"2017-08-19 13:15:00\",\"2017-08-19 13:16:00\",\"2017-08-19 13:17:00\",\"2017-08-19 13:18:00\",\"2017-08-19 13:19:00\",\"2017-08-19 13:20:00\",\"2017-08-19 13:21:00\",\"2017-08-19 13:22:00\",\"2017-08-19 13:23:00\",\"2017-08-19 13:24:00\",\"2017-08-19 13:25:00\",\"2017-08-19 13:26:00\",\"2017-08-19 13:27:00\",\"2017-08-19 13:28:00\",\"2017-08-19 13:29:00\",\"2017-08-19 13:30:00\",\"2017-08-19 13:31:00\",\"2017-08-19 13:32:00\",\"2017-08-19 13:33:00\",\"2017-08-19 13:34:00\",\"2017-08-19 13:35:00\",\"2017-08-19 13:36:00\",\"2017-08-19 13:37:00\",\"2017-08-19 13:38:00\",\"2017-08-19 13:39:00\",\"2017-08-19 13:40:00\",\"2017-08-19 13:41:00\",\"2017-08-19 13:42:00\",\"2017-08-19 13:43:00\",\"2017-08-19 13:44:00\",\"2017-08-19 13:45:00\",\"2017-08-19 13:46:00\",\"2017-08-19 13:47:00\",\"2017-08-19 13:48:00\",\"2017-08-19 13:49:00\",\"2017-08-19 13:50:00\",\"2017-08-19 13:51:00\",\"2017-08-19 13:52:00\",\"2017-08-19 13:53:00\",\"2017-08-19 13:54:00\",\"2017-08-19 13:55:00\",\"2017-08-19 13:56:00\",\"2017-08-19 13:57:00\",\"2017-08-19 13:58:00\",\"2017-08-19 13:59:00\",\"2017-08-19 14:00:00\",\"2017-08-19 14:01:00\",\"2017-08-19 14:02:00\",\"2017-08-19 14:03:00\",\"2017-08-19 14:04:00\",\"2017-08-19 14:05:00\",\"2017-08-19 14:06:00\",\"2017-08-19 14:07:00\",\"2017-08-19 14:08:00\",\"2017-08-19 14:09:00\",\"2017-08-19 14:10:00\",\"2017-08-19 14:11:00\",\"2017-08-19 14:12:00\",\"2017-08-19 14:13:00\",\"2017-08-19 14:14:00\",\"2017-08-19 14:15:00\",\"2017-08-19 14:16:00\",\"2017-08-19 14:17:00\",\"2017-08-19 14:18:00\",\"2017-08-19 14:19:00\",\"2017-08-19 14:20:00\",\"2017-08-19 14:21:00\",\"2017-08-19 14:22:00\",\"2017-08-19 14:23:00\",\"2017-08-19 14:24:00\",\"2017-08-19 14:25:00\",\"2017-08-19 14:26:00\",\"2017-08-19 14:27:00\",\"2017-08-19 14:28:00\",\"2017-08-19 14:29:00\",\"2017-08-19 14:30:00\",\"2017-08-19 14:31:00\",\"2017-08-19 14:32:00\",\"2017-08-19 14:33:00\",\"2017-08-19 14:34:00\",\"2017-08-19 14:35:00\",\"2017-08-19 14:36:00\",\"2017-08-19 14:37:00\",\"2017-08-19 14:38:00\",\"2017-08-19 14:39:00\",\"2017-08-19 14:40:00\",\"2017-08-19 14:41:00\",\"2017-08-19 14:42:00\",\"2017-08-19 14:43:00\",\"2017-08-19 14:44:00\",\"2017-08-19 14:45:00\",\"2017-08-19 14:46:00\",\"2017-08-19 14:47:00\",\"2017-08-19 14:48:00\",\"2017-08-19 14:49:00\",\"2017-08-19 14:50:00\",\"2017-08-19 14:51:00\",\"2017-08-19 14:52:00\",\"2017-08-19 14:53:00\",\"2017-08-19 14:54:00\",\"2017-08-19 14:55:00\",\"2017-08-19 14:56:00\",\"2017-08-19 14:57:00\",\"2017-08-19 14:58:00\",\"2017-08-19 14:59:00\",\"2017-08-19 15:00:00\",\"2017-08-19 15:01:00\",\"2017-08-19 15:02:00\",\"2017-08-19 15:03:00\",\"2017-08-19 15:04:00\",\"2017-08-19 15:05:00\",\"2017-08-19 15:06:00\",\"2017-08-19 15:07:00\",\"2017-08-19 15:08:00\",\"2017-08-19 15:09:00\",\"2017-08-19 15:10:00\",\"2017-08-19 15:11:00\",\"2017-08-19 15:12:00\",\"2017-08-19 15:13:00\",\"2017-08-19 15:14:00\",\"2017-08-19 15:15:00\",\"2017-08-19 15:16:00\",\"2017-08-19 15:17:00\",\"2017-08-19 15:18:00\",\"2017-08-19 15:19:00\",\"2017-08-19 15:20:00\",\"2017-08-19 15:21:00\",\"2017-08-19 15:22:00\",\"2017-08-19 15:23:00\",\"2017-08-19 15:24:00\",\"2017-08-19 15:25:00\",\"2017-08-19 15:26:00\",\"2017-08-19 15:27:00\",\"2017-08-19 15:28:00\",\"2017-08-19 15:29:00\",\"2017-08-19 15:30:00\",\"2017-08-19 15:31:00\",\"2017-08-19 15:32:00\",\"2017-08-19 15:33:00\",\"2017-08-19 15:34:00\",\"2017-08-19 15:35:00\",\"2017-08-19 15:36:00\",\"2017-08-19 15:37:00\",\"2017-08-19 15:38:00\",\"2017-08-19 15:39:00\",\"2017-08-19 15:40:00\",\"2017-08-19 15:41:00\",\"2017-08-19 15:42:00\",\"2017-08-19 15:43:00\",\"2017-08-19 15:44:00\",\"2017-08-19 15:45:00\",\"2017-08-19 15:46:00\",\"2017-08-19 15:47:00\",\"2017-08-19 15:48:00\",\"2017-08-19 15:49:00\",\"2017-08-19 15:50:00\",\"2017-08-19 15:51:00\",\"2017-08-19 15:52:00\",\"2017-08-19 15:53:00\",\"2017-08-19 15:54:00\",\"2017-08-19 15:55:00\",\"2017-08-19 15:56:00\",\"2017-08-19 15:57:00\",\"2017-08-19 15:58:00\",\"2017-08-19 15:59:00\",\"2017-08-19 16:00:00\",\"2017-08-19 16:01:00\",\"2017-08-19 16:02:00\",\"2017-08-19 16:03:00\",\"2017-08-19 16:04:00\",\"2017-08-19 16:05:00\",\"2017-08-19 16:06:00\",\"2017-08-19 16:07:00\",\"2017-08-19 16:08:00\",\"2017-08-19 16:09:00\",\"2017-08-19 16:10:00\",\"2017-08-19 16:11:00\",\"2017-08-19 16:12:00\",\"2017-08-19 16:13:00\",\"2017-08-19 16:14:00\",\"2017-08-19 16:15:00\",\"2017-08-19 16:16:00\",\"2017-08-19 16:17:00\",\"2017-08-19 16:18:00\",\"2017-08-19 16:19:00\",\"2017-08-19 16:20:00\",\"2017-08-19 16:21:00\",\"2017-08-19 16:22:00\",\"2017-08-19 16:23:00\",\"2017-08-19 16:24:00\",\"2017-08-19 16:25:00\",\"2017-08-19 16:26:00\",\"2017-08-19 16:27:00\",\"2017-08-19 16:28:00\",\"2017-08-19 16:29:00\",\"2017-08-19 16:30:00\",\"2017-08-19 16:31:00\",\"2017-08-19 16:32:00\",\"2017-08-19 16:33:00\",\"2017-08-19 16:34:00\",\"2017-08-19 16:35:00\",\"2017-08-19 16:36:00\",\"2017-08-19 16:37:00\",\"2017-08-19 16:38:00\",\"2017-08-19 16:39:00\",\"2017-08-19 16:40:00\",\"2017-08-19 16:41:00\",\"2017-08-19 16:42:00\",\"2017-08-19 16:43:00\",\"2017-08-19 16:44:00\",\"2017-08-19 16:45:00\",\"2017-08-19 16:46:00\",\"2017-08-19 16:47:00\",\"2017-08-19 16:48:00\",\"2017-08-19 16:49:00\",\"2017-08-19 16:50:00\",\"2017-08-19 16:51:00\",\"2017-08-19 16:52:00\",\"2017-08-19 16:53:00\",\"2017-08-19 16:54:00\",\"2017-08-19 16:55:00\",\"2017-08-19 16:56:00\",\"2017-08-19 16:57:00\",\"2017-08-19 16:58:00\",\"2017-08-19 16:59:00\",\"2017-08-19 17:00:00\",\"2017-08-19 17:01:00\",\"2017-08-19 17:02:00\",\"2017-08-19 17:03:00\",\"2017-08-19 17:04:00\",\"2017-08-19 17:05:00\",\"2017-08-19 17:06:00\",\"2017-08-19 17:07:00\",\"2017-08-19 17:08:00\",\"2017-08-19 17:09:00\",\"2017-08-19 17:10:00\",\"2017-08-19 17:11:00\",\"2017-08-19 17:12:00\",\"2017-08-19 17:13:00\",\"2017-08-19 17:14:00\",\"2017-08-19 17:15:00\",\"2017-08-19 17:16:00\",\"2017-08-19 17:17:00\",\"2017-08-19 17:18:00\",\"2017-08-19 17:19:00\",\"2017-08-19 17:20:00\",\"2017-08-19 17:21:00\",\"2017-08-19 17:22:00\",\"2017-08-19 17:23:00\",\"2017-08-19 17:24:00\",\"2017-08-19 17:25:00\",\"2017-08-19 17:26:00\",\"2017-08-19 17:27:00\",\"2017-08-19 17:28:00\",\"2017-08-19 17:29:00\",\"2017-08-19 17:30:00\",\"2017-08-19 17:31:00\",\"2017-08-19 17:32:00\",\"2017-08-19 17:33:00\",\"2017-08-19 17:34:00\",\"2017-08-19 17:35:00\",\"2017-08-19 17:36:00\",\"2017-08-19 17:37:00\",\"2017-08-19 17:38:00\",\"2017-08-19 17:39:00\",\"2017-08-19 17:40:00\",\"2017-08-19 17:41:00\",\"2017-08-19 17:42:00\",\"2017-08-19 17:43:00\",\"2017-08-19 17:44:00\",\"2017-08-19 17:45:00\",\"2017-08-19 17:46:00\",\"2017-08-19 17:47:00\",\"2017-08-19 17:48:00\",\"2017-08-19 17:49:00\",\"2017-08-19 17:50:00\",\"2017-08-19 17:51:00\",\"2017-08-19 17:52:00\",\"2017-08-19 17:53:00\",\"2017-08-19 17:54:00\",\"2017-08-19 17:55:00\",\"2017-08-19 17:56:00\",\"2017-08-19 17:57:00\",\"2017-08-19 17:58:00\",\"2017-08-19 17:59:00\",\"2017-08-19 18:00:00\",\"2017-08-19 18:01:00\",\"2017-08-19 18:02:00\",\"2017-08-19 18:03:00\",\"2017-08-19 18:04:00\",\"2017-08-19 18:05:00\",\"2017-08-19 18:06:00\",\"2017-08-19 18:07:00\",\"2017-08-19 18:08:00\",\"2017-08-19 18:09:00\",\"2017-08-19 18:10:00\",\"2017-08-19 18:11:00\",\"2017-08-19 18:12:00\",\"2017-08-19 18:13:00\",\"2017-08-19 18:14:00\",\"2017-08-19 18:15:00\",\"2017-08-19 18:16:00\",\"2017-08-19 18:17:00\",\"2017-08-19 18:18:00\",\"2017-08-19 18:19:00\",\"2017-08-19 18:20:00\",\"2017-08-19 18:21:00\",\"2017-08-19 18:22:00\",\"2017-08-19 18:23:00\",\"2017-08-19 18:24:00\",\"2017-08-19 18:25:00\",\"2017-08-19 18:26:00\",\"2017-08-19 18:27:00\",\"2017-08-19 18:28:00\",\"2017-08-19 18:29:00\",\"2017-08-19 18:30:00\",\"2017-08-19 18:31:00\",\"2017-08-19 18:32:00\",\"2017-08-19 18:33:00\",\"2017-08-19 18:34:00\",\"2017-08-19 18:35:00\",\"2017-08-19 18:36:00\",\"2017-08-19 18:37:00\",\"2017-08-19 18:38:00\",\"2017-08-19 18:39:00\",\"2017-08-19 18:40:00\",\"2017-08-19 18:41:00\",\"2017-08-19 18:42:00\",\"2017-08-19 18:43:00\",\"2017-08-19 18:44:00\",\"2017-08-19 18:45:00\",\"2017-08-19 18:46:00\",\"2017-08-19 18:47:00\",\"2017-08-19 18:48:00\",\"2017-08-19 18:49:00\",\"2017-08-19 18:50:00\",\"2017-08-19 18:51:00\",\"2017-08-19 18:52:00\",\"2017-08-19 18:53:00\",\"2017-08-19 18:54:00\",\"2017-08-19 18:55:00\",\"2017-08-19 18:56:00\",\"2017-08-19 18:57:00\",\"2017-08-19 18:58:00\",\"2017-08-19 18:59:00\",\"2017-08-19 19:00:00\",\"2017-08-19 19:01:00\",\"2017-08-19 19:02:00\",\"2017-08-19 19:03:00\",\"2017-08-19 19:04:00\",\"2017-08-19 19:05:00\",\"2017-08-19 19:06:00\",\"2017-08-19 19:07:00\",\"2017-08-19 19:08:00\",\"2017-08-19 19:09:00\",\"2017-08-19 19:10:00\",\"2017-08-19 19:11:00\",\"2017-08-19 19:12:00\",\"2017-08-19 19:13:00\",\"2017-08-19 19:14:00\",\"2017-08-19 19:15:00\",\"2017-08-19 19:16:00\",\"2017-08-19 19:17:00\",\"2017-08-19 19:18:00\",\"2017-08-19 19:19:00\",\"2017-08-19 19:20:00\",\"2017-08-19 19:21:00\",\"2017-08-19 19:22:00\",\"2017-08-19 19:23:00\",\"2017-08-19 19:24:00\",\"2017-08-19 19:25:00\",\"2017-08-19 19:26:00\",\"2017-08-19 19:27:00\",\"2017-08-19 19:28:00\",\"2017-08-19 19:29:00\",\"2017-08-19 19:30:00\",\"2017-08-19 19:31:00\",\"2017-08-19 19:32:00\",\"2017-08-19 19:33:00\",\"2017-08-19 19:34:00\",\"2017-08-19 19:35:00\",\"2017-08-19 19:36:00\",\"2017-08-19 19:37:00\",\"2017-08-19 19:38:00\",\"2017-08-19 19:39:00\",\"2017-08-19 19:40:00\",\"2017-08-19 19:41:00\",\"2017-08-19 19:42:00\",\"2017-08-19 19:43:00\",\"2017-08-19 19:44:00\",\"2017-08-19 19:45:00\",\"2017-08-19 19:46:00\",\"2017-08-19 19:47:00\",\"2017-08-19 19:48:00\",\"2017-08-19 19:49:00\",\"2017-08-19 19:50:00\",\"2017-08-19 19:51:00\",\"2017-08-19 19:52:00\",\"2017-08-19 19:53:00\",\"2017-08-19 19:54:00\",\"2017-08-19 19:55:00\",\"2017-08-19 19:56:00\",\"2017-08-19 19:57:00\",\"2017-08-19 19:58:00\",\"2017-08-19 19:59:00\",\"2017-08-19 20:00:00\",\"2017-08-19 20:01:00\",\"2017-08-19 20:02:00\",\"2017-08-19 20:03:00\",\"2017-08-19 20:04:00\",\"2017-08-19 20:05:00\",\"2017-08-19 20:06:00\",\"2017-08-19 20:07:00\",\"2017-08-19 20:08:00\",\"2017-08-19 20:09:00\",\"2017-08-19 20:10:00\",\"2017-08-19 20:11:00\",\"2017-08-19 20:12:00\",\"2017-08-19 20:13:00\",\"2017-08-19 20:14:00\",\"2017-08-19 20:15:00\",\"2017-08-19 20:16:00\",\"2017-08-19 20:17:00\",\"2017-08-19 20:18:00\",\"2017-08-19 20:19:00\",\"2017-08-19 20:20:00\",\"2017-08-19 20:21:00\",\"2017-08-19 20:22:00\",\"2017-08-19 20:23:00\",\"2017-08-19 20:24:00\",\"2017-08-19 20:25:00\",\"2017-08-19 20:26:00\",\"2017-08-19 20:27:00\",\"2017-08-19 20:28:00\",\"2017-08-19 20:29:00\",\"2017-08-19 20:30:00\",\"2017-08-19 20:31:00\",\"2017-08-19 20:32:00\",\"2017-08-19 20:33:00\",\"2017-08-19 20:34:00\",\"2017-08-19 20:35:00\",\"2017-08-19 20:36:00\",\"2017-08-19 20:37:00\",\"2017-08-19 20:38:00\",\"2017-08-19 20:39:00\",\"2017-08-19 20:40:00\",\"2017-08-19 20:41:00\",\"2017-08-19 20:42:00\",\"2017-08-19 20:43:00\",\"2017-08-19 20:44:00\",\"2017-08-19 20:45:00\",\"2017-08-19 20:46:00\",\"2017-08-19 20:47:00\",\"2017-08-19 20:48:00\",\"2017-08-19 20:49:00\",\"2017-08-19 20:50:00\",\"2017-08-19 20:51:00\",\"2017-08-19 20:52:00\",\"2017-08-19 20:53:00\",\"2017-08-19 20:54:00\",\"2017-08-19 20:55:00\",\"2017-08-19 20:56:00\",\"2017-08-19 20:57:00\",\"2017-08-19 20:58:00\",\"2017-08-19 20:59:00\",\"2017-08-19 21:00:00\",\"2017-08-19 21:01:00\",\"2017-08-19 21:02:00\",\"2017-08-19 21:03:00\",\"2017-08-19 21:04:00\",\"2017-08-19 21:05:00\",\"2017-08-19 21:06:00\",\"2017-08-19 21:07:00\",\"2017-08-19 21:08:00\",\"2017-08-19 21:09:00\",\"2017-08-19 21:10:00\",\"2017-08-19 21:11:00\",\"2017-08-19 21:12:00\",\"2017-08-19 21:13:00\",\"2017-08-19 21:14:00\",\"2017-08-19 21:15:00\",\"2017-08-19 21:16:00\",\"2017-08-19 21:17:00\",\"2017-08-19 21:18:00\",\"2017-08-19 21:19:00\",\"2017-08-19 21:20:00\",\"2017-08-19 21:21:00\",\"2017-08-19 21:22:00\",\"2017-08-19 21:23:00\",\"2017-08-19 21:24:00\",\"2017-08-19 21:25:00\",\"2017-08-19 21:26:00\",\"2017-08-19 21:27:00\",\"2017-08-19 21:28:00\",\"2017-08-19 21:29:00\",\"2017-08-19 21:30:00\",\"2017-08-19 21:31:00\",\"2017-08-19 21:32:00\",\"2017-08-19 21:33:00\",\"2017-08-19 21:34:00\",\"2017-08-19 21:35:00\",\"2017-08-19 21:36:00\",\"2017-08-19 21:37:00\",\"2017-08-19 21:38:00\",\"2017-08-19 21:39:00\",\"2017-08-19 21:40:00\",\"2017-08-19 21:41:00\",\"2017-08-19 21:42:00\",\"2017-08-19 21:43:00\",\"2017-08-19 21:44:00\",\"2017-08-19 21:45:00\",\"2017-08-19 21:46:00\",\"2017-08-19 21:47:00\",\"2017-08-19 21:48:00\",\"2017-08-19 21:49:00\",\"2017-08-19 21:50:00\",\"2017-08-19 21:51:00\",\"2017-08-19 21:52:00\",\"2017-08-19 21:53:00\",\"2017-08-19 21:54:00\",\"2017-08-19 21:55:00\",\"2017-08-19 21:56:00\",\"2017-08-19 21:57:00\",\"2017-08-19 21:58:00\",\"2017-08-19 21:59:00\",\"2017-08-19 22:00:00\",\"2017-08-19 22:01:00\",\"2017-08-19 22:02:00\",\"2017-08-19 22:03:00\",\"2017-08-19 22:04:00\",\"2017-08-19 22:05:00\",\"2017-08-19 22:06:00\",\"2017-08-19 22:07:00\",\"2017-08-19 22:08:00\",\"2017-08-19 22:09:00\",\"2017-08-19 22:10:00\",\"2017-08-19 22:11:00\",\"2017-08-19 22:12:00\",\"2017-08-19 22:13:00\",\"2017-08-19 22:14:00\",\"2017-08-19 22:15:00\",\"2017-08-19 22:16:00\",\"2017-08-19 22:17:00\",\"2017-08-19 22:18:00\",\"2017-08-19 22:19:00\",\"2017-08-19 22:20:00\",\"2017-08-19 22:21:00\",\"2017-08-19 22:22:00\",\"2017-08-19 22:23:00\",\"2017-08-19 22:24:00\",\"2017-08-19 22:25:00\",\"2017-08-19 22:26:00\",\"2017-08-19 22:27:00\",\"2017-08-19 22:28:00\",\"2017-08-19 22:29:00\",\"2017-08-19 22:30:00\",\"2017-08-19 22:31:00\",\"2017-08-19 22:32:00\",\"2017-08-19 22:33:00\",\"2017-08-19 22:34:00\",\"2017-08-19 22:35:00\",\"2017-08-19 22:36:00\",\"2017-08-19 22:37:00\",\"2017-08-19 22:38:00\",\"2017-08-19 22:39:00\",\"2017-08-19 22:40:00\",\"2017-08-19 22:41:00\",\"2017-08-19 22:42:00\",\"2017-08-19 22:43:00\",\"2017-08-19 22:44:00\",\"2017-08-19 22:45:00\",\"2017-08-19 22:46:00\",\"2017-08-19 22:47:00\",\"2017-08-19 22:48:00\",\"2017-08-19 22:49:00\",\"2017-08-19 22:50:00\",\"2017-08-19 22:51:00\",\"2017-08-19 22:52:00\",\"2017-08-19 22:53:00\",\"2017-08-19 22:54:00\",\"2017-08-19 22:55:00\",\"2017-08-19 22:56:00\",\"2017-08-19 22:57:00\",\"2017-08-19 22:58:00\",\"2017-08-19 22:59:00\",\"2017-08-19 23:00:00\",\"2017-08-19 23:01:00\",\"2017-08-19 23:02:00\",\"2017-08-19 23:03:00\",\"2017-08-19 23:04:00\",\"2017-08-19 23:05:00\",\"2017-08-19 23:06:00\",\"2017-08-19 23:07:00\",\"2017-08-19 23:08:00\",\"2017-08-19 23:09:00\",\"2017-08-19 23:10:00\",\"2017-08-19 23:11:00\",\"2017-08-19 23:12:00\",\"2017-08-19 23:13:00\",\"2017-08-19 23:14:00\",\"2017-08-19 23:15:00\",\"2017-08-19 23:16:00\",\"2017-08-19 23:17:00\",\"2017-08-19 23:18:00\",\"2017-08-19 23:19:00\",\"2017-08-19 23:20:00\",\"2017-08-19 23:21:00\",\"2017-08-19 23:22:00\",\"2017-08-19 23:23:00\",\"2017-08-19 23:24:00\",\"2017-08-19 23:25:00\",\"2017-08-19 23:26:00\",\"2017-08-19 23:27:00\",\"2017-08-19 23:28:00\",\"2017-08-19 23:29:00\",\"2017-08-19 23:30:00\",\"2017-08-19 23:31:00\",\"2017-08-19 23:32:00\",\"2017-08-19 23:33:00\",\"2017-08-19 23:34:00\",\"2017-08-19 23:35:00\",\"2017-08-19 23:36:00\",\"2017-08-19 23:37:00\",\"2017-08-19 23:38:00\",\"2017-08-19 23:39:00\",\"2017-08-19 23:40:00\",\"2017-08-19 23:41:00\",\"2017-08-19 23:42:00\",\"2017-08-19 23:43:00\",\"2017-08-19 23:44:00\",\"2017-08-19 23:45:00\",\"2017-08-19 23:46:00\",\"2017-08-19 23:47:00\",\"2017-08-19 23:48:00\",\"2017-08-19 23:49:00\",\"2017-08-19 23:50:00\",\"2017-08-19 23:51:00\",\"2017-08-19 23:52:00\",\"2017-08-19 23:53:00\",\"2017-08-19 23:54:00\",\"2017-08-19 23:55:00\",\"2017-08-19 23:56:00\",\"2017-08-19 23:57:00\",\"2017-08-19 23:58:00\",\"2017-08-19 23:59:00\"],\"xaxis\":\"x\",\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.4745092988014221,0.47639867663383484,0.4776596426963806,0.4741184413433075,0.47064247727394104,0.4686222970485687,0.4686276614665985,0.46922436356544495,0.4696928858757019,0.46963000297546387,0.4745635390281677,0.47712185978889465,0.4772118330001831,0.47496497631073,0.47282207012176514,0.4719040095806122,0.472402423620224,0.4586007595062256,0.4492006003856659,0.45595526695251465,0.46222415566444397,0.4653818607330322,0.465069442987442,0.4625135064125061,0.46032240986824036,0.4590177536010742,0.4582297205924988,0.45737653970718384,0.4565930962562561,0.4559427499771118,0.4555535316467285,0.4552001953125,0.462298184633255,0.46697935461997986,0.46826407313346863,0.46650153398513794,0.4643212854862213,0.4645155966281891,0.4651329219341278,0.46571385860443115,0.46494007110595703,0.4609335958957672,0.4589071571826935,0.4596620500087738,0.4652155041694641,0.4694252908229828,0.47059381008148193,0.46898290514945984,0.46689534187316895,0.4655824303627014,0.4654059112071991,0.4655960500240326,0.4704679846763611,0.4739472270011902,0.47456425428390503,0.47320282459259033,0.4716745615005493,0.4713769555091858,0.4720931947231293,0.4729003608226776,0.47361549735069275,0.47416946291923523,0.474595844745636,0.4750012159347534,0.47531595826148987,0.47554653882980347,0.4729573726654053,0.47097551822662354,0.4707932472229004,0.4717373549938202,0.4727528393268585,0.45425736904144287,0.44103580713272095,0.4597576856613159,0.4764721989631653,0.4788472652435303,0.4744683504104614,0.46555405855178833,0.4598647356033325,0.46017616987228394,0.4617890417575836,0.4433920681476593,0.4305112063884735,0.42881491780281067,0.433406800031662,0.43838509917259216,0.44107717275619507,0.4403056800365448,0.4448660910129547,0.456528902053833,0.4637061357498169,0.4663788676261902,0.46649014949798584,0.46610406041145325,0.46413543820381165,0.4623636305332184,0.461507648229599,0.4614127278327942,0.46242555975914,0.4634363651275635,0.45195046067237854,0.44418925046920776,0.4440608024597168,0.43661823868751526,0.4381497800350189,0.44209933280944824,0.44410616159439087,0.45565295219421387,0.46206429600715637,0.4632476568222046,0.4608020484447479,0.45761552453041077,0.45584243535995483,0.4548688530921936,0.45447850227355957,0.45454126596450806,0.4550679922103882,0.4555374085903168,0.456355482339859,0.4571404457092285,0.4577481150627136,0.4587489664554596,0.4585866630077362,0.45828479528427124,0.45809122920036316,0.4585687220096588,0.455785870552063,0.4536201059818268,0.44976159930229187,0.44807305932044983,0.4450620710849762,0.4436551630496979,0.44403013586997986,0.4448433220386505,0.44517725706100464,0.43604251742362976,0.42847874760627747,0.4234088659286499,0.4222574234008789,0.4232179522514343,0.42227694392204285,0.4234028160572052,0.42367398738861084,0.4230882525444031,0.4303474724292755,0.42883971333503723,0.43271100521087646,0.4359326958656311,0.4380115270614624,0.43890467286109924,0.4388048052787781,0.43838587403297424,0.43790897727012634,0.43775662779808044,0.4364958703517914,0.435835063457489,0.43588265776634216,0.4362865686416626,0.43671053647994995,0.43682146072387695,0.437012255191803,0.4369018077850342,0.43679502606391907,0.4367018938064575,0.4366230070590973,0.436556875705719,0.4365012049674988,0.43645620346069336,0.43641650676727295,0.43641650676727295,0.43641650676727295,0.43641889095306396,0.4343762993812561,0.4329391121864319,0.4317045509815216,0.43139779567718506,0.43170249462127686,0.4313865900039673,0.43105292320251465,0.4308053255081177,0.43036821484565735,0.4343651533126831,0.4371965229511261,0.4379628896713257,0.43735456466674805,0.4376266300678253,0.43786346912384033,0.4313412308692932,0.42678171396255493,0.42572420835494995,0.42585545778274536,0.4272909164428711,0.4283474385738373,0.4313074052333832,0.4325173795223236,0.42797204852104187,0.42831504344940186,0.42971640825271606,0.42829564213752747,0.4262374937534332,0.42524975538253784,0.4244914650917053,0.4240320920944214,0.42337894439697266,0.4231347143650055,0.423166424036026,0.4231448769569397,0.4230843782424927,0.4226478040218353,0.4198143482208252,0.4179995059967041,0.4166277050971985,0.4162134826183319,0.4168926775455475,0.4146265983581543,0.4155443012714386,0.41655516624450684,0.4170365035533905,0.4170987606048584,0.41670769453048706,0.41666722297668457,0.41664302349090576,0.4166243076324463,0.409715473651886,0.4050086438655853,0.40076372027397156,0.3961474597454071,0.3938576579093933,0.39064887166023254,0.38592728972435,0.38189342617988586,0.37966489791870117,0.3794514238834381,0.38424599170684814,0.38918304443359375,0.39169609546661377,0.3926469683647156,0.39304372668266296,0.39383041858673096,0.3946670889854431,0.3969888985157013,0.39864230155944824,0.39979976415634155,0.4005903899669647,0.4010058641433716,0.4011426866054535,0.4011699855327606,0.4011562168598175,0.3958754539489746,0.3922540247440338,0.39581790566444397,0.3989565372467041,0.4004659950733185,0.4007655382156372,0.4006327986717224,0.4009034037590027,0.40105003118515015,0.4046788215637207,0.40416428446769714,0.4034487307071686,0.4030212163925171,0.4033533036708832,0.40360119938850403,0.40368756651878357,0.4037424325942993,0.4037852883338928,0.403809130191803,0.40382120013237,0.4038260877132416,0.40363284945487976,0.40388545393943787,0.4040931463241577,0.40417715907096863,0.4042209982872009,0.4042518436908722,0.4042685329914093,0.40427708625793457,0.40612462162971497,0.4105590283870697,0.4112794101238251,0.4113820195198059,0.41138020157814026,0.4112790822982788,0.411162406206131,0.4135686159133911,0.41528216004371643,0.41604942083358765,0.4164702892303467,0.4191037714481354,0.4208708703517914,0.42172783613204956,0.4220903813838959,0.41757285594940186,0.42289695143699646,0.424258291721344,0.4238644540309906,0.42323043942451477,0.42318475246429443,0.4231049716472626,0.42306631803512573,0.42314764857292175,0.4232167899608612,0.4214887022972107,0.42025595903396606,0.41985177993774414,0.41998305916786194,0.4200443923473358,0.41912180185317993,0.41821572184562683,0.41790470480918884,0.41789665818214417,0.4178626239299774,0.4177793860435486,0.4177016317844391,0.41763538122177124,0.4175775945186615,0.41752734780311584,0.4175032675266266,0.41748273372650146,0.4174667298793793,0.413066029548645,0.4100249707698822,0.40894412994384766,0.40909087657928467,0.40926140546798706,0.409307062625885,0.4090237617492676,0.40871018171310425,0.4084189832210541,0.40831005573272705,0.4082871377468109,0.4082360863685608,0.40817686915397644,0.4081278443336487,0.40810540318489075,0.4053088128566742,0.40337204933166504,0.4025762677192688,0.4025181829929352,0.3958553373813629,0.3913278877735138,0.3893408179283142,0.38895776867866516,0.3891719877719879,0.39474087953567505,0.39796707034111023,0.3992461562156677,0.39971688389778137,0.4001573622226715,0.4007262885570526,0.40101176500320435,0.4011648893356323,0.4012264311313629,0.40141478180885315,0.40280982851982117,0.4037770926952362,0.40561822056770325,0.4068474769592285,0.40857481956481934,0.4096791446208954,0.41027316451072693,0.4105640649795532,0.4106604754924774,0.41066035628318787,0.41356274485588074,0.4156530201435089,0.416642427444458,0.41718003153800964,0.41736656427383423,0.41737812757492065,0.41732487082481384,0.41444578766822815,0.41242820024490356,0.41167593002319336,0.4116874933242798,0.4117455780506134,0.4117080271244049,0.4116353392601013,0.41152140498161316,0.4114047884941101,0.411324143409729,0.41125693917274475,0.41120097041130066,0.4111590087413788,0.411122590303421,0.417580783367157,0.4218670427799225,0.42433416843414307,0.4307838976383209,0.4353277385234833,0.4379757046699524,0.43925219774246216,0.4394724667072296,0.43898358941078186,0.43837136030197144,0.43792080879211426,0.43778449296951294,0.43444162607192993,0.43245959281921387,0.4321771264076233,0.43283772468566895,0.43372759222984314,0.4341394603252411,0.43389827013015747,0.43358752131462097,0.4332953095436096,0.42979639768600464,0.4273190200328827,0.4265097379684448,0.42676717042922974,0.4273070693016052,0.427349716424942,0.4271358549594879,0.4268662929534912,0.42660966515541077,0.4263860583305359,0.42621734738349915,0.4261428713798523,0.42608365416526794,0.41757869720458984,0.4200630784034729,0.42402446269989014,0.4266102612018585,0.42277273535728455,0.41853347420692444,0.41717541217803955,0.4174739122390747,0.41762930154800415,0.417818158864975,0.4176183044910431,0.41735920310020447,0.41711223125457764,0.4101905822753906,0.4054553210735321,0.40383580327033997,0.40399229526519775,0.40443259477615356,0.4043201506137848,0.41013577580451965,0.4134403169155121,0.41496914625167847,0.41573622822761536,0.4163801968097687,0.41665732860565186,0.4167217016220093,0.41666078567504883,0.4165644943714142,0.41645896434783936,0.4098048508167267,0.4015084207057953,0.3973838686943054,0.39673346281051636,0.3972718119621277,0.3976407051086426,0.4008573889732361,0.4024025499820709,0.40251195430755615,0.401887446641922,0.40116554498672485,0.4013689458370209,0.40149667859077454,0.4015728235244751,0.40170758962631226,0.40178412199020386,0.4018199145793915,0.40183910727500916,0.40468332171440125,0.40942010283470154,0.41249793767929077,0.41177916526794434,0.4106007218360901,0.40764737129211426,0.4056392014026642,0.40134397149086,0.39983123540878296,0.39512577652931213,0.3922562599182129,0.39603808522224426,0.4011145234107971,0.4038968086242676,0.40340349078178406,0.40201181173324585,0.40269485116004944,0.40360361337661743,0.4040806293487549,0.39434099197387695,0.3944878578186035,0.3961730897426605,0.3974318206310272,0.39791157841682434,0.3976678252220154,0.39735081791877747,0.39970433712005615,0.40114542841911316,0.40186822414398193,0.394776314496994,0.38983482122421265,0.3867385983467102,0.39344102144241333,0.38638028502464294,0.3874145448207855,0.3815101087093353,0.37391334772109985,0.3738424479961395,0.3800351023674011,0.3840974271297455,0.38630402088165283,0.37356826663017273,0.3647101819515228,0.3723903000354767,0.3785724937915802,0.38241398334503174,0.38462120294570923,0.3684413731098175,0.37271127104759216,0.3689333498477936,0.37158283591270447,0.36718857288360596,0.3701384365558624,0.3720463812351227,0.3730507791042328,0.37346377968788147,0.3740299940109253,0.3764573633670807,0.37792742252349854,0.3792192339897156,0.3785175085067749,0.37793442606925964,0.37751835584640503,0.3772298991680145,0.377044141292572,0.3769312798976898,0.37692925333976746,0.37686315178871155,0.37681451439857483,0.37677711248397827,0.37609875202178955,0.3800884783267975,0.3826836347579956,0.38446858525276184,0.38539227843284607,0.3861601948738098,0.3892802894115448,0.3852211833000183,0.3820742666721344,0.3801645040512085,0.3797008693218231,0.3796710669994354,0.3796246349811554,0.38720425963401794,0.3923218250274658,0.3984083831310272,0.40456047654151917,0.40932154655456543,0.41259434819221497,0.414900004863739,0.41630035638809204,0.41704317927360535,0.41735875606536865,0.41714951395988464,0.4168429672718048,0.4165457487106323,0.4215114712715149,0.42484092712402344,0.42659732699394226,0.4251745641231537,0.42610597610473633,0.4240648150444031,0.4304933249950409,0.43763479590415955,0.4392862319946289,0.4422738254070282,0.4430166184902191,0.44250112771987915,0.4418134093284607,0.4425065815448761,0.44202765822410583,0.44258913397789,0.4432961344718933,0.4438111186027527,0.4393056631088257,0.44075503945350647,0.44355106353759766,0.4430106282234192,0.44413521885871887,0.4446652829647064,0.4448440372943878,0.44497451186180115,0.44459494948387146,0.44558462500572205,0.4464562237262726,0.4467616081237793,0.44660449028015137,0.4463579058647156,0.4434722065925598,0.4347066283226013,0.4296698570251465,0.42941537499427795,0.4316452741622925,0.433577299118042,0.43414074182510376,0.4335448145866394,0.4323836863040924,0.4313008785247803,0.4303486943244934,0.42977309226989746,0.42931807041168213,0.4289447069168091,0.42876094579696655,0.4286658465862274,0.4286658465862274,0.4286658465862274,0.4368044435977936,0.44275516271591187,0.44568535685539246,0.43751633167266846,0.43076637387275696,0.4281350076198578,0.428318053483963,0.4295429289340973,0.43953633308410645,0.44453251361846924,0.44603872299194336,0.4454723000526428,0.4445328414440155,0.4440414309501648,0.44077885150909424,0.43846818804740906,0.4380868375301361,0.43470337986946106,0.4325084388256073,0.4325658679008484,0.43345215916633606,0.43445339798927307,0.43475911021232605,0.43423205614089966,0.4334743320941925,0.43290257453918457,0.4324646294116974,0.43210670351982117,0.4318036139011383,0.4316437542438507,0.43157538771629333,0.42455393075942993,0.42071840167045593,0.42004233598709106,0.4267309308052063,0.43177300691604614,0.4332657754421234,0.4278928339481354,0.41636714339256287,0.4106144309043884,0.40940365195274353,0.41027548909187317,0.4149206876754761,0.4173336923122406,0.4243556559085846,0.42814263701438904,0.42987754940986633,0.4310756325721741,0.4256303608417511,0.42794227600097656,0.42556044459342957,0.423000305891037,0.42202329635620117,0.42188528180122375,0.4223249852657318,0.42244744300842285,0.42265042662620544,0.4226243495941162,0.4225705862045288,0.4223138689994812,0.42217257618904114,0.4220600724220276,0.4219806492328644,0.4181968867778778,0.4154984951019287,0.4146156311035156,0.41483816504478455,0.41876378655433655,0.42143985629081726,0.4221680462360382,0.4217805564403534,0.42166733741760254,0.4217415750026703,0.42174339294433594,0.42061373591423035,0.41981977224349976,0.4206777513027191,0.4215277433395386,0.42191389203071594,0.42188358306884766,0.4218670427799225,0.42076197266578674,0.41996094584465027,0.4196929335594177,0.419768750667572,0.41980651021003723,0.41977718472480774,0.419742226600647,0.4197055697441101,0.41968482732772827,0.42022109031677246,0.4205823242664337,0.41935303807258606,0.41970840096473694,0.42028912901878357,0.4212803244590759,0.42167723178863525,0.42177319526672363,0.4256439507007599,0.4284285008907318,0.42950233817100525,0.4300006330013275,0.43005457520484924,0.42990797758102417,0.4298444390296936,0.42574000358581543,0.42287516593933105,0.4209853708744049,0.4227994680404663,0.4244457185268402,0.4253544807434082,0.4252837598323822,0.42467546463012695,0.4221920073032379,0.4206938147544861,0.4201812744140625,0.4183138906955719,0.4169814884662628,0.4164687991142273,0.41348862648010254,0.41163399815559387,0.41086432337760925,0.41078776121139526,0.4109351336956024,0.41073527932167053,0.4103457033634186,0.40997257828712463,0.40964367985725403,0.40951916575431824,0.4094274640083313,0.4051801264286041,0.40227174758911133,0.40109601616859436,0.4010196626186371,0.4009614884853363,0.4009177088737488,0.40063220262527466,0.39957988262176514,0.3987884819507599,0.3983735740184784,0.39823034405708313,0.39809608459472656,0.39552396535873413,0.39374038577079773,0.39288878440856934,0.39268386363983154,0.3924574851989746,0.3922969400882721,0.39207693934440613,0.3918841779232025,0.3917701542377472,0.3916795253753662,0.3906285762786865,0.38989266753196716,0.3895166218280792,0.3893793225288391,0.38924363255500793,0.38913998007774353,0.3890615701675415,0.38900184631347656,0.3889558017253876,0.39857128262519836,0.40545982122421265,0.40838879346847534,0.41044601798057556,0.41170716285705566,0.41238656640052795,0.41710522770881653,0.4204900562763214,0.41212108731269836,0.41640862822532654,0.42052096128463745,0.422611266374588,0.423509806394577,0.42396605014801025,0.4240169823169708,0.42393702268600464,0.42384931445121765,0.4237945079803467,0.4237509071826935,0.41733318567276,0.41301387548446655,0.4178677499294281,0.42267099022865295,0.42511528730392456,0.42497971653938293,0.41827908158302307,0.4115527868270874,0.4111728370189667,0.41264763474464417,0.4136457145214081,0.41416284441947937,0.4135516285896301,0.4084164500236511,0.39555543661117554,0.3881968557834625,0.38605713844299316,0.38629430532455444,0.38686543703079224,0.39309266209602356,0.39607563614845276,0.39717116951942444,0.39704036712646484,0.39647889137268066,0.3981231451034546,0.3996945321559906,0.40077531337738037,0.3993808627128601,0.398240327835083,0.39947429299354553,0.40048542618751526,0.40090617537498474,0.3969646990299225,0.39840713143348694,0.40009230375289917,0.39830902218818665,0.39646250009536743,0.3957929313182831,0.3955490291118622,0.39541926980018616,0.3952465057373047,0.39510613679885864,0.3936155140399933,0.3925783336162567,0.3920545279979706,0.3918723464012146,0.3958117365837097,0.39841440320014954,0.3998081386089325,0.40078645944595337,0.4014832079410553,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"variable=test_predicted_close\\u003cbr\\u003eDate=%{x}\\u003cbr\\u003eStock price=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"test_predicted_close\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Test predicted close price\",\"showlegend\":true,\"x\":[\"2017-08-19 00:00:00\",\"2017-08-19 00:01:00\",\"2017-08-19 00:02:00\",\"2017-08-19 00:03:00\",\"2017-08-19 00:04:00\",\"2017-08-19 00:05:00\",\"2017-08-19 00:06:00\",\"2017-08-19 00:07:00\",\"2017-08-19 00:08:00\",\"2017-08-19 00:09:00\",\"2017-08-19 00:10:00\",\"2017-08-19 00:11:00\",\"2017-08-19 00:12:00\",\"2017-08-19 00:13:00\",\"2017-08-19 00:14:00\",\"2017-08-19 00:15:00\",\"2017-08-19 00:16:00\",\"2017-08-19 00:17:00\",\"2017-08-19 00:18:00\",\"2017-08-19 00:19:00\",\"2017-08-19 00:20:00\",\"2017-08-19 00:21:00\",\"2017-08-19 00:22:00\",\"2017-08-19 00:23:00\",\"2017-08-19 00:24:00\",\"2017-08-19 00:25:00\",\"2017-08-19 00:26:00\",\"2017-08-19 00:27:00\",\"2017-08-19 00:28:00\",\"2017-08-19 00:29:00\",\"2017-08-19 00:30:00\",\"2017-08-19 00:31:00\",\"2017-08-19 00:32:00\",\"2017-08-19 00:33:00\",\"2017-08-19 00:34:00\",\"2017-08-19 00:35:00\",\"2017-08-19 00:36:00\",\"2017-08-19 00:37:00\",\"2017-08-19 00:38:00\",\"2017-08-19 00:39:00\",\"2017-08-19 00:40:00\",\"2017-08-19 00:41:00\",\"2017-08-19 00:42:00\",\"2017-08-19 00:43:00\",\"2017-08-19 00:44:00\",\"2017-08-19 00:45:00\",\"2017-08-19 00:46:00\",\"2017-08-19 00:47:00\",\"2017-08-19 00:48:00\",\"2017-08-19 00:49:00\",\"2017-08-19 00:50:00\",\"2017-08-19 00:51:00\",\"2017-08-19 00:52:00\",\"2017-08-19 00:53:00\",\"2017-08-19 00:54:00\",\"2017-08-19 00:55:00\",\"2017-08-19 00:56:00\",\"2017-08-19 00:57:00\",\"2017-08-19 00:58:00\",\"2017-08-19 00:59:00\",\"2017-08-19 01:00:00\",\"2017-08-19 01:01:00\",\"2017-08-19 01:02:00\",\"2017-08-19 01:03:00\",\"2017-08-19 01:04:00\",\"2017-08-19 01:05:00\",\"2017-08-19 01:06:00\",\"2017-08-19 01:07:00\",\"2017-08-19 01:08:00\",\"2017-08-19 01:09:00\",\"2017-08-19 01:10:00\",\"2017-08-19 01:11:00\",\"2017-08-19 01:12:00\",\"2017-08-19 01:13:00\",\"2017-08-19 01:14:00\",\"2017-08-19 01:15:00\",\"2017-08-19 01:16:00\",\"2017-08-19 01:17:00\",\"2017-08-19 01:18:00\",\"2017-08-19 01:19:00\",\"2017-08-19 01:20:00\",\"2017-08-19 01:21:00\",\"2017-08-19 01:22:00\",\"2017-08-19 01:23:00\",\"2017-08-19 01:24:00\",\"2017-08-19 01:25:00\",\"2017-08-19 01:26:00\",\"2017-08-19 01:27:00\",\"2017-08-19 01:28:00\",\"2017-08-19 01:29:00\",\"2017-08-19 01:30:00\",\"2017-08-19 01:31:00\",\"2017-08-19 01:32:00\",\"2017-08-19 01:33:00\",\"2017-08-19 01:34:00\",\"2017-08-19 01:35:00\",\"2017-08-19 01:36:00\",\"2017-08-19 01:37:00\",\"2017-08-19 01:38:00\",\"2017-08-19 01:39:00\",\"2017-08-19 01:40:00\",\"2017-08-19 01:41:00\",\"2017-08-19 01:42:00\",\"2017-08-19 01:43:00\",\"2017-08-19 01:44:00\",\"2017-08-19 01:45:00\",\"2017-08-19 01:46:00\",\"2017-08-19 01:47:00\",\"2017-08-19 01:48:00\",\"2017-08-19 01:49:00\",\"2017-08-19 01:50:00\",\"2017-08-19 01:51:00\",\"2017-08-19 01:52:00\",\"2017-08-19 01:53:00\",\"2017-08-19 01:54:00\",\"2017-08-19 01:55:00\",\"2017-08-19 01:56:00\",\"2017-08-19 01:57:00\",\"2017-08-19 01:58:00\",\"2017-08-19 01:59:00\",\"2017-08-19 02:00:00\",\"2017-08-19 02:01:00\",\"2017-08-19 02:02:00\",\"2017-08-19 02:03:00\",\"2017-08-19 02:04:00\",\"2017-08-19 02:05:00\",\"2017-08-19 02:06:00\",\"2017-08-19 02:07:00\",\"2017-08-19 02:08:00\",\"2017-08-19 02:09:00\",\"2017-08-19 02:10:00\",\"2017-08-19 02:11:00\",\"2017-08-19 02:12:00\",\"2017-08-19 02:13:00\",\"2017-08-19 02:14:00\",\"2017-08-19 02:15:00\",\"2017-08-19 02:16:00\",\"2017-08-19 02:17:00\",\"2017-08-19 02:18:00\",\"2017-08-19 02:19:00\",\"2017-08-19 02:20:00\",\"2017-08-19 02:21:00\",\"2017-08-19 02:22:00\",\"2017-08-19 02:23:00\",\"2017-08-19 02:24:00\",\"2017-08-19 02:25:00\",\"2017-08-19 02:26:00\",\"2017-08-19 02:27:00\",\"2017-08-19 02:28:00\",\"2017-08-19 02:29:00\",\"2017-08-19 02:30:00\",\"2017-08-19 02:31:00\",\"2017-08-19 02:32:00\",\"2017-08-19 02:33:00\",\"2017-08-19 02:34:00\",\"2017-08-19 02:35:00\",\"2017-08-19 02:36:00\",\"2017-08-19 02:37:00\",\"2017-08-19 02:38:00\",\"2017-08-19 02:39:00\",\"2017-08-19 02:40:00\",\"2017-08-19 02:41:00\",\"2017-08-19 02:42:00\",\"2017-08-19 02:43:00\",\"2017-08-19 02:44:00\",\"2017-08-19 02:45:00\",\"2017-08-19 02:46:00\",\"2017-08-19 02:47:00\",\"2017-08-19 02:48:00\",\"2017-08-19 02:49:00\",\"2017-08-19 02:50:00\",\"2017-08-19 02:51:00\",\"2017-08-19 02:52:00\",\"2017-08-19 02:53:00\",\"2017-08-19 02:54:00\",\"2017-08-19 02:55:00\",\"2017-08-19 02:56:00\",\"2017-08-19 02:57:00\",\"2017-08-19 02:58:00\",\"2017-08-19 02:59:00\",\"2017-08-19 03:00:00\",\"2017-08-19 03:01:00\",\"2017-08-19 03:02:00\",\"2017-08-19 03:03:00\",\"2017-08-19 03:04:00\",\"2017-08-19 03:05:00\",\"2017-08-19 03:06:00\",\"2017-08-19 03:07:00\",\"2017-08-19 03:08:00\",\"2017-08-19 03:09:00\",\"2017-08-19 03:10:00\",\"2017-08-19 03:11:00\",\"2017-08-19 03:12:00\",\"2017-08-19 03:13:00\",\"2017-08-19 03:14:00\",\"2017-08-19 03:15:00\",\"2017-08-19 03:16:00\",\"2017-08-19 03:17:00\",\"2017-08-19 03:18:00\",\"2017-08-19 03:19:00\",\"2017-08-19 03:20:00\",\"2017-08-19 03:21:00\",\"2017-08-19 03:22:00\",\"2017-08-19 03:23:00\",\"2017-08-19 03:24:00\",\"2017-08-19 03:25:00\",\"2017-08-19 03:26:00\",\"2017-08-19 03:27:00\",\"2017-08-19 03:28:00\",\"2017-08-19 03:29:00\",\"2017-08-19 03:30:00\",\"2017-08-19 03:31:00\",\"2017-08-19 03:32:00\",\"2017-08-19 03:33:00\",\"2017-08-19 03:34:00\",\"2017-08-19 03:35:00\",\"2017-08-19 03:36:00\",\"2017-08-19 03:37:00\",\"2017-08-19 03:38:00\",\"2017-08-19 03:39:00\",\"2017-08-19 03:40:00\",\"2017-08-19 03:41:00\",\"2017-08-19 03:42:00\",\"2017-08-19 03:43:00\",\"2017-08-19 03:44:00\",\"2017-08-19 03:45:00\",\"2017-08-19 03:46:00\",\"2017-08-19 03:47:00\",\"2017-08-19 03:48:00\",\"2017-08-19 03:49:00\",\"2017-08-19 03:50:00\",\"2017-08-19 03:51:00\",\"2017-08-19 03:52:00\",\"2017-08-19 03:53:00\",\"2017-08-19 03:54:00\",\"2017-08-19 03:55:00\",\"2017-08-19 03:56:00\",\"2017-08-19 03:57:00\",\"2017-08-19 03:58:00\",\"2017-08-19 03:59:00\",\"2017-08-19 04:00:00\",\"2017-08-19 04:01:00\",\"2017-08-19 04:02:00\",\"2017-08-19 04:03:00\",\"2017-08-19 04:04:00\",\"2017-08-19 04:05:00\",\"2017-08-19 04:06:00\",\"2017-08-19 04:07:00\",\"2017-08-19 04:08:00\",\"2017-08-19 04:09:00\",\"2017-08-19 04:10:00\",\"2017-08-19 04:11:00\",\"2017-08-19 04:12:00\",\"2017-08-19 04:13:00\",\"2017-08-19 04:14:00\",\"2017-08-19 04:15:00\",\"2017-08-19 04:16:00\",\"2017-08-19 04:17:00\",\"2017-08-19 04:18:00\",\"2017-08-19 04:19:00\",\"2017-08-19 04:20:00\",\"2017-08-19 04:21:00\",\"2017-08-19 04:22:00\",\"2017-08-19 04:23:00\",\"2017-08-19 04:24:00\",\"2017-08-19 04:25:00\",\"2017-08-19 04:26:00\",\"2017-08-19 04:27:00\",\"2017-08-19 04:28:00\",\"2017-08-19 04:29:00\",\"2017-08-19 04:30:00\",\"2017-08-19 04:31:00\",\"2017-08-19 04:32:00\",\"2017-08-19 04:33:00\",\"2017-08-19 04:34:00\",\"2017-08-19 04:35:00\",\"2017-08-19 04:36:00\",\"2017-08-19 04:37:00\",\"2017-08-19 04:38:00\",\"2017-08-19 04:39:00\",\"2017-08-19 04:40:00\",\"2017-08-19 04:41:00\",\"2017-08-19 04:42:00\",\"2017-08-19 04:43:00\",\"2017-08-19 04:44:00\",\"2017-08-19 04:45:00\",\"2017-08-19 04:46:00\",\"2017-08-19 04:47:00\",\"2017-08-19 04:48:00\",\"2017-08-19 04:49:00\",\"2017-08-19 04:50:00\",\"2017-08-19 04:51:00\",\"2017-08-19 04:52:00\",\"2017-08-19 04:53:00\",\"2017-08-19 04:54:00\",\"2017-08-19 04:55:00\",\"2017-08-19 04:56:00\",\"2017-08-19 04:57:00\",\"2017-08-19 04:58:00\",\"2017-08-19 04:59:00\",\"2017-08-19 05:00:00\",\"2017-08-19 05:01:00\",\"2017-08-19 05:02:00\",\"2017-08-19 05:03:00\",\"2017-08-19 05:04:00\",\"2017-08-19 05:05:00\",\"2017-08-19 05:06:00\",\"2017-08-19 05:07:00\",\"2017-08-19 05:08:00\",\"2017-08-19 05:09:00\",\"2017-08-19 05:10:00\",\"2017-08-19 05:11:00\",\"2017-08-19 05:12:00\",\"2017-08-19 05:13:00\",\"2017-08-19 05:14:00\",\"2017-08-19 05:15:00\",\"2017-08-19 05:16:00\",\"2017-08-19 05:17:00\",\"2017-08-19 05:18:00\",\"2017-08-19 05:19:00\",\"2017-08-19 05:20:00\",\"2017-08-19 05:21:00\",\"2017-08-19 05:22:00\",\"2017-08-19 05:23:00\",\"2017-08-19 05:24:00\",\"2017-08-19 05:25:00\",\"2017-08-19 05:26:00\",\"2017-08-19 05:27:00\",\"2017-08-19 05:28:00\",\"2017-08-19 05:29:00\",\"2017-08-19 05:30:00\",\"2017-08-19 05:31:00\",\"2017-08-19 05:32:00\",\"2017-08-19 05:33:00\",\"2017-08-19 05:34:00\",\"2017-08-19 05:35:00\",\"2017-08-19 05:36:00\",\"2017-08-19 05:37:00\",\"2017-08-19 05:38:00\",\"2017-08-19 05:39:00\",\"2017-08-19 05:40:00\",\"2017-08-19 05:41:00\",\"2017-08-19 05:42:00\",\"2017-08-19 05:43:00\",\"2017-08-19 05:44:00\",\"2017-08-19 05:45:00\",\"2017-08-19 05:46:00\",\"2017-08-19 05:47:00\",\"2017-08-19 05:48:00\",\"2017-08-19 05:49:00\",\"2017-08-19 05:50:00\",\"2017-08-19 05:51:00\",\"2017-08-19 05:52:00\",\"2017-08-19 05:53:00\",\"2017-08-19 05:54:00\",\"2017-08-19 05:55:00\",\"2017-08-19 05:56:00\",\"2017-08-19 05:57:00\",\"2017-08-19 05:58:00\",\"2017-08-19 05:59:00\",\"2017-08-19 06:00:00\",\"2017-08-19 06:01:00\",\"2017-08-19 06:02:00\",\"2017-08-19 06:03:00\",\"2017-08-19 06:04:00\",\"2017-08-19 06:05:00\",\"2017-08-19 06:06:00\",\"2017-08-19 06:07:00\",\"2017-08-19 06:08:00\",\"2017-08-19 06:09:00\",\"2017-08-19 06:10:00\",\"2017-08-19 06:11:00\",\"2017-08-19 06:12:00\",\"2017-08-19 06:13:00\",\"2017-08-19 06:14:00\",\"2017-08-19 06:15:00\",\"2017-08-19 06:16:00\",\"2017-08-19 06:17:00\",\"2017-08-19 06:18:00\",\"2017-08-19 06:19:00\",\"2017-08-19 06:20:00\",\"2017-08-19 06:21:00\",\"2017-08-19 06:22:00\",\"2017-08-19 06:23:00\",\"2017-08-19 06:24:00\",\"2017-08-19 06:25:00\",\"2017-08-19 06:26:00\",\"2017-08-19 06:27:00\",\"2017-08-19 06:28:00\",\"2017-08-19 06:29:00\",\"2017-08-19 06:30:00\",\"2017-08-19 06:31:00\",\"2017-08-19 06:32:00\",\"2017-08-19 06:33:00\",\"2017-08-19 06:34:00\",\"2017-08-19 06:35:00\",\"2017-08-19 06:36:00\",\"2017-08-19 06:37:00\",\"2017-08-19 06:38:00\",\"2017-08-19 06:39:00\",\"2017-08-19 06:40:00\",\"2017-08-19 06:41:00\",\"2017-08-19 06:42:00\",\"2017-08-19 06:43:00\",\"2017-08-19 06:44:00\",\"2017-08-19 06:45:00\",\"2017-08-19 06:46:00\",\"2017-08-19 06:47:00\",\"2017-08-19 06:48:00\",\"2017-08-19 06:49:00\",\"2017-08-19 06:50:00\",\"2017-08-19 06:51:00\",\"2017-08-19 06:52:00\",\"2017-08-19 06:53:00\",\"2017-08-19 06:54:00\",\"2017-08-19 06:55:00\",\"2017-08-19 06:56:00\",\"2017-08-19 06:57:00\",\"2017-08-19 06:58:00\",\"2017-08-19 06:59:00\",\"2017-08-19 07:00:00\",\"2017-08-19 07:01:00\",\"2017-08-19 07:02:00\",\"2017-08-19 07:03:00\",\"2017-08-19 07:04:00\",\"2017-08-19 07:05:00\",\"2017-08-19 07:06:00\",\"2017-08-19 07:07:00\",\"2017-08-19 07:08:00\",\"2017-08-19 07:09:00\",\"2017-08-19 07:10:00\",\"2017-08-19 07:11:00\",\"2017-08-19 07:12:00\",\"2017-08-19 07:13:00\",\"2017-08-19 07:14:00\",\"2017-08-19 07:15:00\",\"2017-08-19 07:16:00\",\"2017-08-19 07:17:00\",\"2017-08-19 07:18:00\",\"2017-08-19 07:19:00\",\"2017-08-19 07:20:00\",\"2017-08-19 07:21:00\",\"2017-08-19 07:22:00\",\"2017-08-19 07:23:00\",\"2017-08-19 07:24:00\",\"2017-08-19 07:25:00\",\"2017-08-19 07:26:00\",\"2017-08-19 07:27:00\",\"2017-08-19 07:28:00\",\"2017-08-19 07:29:00\",\"2017-08-19 07:30:00\",\"2017-08-19 07:31:00\",\"2017-08-19 07:32:00\",\"2017-08-19 07:33:00\",\"2017-08-19 07:34:00\",\"2017-08-19 07:35:00\",\"2017-08-19 07:36:00\",\"2017-08-19 07:37:00\",\"2017-08-19 07:38:00\",\"2017-08-19 07:39:00\",\"2017-08-19 07:40:00\",\"2017-08-19 07:41:00\",\"2017-08-19 07:42:00\",\"2017-08-19 07:43:00\",\"2017-08-19 07:44:00\",\"2017-08-19 07:45:00\",\"2017-08-19 07:46:00\",\"2017-08-19 07:47:00\",\"2017-08-19 07:48:00\",\"2017-08-19 07:49:00\",\"2017-08-19 07:50:00\",\"2017-08-19 07:51:00\",\"2017-08-19 07:52:00\",\"2017-08-19 07:53:00\",\"2017-08-19 07:54:00\",\"2017-08-19 07:55:00\",\"2017-08-19 07:56:00\",\"2017-08-19 07:57:00\",\"2017-08-19 07:58:00\",\"2017-08-19 07:59:00\",\"2017-08-19 08:00:00\",\"2017-08-19 08:01:00\",\"2017-08-19 08:02:00\",\"2017-08-19 08:03:00\",\"2017-08-19 08:04:00\",\"2017-08-19 08:05:00\",\"2017-08-19 08:06:00\",\"2017-08-19 08:07:00\",\"2017-08-19 08:08:00\",\"2017-08-19 08:09:00\",\"2017-08-19 08:10:00\",\"2017-08-19 08:11:00\",\"2017-08-19 08:12:00\",\"2017-08-19 08:13:00\",\"2017-08-19 08:14:00\",\"2017-08-19 08:15:00\",\"2017-08-19 08:16:00\",\"2017-08-19 08:17:00\",\"2017-08-19 08:18:00\",\"2017-08-19 08:19:00\",\"2017-08-19 08:20:00\",\"2017-08-19 08:21:00\",\"2017-08-19 08:22:00\",\"2017-08-19 08:23:00\",\"2017-08-19 08:24:00\",\"2017-08-19 08:25:00\",\"2017-08-19 08:26:00\",\"2017-08-19 08:27:00\",\"2017-08-19 08:28:00\",\"2017-08-19 08:29:00\",\"2017-08-19 08:30:00\",\"2017-08-19 08:31:00\",\"2017-08-19 08:32:00\",\"2017-08-19 08:33:00\",\"2017-08-19 08:34:00\",\"2017-08-19 08:35:00\",\"2017-08-19 08:36:00\",\"2017-08-19 08:37:00\",\"2017-08-19 08:38:00\",\"2017-08-19 08:39:00\",\"2017-08-19 08:40:00\",\"2017-08-19 08:41:00\",\"2017-08-19 08:42:00\",\"2017-08-19 08:43:00\",\"2017-08-19 08:44:00\",\"2017-08-19 08:45:00\",\"2017-08-19 08:46:00\",\"2017-08-19 08:47:00\",\"2017-08-19 08:48:00\",\"2017-08-19 08:49:00\",\"2017-08-19 08:50:00\",\"2017-08-19 08:51:00\",\"2017-08-19 08:52:00\",\"2017-08-19 08:53:00\",\"2017-08-19 08:54:00\",\"2017-08-19 08:55:00\",\"2017-08-19 08:56:00\",\"2017-08-19 08:57:00\",\"2017-08-19 08:58:00\",\"2017-08-19 08:59:00\",\"2017-08-19 09:00:00\",\"2017-08-19 09:01:00\",\"2017-08-19 09:02:00\",\"2017-08-19 09:03:00\",\"2017-08-19 09:04:00\",\"2017-08-19 09:05:00\",\"2017-08-19 09:06:00\",\"2017-08-19 09:07:00\",\"2017-08-19 09:08:00\",\"2017-08-19 09:09:00\",\"2017-08-19 09:10:00\",\"2017-08-19 09:11:00\",\"2017-08-19 09:12:00\",\"2017-08-19 09:13:00\",\"2017-08-19 09:14:00\",\"2017-08-19 09:15:00\",\"2017-08-19 09:16:00\",\"2017-08-19 09:17:00\",\"2017-08-19 09:18:00\",\"2017-08-19 09:19:00\",\"2017-08-19 09:20:00\",\"2017-08-19 09:21:00\",\"2017-08-19 09:22:00\",\"2017-08-19 09:23:00\",\"2017-08-19 09:24:00\",\"2017-08-19 09:25:00\",\"2017-08-19 09:26:00\",\"2017-08-19 09:27:00\",\"2017-08-19 09:28:00\",\"2017-08-19 09:29:00\",\"2017-08-19 09:30:00\",\"2017-08-19 09:31:00\",\"2017-08-19 09:32:00\",\"2017-08-19 09:33:00\",\"2017-08-19 09:34:00\",\"2017-08-19 09:35:00\",\"2017-08-19 09:36:00\",\"2017-08-19 09:37:00\",\"2017-08-19 09:38:00\",\"2017-08-19 09:39:00\",\"2017-08-19 09:40:00\",\"2017-08-19 09:41:00\",\"2017-08-19 09:42:00\",\"2017-08-19 09:43:00\",\"2017-08-19 09:44:00\",\"2017-08-19 09:45:00\",\"2017-08-19 09:46:00\",\"2017-08-19 09:47:00\",\"2017-08-19 09:48:00\",\"2017-08-19 09:49:00\",\"2017-08-19 09:50:00\",\"2017-08-19 09:51:00\",\"2017-08-19 09:52:00\",\"2017-08-19 09:53:00\",\"2017-08-19 09:54:00\",\"2017-08-19 09:55:00\",\"2017-08-19 09:56:00\",\"2017-08-19 09:57:00\",\"2017-08-19 09:58:00\",\"2017-08-19 09:59:00\",\"2017-08-19 10:00:00\",\"2017-08-19 10:01:00\",\"2017-08-19 10:02:00\",\"2017-08-19 10:03:00\",\"2017-08-19 10:04:00\",\"2017-08-19 10:05:00\",\"2017-08-19 10:06:00\",\"2017-08-19 10:07:00\",\"2017-08-19 10:08:00\",\"2017-08-19 10:09:00\",\"2017-08-19 10:10:00\",\"2017-08-19 10:11:00\",\"2017-08-19 10:12:00\",\"2017-08-19 10:13:00\",\"2017-08-19 10:14:00\",\"2017-08-19 10:15:00\",\"2017-08-19 10:16:00\",\"2017-08-19 10:17:00\",\"2017-08-19 10:18:00\",\"2017-08-19 10:19:00\",\"2017-08-19 10:20:00\",\"2017-08-19 10:21:00\",\"2017-08-19 10:22:00\",\"2017-08-19 10:23:00\",\"2017-08-19 10:24:00\",\"2017-08-19 10:25:00\",\"2017-08-19 10:26:00\",\"2017-08-19 10:27:00\",\"2017-08-19 10:28:00\",\"2017-08-19 10:29:00\",\"2017-08-19 10:30:00\",\"2017-08-19 10:31:00\",\"2017-08-19 10:32:00\",\"2017-08-19 10:33:00\",\"2017-08-19 10:34:00\",\"2017-08-19 10:35:00\",\"2017-08-19 10:36:00\",\"2017-08-19 10:37:00\",\"2017-08-19 10:38:00\",\"2017-08-19 10:39:00\",\"2017-08-19 10:40:00\",\"2017-08-19 10:41:00\",\"2017-08-19 10:42:00\",\"2017-08-19 10:43:00\",\"2017-08-19 10:44:00\",\"2017-08-19 10:45:00\",\"2017-08-19 10:46:00\",\"2017-08-19 10:47:00\",\"2017-08-19 10:48:00\",\"2017-08-19 10:49:00\",\"2017-08-19 10:50:00\",\"2017-08-19 10:51:00\",\"2017-08-19 10:52:00\",\"2017-08-19 10:53:00\",\"2017-08-19 10:54:00\",\"2017-08-19 10:55:00\",\"2017-08-19 10:56:00\",\"2017-08-19 10:57:00\",\"2017-08-19 10:58:00\",\"2017-08-19 10:59:00\",\"2017-08-19 11:00:00\",\"2017-08-19 11:01:00\",\"2017-08-19 11:02:00\",\"2017-08-19 11:03:00\",\"2017-08-19 11:04:00\",\"2017-08-19 11:05:00\",\"2017-08-19 11:06:00\",\"2017-08-19 11:07:00\",\"2017-08-19 11:08:00\",\"2017-08-19 11:09:00\",\"2017-08-19 11:10:00\",\"2017-08-19 11:11:00\",\"2017-08-19 11:12:00\",\"2017-08-19 11:13:00\",\"2017-08-19 11:14:00\",\"2017-08-19 11:15:00\",\"2017-08-19 11:16:00\",\"2017-08-19 11:17:00\",\"2017-08-19 11:18:00\",\"2017-08-19 11:19:00\",\"2017-08-19 11:20:00\",\"2017-08-19 11:21:00\",\"2017-08-19 11:22:00\",\"2017-08-19 11:23:00\",\"2017-08-19 11:24:00\",\"2017-08-19 11:25:00\",\"2017-08-19 11:26:00\",\"2017-08-19 11:27:00\",\"2017-08-19 11:28:00\",\"2017-08-19 11:29:00\",\"2017-08-19 11:30:00\",\"2017-08-19 11:31:00\",\"2017-08-19 11:32:00\",\"2017-08-19 11:33:00\",\"2017-08-19 11:34:00\",\"2017-08-19 11:35:00\",\"2017-08-19 11:36:00\",\"2017-08-19 11:37:00\",\"2017-08-19 11:38:00\",\"2017-08-19 11:39:00\",\"2017-08-19 11:40:00\",\"2017-08-19 11:41:00\",\"2017-08-19 11:42:00\",\"2017-08-19 11:43:00\",\"2017-08-19 11:44:00\",\"2017-08-19 11:45:00\",\"2017-08-19 11:46:00\",\"2017-08-19 11:47:00\",\"2017-08-19 11:48:00\",\"2017-08-19 11:49:00\",\"2017-08-19 11:50:00\",\"2017-08-19 11:51:00\",\"2017-08-19 11:52:00\",\"2017-08-19 11:53:00\",\"2017-08-19 11:54:00\",\"2017-08-19 11:55:00\",\"2017-08-19 11:56:00\",\"2017-08-19 11:57:00\",\"2017-08-19 11:58:00\",\"2017-08-19 11:59:00\",\"2017-08-19 12:00:00\",\"2017-08-19 12:01:00\",\"2017-08-19 12:02:00\",\"2017-08-19 12:03:00\",\"2017-08-19 12:04:00\",\"2017-08-19 12:05:00\",\"2017-08-19 12:06:00\",\"2017-08-19 12:07:00\",\"2017-08-19 12:08:00\",\"2017-08-19 12:09:00\",\"2017-08-19 12:10:00\",\"2017-08-19 12:11:00\",\"2017-08-19 12:12:00\",\"2017-08-19 12:13:00\",\"2017-08-19 12:14:00\",\"2017-08-19 12:15:00\",\"2017-08-19 12:16:00\",\"2017-08-19 12:17:00\",\"2017-08-19 12:18:00\",\"2017-08-19 12:19:00\",\"2017-08-19 12:20:00\",\"2017-08-19 12:21:00\",\"2017-08-19 12:22:00\",\"2017-08-19 12:23:00\",\"2017-08-19 12:24:00\",\"2017-08-19 12:25:00\",\"2017-08-19 12:26:00\",\"2017-08-19 12:27:00\",\"2017-08-19 12:28:00\",\"2017-08-19 12:29:00\",\"2017-08-19 12:30:00\",\"2017-08-19 12:31:00\",\"2017-08-19 12:32:00\",\"2017-08-19 12:33:00\",\"2017-08-19 12:34:00\",\"2017-08-19 12:35:00\",\"2017-08-19 12:36:00\",\"2017-08-19 12:37:00\",\"2017-08-19 12:38:00\",\"2017-08-19 12:39:00\",\"2017-08-19 12:40:00\",\"2017-08-19 12:41:00\",\"2017-08-19 12:42:00\",\"2017-08-19 12:43:00\",\"2017-08-19 12:44:00\",\"2017-08-19 12:45:00\",\"2017-08-19 12:46:00\",\"2017-08-19 12:47:00\",\"2017-08-19 12:48:00\",\"2017-08-19 12:49:00\",\"2017-08-19 12:50:00\",\"2017-08-19 12:51:00\",\"2017-08-19 12:52:00\",\"2017-08-19 12:53:00\",\"2017-08-19 12:54:00\",\"2017-08-19 12:55:00\",\"2017-08-19 12:56:00\",\"2017-08-19 12:57:00\",\"2017-08-19 12:58:00\",\"2017-08-19 12:59:00\",\"2017-08-19 13:00:00\",\"2017-08-19 13:01:00\",\"2017-08-19 13:02:00\",\"2017-08-19 13:03:00\",\"2017-08-19 13:04:00\",\"2017-08-19 13:05:00\",\"2017-08-19 13:06:00\",\"2017-08-19 13:07:00\",\"2017-08-19 13:08:00\",\"2017-08-19 13:09:00\",\"2017-08-19 13:10:00\",\"2017-08-19 13:11:00\",\"2017-08-19 13:12:00\",\"2017-08-19 13:13:00\",\"2017-08-19 13:14:00\",\"2017-08-19 13:15:00\",\"2017-08-19 13:16:00\",\"2017-08-19 13:17:00\",\"2017-08-19 13:18:00\",\"2017-08-19 13:19:00\",\"2017-08-19 13:20:00\",\"2017-08-19 13:21:00\",\"2017-08-19 13:22:00\",\"2017-08-19 13:23:00\",\"2017-08-19 13:24:00\",\"2017-08-19 13:25:00\",\"2017-08-19 13:26:00\",\"2017-08-19 13:27:00\",\"2017-08-19 13:28:00\",\"2017-08-19 13:29:00\",\"2017-08-19 13:30:00\",\"2017-08-19 13:31:00\",\"2017-08-19 13:32:00\",\"2017-08-19 13:33:00\",\"2017-08-19 13:34:00\",\"2017-08-19 13:35:00\",\"2017-08-19 13:36:00\",\"2017-08-19 13:37:00\",\"2017-08-19 13:38:00\",\"2017-08-19 13:39:00\",\"2017-08-19 13:40:00\",\"2017-08-19 13:41:00\",\"2017-08-19 13:42:00\",\"2017-08-19 13:43:00\",\"2017-08-19 13:44:00\",\"2017-08-19 13:45:00\",\"2017-08-19 13:46:00\",\"2017-08-19 13:47:00\",\"2017-08-19 13:48:00\",\"2017-08-19 13:49:00\",\"2017-08-19 13:50:00\",\"2017-08-19 13:51:00\",\"2017-08-19 13:52:00\",\"2017-08-19 13:53:00\",\"2017-08-19 13:54:00\",\"2017-08-19 13:55:00\",\"2017-08-19 13:56:00\",\"2017-08-19 13:57:00\",\"2017-08-19 13:58:00\",\"2017-08-19 13:59:00\",\"2017-08-19 14:00:00\",\"2017-08-19 14:01:00\",\"2017-08-19 14:02:00\",\"2017-08-19 14:03:00\",\"2017-08-19 14:04:00\",\"2017-08-19 14:05:00\",\"2017-08-19 14:06:00\",\"2017-08-19 14:07:00\",\"2017-08-19 14:08:00\",\"2017-08-19 14:09:00\",\"2017-08-19 14:10:00\",\"2017-08-19 14:11:00\",\"2017-08-19 14:12:00\",\"2017-08-19 14:13:00\",\"2017-08-19 14:14:00\",\"2017-08-19 14:15:00\",\"2017-08-19 14:16:00\",\"2017-08-19 14:17:00\",\"2017-08-19 14:18:00\",\"2017-08-19 14:19:00\",\"2017-08-19 14:20:00\",\"2017-08-19 14:21:00\",\"2017-08-19 14:22:00\",\"2017-08-19 14:23:00\",\"2017-08-19 14:24:00\",\"2017-08-19 14:25:00\",\"2017-08-19 14:26:00\",\"2017-08-19 14:27:00\",\"2017-08-19 14:28:00\",\"2017-08-19 14:29:00\",\"2017-08-19 14:30:00\",\"2017-08-19 14:31:00\",\"2017-08-19 14:32:00\",\"2017-08-19 14:33:00\",\"2017-08-19 14:34:00\",\"2017-08-19 14:35:00\",\"2017-08-19 14:36:00\",\"2017-08-19 14:37:00\",\"2017-08-19 14:38:00\",\"2017-08-19 14:39:00\",\"2017-08-19 14:40:00\",\"2017-08-19 14:41:00\",\"2017-08-19 14:42:00\",\"2017-08-19 14:43:00\",\"2017-08-19 14:44:00\",\"2017-08-19 14:45:00\",\"2017-08-19 14:46:00\",\"2017-08-19 14:47:00\",\"2017-08-19 14:48:00\",\"2017-08-19 14:49:00\",\"2017-08-19 14:50:00\",\"2017-08-19 14:51:00\",\"2017-08-19 14:52:00\",\"2017-08-19 14:53:00\",\"2017-08-19 14:54:00\",\"2017-08-19 14:55:00\",\"2017-08-19 14:56:00\",\"2017-08-19 14:57:00\",\"2017-08-19 14:58:00\",\"2017-08-19 14:59:00\",\"2017-08-19 15:00:00\",\"2017-08-19 15:01:00\",\"2017-08-19 15:02:00\",\"2017-08-19 15:03:00\",\"2017-08-19 15:04:00\",\"2017-08-19 15:05:00\",\"2017-08-19 15:06:00\",\"2017-08-19 15:07:00\",\"2017-08-19 15:08:00\",\"2017-08-19 15:09:00\",\"2017-08-19 15:10:00\",\"2017-08-19 15:11:00\",\"2017-08-19 15:12:00\",\"2017-08-19 15:13:00\",\"2017-08-19 15:14:00\",\"2017-08-19 15:15:00\",\"2017-08-19 15:16:00\",\"2017-08-19 15:17:00\",\"2017-08-19 15:18:00\",\"2017-08-19 15:19:00\",\"2017-08-19 15:20:00\",\"2017-08-19 15:21:00\",\"2017-08-19 15:22:00\",\"2017-08-19 15:23:00\",\"2017-08-19 15:24:00\",\"2017-08-19 15:25:00\",\"2017-08-19 15:26:00\",\"2017-08-19 15:27:00\",\"2017-08-19 15:28:00\",\"2017-08-19 15:29:00\",\"2017-08-19 15:30:00\",\"2017-08-19 15:31:00\",\"2017-08-19 15:32:00\",\"2017-08-19 15:33:00\",\"2017-08-19 15:34:00\",\"2017-08-19 15:35:00\",\"2017-08-19 15:36:00\",\"2017-08-19 15:37:00\",\"2017-08-19 15:38:00\",\"2017-08-19 15:39:00\",\"2017-08-19 15:40:00\",\"2017-08-19 15:41:00\",\"2017-08-19 15:42:00\",\"2017-08-19 15:43:00\",\"2017-08-19 15:44:00\",\"2017-08-19 15:45:00\",\"2017-08-19 15:46:00\",\"2017-08-19 15:47:00\",\"2017-08-19 15:48:00\",\"2017-08-19 15:49:00\",\"2017-08-19 15:50:00\",\"2017-08-19 15:51:00\",\"2017-08-19 15:52:00\",\"2017-08-19 15:53:00\",\"2017-08-19 15:54:00\",\"2017-08-19 15:55:00\",\"2017-08-19 15:56:00\",\"2017-08-19 15:57:00\",\"2017-08-19 15:58:00\",\"2017-08-19 15:59:00\",\"2017-08-19 16:00:00\",\"2017-08-19 16:01:00\",\"2017-08-19 16:02:00\",\"2017-08-19 16:03:00\",\"2017-08-19 16:04:00\",\"2017-08-19 16:05:00\",\"2017-08-19 16:06:00\",\"2017-08-19 16:07:00\",\"2017-08-19 16:08:00\",\"2017-08-19 16:09:00\",\"2017-08-19 16:10:00\",\"2017-08-19 16:11:00\",\"2017-08-19 16:12:00\",\"2017-08-19 16:13:00\",\"2017-08-19 16:14:00\",\"2017-08-19 16:15:00\",\"2017-08-19 16:16:00\",\"2017-08-19 16:17:00\",\"2017-08-19 16:18:00\",\"2017-08-19 16:19:00\",\"2017-08-19 16:20:00\",\"2017-08-19 16:21:00\",\"2017-08-19 16:22:00\",\"2017-08-19 16:23:00\",\"2017-08-19 16:24:00\",\"2017-08-19 16:25:00\",\"2017-08-19 16:26:00\",\"2017-08-19 16:27:00\",\"2017-08-19 16:28:00\",\"2017-08-19 16:29:00\",\"2017-08-19 16:30:00\",\"2017-08-19 16:31:00\",\"2017-08-19 16:32:00\",\"2017-08-19 16:33:00\",\"2017-08-19 16:34:00\",\"2017-08-19 16:35:00\",\"2017-08-19 16:36:00\",\"2017-08-19 16:37:00\",\"2017-08-19 16:38:00\",\"2017-08-19 16:39:00\",\"2017-08-19 16:40:00\",\"2017-08-19 16:41:00\",\"2017-08-19 16:42:00\",\"2017-08-19 16:43:00\",\"2017-08-19 16:44:00\",\"2017-08-19 16:45:00\",\"2017-08-19 16:46:00\",\"2017-08-19 16:47:00\",\"2017-08-19 16:48:00\",\"2017-08-19 16:49:00\",\"2017-08-19 16:50:00\",\"2017-08-19 16:51:00\",\"2017-08-19 16:52:00\",\"2017-08-19 16:53:00\",\"2017-08-19 16:54:00\",\"2017-08-19 16:55:00\",\"2017-08-19 16:56:00\",\"2017-08-19 16:57:00\",\"2017-08-19 16:58:00\",\"2017-08-19 16:59:00\",\"2017-08-19 17:00:00\",\"2017-08-19 17:01:00\",\"2017-08-19 17:02:00\",\"2017-08-19 17:03:00\",\"2017-08-19 17:04:00\",\"2017-08-19 17:05:00\",\"2017-08-19 17:06:00\",\"2017-08-19 17:07:00\",\"2017-08-19 17:08:00\",\"2017-08-19 17:09:00\",\"2017-08-19 17:10:00\",\"2017-08-19 17:11:00\",\"2017-08-19 17:12:00\",\"2017-08-19 17:13:00\",\"2017-08-19 17:14:00\",\"2017-08-19 17:15:00\",\"2017-08-19 17:16:00\",\"2017-08-19 17:17:00\",\"2017-08-19 17:18:00\",\"2017-08-19 17:19:00\",\"2017-08-19 17:20:00\",\"2017-08-19 17:21:00\",\"2017-08-19 17:22:00\",\"2017-08-19 17:23:00\",\"2017-08-19 17:24:00\",\"2017-08-19 17:25:00\",\"2017-08-19 17:26:00\",\"2017-08-19 17:27:00\",\"2017-08-19 17:28:00\",\"2017-08-19 17:29:00\",\"2017-08-19 17:30:00\",\"2017-08-19 17:31:00\",\"2017-08-19 17:32:00\",\"2017-08-19 17:33:00\",\"2017-08-19 17:34:00\",\"2017-08-19 17:35:00\",\"2017-08-19 17:36:00\",\"2017-08-19 17:37:00\",\"2017-08-19 17:38:00\",\"2017-08-19 17:39:00\",\"2017-08-19 17:40:00\",\"2017-08-19 17:41:00\",\"2017-08-19 17:42:00\",\"2017-08-19 17:43:00\",\"2017-08-19 17:44:00\",\"2017-08-19 17:45:00\",\"2017-08-19 17:46:00\",\"2017-08-19 17:47:00\",\"2017-08-19 17:48:00\",\"2017-08-19 17:49:00\",\"2017-08-19 17:50:00\",\"2017-08-19 17:51:00\",\"2017-08-19 17:52:00\",\"2017-08-19 17:53:00\",\"2017-08-19 17:54:00\",\"2017-08-19 17:55:00\",\"2017-08-19 17:56:00\",\"2017-08-19 17:57:00\",\"2017-08-19 17:58:00\",\"2017-08-19 17:59:00\",\"2017-08-19 18:00:00\",\"2017-08-19 18:01:00\",\"2017-08-19 18:02:00\",\"2017-08-19 18:03:00\",\"2017-08-19 18:04:00\",\"2017-08-19 18:05:00\",\"2017-08-19 18:06:00\",\"2017-08-19 18:07:00\",\"2017-08-19 18:08:00\",\"2017-08-19 18:09:00\",\"2017-08-19 18:10:00\",\"2017-08-19 18:11:00\",\"2017-08-19 18:12:00\",\"2017-08-19 18:13:00\",\"2017-08-19 18:14:00\",\"2017-08-19 18:15:00\",\"2017-08-19 18:16:00\",\"2017-08-19 18:17:00\",\"2017-08-19 18:18:00\",\"2017-08-19 18:19:00\",\"2017-08-19 18:20:00\",\"2017-08-19 18:21:00\",\"2017-08-19 18:22:00\",\"2017-08-19 18:23:00\",\"2017-08-19 18:24:00\",\"2017-08-19 18:25:00\",\"2017-08-19 18:26:00\",\"2017-08-19 18:27:00\",\"2017-08-19 18:28:00\",\"2017-08-19 18:29:00\",\"2017-08-19 18:30:00\",\"2017-08-19 18:31:00\",\"2017-08-19 18:32:00\",\"2017-08-19 18:33:00\",\"2017-08-19 18:34:00\",\"2017-08-19 18:35:00\",\"2017-08-19 18:36:00\",\"2017-08-19 18:37:00\",\"2017-08-19 18:38:00\",\"2017-08-19 18:39:00\",\"2017-08-19 18:40:00\",\"2017-08-19 18:41:00\",\"2017-08-19 18:42:00\",\"2017-08-19 18:43:00\",\"2017-08-19 18:44:00\",\"2017-08-19 18:45:00\",\"2017-08-19 18:46:00\",\"2017-08-19 18:47:00\",\"2017-08-19 18:48:00\",\"2017-08-19 18:49:00\",\"2017-08-19 18:50:00\",\"2017-08-19 18:51:00\",\"2017-08-19 18:52:00\",\"2017-08-19 18:53:00\",\"2017-08-19 18:54:00\",\"2017-08-19 18:55:00\",\"2017-08-19 18:56:00\",\"2017-08-19 18:57:00\",\"2017-08-19 18:58:00\",\"2017-08-19 18:59:00\",\"2017-08-19 19:00:00\",\"2017-08-19 19:01:00\",\"2017-08-19 19:02:00\",\"2017-08-19 19:03:00\",\"2017-08-19 19:04:00\",\"2017-08-19 19:05:00\",\"2017-08-19 19:06:00\",\"2017-08-19 19:07:00\",\"2017-08-19 19:08:00\",\"2017-08-19 19:09:00\",\"2017-08-19 19:10:00\",\"2017-08-19 19:11:00\",\"2017-08-19 19:12:00\",\"2017-08-19 19:13:00\",\"2017-08-19 19:14:00\",\"2017-08-19 19:15:00\",\"2017-08-19 19:16:00\",\"2017-08-19 19:17:00\",\"2017-08-19 19:18:00\",\"2017-08-19 19:19:00\",\"2017-08-19 19:20:00\",\"2017-08-19 19:21:00\",\"2017-08-19 19:22:00\",\"2017-08-19 19:23:00\",\"2017-08-19 19:24:00\",\"2017-08-19 19:25:00\",\"2017-08-19 19:26:00\",\"2017-08-19 19:27:00\",\"2017-08-19 19:28:00\",\"2017-08-19 19:29:00\",\"2017-08-19 19:30:00\",\"2017-08-19 19:31:00\",\"2017-08-19 19:32:00\",\"2017-08-19 19:33:00\",\"2017-08-19 19:34:00\",\"2017-08-19 19:35:00\",\"2017-08-19 19:36:00\",\"2017-08-19 19:37:00\",\"2017-08-19 19:38:00\",\"2017-08-19 19:39:00\",\"2017-08-19 19:40:00\",\"2017-08-19 19:41:00\",\"2017-08-19 19:42:00\",\"2017-08-19 19:43:00\",\"2017-08-19 19:44:00\",\"2017-08-19 19:45:00\",\"2017-08-19 19:46:00\",\"2017-08-19 19:47:00\",\"2017-08-19 19:48:00\",\"2017-08-19 19:49:00\",\"2017-08-19 19:50:00\",\"2017-08-19 19:51:00\",\"2017-08-19 19:52:00\",\"2017-08-19 19:53:00\",\"2017-08-19 19:54:00\",\"2017-08-19 19:55:00\",\"2017-08-19 19:56:00\",\"2017-08-19 19:57:00\",\"2017-08-19 19:58:00\",\"2017-08-19 19:59:00\",\"2017-08-19 20:00:00\",\"2017-08-19 20:01:00\",\"2017-08-19 20:02:00\",\"2017-08-19 20:03:00\",\"2017-08-19 20:04:00\",\"2017-08-19 20:05:00\",\"2017-08-19 20:06:00\",\"2017-08-19 20:07:00\",\"2017-08-19 20:08:00\",\"2017-08-19 20:09:00\",\"2017-08-19 20:10:00\",\"2017-08-19 20:11:00\",\"2017-08-19 20:12:00\",\"2017-08-19 20:13:00\",\"2017-08-19 20:14:00\",\"2017-08-19 20:15:00\",\"2017-08-19 20:16:00\",\"2017-08-19 20:17:00\",\"2017-08-19 20:18:00\",\"2017-08-19 20:19:00\",\"2017-08-19 20:20:00\",\"2017-08-19 20:21:00\",\"2017-08-19 20:22:00\",\"2017-08-19 20:23:00\",\"2017-08-19 20:24:00\",\"2017-08-19 20:25:00\",\"2017-08-19 20:26:00\",\"2017-08-19 20:27:00\",\"2017-08-19 20:28:00\",\"2017-08-19 20:29:00\",\"2017-08-19 20:30:00\",\"2017-08-19 20:31:00\",\"2017-08-19 20:32:00\",\"2017-08-19 20:33:00\",\"2017-08-19 20:34:00\",\"2017-08-19 20:35:00\",\"2017-08-19 20:36:00\",\"2017-08-19 20:37:00\",\"2017-08-19 20:38:00\",\"2017-08-19 20:39:00\",\"2017-08-19 20:40:00\",\"2017-08-19 20:41:00\",\"2017-08-19 20:42:00\",\"2017-08-19 20:43:00\",\"2017-08-19 20:44:00\",\"2017-08-19 20:45:00\",\"2017-08-19 20:46:00\",\"2017-08-19 20:47:00\",\"2017-08-19 20:48:00\",\"2017-08-19 20:49:00\",\"2017-08-19 20:50:00\",\"2017-08-19 20:51:00\",\"2017-08-19 20:52:00\",\"2017-08-19 20:53:00\",\"2017-08-19 20:54:00\",\"2017-08-19 20:55:00\",\"2017-08-19 20:56:00\",\"2017-08-19 20:57:00\",\"2017-08-19 20:58:00\",\"2017-08-19 20:59:00\",\"2017-08-19 21:00:00\",\"2017-08-19 21:01:00\",\"2017-08-19 21:02:00\",\"2017-08-19 21:03:00\",\"2017-08-19 21:04:00\",\"2017-08-19 21:05:00\",\"2017-08-19 21:06:00\",\"2017-08-19 21:07:00\",\"2017-08-19 21:08:00\",\"2017-08-19 21:09:00\",\"2017-08-19 21:10:00\",\"2017-08-19 21:11:00\",\"2017-08-19 21:12:00\",\"2017-08-19 21:13:00\",\"2017-08-19 21:14:00\",\"2017-08-19 21:15:00\",\"2017-08-19 21:16:00\",\"2017-08-19 21:17:00\",\"2017-08-19 21:18:00\",\"2017-08-19 21:19:00\",\"2017-08-19 21:20:00\",\"2017-08-19 21:21:00\",\"2017-08-19 21:22:00\",\"2017-08-19 21:23:00\",\"2017-08-19 21:24:00\",\"2017-08-19 21:25:00\",\"2017-08-19 21:26:00\",\"2017-08-19 21:27:00\",\"2017-08-19 21:28:00\",\"2017-08-19 21:29:00\",\"2017-08-19 21:30:00\",\"2017-08-19 21:31:00\",\"2017-08-19 21:32:00\",\"2017-08-19 21:33:00\",\"2017-08-19 21:34:00\",\"2017-08-19 21:35:00\",\"2017-08-19 21:36:00\",\"2017-08-19 21:37:00\",\"2017-08-19 21:38:00\",\"2017-08-19 21:39:00\",\"2017-08-19 21:40:00\",\"2017-08-19 21:41:00\",\"2017-08-19 21:42:00\",\"2017-08-19 21:43:00\",\"2017-08-19 21:44:00\",\"2017-08-19 21:45:00\",\"2017-08-19 21:46:00\",\"2017-08-19 21:47:00\",\"2017-08-19 21:48:00\",\"2017-08-19 21:49:00\",\"2017-08-19 21:50:00\",\"2017-08-19 21:51:00\",\"2017-08-19 21:52:00\",\"2017-08-19 21:53:00\",\"2017-08-19 21:54:00\",\"2017-08-19 21:55:00\",\"2017-08-19 21:56:00\",\"2017-08-19 21:57:00\",\"2017-08-19 21:58:00\",\"2017-08-19 21:59:00\",\"2017-08-19 22:00:00\",\"2017-08-19 22:01:00\",\"2017-08-19 22:02:00\",\"2017-08-19 22:03:00\",\"2017-08-19 22:04:00\",\"2017-08-19 22:05:00\",\"2017-08-19 22:06:00\",\"2017-08-19 22:07:00\",\"2017-08-19 22:08:00\",\"2017-08-19 22:09:00\",\"2017-08-19 22:10:00\",\"2017-08-19 22:11:00\",\"2017-08-19 22:12:00\",\"2017-08-19 22:13:00\",\"2017-08-19 22:14:00\",\"2017-08-19 22:15:00\",\"2017-08-19 22:16:00\",\"2017-08-19 22:17:00\",\"2017-08-19 22:18:00\",\"2017-08-19 22:19:00\",\"2017-08-19 22:20:00\",\"2017-08-19 22:21:00\",\"2017-08-19 22:22:00\",\"2017-08-19 22:23:00\",\"2017-08-19 22:24:00\",\"2017-08-19 22:25:00\",\"2017-08-19 22:26:00\",\"2017-08-19 22:27:00\",\"2017-08-19 22:28:00\",\"2017-08-19 22:29:00\",\"2017-08-19 22:30:00\",\"2017-08-19 22:31:00\",\"2017-08-19 22:32:00\",\"2017-08-19 22:33:00\",\"2017-08-19 22:34:00\",\"2017-08-19 22:35:00\",\"2017-08-19 22:36:00\",\"2017-08-19 22:37:00\",\"2017-08-19 22:38:00\",\"2017-08-19 22:39:00\",\"2017-08-19 22:40:00\",\"2017-08-19 22:41:00\",\"2017-08-19 22:42:00\",\"2017-08-19 22:43:00\",\"2017-08-19 22:44:00\",\"2017-08-19 22:45:00\",\"2017-08-19 22:46:00\",\"2017-08-19 22:47:00\",\"2017-08-19 22:48:00\",\"2017-08-19 22:49:00\",\"2017-08-19 22:50:00\",\"2017-08-19 22:51:00\",\"2017-08-19 22:52:00\",\"2017-08-19 22:53:00\",\"2017-08-19 22:54:00\",\"2017-08-19 22:55:00\",\"2017-08-19 22:56:00\",\"2017-08-19 22:57:00\",\"2017-08-19 22:58:00\",\"2017-08-19 22:59:00\",\"2017-08-19 23:00:00\",\"2017-08-19 23:01:00\",\"2017-08-19 23:02:00\",\"2017-08-19 23:03:00\",\"2017-08-19 23:04:00\",\"2017-08-19 23:05:00\",\"2017-08-19 23:06:00\",\"2017-08-19 23:07:00\",\"2017-08-19 23:08:00\",\"2017-08-19 23:09:00\",\"2017-08-19 23:10:00\",\"2017-08-19 23:11:00\",\"2017-08-19 23:12:00\",\"2017-08-19 23:13:00\",\"2017-08-19 23:14:00\",\"2017-08-19 23:15:00\",\"2017-08-19 23:16:00\",\"2017-08-19 23:17:00\",\"2017-08-19 23:18:00\",\"2017-08-19 23:19:00\",\"2017-08-19 23:20:00\",\"2017-08-19 23:21:00\",\"2017-08-19 23:22:00\",\"2017-08-19 23:23:00\",\"2017-08-19 23:24:00\",\"2017-08-19 23:25:00\",\"2017-08-19 23:26:00\",\"2017-08-19 23:27:00\",\"2017-08-19 23:28:00\",\"2017-08-19 23:29:00\",\"2017-08-19 23:30:00\",\"2017-08-19 23:31:00\",\"2017-08-19 23:32:00\",\"2017-08-19 23:33:00\",\"2017-08-19 23:34:00\",\"2017-08-19 23:35:00\",\"2017-08-19 23:36:00\",\"2017-08-19 23:37:00\",\"2017-08-19 23:38:00\",\"2017-08-19 23:39:00\",\"2017-08-19 23:40:00\",\"2017-08-19 23:41:00\",\"2017-08-19 23:42:00\",\"2017-08-19 23:43:00\",\"2017-08-19 23:44:00\",\"2017-08-19 23:45:00\",\"2017-08-19 23:46:00\",\"2017-08-19 23:47:00\",\"2017-08-19 23:48:00\",\"2017-08-19 23:49:00\",\"2017-08-19 23:50:00\",\"2017-08-19 23:51:00\",\"2017-08-19 23:52:00\",\"2017-08-19 23:53:00\",\"2017-08-19 23:54:00\",\"2017-08-19 23:55:00\",\"2017-08-19 23:56:00\",\"2017-08-19 23:57:00\",\"2017-08-19 23:58:00\",\"2017-08-19 23:59:00\"],\"xaxis\":\"x\",\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.368985652923584,0.3670997619628906,0.3652423918247223,0.3637787699699402,0.3628389239311218,0.36236339807510376,0.362233966588974,0.3623056709766388,0.35863611102104187,0.3561271131038666,0.35766950249671936,0.3588913381099701,0.35965991020202637,0.36005643010139465,0.36005163192749023,0.35999083518981934,0.35981807112693787,0.35983845591545105,0.3599395155906677,0.36003920435905457,0.36012113094329834,0.36018824577331543,0.3602457344532013,0.36038145422935486,0.3604978919029236,0.3604978919029236,0.3604978919029236,0.3604978919029236,0.3604978919029236,0.3604978919029236,0.3604978919029236,0.36542364954948425,0.3688928186893463,0.3715013861656189,0.3734985888004303,0.3750578761100769,0.3763127028942108,0.3772355914115906,0.37894362211227417,0.3801920413970947,0.3856567442417145,0.3898050785064697,0.3884986340999603,0.38716140389442444,0.38606011867523193,0.38538891077041626,0.38498663902282715,0.3847406506538391,0.3935796916484833,0.3998456299304962,0.4043199419975281,0.4075551927089691,0.4098129868507385,0.4112131893634796,0.4120236039161682,0.412445068359375,0.41202569007873535,0.41156867146492004,0.41120103001594543,0.41841912269592285,0.42344143986701965,0.4264718294143677,0.420566201210022,0.41543468832969666,0.412832111120224,0.4120325446128845,0.41232505440711975,0.41240283846855164,0.41242632269859314,0.4122895300388336,0.4120984971523285,0.4119221270084381,0.41175636649131775,0.41165655851364136,0.414991170167923,0.4173303246498108,0.4182717800140381,0.4188770055770874,0.4191194772720337,0.41914477944374084,0.41908174753189087,0.4190656542778015,0.41904282569885254,0.41902315616607666,0.4190090000629425,0.4202798902988434,0.42122772336006165,0.42160385847091675,0.4215966761112213,0.4216519296169281,0.4285554587841034,0.4331141412258148,0.4355538785457611,0.43687811493873596,0.4370664060115814,0.4367657005786896,0.42872193455696106,0.4232005476951599,0.42169955372810364,0.42267662286758423,0.4238080084323883,0.42455706000328064,0.4244683086872101,0.4240955114364624,0.42362362146377563,0.42306265234947205,0.4226329028606415,0.4222768545150757,0.42210447788238525,0.4219961166381836,0.42190057039260864,0.42190057039260864,0.42190057039260864,0.4217585325241089,0.4216587543487549,0.42162439227104187,0.4216328263282776,0.42163676023483276,0.421632319688797,0.4216272234916687,0.42162221670150757,0.42161762714385986,0.42161351442337036,0.42160993814468384,0.4216068983078003,0.4216044545173645,0.42160236835479736,0.42160046100616455,0.415666401386261,0.4115811884403229,0.41022926568984985,0.4105660021305084,0.4110881984233856,0.4111804664134979,0.4107797145843506,0.41033515334129333,0.4099277853965759,0.40957826375961304,0.4093216061592102,0.40920841693878174,0.40912526845932007,0.40905383229255676,0.4143899381160736,0.417880654335022,0.4036868214607239,0.4098302125930786,0.4164159893989563,0.42011508345603943,0.4215223789215088,0.4276874363422394,0.43013107776641846,0.43129029870033264,0.431595116853714,0.4312678575515747,0.4308164119720459,0.43042418360710144,0.43032124638557434,0.43324440717697144,0.43533578515052795,0.4209229350090027,0.410185307264328,0.397137850522995,0.3922230303287506,0.3927035331726074,0.39409729838371277,0.39507779479026794,0.4018765985965729,0.40502095222473145,0.4052428603172302,0.4042443633079529,0.4027416408061981,0.4021441638469696,0.4024026691913605,0.40259891748428345,0.4026869833469391,0.40269866585731506,0.4026317298412323,0.40257003903388977,0.40255171060562134,0.4025389850139618,0.4025355875492096,0.4025355875492096,0.4025355875492096,0.4025355875492096,0.4025355875492096,0.4025355875492096,0.4040362238883972,0.40509167313575745,0.40385961532592773,0.40465831756591797,0.4150896370410919,0.4139058291912079,0.40203285217285156,0.3945350646972656,0.40042656660079956,0.3993438184261322,0.3975662887096405,0.4023934304714203,0.40560173988342285,0.4071986973285675,0.408048540353775,0.4083780348300934,0.4087521731853485,0.40891537070274353,0.4089490473270416,0.4090045690536499,0.4089411199092865,0.4088851809501648,0.4088740944862366,0.40885332226753235,0.4088420867919922,0.4088514745235443,0.4147723913192749,0.4186541438102722,0.42091506719589233,0.42238229513168335,0.4230988025665283,0.42319902777671814,0.42307600378990173,0.42287540435791016,0.4227232336997986,0.422672301530838,0.4226371943950653,0.42260777950286865,0.4226981997489929,0.42280063033103943,0.42289096117019653,0.42289096117019653,0.42289096117019653,0.42289096117019653,0.4486052989959717,0.46835243701934814,0.4806777834892273,0.48657214641571045,0.4873717129230499,0.48469868302345276,0.4802246689796448,0.476926326751709,0.4763057231903076,0.47752633690834045,0.4800267517566681,0.4829477071762085,0.4853215515613556,0.48712393641471863,0.48832520842552185,0.4883267283439636,0.4883280098438263,0.48832881450653076,0.48832938075065613,0.48832979798316956,0.48833009600639343,0.4828933775424957,0.47903159260749817,0.47888001799583435,0.4810009002685547,0.48312729597091675,0.4427920877933502,0.42401087284088135,0.4187619090080261,0.42425596714019775,0.431450754404068,0.4342997968196869,0.43192288279533386,0.42695677280426025,0.42901864647865295,0.4497338831424713,0.46426624059677124,0.47246053814888,0.45802414417266846,0.4435921609401703,0.45635199546813965,0.4672565162181854,0.472354918718338,0.4731799364089966,0.4720207154750824,0.4699830710887909,0.46897271275520325,0.4694269597530365,0.4710192382335663,0.47293907403945923,0.4736892580986023,0.45087453722953796,0.4580060839653015,0.4729870557785034,0.4824817180633545,0.4842601418495178,0.48096615076065063,0.4743470847606659,0.4722611904144287,0.47285133600234985,0.4737327992916107,0.4744223356246948,0.47490090131759644,0.47524455189704895,0.4755645990371704,0.4757530093193054,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.46488818526268005,0.45663559436798096,0.46741244196891785,0.47814542055130005,0.48332396149635315,0.48257747292518616,0.4774782359600067,0.4732299745082855,0.4725683331489563,0.47329920530319214,0.4740765690803528,0.47465628385543823,0.47506746649742126,0.4636021554470062,0.4556117057800293,0.46694788336753845,0.47814542055130005,0.48332396149635315,0.48257747292518616,0.4774782359600067,0.4732299745082855,0.4725683331489563,0.4615423381328583,0.45408037304878235,0.4653705060482025,0.476610004901886,0.4820363223552704,0.48137328028678894,0.47692346572875977,0.4732299745082855,0.4725683331489563,0.47329920530319214,0.4740765690803528,0.47465628385543823,0.47506746649742126,0.4753861725330353,0.475647509098053,0.47594329714775085,0.47618934512138367,0.47646623849868774,0.4767829477787018,0.47691458463668823,0.47685205936431885,0.4767049551010132,0.47660139203071594,0.4765818417072296,0.47660326957702637,0.47662755846977234,0.4766455888748169,0.4766579866409302,0.476667582988739,0.47667428851127625,0.476687490940094,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.4766986668109894,0.46728482842445374,0.4606693983078003,0.46013519167900085,0.4496425986289978,0.43693992495536804,0.4326463043689728,0.41037312150001526,0.42443734407424927,0.4387780427932739,0.4341549277305603,0.43706214427948,0.43663740158081055,0.4347732365131378,0.43244510889053345,0.4299345910549164,0.4291926920413971,0.42904576659202576,0.4289097487926483,0.42882630228996277,0.4287489950656891,0.42870819568634033,0.4289722144603729,0.4290063977241516,0.42903193831443787,0.42922869324684143,0.4292287230491638,0.4292287230491638,0.4292287230491638,0.4292287230491638,0.4292287230491638,0.4292287230491638,0.4287325441837311,0.4283832907676697,0.4282768666744232,0.4283275902271271,0.42835748195648193,0.42834705114364624,0.42832985520362854,0.4283111095428467,0.42829328775405884,0.4282774031162262,0.4282635748386383,0.428251713514328,0.4282420575618744,0.4282338619232178,0.428226500749588,0.428226500749588,0.428226500749588,0.423677921295166,0.4205193519592285,0.4195709824562073,0.41999998688697815,0.4205961525440216,0.42075058817863464,0.42045047879219055,0.4200918972492218,0.41975581645965576,0.41946470737457275,0.41926464438438416,0.419170081615448,0.41909706592559814,0.41903454065322876,0.4189794063568115,0.4114239811897278,0.4062604606151581,0.4045049250125885,0.404825359582901,0.4054378569126129,0.405473917722702,0.40515464544296265,0.4045061767101288,0.40385210514068604,0.4034194350242615,0.40170395374298096,0.40848052501678467,0.413073867559433,0.4145852029323578,0.4153810441493988,0.4158276319503784,0.4158356487751007,0.415709912776947,0.415546715259552,0.40978989005088806,0.4058752655982971,0.404403418302536,0.40437790751457214,0.4045600891113281,0.40474316477775574,0.40454643964767456,0.40407663583755493,0.40365922451019287,0.4033374488353729,0.40312984585762024,0.40302228927612305,0.4029453992843628,0.39582839608192444,0.39102986454963684,0.38900434970855713,0.4000764787197113,0.4071787893772125,0.41106414794921875,0.41324105858802795,0.4143495559692383,0.4152289927005768,0.4158221185207367,0.41592052578926086,0.415831595659256,0.4156814217567444,0.4155327081680298,0.4153968095779419,0.4153308868408203,0.41530901193618774,0.41541656851768494,0.41541656851768494,0.41541656851768494,0.41541656851768494,0.41541656851768494,0.41541656851768494,0.41541656851768494,0.41541650891304016,0.41541650891304016,0.42160722613334656,0.4256269037723541,0.4277910590171814,0.4290553033351898,0.4294530749320984,0.4293791949748993,0.42912307381629944,0.4288848340511322,0.4363979995250702,0.4413992762565613,0.44389334321022034,0.44506022334098816,0.44489461183547974,0.44431278109550476,0.44384756684303284,0.44366416335105896,0.4436439275741577,0.44396039843559265,0.44425544142723083,0.44450902938842773,0.44478461146354675,0.44513916969299316,0.44544222950935364,0.44544222950935364,0.44544222950935364,0.4295766055583954,0.41880711913108826,0.4167122542858124,0.43975383043289185,0.4559924602508545,0.46309444308280945,0.463554710149765,0.46128812432289124,0.4584434926509857,0.45665857195854187,0.4554908573627472,0.4551644027233124,0.4551600217819214,0.4557322859764099,0.45623692870140076,0.4571962058544159,0.4583335816860199,0.4592072367668152,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Date\"},\"showgrid\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Stock price\"},\"showgrid\":false},\"legend\":{\"title\":{\"text\":\"Close Price\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Comparision between original close price vs predicted close price\"},\"font\":{\"size\":15,\"color\":\"black\"},\"plot_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bf3d5138-9ba9-4118-829d-30a9a54803c7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# shift train predictions for plotting\n",
        "\n",
        "look_back=time_step\n",
        "trainPredictPlot = np.empty_like(closedf)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "print(\"Train predicted data: \", trainPredictPlot.shape)\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(closedf)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-11, :] = test_predict[:]\n",
        "print(\"Test predicted data: \", testPredictPlot.shape)\n",
        "\n",
        "names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
        "\n",
        "\n",
        "plotdf = pd.DataFrame({'date': df_normal.index,\n",
        "                       'original_close': df_normal['Close'],\n",
        "                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
        "                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
        "\n",
        "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
        "                                          plotdf['test_predicted_close']],\n",
        "              labels={'value':'Stock price','date': 'Date'})\n",
        "fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
        "                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
        "fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
        "\n",
        "fig.update_xaxes(showgrid=False)\n",
        "fig.update_yaxes(showgrid=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LpO_EsjvMQE"
      },
      "source": [
        "# Entrenamiento\n",
        "\n",
        "A partir de este punto, cada ejecucion de las siguientes celdas entrenara al modelo con la información de un dia, para luego avanzar al dia siguiente.\n",
        "\n",
        "17/01: Comienzo el entrenamiento con 30 dias, para observar el comportamiento del modelo a mediano plazo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First we will import the necessary Library\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For Evalution we will use these library\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# For model building we will use these library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# For PLotting we will use these library\n",
        "\n",
        "\n",
        "from itertools import cycle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import PIL\n",
        "import itertools"
      ],
      "metadata": {
        "id": "Cn4OrV5zrnTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Notebookfinal/usdt-btc2.csv', index_col='Time')"
      ],
      "metadata": {
        "id": "38sxoou_tSTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "4pcsu3gmBi70",
        "outputId": "6c3616d0-5e68-4702-8753-7a2c6b68352e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Open     High      Low    Close    Volume\n",
              "Time                                                             \n",
              "2017-08-18 00:00:00  4244.77  4267.59  4244.77  4244.77  0.657267\n",
              "2017-08-18 00:01:00  4267.59  4278.05  4267.59  4278.05  0.643297\n",
              "2017-08-18 00:02:00  4244.77  4244.77  4244.77  4244.77  0.216000\n",
              "2017-08-18 00:03:00  4278.05  4278.05  4278.05  4278.05  0.456560\n",
              "2017-08-18 00:04:00  4278.05  4278.05  4278.05  4278.05  0.055644"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8f5fd8c-86f6-4ab7-8735-d79b25d36e21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:00:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>0.657267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:01:00</th>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.643297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:02:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>0.216000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:03:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.456560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:04:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.055644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8f5fd8c-86f6-4ab7-8735-d79b25d36e21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8f5fd8c-86f6-4ab7-8735-d79b25d36e21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8f5fd8c-86f6-4ab7-8735-d79b25d36e21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f48fa4f-a3eb-479c-a463-5226c77c403b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f48fa4f-a3eb-479c-a463-5226c77c403b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f48fa4f-a3eb-479c-a463-5226c77c403b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación defino las dos funciones personalizadas que utilizo"
      ],
      "metadata": {
        "id": "duvsOF3EDwNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizar(dataframe, dia):\n",
        "  i = dia * 1440\n",
        "  df_final_dia1 = df[:][i:i+1440]\n",
        "  df_final_dia2 = df[:][i+1440:i+2880]\n",
        "\n",
        "  nuevo_min = 0.25\n",
        "  nuevo_max = 0.75\n",
        "\n",
        "\n",
        "  df_final_dia2['Open'] = ((df_final_dia2['Open'] - df_final_dia1['Open'].min()) / (df_final_dia1['Open'].max() - df_final_dia1['Open'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "  df_final_dia2['High'] = ((df_final_dia2['High'] - df_final_dia1['High'].min()) / (df_final_dia1['High'].max() - df_final_dia1['High'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "  df_final_dia2['Low'] = ((df_final_dia2['Low'] - df_final_dia1['Low'].min()) / (df_final_dia1['Low'].max() - df_final_dia1['Low'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "  df_final_dia2['Close'] = ((df_final_dia2['Close'] - df_final_dia1['Close'].min()) / (df_final_dia1['Close'].max() - df_final_dia1['Close'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "  df_final_dia2['Volume'] = ((df_final_dia2['Volume'] - df_final_dia1['Volume'].min()) / (df_final_dia1['Volume'].max() - df_final_dia1['Volume'].min())) * (nuevo_max - nuevo_min) + nuevo_min\n",
        "\n",
        "  global df_final\n",
        "  global df_normal\n",
        "  df_normal = df_final_dia2\n",
        "  df_final = df[:][i:i+1440]\n",
        "  return df_final\n",
        "  return df_normal\n",
        "\n",
        "\n",
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    dfaux = dataset.copy(deep = True)\n",
        "    dfaux['0'] = dfaux[0]\n",
        "    dfaux['0'] = dfaux[1]\n",
        "    dfaux['0'] = dfaux[2]\n",
        "    dfaux['0'] = dfaux[3]\n",
        "    dfaux['0'] = dfaux[4]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return np.array(dataX[:-5]), np.array(dataY)"
      ],
      "metadata": {
        "id": "vR0rqNH-tefw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(5))\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "FDyMaj47tRxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizar(df,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ICwu8hwR8Op1",
        "outputId": "3bdbf5ae-3089-48e4-8147-295851ad8a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Open     High      Low    Close    Volume\n",
              "Time                                                             \n",
              "2017-08-18 00:00:00  4244.77  4267.59  4244.77  4244.77  0.657267\n",
              "2017-08-18 00:01:00  4267.59  4278.05  4267.59  4278.05  0.643297\n",
              "2017-08-18 00:02:00  4244.77  4244.77  4244.77  4244.77  0.216000\n",
              "2017-08-18 00:03:00  4278.05  4278.05  4278.05  4278.05  0.456560\n",
              "2017-08-18 00:04:00  4278.05  4278.05  4278.05  4278.05  0.055644\n",
              "...                      ...      ...      ...      ...       ...\n",
              "2017-08-18 23:55:00  4156.39  4156.39  4156.39  4156.39  0.100000\n",
              "2017-08-18 23:56:00  4156.39  4156.39  4156.39  4156.39  0.000000\n",
              "2017-08-18 23:57:00  4156.39  4156.39  4156.39  4156.39  0.000000\n",
              "2017-08-18 23:58:00  4156.39  4156.39  4156.39  4156.39  0.000000\n",
              "2017-08-18 23:59:00  4156.39  4156.39  4156.39  4156.39  0.000000\n",
              "\n",
              "[1440 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b40682f-b8b2-4e7f-8ea7-6dc778a38b4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:00:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>0.657267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:01:00</th>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4267.59</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.643297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:02:00</th>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>4244.77</td>\n",
              "      <td>0.216000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:03:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.456560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 00:04:00</th>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>4278.05</td>\n",
              "      <td>0.055644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:55:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:56:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:57:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:58:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18 23:59:00</th>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>4156.39</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b40682f-b8b2-4e7f-8ea7-6dc778a38b4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b40682f-b8b2-4e7f-8ea7-6dc778a38b4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b40682f-b8b2-4e7f-8ea7-6dc778a38b4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88826fcb-5725-4e52-9a18-46207cca7ab7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88826fcb-5725-4e52-9a18-46207cca7ab7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88826fcb-5725-4e52-9a18-46207cca7ab7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6ed6342d-e827-41f8-9f80-772d842ec3e7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6ed6342d-e827-41f8-9f80-772d842ec3e7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1440,\n        \"samples\": [\n          \"2017-08-18 02:48:00\",\n          \"2017-08-18 10:05:00\",\n          \"2017-08-18 09:08:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.16544009874012,\n        \"min\": 3949.36,\n        \"max\": 4371.42,\n        \"num_unique_values\": 476,\n        \"samples\": [\n          4152.55,\n          4245.0,\n          4307.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 103.83975512777414,\n        \"min\": 3956.3,\n        \"max\": 4371.52,\n        \"num_unique_values\": 381,\n        \"samples\": [\n          4015.7,\n          4225.84,\n          4330.82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.40802715412487,\n        \"min\": 3938.77,\n        \"max\": 4371.4,\n        \"num_unique_values\": 478,\n        \"samples\": [\n          4152.55,\n          4234.43,\n          4283.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.1671398651228,\n        \"min\": 3938.77,\n        \"max\": 4371.52,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          4063.13,\n          4330.82,\n          4286.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.152574883538588,\n        \"min\": 0.0,\n        \"max\": 8.619423,\n        \"num_unique_values\": 1160,\n        \"samples\": [\n          0.121217,\n          0.449804,\n          0.343702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_normal.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PqcEF8p0RXsR",
        "outputId": "12d6c908-cbe8-46a3-9472-8fb95005dadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close       Volume\n",
              "count  1440.000000  1440.000000  1440.000000  1440.000000  1440.000000\n",
              "mean      0.384341     0.380229     0.392723     0.394431     0.262032\n",
              "std       0.065091     0.064382     0.063941     0.062682     0.035114\n",
              "min       0.156719     0.161240     0.147407     0.147435     0.250000\n",
              "25%       0.338281     0.335581     0.348355     0.352369     0.250000\n",
              "50%       0.390821     0.386506     0.399585     0.399642     0.250000\n",
              "75%       0.424110     0.418621     0.432096     0.432045     0.257762\n",
              "max       0.523231     0.519375     0.528795     0.528718     0.740453"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b8a4cb6-a52f-4a22-8a54-4a8a9f7cf62a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.384341</td>\n",
              "      <td>0.380229</td>\n",
              "      <td>0.392723</td>\n",
              "      <td>0.394431</td>\n",
              "      <td>0.262032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.065091</td>\n",
              "      <td>0.064382</td>\n",
              "      <td>0.063941</td>\n",
              "      <td>0.062682</td>\n",
              "      <td>0.035114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.156719</td>\n",
              "      <td>0.161240</td>\n",
              "      <td>0.147407</td>\n",
              "      <td>0.147435</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.338281</td>\n",
              "      <td>0.335581</td>\n",
              "      <td>0.348355</td>\n",
              "      <td>0.352369</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.390821</td>\n",
              "      <td>0.386506</td>\n",
              "      <td>0.399585</td>\n",
              "      <td>0.399642</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.424110</td>\n",
              "      <td>0.418621</td>\n",
              "      <td>0.432096</td>\n",
              "      <td>0.432045</td>\n",
              "      <td>0.257762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.523231</td>\n",
              "      <td>0.519375</td>\n",
              "      <td>0.528795</td>\n",
              "      <td>0.528718</td>\n",
              "      <td>0.740453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b8a4cb6-a52f-4a22-8a54-4a8a9f7cf62a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b8a4cb6-a52f-4a22-8a54-4a8a9f7cf62a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b8a4cb6-a52f-4a22-8a54-4a8a9f7cf62a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e47c6c11-5c21-42fd-8e15-04f263a202c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e47c6c11-5c21-42fd-8e15-04f263a202c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e47c6c11-5c21-42fd-8e15-04f263a202c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_normal\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 509.0016154573155,\n        \"min\": 0.06509109114188398,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.38434061178768664,\n          0.3908212102544661,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 509.00245628063516,\n        \"min\": 0.06438209336775133,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3802287375099676,\n          0.38650594865372523,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 509.0000862188769,\n        \"min\": 0.06394114157452202,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.39272287616824236,\n          0.39958509580935203,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 508.99986310511247,\n        \"min\": 0.06268215421479532,\n        \"max\": 1440.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3944309567366324,\n          0.3996418255343731,\n          1440.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 509.0136146354819,\n        \"min\": 0.03511405515604025,\n        \"max\": 1440.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1440.0,\n          0.2620317279277923,\n          0.7404527832083425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  training_size = int(len(df_normal.Open)*0.60)\n",
        "  test_size=len(df_normal.Open)-training_size\n",
        "  train_data,test_data=df_normal[['Open', 'High', 'Low', 'Close', 'Volume']][0:training_size],df_normal[['Open', 'High', 'Low', 'Close', 'Volume']][training_size:]\n",
        "  print(\"train_data: \", train_data.shape)\n",
        "  print(\"test_data: \", test_data.shape)\n",
        "\n",
        "  scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  train_data=scaler.fit_transform(np.array(train_data).reshape(-1,5))\n",
        "  print(train_data.shape)\n",
        "\n",
        "  test_data=scaler.fit_transform(np.array(test_data).reshape(-1,5))\n",
        "  print(test_data.shape)\n",
        "\n",
        "  time_step = 5\n",
        "  X_train, y_train = create_dataset(train_data, time_step)\n",
        "  X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "  print(\"X_train: \", X_train.shape)\n",
        "  print(\"y_train: \", y_train.shape)\n",
        "  print(\"X_test: \", X_test.shape)\n",
        "  print(\"y_test\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dKD8m41Ek-X",
        "outputId": "131510ff-85ae-4848-af68-c5952681e7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data:  (864, 5)\n",
            "test_data:  (576, 5)\n",
            "(864, 5)\n",
            "(576, 5)\n",
            "[0.42135885 0.42135885 0.42135885 0.42135885 0.42135885]\n",
            "[0.83021274 0.83007852 0.83021274 0.83021274 0.83021274]\n",
            "X_train:  (0,)\n",
            "y_train:  (0,)\n",
            "X_test:  (0,)\n",
            "y_test (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE6uuzlQHENK",
        "outputId": "54d5c9a6-8741-4257-e530-b57d1ce5222f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92368608, 0.92061464, 0.92845455, 0.92845455, 0.        ],\n",
              "       [0.92368608, 0.92061464, 0.92845455, 0.92845455, 0.        ],\n",
              "       [0.92368608, 0.92061464, 0.92845455, 0.92845455, 0.        ],\n",
              "       ...,\n",
              "       [0.42135885, 0.39807   , 0.45751515, 0.45751515, 0.        ],\n",
              "       [0.42135885, 0.39807   , 0.45751515, 0.45751515, 0.        ],\n",
              "       [0.42135885, 0.39807   , 0.45751515, 0.45751515, 0.05842807]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_normal[['Open', 'High', 'Low', 'Close', 'Volume']][0:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "TUPlxFQxE8-B",
        "outputId": "d854bb78-6ea0-4ba1-f958-6a53cfbec274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Open      High       Low     Close  Volume\n",
              "Time                                                               \n",
              "2017-08-19 00:00:00  0.495261  0.490945  0.501508  0.501438    0.25"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24946065-bc72-422c-9f2e-4e111012dd58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-19 00:00:00</th>\n",
              "      <td>0.495261</td>\n",
              "      <td>0.490945</td>\n",
              "      <td>0.501508</td>\n",
              "      <td>0.501438</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24946065-bc72-422c-9f2e-4e111012dd58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24946065-bc72-422c-9f2e-4e111012dd58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24946065-bc72-422c-9f2e-4e111012dd58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_normal[['Open', 'High', 'Low', 'Close', 'Volume']][0:1]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2017-08-19 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.49526133725062815,\n        \"max\": 0.49526133725062815,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.49526133725062815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4909445595106209,\n        \"max\": 0.4909445595106209,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4909445595106209\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.501508217183275,\n        \"max\": 0.501508217183275,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.501508217183275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5014384748700175,\n        \"max\": 0.5014384748700175,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5014384748700175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.25,\n        \"max\": 0.25,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contador_de_vueltas = 0\n",
        "\n",
        "while contador_de_vueltas <= 365:\n",
        "\n",
        "  i = contador_de_vueltas\n",
        "\n",
        "  normalizar(df,i)\n",
        "\n",
        "#Crear train-test datasets\n",
        "\n",
        "  training_size = int(len(df_normal.Open)*0.60)\n",
        "  test_size=len(df_normal.Open)-training_size\n",
        "  train_data,test_data=df_normal[['Open', 'High', 'Low', 'Close', 'Volume']][0:training_size],df_normal[['Open', 'High', 'Low', 'Close', 'Volume']][training_size:]\n",
        "  print(\"train_data: \", train_data.shape)\n",
        "  print(\"test_data: \", test_data.shape)\n",
        "\n",
        "  scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  train_data=scaler.fit_transform(np.array(train_data).reshape(-1,1))\n",
        "  print(train_data.shape)\n",
        "\n",
        "  test_data=scaler.fit_transform(np.array(test_data).reshape(-1,1))\n",
        "  print(test_data.shape)\n",
        "\n",
        "  time_step = 5\n",
        "  X_train, y_train = create_dataset(train_data, time_step)\n",
        "  X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "  print(\"X_train: \", X_train.shape)\n",
        "  print(\"y_train: \", y_train.shape)\n",
        "  print(\"X_test: \", X_test.shape)\n",
        "  print(\"y_test\", y_test.shape)\n",
        "\n",
        "\n",
        "#Entrenar el modelo\n",
        "\n",
        "  history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=30,batch_size=32,verbose=1)\n",
        "\n",
        "  contador_de_vueltas = contador_de_vueltas + 1\n",
        "\n",
        "  print('---------------------------------------------------')\n",
        "  print('El entrenamiento va en el dia', contador_de_vueltas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeUIy4fnrJrA",
        "outputId": "0884d3b2-d29e-415d-b4c9-723548fed593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 48ms/step - loss: 0.0040 - val_loss: 0.0079\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0039 - val_loss: 0.0077\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0039 - val_loss: 0.0076\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0038 - val_loss: 0.0076\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0076\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0073\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0038 - val_loss: 0.0080\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0038 - val_loss: 0.0072\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0072\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0076\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0072\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0076\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0072\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0072\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0074\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0072\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0071\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 1\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0057\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0054\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0059\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0054\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0055\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0055\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0055\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0056\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0056\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0067 - val_loss: 0.0055\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0056\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0055\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0057\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0067 - val_loss: 0.0055\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0067 - val_loss: 0.0054\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0056\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0056\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0054\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0054\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0055\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0057\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0055\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0055\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0054\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0058\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0054\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0053\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0055\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0060\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 2\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0078 - val_loss: 0.0060\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0060\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0060\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0059\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0061\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0067\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0059\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0059\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0062\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0060\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0061\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0059\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0060\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0063\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0060\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0060\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0059\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0059\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0061\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0073 - val_loss: 0.0060\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0073 - val_loss: 0.0059\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0060\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0074 - val_loss: 0.0059\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0073 - val_loss: 0.0060\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0073 - val_loss: 0.0059\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 3\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0041 - val_loss: 0.0136\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0136\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0135\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0135\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0135\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0135\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0137\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0136\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0136\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0137\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0135\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0137\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0136\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0137\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0136\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0137\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0137\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0137\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0137\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0139\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0138\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0039 - val_loss: 0.0139\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 4\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0102\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0103\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0109\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0106\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0107\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0110\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0051 - val_loss: 0.0108\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0110\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0051 - val_loss: 0.0105\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0111\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0114\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0110\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0107\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0108\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0106\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0115\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0109\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0110\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0107\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0108\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0106\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0106\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0107\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0107\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0110\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0107\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0107\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0104\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0110\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0104\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 5\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0045\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0043\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0045\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0043\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0042\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0043\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0046\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0043\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0067 - val_loss: 0.0044\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0045\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0045\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0044\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0042\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0043\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 6\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0067\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0068\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0066\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0067\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0065\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0064\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0065\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0060\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0066\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0065\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0061\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0060\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0066\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0060\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 7\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.0102 - val_loss: 0.0052\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0101 - val_loss: 0.0053\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0103 - val_loss: 0.0054\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0054\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0056\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0055\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0056\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0055\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0057\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0056\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0057\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0057\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0056\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0060\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0057\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0058\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0058\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0057\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0059\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0057\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0057\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0060\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0057\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0058\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0058\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0100 - val_loss: 0.0058\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0058\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0058\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0058\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0099 - val_loss: 0.0057\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 8\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0149 - val_loss: 0.0202\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.0205\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0207\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0208\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0215\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0144 - val_loss: 0.0212\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0144 - val_loss: 0.0209\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0201\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0143 - val_loss: 0.0205\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0203\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0143 - val_loss: 0.0200\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0210\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0143 - val_loss: 0.0212\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0204\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0202\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0195\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0204\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0200\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0198\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0219\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0200\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0206\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0208\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0198\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0205\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0209\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0199\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0220\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0207\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0201\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 9\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0204\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0205\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0209\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0207\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0204\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0207\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0204\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0205\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0204\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0075 - val_loss: 0.0205\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0075 - val_loss: 0.0204\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0076 - val_loss: 0.0207\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0205\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0076 - val_loss: 0.0206\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0075 - val_loss: 0.0205\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0207\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 10\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0119\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0117\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0116\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0116\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0113\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0111\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0111\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0110\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0110\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0110\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0108\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0110\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0108\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0108\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0108\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0109\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0108\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0110\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0110\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0108\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0108\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 11\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0105\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0104\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0105\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0105\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0104\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0103\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0104\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0104\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0104\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0107\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0105\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0105\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 0.0104\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0104\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0105\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0070 - val_loss: 0.0104\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0104\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0104\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0105\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0105\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0105\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0104\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0071 - val_loss: 0.0104\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0105\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0069 - val_loss: 0.0104\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0105\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0070 - val_loss: 0.0105\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0105\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0105\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0105\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 12\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0126 - val_loss: 0.0127\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0152\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0114 - val_loss: 0.0150\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0114 - val_loss: 0.0152\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0115 - val_loss: 0.0165\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.0114 - val_loss: 0.0162\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 35ms/step - loss: 0.0115 - val_loss: 0.0174\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0180\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0156\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0168\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0165\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0170\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0186\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0193\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0168\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0207\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0179\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0168\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0192\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0185\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0186\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0183\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0185\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0174\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0190\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0178\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0188\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0176\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 13\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0126\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0126\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0120\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0118\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0118\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0114\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0114\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0114\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0110\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0110\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0111\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0109\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0108\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0107\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0108\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0107\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0111\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0112\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0106\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0110\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0108\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.0108\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0107\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0106\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0106\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0107\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0109\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0107\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.0106\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0106\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 14\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0084\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0084\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0082\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0085\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0083\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0082\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0083\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0082\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0082\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0082\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0082\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0082\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0083\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0082\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0084\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0084\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0083\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0083\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0083\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0083\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0084\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 15\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0133\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0131\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0131\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0133\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0132\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 16\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0020\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0021\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0021\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0024\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0021\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.0021\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0056 - val_loss: 0.0021\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0022\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0021\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0055 - val_loss: 0.0021\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.0022\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0021\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0055 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0054 - val_loss: 0.0021\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0021\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0020\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0025\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0020\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0021\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0021\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0021\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0026\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0021\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0022\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0022\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0021\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0054 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 17\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0048\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0048\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0046\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 18\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0106\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0106\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0106\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0109\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0107\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0022 - val_loss: 0.0106\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0106\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0104\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0106\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0108\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0104\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0104\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0104\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0104\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0104\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0104\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0104\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0105\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 19\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0056\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 20\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0041\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0041\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0041\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0042\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0041\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0041\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0045\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0045\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0047\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0045\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0045\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 21\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0078\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0079\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0082\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0082\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0080\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0081\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0082\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0081\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 22\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0062\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0062\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0063\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0062\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0063\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0059 - val_loss: 0.0062\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0057 - val_loss: 0.0061\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0063\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0063\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0064\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0063\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0065\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0062\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0064\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0062\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0057 - val_loss: 0.0062\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 23\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0034\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 24\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0054 - val_loss: 0.0144\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0143\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0144\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0144\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0145\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0144\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0144\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0144\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0143\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0144\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0143\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0143\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0143\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0142\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0142\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0144\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 25\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 26\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 27\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0183\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0183\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0181\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0183\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0182\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0183\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0184\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0182\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0182\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0183\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0182\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0183\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 28\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0082\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0082\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0082\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0081\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0081\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0081\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0080\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0038 - val_loss: 0.0080\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0080\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0080\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0079\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0037 - val_loss: 0.0079\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0079\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0079\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0079\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 0.0079\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0078\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0079\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0079\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0078\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0078\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0078\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0078\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0077\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0078\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0077\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0078\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0077\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0077\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0077\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 29\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0048\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0051\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 30\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0077\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0078\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0076\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0077\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0078\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0076\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0078\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0078\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0077\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0075\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0076\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0082\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0076\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0079\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0076\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0076\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0077\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 31\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0035 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 32\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 33\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0063\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0061\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0061\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0063\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0063\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 34\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 0.0220\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0219\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0219\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0218\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0217\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0217\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0216\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 35\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0045\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0045\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0045\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0046\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 36\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0025 - val_loss: 0.0107\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0108\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0109\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0108\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0108\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0108\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0107\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0107\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0107\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0107\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 37\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0248\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0076 - val_loss: 0.0246\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0247\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0077 - val_loss: 0.0248\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0075 - val_loss: 0.0244\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0074 - val_loss: 0.0243\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0075 - val_loss: 0.0246\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0075 - val_loss: 0.0243\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0075 - val_loss: 0.0243\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0074 - val_loss: 0.0243\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0243\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0246\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0245\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0243\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0242\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0243\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0243\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0243\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0242\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0242\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0242\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0242\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 38\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 0.0068\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0068\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0070\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0069\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0066\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0069\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0070\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0069\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0070\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0075\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0077\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0070\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0074\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0072\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0068\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0077\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0076\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0083\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0084\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0076\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0080\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0085\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0083\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0029 - val_loss: 0.0083\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0092\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0086\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 39\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0055 - val_loss: 0.0049\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 40\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0029 - val_loss: 0.0154\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0154\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0154\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0154\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0154\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0154\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0155\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0155\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0156\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0156\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0157\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0157\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0157\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0157\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0156\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 41\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0047 - val_loss: 0.0425\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0425\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0425\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0425\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0424\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0423\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0424\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0424\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0422\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0422\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0422\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0425\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0424\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0422\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0419\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0419\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0419\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0419\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0414\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0418\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0417\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0414\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0417\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0418\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0415\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0418\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0046 - val_loss: 0.0418\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0419\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0046 - val_loss: 0.0419\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0418\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 42\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0042\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0045\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0046\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0049\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0049\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0051\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0048\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0048\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0047\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0047\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0118 - val_loss: 0.0048\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0118 - val_loss: 0.0048\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0119 - val_loss: 0.0048\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0118 - val_loss: 0.0049\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0118 - val_loss: 0.0049\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0117 - val_loss: 0.0048\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0117 - val_loss: 0.0047\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0047\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0047\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0117 - val_loss: 0.0048\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0117 - val_loss: 0.0047\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0118 - val_loss: 0.0046\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0047\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0047\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0047\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0047\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0046\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0047\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0046\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0048\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 43\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0060 - val_loss: 0.0184\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0056 - val_loss: 0.0181\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0180\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0056 - val_loss: 0.0183\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0056 - val_loss: 0.0182\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0056 - val_loss: 0.0183\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0056 - val_loss: 0.0182\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0056 - val_loss: 0.0182\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0183\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0182\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0056 - val_loss: 0.0184\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0183\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0184\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0181\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0185\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0184\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0190\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0186\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0186\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0056 - val_loss: 0.0187\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0192\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0188\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0186\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0186\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0191\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0191\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0188\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0188\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0194\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0196\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 44\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0104\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0105\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0104\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0105\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0104\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0104\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0105\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0105\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0105\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0107\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0105\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0105\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0108\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0109\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0106\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0110\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0107\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 45\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0027 - val_loss: 0.0164\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0164\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0163\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0164\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0164\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0164\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0163\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0164\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0162\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 46\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0032 - val_loss: 0.0175\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0173\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 0.0174\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0174\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0174\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0173\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0174\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0175\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0179\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0176\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0175\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0177\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0178\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0174\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0031 - val_loss: 0.0175\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0176\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0178\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0177\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0177\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0176\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0177\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0177\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0176\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0176\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0178\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0177\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0177\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0176\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0030 - val_loss: 0.0182\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0178\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 47\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0113\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0114\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0113\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0113\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0113\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0045 - val_loss: 0.0113\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0115\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0113\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0046 - val_loss: 0.0115\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0113\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0114\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0115\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0114\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0114\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0113\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 48\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0036\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0037\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0042\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0039\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0039\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0040\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0039\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0042\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0131 - val_loss: 0.0042\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0042\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0042\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0043\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0043\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0044\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0042\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0130 - val_loss: 0.0044\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0132 - val_loss: 0.0044\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0130 - val_loss: 0.0044\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0130 - val_loss: 0.0046\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0131 - val_loss: 0.0047\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0129 - val_loss: 0.0046\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0129 - val_loss: 0.0048\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0129 - val_loss: 0.0048\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0129 - val_loss: 0.0047\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0130 - val_loss: 0.0046\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0049\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0048\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0049\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0049\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 49\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0062\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0061\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0064\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0026 - val_loss: 0.0063\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0061\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0058\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0060\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0061\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0060\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0061\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0060\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0060\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0060\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0061\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0060\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0062\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0061\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0060\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0060\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0059\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0060\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 50\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0063\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0034 - val_loss: 0.0065\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0064\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0035 - val_loss: 0.0062\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0035 - val_loss: 0.0062\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0064\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0062\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0064\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 51\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 52\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0099\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0099\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0098\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0046 - val_loss: 0.0097\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0046 - val_loss: 0.0097\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0097\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0098\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 53\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.9989e-04 - val_loss: 0.0014\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.7009e-04 - val_loss: 0.0013\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.4577e-04 - val_loss: 0.0013\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.3803e-04 - val_loss: 0.0013\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.3393e-04 - val_loss: 0.0013\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.1441e-04 - val_loss: 0.0012\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.2925e-04 - val_loss: 0.0012\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.0714e-04 - val_loss: 0.0012\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.0171e-04 - val_loss: 0.0012\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.0053e-04 - val_loss: 0.0012\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.1077e-04 - val_loss: 0.0012\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.9625e-04 - val_loss: 0.0012\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.8384e-04 - val_loss: 0.0012\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.7947e-04 - val_loss: 0.0012\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.7424e-04 - val_loss: 0.0012\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.8048e-04 - val_loss: 0.0012\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.8676e-04 - val_loss: 0.0012\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.6994e-04 - val_loss: 0.0012\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.6533e-04 - val_loss: 0.0012\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.6258e-04 - val_loss: 0.0012\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 7.6164e-04 - val_loss: 0.0012\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.6456e-04 - val_loss: 0.0012\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 7.6359e-04 - val_loss: 0.0012\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.6155e-04 - val_loss: 0.0012\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.6136e-04 - val_loss: 0.0012\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 7.6950e-04 - val_loss: 0.0012\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 7.7089e-04 - val_loss: 0.0012\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 7.6272e-04 - val_loss: 0.0012\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.5211e-04 - val_loss: 0.0012\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.5327e-04 - val_loss: 0.0012\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 54\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 0.0032"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5516c138bc37>:10: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "<ipython-input-5-5516c138bc37>:11: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "<ipython-input-5-5516c138bc37>:12: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0043\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0043\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0043\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0043\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0043\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0044\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0043\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 55\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 56\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 57\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0060 - val_loss: 0.0032\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0030\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0030\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0030\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0031\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0032\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0056 - val_loss: 0.0032\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 58\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0026\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0024\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0025\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0026\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0025\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0026\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0026\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0026\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0026\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0026\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0026\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 59\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 60\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0158\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0156\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0153\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0156\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0156\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0157\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0156\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0155\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0155\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0157\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0156\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0155\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0156\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0154\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0154\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0155\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0154\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0155\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0153\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0154\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0155\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0154\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0053 - val_loss: 0.0156\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0053 - val_loss: 0.0153\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0155\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0154\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0155\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0153\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0153\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0154\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 61\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0019 - val_loss: 0.0065\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0064\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0064\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0063\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0064\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0065\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0066\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0068\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0066\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0067\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0069\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0071\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0071\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0071\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0074\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0072\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0071\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0073\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0073\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0073\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0073\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0074\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0075\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0075\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0077\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0075\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0076\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0075\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0076\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 62\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0059 - val_loss: 0.0059\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0057\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0058\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0058\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0057\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0056\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0057\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0058\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0056\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0056\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0056\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0057\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0060\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0058\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0058\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0056\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0058\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0055\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0059\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0056\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0059\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0057\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0058\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0045 - val_loss: 0.0057\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0056\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0057\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0058\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0057\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0057\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0056\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 63\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0091\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0092\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0092\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0091\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0092\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 0.0092\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0092\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0093\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0095\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0093\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0094\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0094\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0094\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0092\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0093\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0094\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0093\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0032 - val_loss: 0.0093\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0032 - val_loss: 0.0092\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0093\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0032 - val_loss: 0.0093\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 64\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 65\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0021\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0021\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0026\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0027\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 66\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0058\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0061\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0060\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0059\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0058\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 67\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0044\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0043\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0046\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 68\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0060\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0061\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0061\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0063\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0061\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0064\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 69\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0128\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0126\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0126\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0126\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0127\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0127\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0127\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0125\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0035 - val_loss: 0.0126\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0126\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0035 - val_loss: 0.0125\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0125\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0126\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0125\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0126\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0124\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0124\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0126\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0125\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0125\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0124\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0124\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 70\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0039\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 71\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0093\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0093\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0091\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0092\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0092\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0093\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0092\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0091\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0093\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0091\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 72\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0057\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0056\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0057\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9449e-04 - val_loss: 0.0057\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0056\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.8282e-04 - val_loss: 0.0057\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.9357e-04 - val_loss: 0.0056\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.8222e-04 - val_loss: 0.0056\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.8981e-04 - val_loss: 0.0056\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.8736e-04 - val_loss: 0.0057\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.8606e-04 - val_loss: 0.0057\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.9115e-04 - val_loss: 0.0056\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.9376e-04 - val_loss: 0.0055\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.7943e-04 - val_loss: 0.0055\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.8523e-04 - val_loss: 0.0056\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.7956e-04 - val_loss: 0.0056\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0056\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.8537e-04 - val_loss: 0.0056\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.9097e-04 - val_loss: 0.0055\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.7660e-04 - val_loss: 0.0056\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.8368e-04 - val_loss: 0.0056\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.7467e-04 - val_loss: 0.0056\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.8233e-04 - val_loss: 0.0056\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.7789e-04 - val_loss: 0.0055\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.8605e-04 - val_loss: 0.0056\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.7695e-04 - val_loss: 0.0056\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.8618e-04 - val_loss: 0.0057\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9366e-04 - val_loss: 0.0057\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 73\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 74\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0043\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0045\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0045\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0043\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0028 - val_loss: 0.0045\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0045\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0045\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0045\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0051\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0047\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0045\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0050\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0049\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0057\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0051\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0052\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0051\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0044\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0051\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 75\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0041 - val_loss: 0.0029\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0034\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0030\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0031\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0031\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0032\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0039 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0033\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0038 - val_loss: 0.0033\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0033\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0032\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0032\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0032\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0033\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0032\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0032\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0032\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0033\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0033\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 76\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 0.0030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5516c138bc37>:10: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 77\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0039\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0037\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0037\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0043\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0043\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 78\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0074\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0073\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0073\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0073\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 79\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0024\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0027\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0027\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0026\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0031\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0036\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0036\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0035\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 80\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0037\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 81\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0051\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0051\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0052\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0052\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0051\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0051\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0051\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0052\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0052\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 82\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0035\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.2832e-04 - val_loss: 0.0034\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.2866e-04 - val_loss: 0.0035\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.1684e-04 - val_loss: 0.0034\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.1447e-04 - val_loss: 0.0034\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.1762e-04 - val_loss: 0.0034\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.0146e-04 - val_loss: 0.0034\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.0059e-04 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.9184e-04 - val_loss: 0.0035\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.9326e-04 - val_loss: 0.0035\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.8224e-04 - val_loss: 0.0035\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.8929e-04 - val_loss: 0.0035\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.8619e-04 - val_loss: 0.0035\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.9833e-04 - val_loss: 0.0035\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.8648e-04 - val_loss: 0.0035\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.8464e-04 - val_loss: 0.0035\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.8887e-04 - val_loss: 0.0035\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.8276e-04 - val_loss: 0.0035\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.8395e-04 - val_loss: 0.0035\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.7620e-04 - val_loss: 0.0035\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.8173e-04 - val_loss: 0.0035\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.8309e-04 - val_loss: 0.0035\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.8505e-04 - val_loss: 0.0035\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.9060e-04 - val_loss: 0.0035\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.7874e-04 - val_loss: 0.0035\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.8437e-04 - val_loss: 0.0035\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.9436e-04 - val_loss: 0.0035\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.8888e-04 - val_loss: 0.0035\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.8141e-04 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.7908e-04 - val_loss: 0.0035\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 83\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 84\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0034\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0034\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 85\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0012\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0012\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0012\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0013\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0012\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0012\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0012\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0012\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0012\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0012\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0013\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0014\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0015\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0016\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0015\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0016\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0015\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0016\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 86\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.9433e-04 - val_loss: 0.0055\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.9743e-04 - val_loss: 0.0055\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.9025e-04 - val_loss: 0.0054\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9673e-04 - val_loss: 0.0055\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9715e-04 - val_loss: 0.0055\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9085e-04 - val_loss: 0.0055\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.9861e-04 - val_loss: 0.0055\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.8558e-04 - val_loss: 0.0055\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.8735e-04 - val_loss: 0.0055\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.9076e-04 - val_loss: 0.0055\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9795e-04 - val_loss: 0.0054\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.9273e-04 - val_loss: 0.0055\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.9386e-04 - val_loss: 0.0055\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0057\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.9648e-04 - val_loss: 0.0056\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.9463e-04 - val_loss: 0.0055\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.9752e-04 - val_loss: 0.0055\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.9214e-04 - val_loss: 0.0055\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.9151e-04 - val_loss: 0.0055\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.8882e-04 - val_loss: 0.0055\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.9198e-04 - val_loss: 0.0055\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.9052e-04 - val_loss: 0.0055\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.8882e-04 - val_loss: 0.0056\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 87\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0026\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0026\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0027\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0026\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 88\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 89\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0043\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0041\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 90\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0036 - val_loss: 0.0032\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0033\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0036\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 91\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 92\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0046\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0046\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0046\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0046\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 93\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0078\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0078\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0077\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0077\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0077\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0076\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0076\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 0.0077\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0077\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0080\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0078\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0080\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0077\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0079\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 94\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 95\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0163\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0164\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0164\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0165\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0165\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0166\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0166\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0166\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0168\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0168\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0168\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0169\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0170\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0170\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0170\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0170\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0171\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0171\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0171\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0172\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0172\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0173\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0173\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0173\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0174\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0174\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0174\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0175\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0177\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0176\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 96\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0034\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.9520e-04 - val_loss: 0.0033\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.9363e-04 - val_loss: 0.0033\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.7271e-04 - val_loss: 0.0032\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.6970e-04 - val_loss: 0.0032\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.5830e-04 - val_loss: 0.0032\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.6745e-04 - val_loss: 0.0031\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.5644e-04 - val_loss: 0.0031\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.5464e-04 - val_loss: 0.0032\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.6106e-04 - val_loss: 0.0031\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.5701e-04 - val_loss: 0.0031\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.4384e-04 - val_loss: 0.0031\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.5457e-04 - val_loss: 0.0031\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.3985e-04 - val_loss: 0.0031\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.3960e-04 - val_loss: 0.0031\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.5155e-04 - val_loss: 0.0031\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.3919e-04 - val_loss: 0.0031\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.3928e-04 - val_loss: 0.0031\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.5134e-04 - val_loss: 0.0031\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.3985e-04 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.3264e-04 - val_loss: 0.0031\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.4206e-04 - val_loss: 0.0031\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.3081e-04 - val_loss: 0.0031\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.5271e-04 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.5312e-04 - val_loss: 0.0031\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.3916e-04 - val_loss: 0.0030\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.3398e-04 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.2541e-04 - val_loss: 0.0030\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.2946e-04 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.3095e-04 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 97\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.4200e-04 - val_loss: 0.0025\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.3154e-04 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.2611e-04 - val_loss: 0.0025\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.1699e-04 - val_loss: 0.0025\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.1809e-04 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.1601e-04 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.1723e-04 - val_loss: 0.0025\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.1513e-04 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 7.1663e-04 - val_loss: 0.0025\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 7.0967e-04 - val_loss: 0.0025\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.1579e-04 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.2046e-04 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.2252e-04 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.0990e-04 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.0859e-04 - val_loss: 0.0025\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.0861e-04 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.1887e-04 - val_loss: 0.0025\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.0574e-04 - val_loss: 0.0025\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.0926e-04 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.1553e-04 - val_loss: 0.0025\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.0592e-04 - val_loss: 0.0025\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.1139e-04 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.0377e-04 - val_loss: 0.0025\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.0704e-04 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.1226e-04 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.0366e-04 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0323e-04 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.0869e-04 - val_loss: 0.0025\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.0057e-04 - val_loss: 0.0025\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0239e-04 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 98\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 99\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0030 - val_loss: 0.0035\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0035\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0037\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0034\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0037\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0037\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0039\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0037\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0040\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0035\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0037\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0039\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0037\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 100\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 101\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 102\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.0583e-04 - val_loss: 0.0015\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.0976e-04 - val_loss: 0.0015\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.9472e-04 - val_loss: 0.0015\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.9051e-04 - val_loss: 0.0015\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8483e-04 - val_loss: 0.0015\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.9445e-04 - val_loss: 0.0015\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.0246e-04 - val_loss: 0.0015\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.7804e-04 - val_loss: 0.0015\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 7.7415e-04 - val_loss: 0.0015\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.8112e-04 - val_loss: 0.0015\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.8009e-04 - val_loss: 0.0015\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.7144e-04 - val_loss: 0.0015\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.7703e-04 - val_loss: 0.0015\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.8771e-04 - val_loss: 0.0016\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.7815e-04 - val_loss: 0.0015\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.7395e-04 - val_loss: 0.0015\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.0055e-04 - val_loss: 0.0015\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.7499e-04 - val_loss: 0.0015\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 7.7157e-04 - val_loss: 0.0015\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.8167e-04 - val_loss: 0.0015\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.7503e-04 - val_loss: 0.0015\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.6824e-04 - val_loss: 0.0015\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8686e-04 - val_loss: 0.0015\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.7710e-04 - val_loss: 0.0015\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.8252e-04 - val_loss: 0.0015\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.9393e-04 - val_loss: 0.0015\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.8425e-04 - val_loss: 0.0015\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.7768e-04 - val_loss: 0.0015\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.7000e-04 - val_loss: 0.0015\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.9762e-04 - val_loss: 0.0015\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 103\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0073\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0074\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 104\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.8421e-04 - val_loss: 0.0026\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.3300e-04 - val_loss: 0.0026\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.1522e-04 - val_loss: 0.0026\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.1254e-04 - val_loss: 0.0026\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.0846e-04 - val_loss: 0.0026\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.1062e-04 - val_loss: 0.0026\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.1447e-04 - val_loss: 0.0026\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.0724e-04 - val_loss: 0.0026\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.0353e-04 - val_loss: 0.0026\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.0854e-04 - val_loss: 0.0026\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.0705e-04 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.9978e-04 - val_loss: 0.0027\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8930e-04 - val_loss: 0.0026\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.8737e-04 - val_loss: 0.0027\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.8907e-04 - val_loss: 0.0027\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.9480e-04 - val_loss: 0.0026\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.8176e-04 - val_loss: 0.0026\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.9200e-04 - val_loss: 0.0027\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8847e-04 - val_loss: 0.0027\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8161e-04 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.7738e-04 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.7979e-04 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8053e-04 - val_loss: 0.0027\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.7757e-04 - val_loss: 0.0026\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8212e-04 - val_loss: 0.0027\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8159e-04 - val_loss: 0.0026\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8165e-04 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8833e-04 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.9281e-04 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.9154e-04 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 105\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0011\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0012\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0011\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0011\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0011\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0012\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0011\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0011\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0036 - val_loss: 0.0012\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 106\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 107\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 108\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 109\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 7.6535e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5516c138bc37>:10: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.7864e-04 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.6510e-04 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.6512e-04 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.6245e-04 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.5852e-04 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.6141e-04 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.7397e-04 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.5937e-04 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.5675e-04 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.5767e-04 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.6700e-04 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.5636e-04 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.5791e-04 - val_loss: 0.0029\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.6290e-04 - val_loss: 0.0029\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.7828e-04 - val_loss: 0.0029\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.4770e-04 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.4938e-04 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.5964e-04 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.7511e-04 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.7734e-04 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.7619e-04 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.7880e-04 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.5759e-04 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.4656e-04 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.5224e-04 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.5775e-04 - val_loss: 0.0029\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.5004e-04 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.5953e-04 - val_loss: 0.0029\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.4492e-04 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 110\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0044\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9942e-04 - val_loss: 0.0045\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9415e-04 - val_loss: 0.0045\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9473e-04 - val_loss: 0.0045\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9522e-04 - val_loss: 0.0045\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9844e-04 - val_loss: 0.0045\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9818e-04 - val_loss: 0.0045\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.9293e-04 - val_loss: 0.0045\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.9012e-04 - val_loss: 0.0045\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.9764e-04 - val_loss: 0.0045\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.9306e-04 - val_loss: 0.0045\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9061e-04 - val_loss: 0.0045\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.9955e-04 - val_loss: 0.0045\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.9362e-04 - val_loss: 0.0045\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9987e-04 - val_loss: 0.0045\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.9185e-04 - val_loss: 0.0045\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.8891e-04 - val_loss: 0.0045\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.8905e-04 - val_loss: 0.0045\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0046\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.9257e-04 - val_loss: 0.0045\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 9.8967e-04 - val_loss: 0.0045\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.9216e-04 - val_loss: 0.0045\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.8743e-04 - val_loss: 0.0045\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.9047e-04 - val_loss: 0.0045\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 111\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0027\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0033\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0030\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 112\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 0.0023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5516c138bc37>:10: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0015\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0013\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0013\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0022 - val_loss: 0.0013\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 113\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 114\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 9.1928e-04\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0010\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 8.9528e-04\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 8.6753e-04\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 8.7901e-04\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 8.8796e-04\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 8.9507e-04\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 8.4809e-04\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 8.5538e-04\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 8.4377e-04\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 8.3720e-04\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 8.4151e-04\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 8.7659e-04\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 8.6272e-04\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 8.1843e-04\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 8.4130e-04\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 8.6978e-04\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 8.7973e-04\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 8.1299e-04\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 8.1234e-04\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.1518e-04\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 8.1293e-04\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 8.0856e-04\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.2944e-04\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.1371e-04\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 7.9448e-04\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.1042e-04\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.0422e-04\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 8.1244e-04\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 8.1134e-04\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 115\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0057\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0056\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0056\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0056\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 116\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.3336e-04 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 6.3054e-04 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 6.2007e-04 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.2125e-04 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 6.2584e-04 - val_loss: 0.0028\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 6.2196e-04 - val_loss: 0.0028\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1773e-04 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1858e-04 - val_loss: 0.0028\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.2538e-04 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.1963e-04 - val_loss: 0.0028\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1673e-04 - val_loss: 0.0028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.2150e-04 - val_loss: 0.0028\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.1982e-04 - val_loss: 0.0028\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 6.1272e-04 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.1665e-04 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 6.1829e-04 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.2338e-04 - val_loss: 0.0028\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 6.1582e-04 - val_loss: 0.0028\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 6.1478e-04 - val_loss: 0.0028\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.1074e-04 - val_loss: 0.0028\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.1292e-04 - val_loss: 0.0028\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.1916e-04 - val_loss: 0.0028\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 6.1632e-04 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.0972e-04 - val_loss: 0.0028\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.1213e-04 - val_loss: 0.0028\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.1220e-04 - val_loss: 0.0028\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.0729e-04 - val_loss: 0.0028\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 6.1337e-04 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.0917e-04 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.0710e-04 - val_loss: 0.0028\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 117\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 118\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 119\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0036\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0034\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0034\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0034\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 120\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9417e-04 - val_loss: 0.0023\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9985e-04 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.9112e-04 - val_loss: 0.0024\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.9388e-04 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.9383e-04 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.9179e-04 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.9558e-04 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.8540e-04 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.8984e-04 - val_loss: 0.0024\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.9842e-04 - val_loss: 0.0024\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.9558e-04 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.8710e-04 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.9087e-04 - val_loss: 0.0024\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.9765e-04 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.9832e-04 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.8221e-04 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.8524e-04 - val_loss: 0.0024\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.8587e-04 - val_loss: 0.0024\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 121\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0031\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 122\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 123\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 124\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 125\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.2336e-04 - val_loss: 0.0074\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9587e-04 - val_loss: 0.0075\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.1842e-04 - val_loss: 0.0075\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 6.9932e-04 - val_loss: 0.0075\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9450e-04 - val_loss: 0.0075\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.9755e-04 - val_loss: 0.0075\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 6.9435e-04 - val_loss: 0.0075\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.9184e-04 - val_loss: 0.0075\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.0456e-04 - val_loss: 0.0075\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 6.9664e-04 - val_loss: 0.0075\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.9549e-04 - val_loss: 0.0075\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 6.9453e-04 - val_loss: 0.0075\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.9772e-04 - val_loss: 0.0074\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 7.2278e-04 - val_loss: 0.0075\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.9510e-04 - val_loss: 0.0075\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 7.0013e-04 - val_loss: 0.0075\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.9792e-04 - val_loss: 0.0075\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0513e-04 - val_loss: 0.0074\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9550e-04 - val_loss: 0.0074\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 7.0690e-04 - val_loss: 0.0075\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9352e-04 - val_loss: 0.0075\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 6.9517e-04 - val_loss: 0.0074\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.0888e-04 - val_loss: 0.0074\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.9520e-04 - val_loss: 0.0075\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9466e-04 - val_loss: 0.0074\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9631e-04 - val_loss: 0.0075\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.0100e-04 - val_loss: 0.0074\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.0395e-04 - val_loss: 0.0075\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9318e-04 - val_loss: 0.0074\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.1654e-04 - val_loss: 0.0075\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 126\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.6152e-04 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.3273e-04 - val_loss: 0.0020\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.2507e-04 - val_loss: 0.0020\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.2537e-04 - val_loss: 0.0020\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.2456e-04 - val_loss: 0.0020\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.2672e-04 - val_loss: 0.0020\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.2532e-04 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.2411e-04 - val_loss: 0.0020\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.2677e-04 - val_loss: 0.0020\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.2386e-04 - val_loss: 0.0020\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.2731e-04 - val_loss: 0.0020\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.4316e-04 - val_loss: 0.0020\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.2616e-04 - val_loss: 0.0020\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.4080e-04 - val_loss: 0.0020\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.2132e-04 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.2081e-04 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.3452e-04 - val_loss: 0.0020\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.2509e-04 - val_loss: 0.0020\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.2496e-04 - val_loss: 0.0020\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.4056e-04 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.3806e-04 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.2554e-04 - val_loss: 0.0020\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.2772e-04 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.2304e-04 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.2825e-04 - val_loss: 0.0020\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.2660e-04 - val_loss: 0.0020\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.1942e-04 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.2342e-04 - val_loss: 0.0020\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 8.2836e-04 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3496e-04 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 127\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0015\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0015\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0017\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0017\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0017\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0016\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 128\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0012\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 129\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 130\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            " 7/27 [======>.......................] - ETA: 0s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5516c138bc37>:10: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 131\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 132\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 133\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0030\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 134\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.1310e-04 - val_loss: 0.0050\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.4149e-04 - val_loss: 0.0049\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.3986e-04 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.4512e-04 - val_loss: 0.0049\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.3054e-04 - val_loss: 0.0050\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.5689e-04 - val_loss: 0.0050\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.3550e-04 - val_loss: 0.0049\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2873e-04 - val_loss: 0.0049\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.2559e-04 - val_loss: 0.0049\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2519e-04 - val_loss: 0.0049\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2178e-04 - val_loss: 0.0049\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 7.3008e-04 - val_loss: 0.0049\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2248e-04 - val_loss: 0.0049\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2532e-04 - val_loss: 0.0049\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2432e-04 - val_loss: 0.0049\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 7.2808e-04 - val_loss: 0.0050\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2271e-04 - val_loss: 0.0049\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 7.2161e-04 - val_loss: 0.0049\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2185e-04 - val_loss: 0.0049\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.2284e-04 - val_loss: 0.0049\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2149e-04 - val_loss: 0.0049\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.2555e-04 - val_loss: 0.0049\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2343e-04 - val_loss: 0.0049\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.1833e-04 - val_loss: 0.0049\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.2035e-04 - val_loss: 0.0049\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.2244e-04 - val_loss: 0.0049\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 7.2365e-04 - val_loss: 0.0049\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.1995e-04 - val_loss: 0.0049\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.1816e-04 - val_loss: 0.0049\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.1815e-04 - val_loss: 0.0049\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 135\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0022 - val_loss: 0.0054\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0054\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 136\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 137\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0046\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 138\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 139\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0034\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 140\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 141\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 142\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 143\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 144\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 145\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0037\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0037\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0037\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0037\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 146\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 147\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0036\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 148\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 149\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 150\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0045\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0045\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0045\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 151\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.3909e-04 - val_loss: 0.0032\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.2200e-04 - val_loss: 0.0032\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.2300e-04 - val_loss: 0.0032\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1770e-04 - val_loss: 0.0032\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.3724e-04 - val_loss: 0.0033\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.2300e-04 - val_loss: 0.0032\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1990e-04 - val_loss: 0.0033\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1942e-04 - val_loss: 0.0033\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.1383e-04 - val_loss: 0.0033\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.2071e-04 - val_loss: 0.0033\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1175e-04 - val_loss: 0.0032\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.2569e-04 - val_loss: 0.0033\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.3111e-04 - val_loss: 0.0033\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.1795e-04 - val_loss: 0.0032\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.0865e-04 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1034e-04 - val_loss: 0.0033\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.0825e-04 - val_loss: 0.0033\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.1745e-04 - val_loss: 0.0033\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.0519e-04 - val_loss: 0.0033\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.0936e-04 - val_loss: 0.0033\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.0547e-04 - val_loss: 0.0033\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1029e-04 - val_loss: 0.0033\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 9.0582e-04 - val_loss: 0.0033\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.0623e-04 - val_loss: 0.0033\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.0838e-04 - val_loss: 0.0033\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1556e-04 - val_loss: 0.0033\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.1153e-04 - val_loss: 0.0032\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 9.0350e-04 - val_loss: 0.0033\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.0325e-04 - val_loss: 0.0033\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.0506e-04 - val_loss: 0.0033\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 152\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 153\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 154\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 155\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 156\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0086\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0086\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0088\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0086\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0088\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0086\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0086\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0088\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0087\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 157\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 158\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 159\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0039\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0039\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0039\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 160\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0032 - val_loss: 0.0037\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 161\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.1527e-04 - val_loss: 0.0035\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.5982e-04 - val_loss: 0.0034\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.4906e-04 - val_loss: 0.0034\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.5477e-04 - val_loss: 0.0034\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.4165e-04 - val_loss: 0.0034\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.4082e-04 - val_loss: 0.0034\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3654e-04 - val_loss: 0.0034\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.4021e-04 - val_loss: 0.0034\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.3471e-04 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.3613e-04 - val_loss: 0.0034\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3182e-04 - val_loss: 0.0034\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.3216e-04 - val_loss: 0.0034\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3099e-04 - val_loss: 0.0034\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.3865e-04 - val_loss: 0.0034\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3236e-04 - val_loss: 0.0034\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.3130e-04 - val_loss: 0.0034\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3004e-04 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.3499e-04 - val_loss: 0.0034\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.2933e-04 - val_loss: 0.0034\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.2719e-04 - val_loss: 0.0034\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.3209e-04 - val_loss: 0.0034\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.3035e-04 - val_loss: 0.0035\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3295e-04 - val_loss: 0.0034\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.2427e-04 - val_loss: 0.0035\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.3337e-04 - val_loss: 0.0035\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.3714e-04 - val_loss: 0.0034\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.2803e-04 - val_loss: 0.0034\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.2697e-04 - val_loss: 0.0034\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.2830e-04 - val_loss: 0.0034\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.3601e-04 - val_loss: 0.0035\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 162\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0075\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0074\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0074\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0074\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0074\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0075\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0074\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 163\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0031\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 164\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 165\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0034\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 166\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 167\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0042\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0042\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0042\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 168\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0048\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0048\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0048\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0049\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0023 - val_loss: 0.0048\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 169\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.0283e-04 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.7070e-04 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.7134e-04 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.7488e-04 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.6491e-04 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 8.6086e-04 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.5544e-04 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.5197e-04 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 8.4989e-04 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.5296e-04 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 8.4424e-04 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.5338e-04 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.5355e-04 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.4717e-04 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.4888e-04 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.5287e-04 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.4883e-04 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.3623e-04 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.4678e-04 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.4276e-04 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.4126e-04 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.4225e-04 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3507e-04 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3546e-04 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.4065e-04 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.3951e-04 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.3710e-04 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.4132e-04 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.3683e-04 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.4126e-04 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 170\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0021 - val_loss: 0.0035\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 171\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 172\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 173\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 174\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 9.1599e-04 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.5431e-04 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 8.4986e-04 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5401e-04 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.5069e-04 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.5544e-04 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.5256e-04 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5207e-04 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.4956e-04 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5455e-04 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5408e-04 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.5582e-04 - val_loss: 0.0017\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5542e-04 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5050e-04 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.4750e-04 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.5286e-04 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5561e-04 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 8.4933e-04 - val_loss: 0.0017\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.5090e-04 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.5319e-04 - val_loss: 0.0017\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.5186e-04 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.5624e-04 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.5827e-04 - val_loss: 0.0017\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.5121e-04 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 8.5388e-04 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.4971e-04 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.5112e-04 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 8.4881e-04 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.6714e-04 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 8.5713e-04 - val_loss: 0.0017\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 175\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 176\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 177\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.0800e-04 - val_loss: 0.0025\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.0220e-04 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.9923e-04 - val_loss: 0.0025\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.9838e-04 - val_loss: 0.0025\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.0126e-04 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 8.9253e-04 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.0073e-04 - val_loss: 0.0025\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.9787e-04 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 8.9696e-04 - val_loss: 0.0025\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.9228e-04 - val_loss: 0.0025\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.9617e-04 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.0851e-04 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 8.9259e-04 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.9375e-04 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.9140e-04 - val_loss: 0.0025\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.9606e-04 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.0076e-04 - val_loss: 0.0025\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.9349e-04 - val_loss: 0.0025\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.9523e-04 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.9785e-04 - val_loss: 0.0025\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.9639e-04 - val_loss: 0.0025\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.9103e-04 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.9000e-04 - val_loss: 0.0025\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.9162e-04 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.9296e-04 - val_loss: 0.0025\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.9326e-04 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.8889e-04 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.0160e-04 - val_loss: 0.0025\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.0677e-04 - val_loss: 0.0025\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.0035e-04 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 178\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 179\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0036\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 180\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 181\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 7.4325e-04 - val_loss: 0.0043\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 7.3073e-04 - val_loss: 0.0043\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.2249e-04 - val_loss: 0.0043\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.1546e-04 - val_loss: 0.0043\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.2082e-04 - val_loss: 0.0043\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.0893e-04 - val_loss: 0.0043\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.1238e-04 - val_loss: 0.0043\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0843e-04 - val_loss: 0.0043\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 7.1361e-04 - val_loss: 0.0043\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 7.1060e-04 - val_loss: 0.0043\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0618e-04 - val_loss: 0.0043\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.1060e-04 - val_loss: 0.0043\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.1175e-04 - val_loss: 0.0043\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0476e-04 - val_loss: 0.0043\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.0526e-04 - val_loss: 0.0043\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.0657e-04 - val_loss: 0.0043\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.0099e-04 - val_loss: 0.0043\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.0543e-04 - val_loss: 0.0043\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.0773e-04 - val_loss: 0.0043\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0474e-04 - val_loss: 0.0043\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0394e-04 - val_loss: 0.0043\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 6.9952e-04 - val_loss: 0.0043\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.0124e-04 - val_loss: 0.0043\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.0501e-04 - val_loss: 0.0043\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 7.0433e-04 - val_loss: 0.0043\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.0270e-04 - val_loss: 0.0043\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 6.9922e-04 - val_loss: 0.0043\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.0327e-04 - val_loss: 0.0043\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.0403e-04 - val_loss: 0.0043\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.0114e-04 - val_loss: 0.0043\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 182\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 183\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 184\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 185\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0027 - val_loss: 0.0014\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0014\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 186\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0048\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 0.0048\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0048\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 187\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0017\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0024\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0021\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0021\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0034 - val_loss: 0.0021\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0026\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0061\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0060\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0034 - val_loss: 0.0066\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0054\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0071\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0064\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0084\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0034 - val_loss: 0.0065\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0065\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0077\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0065\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0033 - val_loss: 0.0064\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0070\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0066\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0060\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 188\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0021\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0021\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0022\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0047 - val_loss: 0.0024\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0026\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0047 - val_loss: 0.0024\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0047 - val_loss: 0.0022\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0022\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0047 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0047 - val_loss: 0.0026\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0047 - val_loss: 0.0025\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0025\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0047 - val_loss: 0.0024\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0023\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0024\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 189\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 190\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 6.5844e-04 - val_loss: 0.0044\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 6.4316e-04 - val_loss: 0.0044\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.2939e-04 - val_loss: 0.0045\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 6.4022e-04 - val_loss: 0.0045\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 6.2400e-04 - val_loss: 0.0045\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.1953e-04 - val_loss: 0.0046\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.2263e-04 - val_loss: 0.0046\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.1900e-04 - val_loss: 0.0046\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 6.1901e-04 - val_loss: 0.0046\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1847e-04 - val_loss: 0.0046\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.2108e-04 - val_loss: 0.0046\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 6.1842e-04 - val_loss: 0.0047\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.1453e-04 - val_loss: 0.0047\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 6.1723e-04 - val_loss: 0.0047\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1432e-04 - val_loss: 0.0047\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 6.2296e-04 - val_loss: 0.0048\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1709e-04 - val_loss: 0.0048\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.1731e-04 - val_loss: 0.0047\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.1583e-04 - val_loss: 0.0048\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.1701e-04 - val_loss: 0.0048\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1920e-04 - val_loss: 0.0047\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.2362e-04 - val_loss: 0.0048\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.1053e-04 - val_loss: 0.0048\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 6.1408e-04 - val_loss: 0.0047\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.1162e-04 - val_loss: 0.0048\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1010e-04 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 6.1027e-04 - val_loss: 0.0048\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.1043e-04 - val_loss: 0.0048\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 6.1865e-04 - val_loss: 0.0048\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 6.1046e-04 - val_loss: 0.0048\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 191\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0027\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.9540e-04 - val_loss: 0.0026\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.9105e-04 - val_loss: 0.0026\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.7336e-04 - val_loss: 0.0026\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.6095e-04 - val_loss: 0.0026\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.6127e-04 - val_loss: 0.0026\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.7603e-04 - val_loss: 0.0026\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.6716e-04 - val_loss: 0.0026\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.7301e-04 - val_loss: 0.0026\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.8054e-04 - val_loss: 0.0026\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.7538e-04 - val_loss: 0.0026\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 9.7585e-04 - val_loss: 0.0026\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.5948e-04 - val_loss: 0.0026\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.6199e-04 - val_loss: 0.0026\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.6045e-04 - val_loss: 0.0026\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.6846e-04 - val_loss: 0.0026\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.6776e-04 - val_loss: 0.0026\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.5616e-04 - val_loss: 0.0026\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.6460e-04 - val_loss: 0.0026\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.7140e-04 - val_loss: 0.0026\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.6036e-04 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.6584e-04 - val_loss: 0.0026\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.5713e-04 - val_loss: 0.0026\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 9.5933e-04 - val_loss: 0.0026\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.5967e-04 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 9.5935e-04 - val_loss: 0.0026\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.5901e-04 - val_loss: 0.0026\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.5944e-04 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.5862e-04 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.6411e-04 - val_loss: 0.0026\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 192\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0027 - val_loss: 0.0017\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 0.0017\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0017\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 193\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5516c138bc37>:10: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "<ipython-input-5-5516c138bc37>:11: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 295\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.9894e-04 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 9.4611e-04 - val_loss: 0.0030\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.3297e-04 - val_loss: 0.0030\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.2888e-04 - val_loss: 0.0031\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.2855e-04 - val_loss: 0.0031\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.3649e-04 - val_loss: 0.0031\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.3258e-04 - val_loss: 0.0031\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.2475e-04 - val_loss: 0.0031\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.2546e-04 - val_loss: 0.0031\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.2407e-04 - val_loss: 0.0031\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.2194e-04 - val_loss: 0.0031\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.2154e-04 - val_loss: 0.0031\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.2442e-04 - val_loss: 0.0032\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.2377e-04 - val_loss: 0.0031\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.2237e-04 - val_loss: 0.0031\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.2747e-04 - val_loss: 0.0031\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.2465e-04 - val_loss: 0.0031\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.2339e-04 - val_loss: 0.0031\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.2641e-04 - val_loss: 0.0031\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.2066e-04 - val_loss: 0.0032\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.2487e-04 - val_loss: 0.0031\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.2091e-04 - val_loss: 0.0031\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.1969e-04 - val_loss: 0.0031\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.1985e-04 - val_loss: 0.0031\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.2331e-04 - val_loss: 0.0031\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.2828e-04 - val_loss: 0.0031\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.2145e-04 - val_loss: 0.0031\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 9.1874e-04 - val_loss: 0.0031\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.2374e-04 - val_loss: 0.0031\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.2746e-04 - val_loss: 0.0032\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 296\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 297\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.8430e-04 - val_loss: 0.0031\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.8224e-04 - val_loss: 0.0031\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 6.4009e-04 - val_loss: 0.0031\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.3042e-04 - val_loss: 0.0031\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.1650e-04 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.0848e-04 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 6.0183e-04 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 5.9568e-04 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.0071e-04 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.9567e-04 - val_loss: 0.0030\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 6.0020e-04 - val_loss: 0.0031\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 6.0003e-04 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 5.9591e-04 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 5.8829e-04 - val_loss: 0.0031\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 5.9081e-04 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.9434e-04 - val_loss: 0.0030\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 5.9278e-04 - val_loss: 0.0031\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.9779e-04 - val_loss: 0.0031\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.0187e-04 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.8911e-04 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.8957e-04 - val_loss: 0.0030\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.8822e-04 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.8762e-04 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.8930e-04 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.9287e-04 - val_loss: 0.0030\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.8658e-04 - val_loss: 0.0030\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.9093e-04 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.8900e-04 - val_loss: 0.0030\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.9788e-04 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.8735e-04 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 298\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0031 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0022\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0029 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0022\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 299\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 300\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0025\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0047\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0054\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0053\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0049 - val_loss: 0.0053\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0048 - val_loss: 0.0052\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0049 - val_loss: 0.0054\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0053\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0048 - val_loss: 0.0050\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0049 - val_loss: 0.0053\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0052\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0048 - val_loss: 0.0055\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0052\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0048 - val_loss: 0.0053\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 301\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0044 - val_loss: 0.0064\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0041 - val_loss: 0.0053\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0041 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0041 - val_loss: 0.0047\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0041 - val_loss: 0.0047\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0041 - val_loss: 0.0050\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0050\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0050\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0049\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0050\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0050\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0052\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0050\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0053\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0051\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0052\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0040 - val_loss: 0.0051\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0040 - val_loss: 0.0051\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0040 - val_loss: 0.0053\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0051\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0051\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0040 - val_loss: 0.0051\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0040 - val_loss: 0.0049\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0040 - val_loss: 0.0053\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0056\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0040 - val_loss: 0.0053\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0054\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0053\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0054\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 302\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0030\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 303\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0025 - val_loss: 0.0054\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 304\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0041\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0041\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0041\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0041\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0041\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0042\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0041\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0043\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.9665e-04 - val_loss: 0.0043\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.9355e-04 - val_loss: 0.0044\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.8960e-04 - val_loss: 0.0044\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.8373e-04 - val_loss: 0.0044\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.8508e-04 - val_loss: 0.0045\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.7534e-04 - val_loss: 0.0045\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.7727e-04 - val_loss: 0.0047\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.7015e-04 - val_loss: 0.0046\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.7070e-04 - val_loss: 0.0048\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.6832e-04 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.6144e-04 - val_loss: 0.0050\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.7902e-04 - val_loss: 0.0049\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.5915e-04 - val_loss: 0.0050\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.5615e-04 - val_loss: 0.0049\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 305\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0039 - val_loss: 0.0050\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0049\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0051\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 306\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0046\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0046\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 307\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 308\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0037\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0039\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0027 - val_loss: 0.0043\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0027 - val_loss: 0.0044\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0041\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0043\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0043\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0044\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0027 - val_loss: 0.0043\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0041\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0044\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0044\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 309\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0024\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0024\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0024\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 310\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.7695e-04 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.3223e-04 - val_loss: 0.0038\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.1720e-04 - val_loss: 0.0038\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.1243e-04 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.1017e-04 - val_loss: 0.0038\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.0210e-04 - val_loss: 0.0038\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.0386e-04 - val_loss: 0.0038\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.0084e-04 - val_loss: 0.0038\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.0260e-04 - val_loss: 0.0038\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.9112e-04 - val_loss: 0.0037\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.9652e-04 - val_loss: 0.0038\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.9173e-04 - val_loss: 0.0039\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.9878e-04 - val_loss: 0.0038\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.9036e-04 - val_loss: 0.0037\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.9017e-04 - val_loss: 0.0037\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.8996e-04 - val_loss: 0.0038\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.8875e-04 - val_loss: 0.0037\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.8941e-04 - val_loss: 0.0038\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.9414e-04 - val_loss: 0.0038\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 7.8885e-04 - val_loss: 0.0038\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 7.9347e-04 - val_loss: 0.0037\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.8930e-04 - val_loss: 0.0037\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.9096e-04 - val_loss: 0.0038\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.9479e-04 - val_loss: 0.0037\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.8788e-04 - val_loss: 0.0037\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 7.9342e-04 - val_loss: 0.0037\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.9232e-04 - val_loss: 0.0038\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 7.8686e-04 - val_loss: 0.0038\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.0322e-04 - val_loss: 0.0038\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 311\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0039\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0041\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 312\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0014 - val_loss: 0.0027\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0033\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0033\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0033\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0033\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0035\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 313\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0043 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0038 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0038 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0037 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0037 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0037 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 314\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0044\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 315\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0048\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0048\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0049\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0047\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0048\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 316\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 5.5820e-04 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.3491e-04 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 5.2528e-04 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 5.1400e-04 - val_loss: 0.0029\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.0623e-04 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0556e-04 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0356e-04 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 4.9906e-04 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 4.9840e-04 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 4.9767e-04 - val_loss: 0.0030\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 4.9592e-04 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 4.9873e-04 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.0792e-04 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 4.9805e-04 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 4.9386e-04 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 4.9790e-04 - val_loss: 0.0030\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 4.9406e-04 - val_loss: 0.0030\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 4.9670e-04 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.9838e-04 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 4.9712e-04 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.0243e-04 - val_loss: 0.0031\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 4.9559e-04 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 4.9092e-04 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 4.9346e-04 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 4.9197e-04 - val_loss: 0.0030\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 4.9283e-04 - val_loss: 0.0031\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 4.9262e-04 - val_loss: 0.0032\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.0056e-04 - val_loss: 0.0031\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 4.9457e-04 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 4.8962e-04 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 317\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 9.9772e-04\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0011\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0011\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0010\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0010\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0010\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0010\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0011\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 318\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0021 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 319\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0031\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 320\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0039\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0042\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0042\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0042\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 321\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 322\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 323\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0029 - val_loss: 0.0082\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0082\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0082\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0029 - val_loss: 0.0082\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 324\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 6.3692e-04 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.0028e-04 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 6.0269e-04 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.9570e-04 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 5.9186e-04 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.8122e-04 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.8293e-04 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 5.7826e-04 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.7848e-04 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.7854e-04 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.8204e-04 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.8171e-04 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.7713e-04 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 5.8144e-04 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.7842e-04 - val_loss: 0.0019\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.8053e-04 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.8188e-04 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 5.8985e-04 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.7732e-04 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.7601e-04 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.8565e-04 - val_loss: 0.0019\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.7931e-04 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.8190e-04 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.7429e-04 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.8172e-04 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.7830e-04 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 5.7784e-04 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.7444e-04 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.7571e-04 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 5.7908e-04 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 325\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.8804e-04 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.7805e-04 - val_loss: 0.0022\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.8604e-04 - val_loss: 0.0023\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.8271e-04 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.7478e-04 - val_loss: 0.0023\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.7007e-04 - val_loss: 0.0023\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.7355e-04 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.7980e-04 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.8204e-04 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.6717e-04 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.8050e-04 - val_loss: 0.0022\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.8458e-04 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.8279e-04 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.7454e-04 - val_loss: 0.0022\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.6589e-04 - val_loss: 0.0023\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.6647e-04 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 9.6929e-04 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.6220e-04 - val_loss: 0.0023\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.5469e-04 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.8738e-04 - val_loss: 0.0022\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.7823e-04 - val_loss: 0.0023\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.8064e-04 - val_loss: 0.0022\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.6320e-04 - val_loss: 0.0023\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.5759e-04 - val_loss: 0.0023\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.6787e-04 - val_loss: 0.0022\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.6298e-04 - val_loss: 0.0023\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.6127e-04 - val_loss: 0.0022\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 9.6785e-04 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.6883e-04 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 326\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0013\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0015\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0015\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0016\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0017\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0039 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0040 - val_loss: 0.0019\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0021\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 327\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0049\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.3606e-04 - val_loss: 0.0051\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 9.2165e-04 - val_loss: 0.0051\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.0569e-04 - val_loss: 0.0052\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.9426e-04 - val_loss: 0.0052\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.9223e-04 - val_loss: 0.0052\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.8963e-04 - val_loss: 0.0052\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.8685e-04 - val_loss: 0.0053\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.8380e-04 - val_loss: 0.0053\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.8701e-04 - val_loss: 0.0053\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.8734e-04 - val_loss: 0.0054\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.8239e-04 - val_loss: 0.0054\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 8.8175e-04 - val_loss: 0.0053\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.8234e-04 - val_loss: 0.0054\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 8.8048e-04 - val_loss: 0.0054\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 8.8984e-04 - val_loss: 0.0054\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.8292e-04 - val_loss: 0.0053\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.8168e-04 - val_loss: 0.0055\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.7969e-04 - val_loss: 0.0054\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.8210e-04 - val_loss: 0.0055\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.8853e-04 - val_loss: 0.0055\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.8124e-04 - val_loss: 0.0056\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.8374e-04 - val_loss: 0.0055\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.8462e-04 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.7878e-04 - val_loss: 0.0054\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.8061e-04 - val_loss: 0.0054\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.8462e-04 - val_loss: 0.0055\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.7644e-04 - val_loss: 0.0053\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 8.8123e-04 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.7864e-04 - val_loss: 0.0055\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 328\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0037\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 329\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 330\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 331\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.4234e-04 - val_loss: 0.0022\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.3061e-04 - val_loss: 0.0022\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.2127e-04 - val_loss: 0.0022\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.1657e-04 - val_loss: 0.0022\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.1169e-04 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.1362e-04 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.0386e-04 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.0555e-04 - val_loss: 0.0022\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.0528e-04 - val_loss: 0.0022\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 8.0161e-04 - val_loss: 0.0022\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.0692e-04 - val_loss: 0.0022\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.1593e-04 - val_loss: 0.0022\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 8.0828e-04 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.0043e-04 - val_loss: 0.0022\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.0037e-04 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.0131e-04 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.0377e-04 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.0241e-04 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 8.0848e-04 - val_loss: 0.0022\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 8.0073e-04 - val_loss: 0.0023\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 7.9813e-04 - val_loss: 0.0022\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.0361e-04 - val_loss: 0.0022\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.0307e-04 - val_loss: 0.0022\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 8.0666e-04 - val_loss: 0.0022\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.0341e-04 - val_loss: 0.0022\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.0528e-04 - val_loss: 0.0022\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.9906e-04 - val_loss: 0.0022\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.9619e-04 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 8.0580e-04 - val_loss: 0.0022\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 332\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 333\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 334\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0030\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0030\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 335\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 6.7093e-04 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.4316e-04 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 5.2346e-04 - val_loss: 0.0037\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 5.1949e-04 - val_loss: 0.0036\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 5.1644e-04 - val_loss: 0.0036\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 5.1097e-04 - val_loss: 0.0037\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.1149e-04 - val_loss: 0.0036\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.1304e-04 - val_loss: 0.0036\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.1625e-04 - val_loss: 0.0037\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.0617e-04 - val_loss: 0.0036\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.0831e-04 - val_loss: 0.0036\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 5.0878e-04 - val_loss: 0.0036\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 5.1433e-04 - val_loss: 0.0036\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0856e-04 - val_loss: 0.0036\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.1045e-04 - val_loss: 0.0036\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.0529e-04 - val_loss: 0.0036\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.0607e-04 - val_loss: 0.0036\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 5.0943e-04 - val_loss: 0.0036\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0989e-04 - val_loss: 0.0036\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 5.0586e-04 - val_loss: 0.0037\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.1721e-04 - val_loss: 0.0036\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0629e-04 - val_loss: 0.0036\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 5.0679e-04 - val_loss: 0.0036\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 5.0497e-04 - val_loss: 0.0036\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0618e-04 - val_loss: 0.0036\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0976e-04 - val_loss: 0.0036\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 5.0644e-04 - val_loss: 0.0036\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0557e-04 - val_loss: 0.0036\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 5.1040e-04 - val_loss: 0.0036\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 5.0404e-04 - val_loss: 0.0036\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 336\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 337\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 338\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0010\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0010\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0010\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 339\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0038\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0036\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0038\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0038\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 340\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0028\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 341\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0028\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0031 - val_loss: 0.0028\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 342\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0026\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0025\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0026\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0027\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0031\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 0.0015 - val_loss: 0.0033\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 343\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0049 - val_loss: 0.0041\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0041 - val_loss: 0.0042\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0040 - val_loss: 0.0044\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0041 - val_loss: 0.0042\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0044\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0041 - val_loss: 0.0042\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 344\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 7.9444e-04 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 7.2741e-04 - val_loss: 0.0016\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 7.0680e-04 - val_loss: 0.0015\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 6.9940e-04 - val_loss: 0.0015\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 6.9646e-04 - val_loss: 0.0015\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.9931e-04 - val_loss: 0.0015\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 6.9131e-04 - val_loss: 0.0015\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 6.8988e-04 - val_loss: 0.0015\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 6.9184e-04 - val_loss: 0.0015\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 6.8920e-04 - val_loss: 0.0015\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8853e-04 - val_loss: 0.0015\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8618e-04 - val_loss: 0.0015\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 6.8788e-04 - val_loss: 0.0015\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.8296e-04 - val_loss: 0.0015\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8781e-04 - val_loss: 0.0015\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.8555e-04 - val_loss: 0.0015\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.8412e-04 - val_loss: 0.0015\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8998e-04 - val_loss: 0.0015\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.9195e-04 - val_loss: 0.0015\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8587e-04 - val_loss: 0.0015\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8783e-04 - val_loss: 0.0015\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.8462e-04 - val_loss: 0.0015\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.7851e-04 - val_loss: 0.0015\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8039e-04 - val_loss: 0.0015\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 6.8220e-04 - val_loss: 0.0015\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8337e-04 - val_loss: 0.0015\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.7884e-04 - val_loss: 0.0015\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 6.7827e-04 - val_loss: 0.0015\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 6.7877e-04 - val_loss: 0.0015\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 6.8337e-04 - val_loss: 0.0015\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 345\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 346\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 347\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0022\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 348\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0064 - val_loss: 0.0039\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0063 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0038\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0062 - val_loss: 0.0040\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0061 - val_loss: 0.0040\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0061 - val_loss: 0.0040\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0060 - val_loss: 0.0041\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0041\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0041\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0040\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 349\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 350\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 351\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0044 - val_loss: 0.0021\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0044 - val_loss: 0.0021\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0021\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0022\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0044 - val_loss: 0.0022\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0022\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0021\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0044 - val_loss: 0.0022\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 352\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 353\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 354\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0036 - val_loss: 0.0019\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0034 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0034 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0017\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0032 - val_loss: 0.0017\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0033 - val_loss: 0.0017\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0017\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0017\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0017\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0033 - val_loss: 0.0017\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 355\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 356\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0028\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 357\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 358\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0028 - val_loss: 0.0020\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 359\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0044\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.5896e-04 - val_loss: 0.0044\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 9.3981e-04 - val_loss: 0.0044\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.1709e-04 - val_loss: 0.0044\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.1384e-04 - val_loss: 0.0044\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.1520e-04 - val_loss: 0.0044\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.1315e-04 - val_loss: 0.0044\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.1667e-04 - val_loss: 0.0044\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.0999e-04 - val_loss: 0.0044\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.0538e-04 - val_loss: 0.0044\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.1403e-04 - val_loss: 0.0043\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 9.0816e-04 - val_loss: 0.0044\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 9.0259e-04 - val_loss: 0.0044\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.0345e-04 - val_loss: 0.0044\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.0369e-04 - val_loss: 0.0043\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 9.0621e-04 - val_loss: 0.0044\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.0339e-04 - val_loss: 0.0044\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 9.0573e-04 - val_loss: 0.0044\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.0749e-04 - val_loss: 0.0044\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.1428e-04 - val_loss: 0.0044\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.0288e-04 - val_loss: 0.0044\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.0673e-04 - val_loss: 0.0044\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 9.0198e-04 - val_loss: 0.0044\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.0222e-04 - val_loss: 0.0043\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 8.9511e-04 - val_loss: 0.0044\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.9906e-04 - val_loss: 0.0043\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 18ms/step - loss: 8.9835e-04 - val_loss: 0.0045\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 9.0991e-04 - val_loss: 0.0044\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 8.9931e-04 - val_loss: 0.0044\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 9.1273e-04 - val_loss: 0.0044\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 360\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0039\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0039\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0039\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 361\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 362\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0030 - val_loss: 0.0062\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0030 - val_loss: 0.0061\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0063\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0061\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0061\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 363\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 25ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 27ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 364\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0067\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 365\n",
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "Epoch 1/30\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0045\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0045\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0045\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0025 - val_loss: 0.0045\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 0.0044\n",
            "---------------------------------------------------\n",
            "El entrenamiento va en el dia 366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalizar(df,250)\n",
        "\n",
        "#Crear train-test datasets\n",
        "\n",
        "training_size = int(len(df_normal.Open)*0.60)\n",
        "test_size=len(df_normal.Open)-training_size\n",
        "train_data,test_data=df_normal[['Close']][0:training_size],df_normal[['Close']][training_size:]\n",
        "print(\"train_data: \", train_data.shape)\n",
        "print(\"test_data: \", test_data.shape)\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "train_data=scaler.fit_transform(np.array(train_data).reshape(-1,1))\n",
        "print(train_data.shape)\n",
        "\n",
        "test_data=scaler.fit_transform(np.array(test_data).reshape(-1,1))\n",
        "print(test_data.shape)\n",
        "\n",
        "time_step = 15\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)\n",
        "\n",
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)\n",
        "train_predict.shape, test_predict.shape\n",
        "\n",
        "lista = [train_predict[i][4] for i in range(len(train_predict))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "train_predict = np.array(lista2)\n",
        "\n",
        "lista = [test_predict[i][4] for i in range(len(test_predict))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "test_predict = np.array(lista2)\n",
        "\n",
        "lista = [y_train[i][4] for i in range(len(y_train))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "y_train = np.array(lista2)\n",
        "\n",
        "lista = [y_test[i][4] for i in range(len(y_test))]\n",
        "lista2 = []\n",
        "for i in lista:\n",
        "  lista2.append(np.array([i]))\n",
        "\n",
        "y_test = np.array(lista2)\n",
        "\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1))\n",
        "original_ytest = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_ytest,test_predict)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_ytest,test_predict))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_ytest,test_predict))\n",
        "\n",
        "print(\"Train data explained variance regression score:\",\n",
        "      explained_variance_score(original_ytrain, train_predict))\n",
        "print(\"Test data explained variance regression score:\",\n",
        "      explained_variance_score(original_ytest, test_predict))\n",
        "\n",
        "closedf = df_normal[['Close']].copy(deep=True)\n",
        "closedf.head()\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "closedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))\n",
        "print(closedf.shape)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "\n",
        "look_back=time_step\n",
        "trainPredictPlot = np.empty_like(closedf)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "print(\"Train predicted data: \", trainPredictPlot.shape)\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(closedf)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-11, :] = test_predict[:]\n",
        "print(\"Test predicted data: \", testPredictPlot.shape)\n",
        "\n",
        "names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
        "\n",
        "\n",
        "plotdf = pd.DataFrame({'date': df_normal.index,\n",
        "                       'original_close': df_normal['Close'],\n",
        "                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
        "                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
        "\n",
        "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
        "                                          plotdf['test_predicted_close']],\n",
        "              labels={'value':'Stock price','date': 'Date'})\n",
        "fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
        "                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
        "fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
        "\n",
        "fig.update_xaxes(showgrid=False)\n",
        "fig.update_yaxes(showgrid=False)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "5IQZrtfdsqHZ",
        "outputId": "de3908e6-3d47-468a-b1a0-441799d33f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data:  (864, 1)\n",
            "test_data:  (576, 1)\n",
            "(864, 1)\n",
            "(576, 1)\n",
            "X_train:  (843, 15)\n",
            "y_train:  (843, 5)\n",
            "X_test:  (555, 15)\n",
            "y_test (555, 5)\n",
            "27/27 [==============================] - 0s 5ms/step\n",
            "18/18 [==============================] - 0s 6ms/step\n",
            "Train data RMSE:  0.03418401105803977\n",
            "Train data MSE:  0.0011685466120161853\n",
            "Train data MAE:  0.027310275348236098\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.040999131167589735\n",
            "Test data MSE:  0.0016809287564972283\n",
            "Test data MAE:  0.030897676496372838\n",
            "Train data explained variance regression score: 0.9604929417265059\n",
            "Test data explained variance regression score: 0.9560984783786493\n",
            "(1440, 1)\n",
            "Train predicted data:  (1440, 1)\n",
            "Test predicted data:  (1440, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5847b7e8-60ca-4c3e-a13c-eedd4705a738\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5847b7e8-60ca-4c3e-a13c-eedd4705a738\")) {                    Plotly.newPlot(                        \"5847b7e8-60ca-4c3e-a13c-eedd4705a738\",                        [{\"hovertemplate\":\"variable=original_close\\u003cbr\\u003eDate=%{x}\\u003cbr\\u003eStock price=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"original_close\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Original close price\",\"showlegend\":true,\"x\":[\"2018-05-06 00:00:00\",\"2018-05-06 00:01:00\",\"2018-05-06 00:02:00\",\"2018-05-06 00:03:00\",\"2018-05-06 00:04:00\",\"2018-05-06 00:05:00\",\"2018-05-06 00:06:00\",\"2018-05-06 00:07:00\",\"2018-05-06 00:08:00\",\"2018-05-06 00:09:00\",\"2018-05-06 00:10:00\",\"2018-05-06 00:11:00\",\"2018-05-06 00:12:00\",\"2018-05-06 00:13:00\",\"2018-05-06 00:14:00\",\"2018-05-06 00:15:00\",\"2018-05-06 00:16:00\",\"2018-05-06 00:17:00\",\"2018-05-06 00:18:00\",\"2018-05-06 00:19:00\",\"2018-05-06 00:20:00\",\"2018-05-06 00:21:00\",\"2018-05-06 00:22:00\",\"2018-05-06 00:23:00\",\"2018-05-06 00:24:00\",\"2018-05-06 00:25:00\",\"2018-05-06 00:26:00\",\"2018-05-06 00:27:00\",\"2018-05-06 00:28:00\",\"2018-05-06 00:29:00\",\"2018-05-06 00:30:00\",\"2018-05-06 00:31:00\",\"2018-05-06 00:32:00\",\"2018-05-06 00:33:00\",\"2018-05-06 00:34:00\",\"2018-05-06 00:35:00\",\"2018-05-06 00:36:00\",\"2018-05-06 00:37:00\",\"2018-05-06 00:38:00\",\"2018-05-06 00:39:00\",\"2018-05-06 00:40:00\",\"2018-05-06 00:41:00\",\"2018-05-06 00:42:00\",\"2018-05-06 00:43:00\",\"2018-05-06 00:44:00\",\"2018-05-06 00:45:00\",\"2018-05-06 00:46:00\",\"2018-05-06 00:47:00\",\"2018-05-06 00:48:00\",\"2018-05-06 00:49:00\",\"2018-05-06 00:50:00\",\"2018-05-06 00:51:00\",\"2018-05-06 00:52:00\",\"2018-05-06 00:53:00\",\"2018-05-06 00:54:00\",\"2018-05-06 00:55:00\",\"2018-05-06 00:56:00\",\"2018-05-06 00:57:00\",\"2018-05-06 00:58:00\",\"2018-05-06 00:59:00\",\"2018-05-06 01:00:00\",\"2018-05-06 01:01:00\",\"2018-05-06 01:02:00\",\"2018-05-06 01:03:00\",\"2018-05-06 01:04:00\",\"2018-05-06 01:05:00\",\"2018-05-06 01:06:00\",\"2018-05-06 01:07:00\",\"2018-05-06 01:08:00\",\"2018-05-06 01:09:00\",\"2018-05-06 01:10:00\",\"2018-05-06 01:11:00\",\"2018-05-06 01:12:00\",\"2018-05-06 01:13:00\",\"2018-05-06 01:14:00\",\"2018-05-06 01:15:00\",\"2018-05-06 01:16:00\",\"2018-05-06 01:17:00\",\"2018-05-06 01:18:00\",\"2018-05-06 01:19:00\",\"2018-05-06 01:20:00\",\"2018-05-06 01:21:00\",\"2018-05-06 01:22:00\",\"2018-05-06 01:23:00\",\"2018-05-06 01:24:00\",\"2018-05-06 01:25:00\",\"2018-05-06 01:26:00\",\"2018-05-06 01:27:00\",\"2018-05-06 01:28:00\",\"2018-05-06 01:29:00\",\"2018-05-06 01:30:00\",\"2018-05-06 01:31:00\",\"2018-05-06 01:32:00\",\"2018-05-06 01:33:00\",\"2018-05-06 01:34:00\",\"2018-05-06 01:35:00\",\"2018-05-06 01:36:00\",\"2018-05-06 01:37:00\",\"2018-05-06 01:38:00\",\"2018-05-06 01:39:00\",\"2018-05-06 01:40:00\",\"2018-05-06 01:41:00\",\"2018-05-06 01:42:00\",\"2018-05-06 01:43:00\",\"2018-05-06 01:44:00\",\"2018-05-06 01:45:00\",\"2018-05-06 01:46:00\",\"2018-05-06 01:47:00\",\"2018-05-06 01:48:00\",\"2018-05-06 01:49:00\",\"2018-05-06 01:50:00\",\"2018-05-06 01:51:00\",\"2018-05-06 01:52:00\",\"2018-05-06 01:53:00\",\"2018-05-06 01:54:00\",\"2018-05-06 01:55:00\",\"2018-05-06 01:56:00\",\"2018-05-06 01:57:00\",\"2018-05-06 01:58:00\",\"2018-05-06 01:59:00\",\"2018-05-06 02:00:00\",\"2018-05-06 02:01:00\",\"2018-05-06 02:02:00\",\"2018-05-06 02:03:00\",\"2018-05-06 02:04:00\",\"2018-05-06 02:05:00\",\"2018-05-06 02:06:00\",\"2018-05-06 02:07:00\",\"2018-05-06 02:08:00\",\"2018-05-06 02:09:00\",\"2018-05-06 02:10:00\",\"2018-05-06 02:11:00\",\"2018-05-06 02:12:00\",\"2018-05-06 02:13:00\",\"2018-05-06 02:14:00\",\"2018-05-06 02:15:00\",\"2018-05-06 02:16:00\",\"2018-05-06 02:17:00\",\"2018-05-06 02:18:00\",\"2018-05-06 02:19:00\",\"2018-05-06 02:20:00\",\"2018-05-06 02:21:00\",\"2018-05-06 02:22:00\",\"2018-05-06 02:23:00\",\"2018-05-06 02:24:00\",\"2018-05-06 02:25:00\",\"2018-05-06 02:26:00\",\"2018-05-06 02:27:00\",\"2018-05-06 02:28:00\",\"2018-05-06 02:29:00\",\"2018-05-06 02:30:00\",\"2018-05-06 02:31:00\",\"2018-05-06 02:32:00\",\"2018-05-06 02:33:00\",\"2018-05-06 02:34:00\",\"2018-05-06 02:35:00\",\"2018-05-06 02:36:00\",\"2018-05-06 02:37:00\",\"2018-05-06 02:38:00\",\"2018-05-06 02:39:00\",\"2018-05-06 02:40:00\",\"2018-05-06 02:41:00\",\"2018-05-06 02:42:00\",\"2018-05-06 02:43:00\",\"2018-05-06 02:44:00\",\"2018-05-06 02:45:00\",\"2018-05-06 02:46:00\",\"2018-05-06 02:47:00\",\"2018-05-06 02:48:00\",\"2018-05-06 02:49:00\",\"2018-05-06 02:50:00\",\"2018-05-06 02:51:00\",\"2018-05-06 02:52:00\",\"2018-05-06 02:53:00\",\"2018-05-06 02:54:00\",\"2018-05-06 02:55:00\",\"2018-05-06 02:56:00\",\"2018-05-06 02:57:00\",\"2018-05-06 02:58:00\",\"2018-05-06 02:59:00\",\"2018-05-06 03:00:00\",\"2018-05-06 03:01:00\",\"2018-05-06 03:02:00\",\"2018-05-06 03:03:00\",\"2018-05-06 03:04:00\",\"2018-05-06 03:05:00\",\"2018-05-06 03:06:00\",\"2018-05-06 03:07:00\",\"2018-05-06 03:08:00\",\"2018-05-06 03:09:00\",\"2018-05-06 03:10:00\",\"2018-05-06 03:11:00\",\"2018-05-06 03:12:00\",\"2018-05-06 03:13:00\",\"2018-05-06 03:14:00\",\"2018-05-06 03:15:00\",\"2018-05-06 03:16:00\",\"2018-05-06 03:17:00\",\"2018-05-06 03:18:00\",\"2018-05-06 03:19:00\",\"2018-05-06 03:20:00\",\"2018-05-06 03:21:00\",\"2018-05-06 03:22:00\",\"2018-05-06 03:23:00\",\"2018-05-06 03:24:00\",\"2018-05-06 03:25:00\",\"2018-05-06 03:26:00\",\"2018-05-06 03:27:00\",\"2018-05-06 03:28:00\",\"2018-05-06 03:29:00\",\"2018-05-06 03:30:00\",\"2018-05-06 03:31:00\",\"2018-05-06 03:32:00\",\"2018-05-06 03:33:00\",\"2018-05-06 03:34:00\",\"2018-05-06 03:35:00\",\"2018-05-06 03:36:00\",\"2018-05-06 03:37:00\",\"2018-05-06 03:38:00\",\"2018-05-06 03:39:00\",\"2018-05-06 03:40:00\",\"2018-05-06 03:41:00\",\"2018-05-06 03:42:00\",\"2018-05-06 03:43:00\",\"2018-05-06 03:44:00\",\"2018-05-06 03:45:00\",\"2018-05-06 03:46:00\",\"2018-05-06 03:47:00\",\"2018-05-06 03:48:00\",\"2018-05-06 03:49:00\",\"2018-05-06 03:50:00\",\"2018-05-06 03:51:00\",\"2018-05-06 03:52:00\",\"2018-05-06 03:53:00\",\"2018-05-06 03:54:00\",\"2018-05-06 03:55:00\",\"2018-05-06 03:56:00\",\"2018-05-06 03:57:00\",\"2018-05-06 03:58:00\",\"2018-05-06 03:59:00\",\"2018-05-06 04:00:00\",\"2018-05-06 04:01:00\",\"2018-05-06 04:02:00\",\"2018-05-06 04:03:00\",\"2018-05-06 04:04:00\",\"2018-05-06 04:05:00\",\"2018-05-06 04:06:00\",\"2018-05-06 04:07:00\",\"2018-05-06 04:08:00\",\"2018-05-06 04:09:00\",\"2018-05-06 04:10:00\",\"2018-05-06 04:11:00\",\"2018-05-06 04:12:00\",\"2018-05-06 04:13:00\",\"2018-05-06 04:14:00\",\"2018-05-06 04:15:00\",\"2018-05-06 04:16:00\",\"2018-05-06 04:17:00\",\"2018-05-06 04:18:00\",\"2018-05-06 04:19:00\",\"2018-05-06 04:20:00\",\"2018-05-06 04:21:00\",\"2018-05-06 04:22:00\",\"2018-05-06 04:23:00\",\"2018-05-06 04:24:00\",\"2018-05-06 04:25:00\",\"2018-05-06 04:26:00\",\"2018-05-06 04:27:00\",\"2018-05-06 04:28:00\",\"2018-05-06 04:29:00\",\"2018-05-06 04:30:00\",\"2018-05-06 04:31:00\",\"2018-05-06 04:32:00\",\"2018-05-06 04:33:00\",\"2018-05-06 04:34:00\",\"2018-05-06 04:35:00\",\"2018-05-06 04:36:00\",\"2018-05-06 04:37:00\",\"2018-05-06 04:38:00\",\"2018-05-06 04:39:00\",\"2018-05-06 04:40:00\",\"2018-05-06 04:41:00\",\"2018-05-06 04:42:00\",\"2018-05-06 04:43:00\",\"2018-05-06 04:44:00\",\"2018-05-06 04:45:00\",\"2018-05-06 04:46:00\",\"2018-05-06 04:47:00\",\"2018-05-06 04:48:00\",\"2018-05-06 04:49:00\",\"2018-05-06 04:50:00\",\"2018-05-06 04:51:00\",\"2018-05-06 04:52:00\",\"2018-05-06 04:53:00\",\"2018-05-06 04:54:00\",\"2018-05-06 04:55:00\",\"2018-05-06 04:56:00\",\"2018-05-06 04:57:00\",\"2018-05-06 04:58:00\",\"2018-05-06 04:59:00\",\"2018-05-06 05:00:00\",\"2018-05-06 05:01:00\",\"2018-05-06 05:02:00\",\"2018-05-06 05:03:00\",\"2018-05-06 05:04:00\",\"2018-05-06 05:05:00\",\"2018-05-06 05:06:00\",\"2018-05-06 05:07:00\",\"2018-05-06 05:08:00\",\"2018-05-06 05:09:00\",\"2018-05-06 05:10:00\",\"2018-05-06 05:11:00\",\"2018-05-06 05:12:00\",\"2018-05-06 05:13:00\",\"2018-05-06 05:14:00\",\"2018-05-06 05:15:00\",\"2018-05-06 05:16:00\",\"2018-05-06 05:17:00\",\"2018-05-06 05:18:00\",\"2018-05-06 05:19:00\",\"2018-05-06 05:20:00\",\"2018-05-06 05:21:00\",\"2018-05-06 05:22:00\",\"2018-05-06 05:23:00\",\"2018-05-06 05:24:00\",\"2018-05-06 05:25:00\",\"2018-05-06 05:26:00\",\"2018-05-06 05:27:00\",\"2018-05-06 05:28:00\",\"2018-05-06 05:29:00\",\"2018-05-06 05:30:00\",\"2018-05-06 05:31:00\",\"2018-05-06 05:32:00\",\"2018-05-06 05:33:00\",\"2018-05-06 05:34:00\",\"2018-05-06 05:35:00\",\"2018-05-06 05:36:00\",\"2018-05-06 05:37:00\",\"2018-05-06 05:38:00\",\"2018-05-06 05:39:00\",\"2018-05-06 05:40:00\",\"2018-05-06 05:41:00\",\"2018-05-06 05:42:00\",\"2018-05-06 05:43:00\",\"2018-05-06 05:44:00\",\"2018-05-06 05:45:00\",\"2018-05-06 05:46:00\",\"2018-05-06 05:47:00\",\"2018-05-06 05:48:00\",\"2018-05-06 05:49:00\",\"2018-05-06 05:50:00\",\"2018-05-06 05:51:00\",\"2018-05-06 05:52:00\",\"2018-05-06 05:53:00\",\"2018-05-06 05:54:00\",\"2018-05-06 05:55:00\",\"2018-05-06 05:56:00\",\"2018-05-06 05:57:00\",\"2018-05-06 05:58:00\",\"2018-05-06 05:59:00\",\"2018-05-06 06:00:00\",\"2018-05-06 06:01:00\",\"2018-05-06 06:02:00\",\"2018-05-06 06:03:00\",\"2018-05-06 06:04:00\",\"2018-05-06 06:05:00\",\"2018-05-06 06:06:00\",\"2018-05-06 06:07:00\",\"2018-05-06 06:08:00\",\"2018-05-06 06:09:00\",\"2018-05-06 06:10:00\",\"2018-05-06 06:11:00\",\"2018-05-06 06:12:00\",\"2018-05-06 06:13:00\",\"2018-05-06 06:14:00\",\"2018-05-06 06:15:00\",\"2018-05-06 06:16:00\",\"2018-05-06 06:17:00\",\"2018-05-06 06:18:00\",\"2018-05-06 06:19:00\",\"2018-05-06 06:20:00\",\"2018-05-06 06:21:00\",\"2018-05-06 06:22:00\",\"2018-05-06 06:23:00\",\"2018-05-06 06:24:00\",\"2018-05-06 06:25:00\",\"2018-05-06 06:26:00\",\"2018-05-06 06:27:00\",\"2018-05-06 06:28:00\",\"2018-05-06 06:29:00\",\"2018-05-06 06:30:00\",\"2018-05-06 06:31:00\",\"2018-05-06 06:32:00\",\"2018-05-06 06:33:00\",\"2018-05-06 06:34:00\",\"2018-05-06 06:35:00\",\"2018-05-06 06:36:00\",\"2018-05-06 06:37:00\",\"2018-05-06 06:38:00\",\"2018-05-06 06:39:00\",\"2018-05-06 06:40:00\",\"2018-05-06 06:41:00\",\"2018-05-06 06:42:00\",\"2018-05-06 06:43:00\",\"2018-05-06 06:44:00\",\"2018-05-06 06:45:00\",\"2018-05-06 06:46:00\",\"2018-05-06 06:47:00\",\"2018-05-06 06:48:00\",\"2018-05-06 06:49:00\",\"2018-05-06 06:50:00\",\"2018-05-06 06:51:00\",\"2018-05-06 06:52:00\",\"2018-05-06 06:53:00\",\"2018-05-06 06:54:00\",\"2018-05-06 06:55:00\",\"2018-05-06 06:56:00\",\"2018-05-06 06:57:00\",\"2018-05-06 06:58:00\",\"2018-05-06 06:59:00\",\"2018-05-06 07:00:00\",\"2018-05-06 07:01:00\",\"2018-05-06 07:02:00\",\"2018-05-06 07:03:00\",\"2018-05-06 07:04:00\",\"2018-05-06 07:05:00\",\"2018-05-06 07:06:00\",\"2018-05-06 07:07:00\",\"2018-05-06 07:08:00\",\"2018-05-06 07:09:00\",\"2018-05-06 07:10:00\",\"2018-05-06 07:11:00\",\"2018-05-06 07:12:00\",\"2018-05-06 07:13:00\",\"2018-05-06 07:14:00\",\"2018-05-06 07:15:00\",\"2018-05-06 07:16:00\",\"2018-05-06 07:17:00\",\"2018-05-06 07:18:00\",\"2018-05-06 07:19:00\",\"2018-05-06 07:20:00\",\"2018-05-06 07:21:00\",\"2018-05-06 07:22:00\",\"2018-05-06 07:23:00\",\"2018-05-06 07:24:00\",\"2018-05-06 07:25:00\",\"2018-05-06 07:26:00\",\"2018-05-06 07:27:00\",\"2018-05-06 07:28:00\",\"2018-05-06 07:29:00\",\"2018-05-06 07:30:00\",\"2018-05-06 07:31:00\",\"2018-05-06 07:32:00\",\"2018-05-06 07:33:00\",\"2018-05-06 07:34:00\",\"2018-05-06 07:35:00\",\"2018-05-06 07:36:00\",\"2018-05-06 07:37:00\",\"2018-05-06 07:38:00\",\"2018-05-06 07:39:00\",\"2018-05-06 07:40:00\",\"2018-05-06 07:41:00\",\"2018-05-06 07:42:00\",\"2018-05-06 07:43:00\",\"2018-05-06 07:44:00\",\"2018-05-06 07:45:00\",\"2018-05-06 07:46:00\",\"2018-05-06 07:47:00\",\"2018-05-06 07:48:00\",\"2018-05-06 07:49:00\",\"2018-05-06 07:50:00\",\"2018-05-06 07:51:00\",\"2018-05-06 07:52:00\",\"2018-05-06 07:53:00\",\"2018-05-06 07:54:00\",\"2018-05-06 07:55:00\",\"2018-05-06 07:56:00\",\"2018-05-06 07:57:00\",\"2018-05-06 07:58:00\",\"2018-05-06 07:59:00\",\"2018-05-06 08:00:00\",\"2018-05-06 08:01:00\",\"2018-05-06 08:02:00\",\"2018-05-06 08:03:00\",\"2018-05-06 08:04:00\",\"2018-05-06 08:05:00\",\"2018-05-06 08:06:00\",\"2018-05-06 08:07:00\",\"2018-05-06 08:08:00\",\"2018-05-06 08:09:00\",\"2018-05-06 08:10:00\",\"2018-05-06 08:11:00\",\"2018-05-06 08:12:00\",\"2018-05-06 08:13:00\",\"2018-05-06 08:14:00\",\"2018-05-06 08:15:00\",\"2018-05-06 08:16:00\",\"2018-05-06 08:17:00\",\"2018-05-06 08:18:00\",\"2018-05-06 08:19:00\",\"2018-05-06 08:20:00\",\"2018-05-06 08:21:00\",\"2018-05-06 08:22:00\",\"2018-05-06 08:23:00\",\"2018-05-06 08:24:00\",\"2018-05-06 08:25:00\",\"2018-05-06 08:26:00\",\"2018-05-06 08:27:00\",\"2018-05-06 08:28:00\",\"2018-05-06 08:29:00\",\"2018-05-06 08:30:00\",\"2018-05-06 08:31:00\",\"2018-05-06 08:32:00\",\"2018-05-06 08:33:00\",\"2018-05-06 08:34:00\",\"2018-05-06 08:35:00\",\"2018-05-06 08:36:00\",\"2018-05-06 08:37:00\",\"2018-05-06 08:38:00\",\"2018-05-06 08:39:00\",\"2018-05-06 08:40:00\",\"2018-05-06 08:41:00\",\"2018-05-06 08:42:00\",\"2018-05-06 08:43:00\",\"2018-05-06 08:44:00\",\"2018-05-06 08:45:00\",\"2018-05-06 08:46:00\",\"2018-05-06 08:47:00\",\"2018-05-06 08:48:00\",\"2018-05-06 08:49:00\",\"2018-05-06 08:50:00\",\"2018-05-06 08:51:00\",\"2018-05-06 08:52:00\",\"2018-05-06 08:53:00\",\"2018-05-06 08:54:00\",\"2018-05-06 08:55:00\",\"2018-05-06 08:56:00\",\"2018-05-06 08:57:00\",\"2018-05-06 08:58:00\",\"2018-05-06 08:59:00\",\"2018-05-06 09:00:00\",\"2018-05-06 09:01:00\",\"2018-05-06 09:02:00\",\"2018-05-06 09:03:00\",\"2018-05-06 09:04:00\",\"2018-05-06 09:05:00\",\"2018-05-06 09:06:00\",\"2018-05-06 09:07:00\",\"2018-05-06 09:08:00\",\"2018-05-06 09:09:00\",\"2018-05-06 09:10:00\",\"2018-05-06 09:11:00\",\"2018-05-06 09:12:00\",\"2018-05-06 09:13:00\",\"2018-05-06 09:14:00\",\"2018-05-06 09:15:00\",\"2018-05-06 09:16:00\",\"2018-05-06 09:17:00\",\"2018-05-06 09:18:00\",\"2018-05-06 09:19:00\",\"2018-05-06 09:20:00\",\"2018-05-06 09:21:00\",\"2018-05-06 09:22:00\",\"2018-05-06 09:23:00\",\"2018-05-06 09:24:00\",\"2018-05-06 09:25:00\",\"2018-05-06 09:26:00\",\"2018-05-06 09:27:00\",\"2018-05-06 09:28:00\",\"2018-05-06 09:29:00\",\"2018-05-06 09:30:00\",\"2018-05-06 09:31:00\",\"2018-05-06 09:32:00\",\"2018-05-06 09:33:00\",\"2018-05-06 09:34:00\",\"2018-05-06 09:35:00\",\"2018-05-06 09:36:00\",\"2018-05-06 09:37:00\",\"2018-05-06 09:38:00\",\"2018-05-06 09:39:00\",\"2018-05-06 09:40:00\",\"2018-05-06 09:41:00\",\"2018-05-06 09:42:00\",\"2018-05-06 09:43:00\",\"2018-05-06 09:44:00\",\"2018-05-06 09:45:00\",\"2018-05-06 09:46:00\",\"2018-05-06 09:47:00\",\"2018-05-06 09:48:00\",\"2018-05-06 09:49:00\",\"2018-05-06 09:50:00\",\"2018-05-06 09:51:00\",\"2018-05-06 09:52:00\",\"2018-05-06 09:53:00\",\"2018-05-06 09:54:00\",\"2018-05-06 09:55:00\",\"2018-05-06 09:56:00\",\"2018-05-06 09:57:00\",\"2018-05-06 09:58:00\",\"2018-05-06 09:59:00\",\"2018-05-06 10:00:00\",\"2018-05-06 10:01:00\",\"2018-05-06 10:02:00\",\"2018-05-06 10:03:00\",\"2018-05-06 10:04:00\",\"2018-05-06 10:05:00\",\"2018-05-06 10:06:00\",\"2018-05-06 10:07:00\",\"2018-05-06 10:08:00\",\"2018-05-06 10:09:00\",\"2018-05-06 10:10:00\",\"2018-05-06 10:11:00\",\"2018-05-06 10:12:00\",\"2018-05-06 10:13:00\",\"2018-05-06 10:14:00\",\"2018-05-06 10:15:00\",\"2018-05-06 10:16:00\",\"2018-05-06 10:17:00\",\"2018-05-06 10:18:00\",\"2018-05-06 10:19:00\",\"2018-05-06 10:20:00\",\"2018-05-06 10:21:00\",\"2018-05-06 10:22:00\",\"2018-05-06 10:23:00\",\"2018-05-06 10:24:00\",\"2018-05-06 10:25:00\",\"2018-05-06 10:26:00\",\"2018-05-06 10:27:00\",\"2018-05-06 10:28:00\",\"2018-05-06 10:29:00\",\"2018-05-06 10:30:00\",\"2018-05-06 10:31:00\",\"2018-05-06 10:32:00\",\"2018-05-06 10:33:00\",\"2018-05-06 10:34:00\",\"2018-05-06 10:35:00\",\"2018-05-06 10:36:00\",\"2018-05-06 10:37:00\",\"2018-05-06 10:38:00\",\"2018-05-06 10:39:00\",\"2018-05-06 10:40:00\",\"2018-05-06 10:41:00\",\"2018-05-06 10:42:00\",\"2018-05-06 10:43:00\",\"2018-05-06 10:44:00\",\"2018-05-06 10:45:00\",\"2018-05-06 10:46:00\",\"2018-05-06 10:47:00\",\"2018-05-06 10:48:00\",\"2018-05-06 10:49:00\",\"2018-05-06 10:50:00\",\"2018-05-06 10:51:00\",\"2018-05-06 10:52:00\",\"2018-05-06 10:53:00\",\"2018-05-06 10:54:00\",\"2018-05-06 10:55:00\",\"2018-05-06 10:56:00\",\"2018-05-06 10:57:00\",\"2018-05-06 10:58:00\",\"2018-05-06 10:59:00\",\"2018-05-06 11:00:00\",\"2018-05-06 11:01:00\",\"2018-05-06 11:02:00\",\"2018-05-06 11:03:00\",\"2018-05-06 11:04:00\",\"2018-05-06 11:05:00\",\"2018-05-06 11:06:00\",\"2018-05-06 11:07:00\",\"2018-05-06 11:08:00\",\"2018-05-06 11:09:00\",\"2018-05-06 11:10:00\",\"2018-05-06 11:11:00\",\"2018-05-06 11:12:00\",\"2018-05-06 11:13:00\",\"2018-05-06 11:14:00\",\"2018-05-06 11:15:00\",\"2018-05-06 11:16:00\",\"2018-05-06 11:17:00\",\"2018-05-06 11:18:00\",\"2018-05-06 11:19:00\",\"2018-05-06 11:20:00\",\"2018-05-06 11:21:00\",\"2018-05-06 11:22:00\",\"2018-05-06 11:23:00\",\"2018-05-06 11:24:00\",\"2018-05-06 11:25:00\",\"2018-05-06 11:26:00\",\"2018-05-06 11:27:00\",\"2018-05-06 11:28:00\",\"2018-05-06 11:29:00\",\"2018-05-06 11:30:00\",\"2018-05-06 11:31:00\",\"2018-05-06 11:32:00\",\"2018-05-06 11:33:00\",\"2018-05-06 11:34:00\",\"2018-05-06 11:35:00\",\"2018-05-06 11:36:00\",\"2018-05-06 11:37:00\",\"2018-05-06 11:38:00\",\"2018-05-06 11:39:00\",\"2018-05-06 11:40:00\",\"2018-05-06 11:41:00\",\"2018-05-06 11:42:00\",\"2018-05-06 11:43:00\",\"2018-05-06 11:44:00\",\"2018-05-06 11:45:00\",\"2018-05-06 11:46:00\",\"2018-05-06 11:47:00\",\"2018-05-06 11:48:00\",\"2018-05-06 11:49:00\",\"2018-05-06 11:50:00\",\"2018-05-06 11:51:00\",\"2018-05-06 11:52:00\",\"2018-05-06 11:53:00\",\"2018-05-06 11:54:00\",\"2018-05-06 11:55:00\",\"2018-05-06 11:56:00\",\"2018-05-06 11:57:00\",\"2018-05-06 11:58:00\",\"2018-05-06 11:59:00\",\"2018-05-06 12:00:00\",\"2018-05-06 12:01:00\",\"2018-05-06 12:02:00\",\"2018-05-06 12:03:00\",\"2018-05-06 12:04:00\",\"2018-05-06 12:05:00\",\"2018-05-06 12:06:00\",\"2018-05-06 12:07:00\",\"2018-05-06 12:08:00\",\"2018-05-06 12:09:00\",\"2018-05-06 12:10:00\",\"2018-05-06 12:11:00\",\"2018-05-06 12:12:00\",\"2018-05-06 12:13:00\",\"2018-05-06 12:14:00\",\"2018-05-06 12:15:00\",\"2018-05-06 12:16:00\",\"2018-05-06 12:17:00\",\"2018-05-06 12:18:00\",\"2018-05-06 12:19:00\",\"2018-05-06 12:20:00\",\"2018-05-06 12:21:00\",\"2018-05-06 12:22:00\",\"2018-05-06 12:23:00\",\"2018-05-06 12:24:00\",\"2018-05-06 12:25:00\",\"2018-05-06 12:26:00\",\"2018-05-06 12:27:00\",\"2018-05-06 12:28:00\",\"2018-05-06 12:29:00\",\"2018-05-06 12:30:00\",\"2018-05-06 12:31:00\",\"2018-05-06 12:32:00\",\"2018-05-06 12:33:00\",\"2018-05-06 12:34:00\",\"2018-05-06 12:35:00\",\"2018-05-06 12:36:00\",\"2018-05-06 12:37:00\",\"2018-05-06 12:38:00\",\"2018-05-06 12:39:00\",\"2018-05-06 12:40:00\",\"2018-05-06 12:41:00\",\"2018-05-06 12:42:00\",\"2018-05-06 12:43:00\",\"2018-05-06 12:44:00\",\"2018-05-06 12:45:00\",\"2018-05-06 12:46:00\",\"2018-05-06 12:47:00\",\"2018-05-06 12:48:00\",\"2018-05-06 12:49:00\",\"2018-05-06 12:50:00\",\"2018-05-06 12:51:00\",\"2018-05-06 12:52:00\",\"2018-05-06 12:53:00\",\"2018-05-06 12:54:00\",\"2018-05-06 12:55:00\",\"2018-05-06 12:56:00\",\"2018-05-06 12:57:00\",\"2018-05-06 12:58:00\",\"2018-05-06 12:59:00\",\"2018-05-06 13:00:00\",\"2018-05-06 13:01:00\",\"2018-05-06 13:02:00\",\"2018-05-06 13:03:00\",\"2018-05-06 13:04:00\",\"2018-05-06 13:05:00\",\"2018-05-06 13:06:00\",\"2018-05-06 13:07:00\",\"2018-05-06 13:08:00\",\"2018-05-06 13:09:00\",\"2018-05-06 13:10:00\",\"2018-05-06 13:11:00\",\"2018-05-06 13:12:00\",\"2018-05-06 13:13:00\",\"2018-05-06 13:14:00\",\"2018-05-06 13:15:00\",\"2018-05-06 13:16:00\",\"2018-05-06 13:17:00\",\"2018-05-06 13:18:00\",\"2018-05-06 13:19:00\",\"2018-05-06 13:20:00\",\"2018-05-06 13:21:00\",\"2018-05-06 13:22:00\",\"2018-05-06 13:23:00\",\"2018-05-06 13:24:00\",\"2018-05-06 13:25:00\",\"2018-05-06 13:26:00\",\"2018-05-06 13:27:00\",\"2018-05-06 13:28:00\",\"2018-05-06 13:29:00\",\"2018-05-06 13:30:00\",\"2018-05-06 13:31:00\",\"2018-05-06 13:32:00\",\"2018-05-06 13:33:00\",\"2018-05-06 13:34:00\",\"2018-05-06 13:35:00\",\"2018-05-06 13:36:00\",\"2018-05-06 13:37:00\",\"2018-05-06 13:38:00\",\"2018-05-06 13:39:00\",\"2018-05-06 13:40:00\",\"2018-05-06 13:41:00\",\"2018-05-06 13:42:00\",\"2018-05-06 13:43:00\",\"2018-05-06 13:44:00\",\"2018-05-06 13:45:00\",\"2018-05-06 13:46:00\",\"2018-05-06 13:47:00\",\"2018-05-06 13:48:00\",\"2018-05-06 13:49:00\",\"2018-05-06 13:50:00\",\"2018-05-06 13:51:00\",\"2018-05-06 13:52:00\",\"2018-05-06 13:53:00\",\"2018-05-06 13:54:00\",\"2018-05-06 13:55:00\",\"2018-05-06 13:56:00\",\"2018-05-06 13:57:00\",\"2018-05-06 13:58:00\",\"2018-05-06 13:59:00\",\"2018-05-06 14:00:00\",\"2018-05-06 14:01:00\",\"2018-05-06 14:02:00\",\"2018-05-06 14:03:00\",\"2018-05-06 14:04:00\",\"2018-05-06 14:05:00\",\"2018-05-06 14:06:00\",\"2018-05-06 14:07:00\",\"2018-05-06 14:08:00\",\"2018-05-06 14:09:00\",\"2018-05-06 14:10:00\",\"2018-05-06 14:11:00\",\"2018-05-06 14:12:00\",\"2018-05-06 14:13:00\",\"2018-05-06 14:14:00\",\"2018-05-06 14:15:00\",\"2018-05-06 14:16:00\",\"2018-05-06 14:17:00\",\"2018-05-06 14:18:00\",\"2018-05-06 14:19:00\",\"2018-05-06 14:20:00\",\"2018-05-06 14:21:00\",\"2018-05-06 14:22:00\",\"2018-05-06 14:23:00\",\"2018-05-06 14:24:00\",\"2018-05-06 14:25:00\",\"2018-05-06 14:26:00\",\"2018-05-06 14:27:00\",\"2018-05-06 14:28:00\",\"2018-05-06 14:29:00\",\"2018-05-06 14:30:00\",\"2018-05-06 14:31:00\",\"2018-05-06 14:32:00\",\"2018-05-06 14:33:00\",\"2018-05-06 14:34:00\",\"2018-05-06 14:35:00\",\"2018-05-06 14:36:00\",\"2018-05-06 14:37:00\",\"2018-05-06 14:38:00\",\"2018-05-06 14:39:00\",\"2018-05-06 14:40:00\",\"2018-05-06 14:41:00\",\"2018-05-06 14:42:00\",\"2018-05-06 14:43:00\",\"2018-05-06 14:44:00\",\"2018-05-06 14:45:00\",\"2018-05-06 14:46:00\",\"2018-05-06 14:47:00\",\"2018-05-06 14:48:00\",\"2018-05-06 14:49:00\",\"2018-05-06 14:50:00\",\"2018-05-06 14:51:00\",\"2018-05-06 14:52:00\",\"2018-05-06 14:53:00\",\"2018-05-06 14:54:00\",\"2018-05-06 14:55:00\",\"2018-05-06 14:56:00\",\"2018-05-06 14:57:00\",\"2018-05-06 14:58:00\",\"2018-05-06 14:59:00\",\"2018-05-06 15:00:00\",\"2018-05-06 15:01:00\",\"2018-05-06 15:02:00\",\"2018-05-06 15:03:00\",\"2018-05-06 15:04:00\",\"2018-05-06 15:05:00\",\"2018-05-06 15:06:00\",\"2018-05-06 15:07:00\",\"2018-05-06 15:08:00\",\"2018-05-06 15:09:00\",\"2018-05-06 15:10:00\",\"2018-05-06 15:11:00\",\"2018-05-06 15:12:00\",\"2018-05-06 15:13:00\",\"2018-05-06 15:14:00\",\"2018-05-06 15:15:00\",\"2018-05-06 15:16:00\",\"2018-05-06 15:17:00\",\"2018-05-06 15:18:00\",\"2018-05-06 15:19:00\",\"2018-05-06 15:20:00\",\"2018-05-06 15:21:00\",\"2018-05-06 15:22:00\",\"2018-05-06 15:23:00\",\"2018-05-06 15:24:00\",\"2018-05-06 15:25:00\",\"2018-05-06 15:26:00\",\"2018-05-06 15:27:00\",\"2018-05-06 15:28:00\",\"2018-05-06 15:29:00\",\"2018-05-06 15:30:00\",\"2018-05-06 15:31:00\",\"2018-05-06 15:32:00\",\"2018-05-06 15:33:00\",\"2018-05-06 15:34:00\",\"2018-05-06 15:35:00\",\"2018-05-06 15:36:00\",\"2018-05-06 15:37:00\",\"2018-05-06 15:38:00\",\"2018-05-06 15:39:00\",\"2018-05-06 15:40:00\",\"2018-05-06 15:41:00\",\"2018-05-06 15:42:00\",\"2018-05-06 15:43:00\",\"2018-05-06 15:44:00\",\"2018-05-06 15:45:00\",\"2018-05-06 15:46:00\",\"2018-05-06 15:47:00\",\"2018-05-06 15:48:00\",\"2018-05-06 15:49:00\",\"2018-05-06 15:50:00\",\"2018-05-06 15:51:00\",\"2018-05-06 15:52:00\",\"2018-05-06 15:53:00\",\"2018-05-06 15:54:00\",\"2018-05-06 15:55:00\",\"2018-05-06 15:56:00\",\"2018-05-06 15:57:00\",\"2018-05-06 15:58:00\",\"2018-05-06 15:59:00\",\"2018-05-06 16:00:00\",\"2018-05-06 16:01:00\",\"2018-05-06 16:02:00\",\"2018-05-06 16:03:00\",\"2018-05-06 16:04:00\",\"2018-05-06 16:05:00\",\"2018-05-06 16:06:00\",\"2018-05-06 16:07:00\",\"2018-05-06 16:08:00\",\"2018-05-06 16:09:00\",\"2018-05-06 16:10:00\",\"2018-05-06 16:11:00\",\"2018-05-06 16:12:00\",\"2018-05-06 16:13:00\",\"2018-05-06 16:14:00\",\"2018-05-06 16:15:00\",\"2018-05-06 16:16:00\",\"2018-05-06 16:17:00\",\"2018-05-06 16:18:00\",\"2018-05-06 16:19:00\",\"2018-05-06 16:20:00\",\"2018-05-06 16:21:00\",\"2018-05-06 16:22:00\",\"2018-05-06 16:23:00\",\"2018-05-06 16:24:00\",\"2018-05-06 16:25:00\",\"2018-05-06 16:26:00\",\"2018-05-06 16:27:00\",\"2018-05-06 16:28:00\",\"2018-05-06 16:29:00\",\"2018-05-06 16:30:00\",\"2018-05-06 16:31:00\",\"2018-05-06 16:32:00\",\"2018-05-06 16:33:00\",\"2018-05-06 16:34:00\",\"2018-05-06 16:35:00\",\"2018-05-06 16:36:00\",\"2018-05-06 16:37:00\",\"2018-05-06 16:38:00\",\"2018-05-06 16:39:00\",\"2018-05-06 16:40:00\",\"2018-05-06 16:41:00\",\"2018-05-06 16:42:00\",\"2018-05-06 16:43:00\",\"2018-05-06 16:44:00\",\"2018-05-06 16:45:00\",\"2018-05-06 16:46:00\",\"2018-05-06 16:47:00\",\"2018-05-06 16:48:00\",\"2018-05-06 16:49:00\",\"2018-05-06 16:50:00\",\"2018-05-06 16:51:00\",\"2018-05-06 16:52:00\",\"2018-05-06 16:53:00\",\"2018-05-06 16:54:00\",\"2018-05-06 16:55:00\",\"2018-05-06 16:56:00\",\"2018-05-06 16:57:00\",\"2018-05-06 16:58:00\",\"2018-05-06 16:59:00\",\"2018-05-06 17:00:00\",\"2018-05-06 17:01:00\",\"2018-05-06 17:02:00\",\"2018-05-06 17:03:00\",\"2018-05-06 17:04:00\",\"2018-05-06 17:05:00\",\"2018-05-06 17:06:00\",\"2018-05-06 17:07:00\",\"2018-05-06 17:08:00\",\"2018-05-06 17:09:00\",\"2018-05-06 17:10:00\",\"2018-05-06 17:11:00\",\"2018-05-06 17:12:00\",\"2018-05-06 17:13:00\",\"2018-05-06 17:14:00\",\"2018-05-06 17:15:00\",\"2018-05-06 17:16:00\",\"2018-05-06 17:17:00\",\"2018-05-06 17:18:00\",\"2018-05-06 17:19:00\",\"2018-05-06 17:20:00\",\"2018-05-06 17:21:00\",\"2018-05-06 17:22:00\",\"2018-05-06 17:23:00\",\"2018-05-06 17:24:00\",\"2018-05-06 17:25:00\",\"2018-05-06 17:26:00\",\"2018-05-06 17:27:00\",\"2018-05-06 17:28:00\",\"2018-05-06 17:29:00\",\"2018-05-06 17:30:00\",\"2018-05-06 17:31:00\",\"2018-05-06 17:32:00\",\"2018-05-06 17:33:00\",\"2018-05-06 17:34:00\",\"2018-05-06 17:35:00\",\"2018-05-06 17:36:00\",\"2018-05-06 17:37:00\",\"2018-05-06 17:38:00\",\"2018-05-06 17:39:00\",\"2018-05-06 17:40:00\",\"2018-05-06 17:41:00\",\"2018-05-06 17:42:00\",\"2018-05-06 17:43:00\",\"2018-05-06 17:44:00\",\"2018-05-06 17:45:00\",\"2018-05-06 17:46:00\",\"2018-05-06 17:47:00\",\"2018-05-06 17:48:00\",\"2018-05-06 17:49:00\",\"2018-05-06 17:50:00\",\"2018-05-06 17:51:00\",\"2018-05-06 17:52:00\",\"2018-05-06 17:53:00\",\"2018-05-06 17:54:00\",\"2018-05-06 17:55:00\",\"2018-05-06 17:56:00\",\"2018-05-06 17:57:00\",\"2018-05-06 17:58:00\",\"2018-05-06 17:59:00\",\"2018-05-06 18:00:00\",\"2018-05-06 18:01:00\",\"2018-05-06 18:02:00\",\"2018-05-06 18:03:00\",\"2018-05-06 18:04:00\",\"2018-05-06 18:05:00\",\"2018-05-06 18:06:00\",\"2018-05-06 18:07:00\",\"2018-05-06 18:08:00\",\"2018-05-06 18:09:00\",\"2018-05-06 18:10:00\",\"2018-05-06 18:11:00\",\"2018-05-06 18:12:00\",\"2018-05-06 18:13:00\",\"2018-05-06 18:14:00\",\"2018-05-06 18:15:00\",\"2018-05-06 18:16:00\",\"2018-05-06 18:17:00\",\"2018-05-06 18:18:00\",\"2018-05-06 18:19:00\",\"2018-05-06 18:20:00\",\"2018-05-06 18:21:00\",\"2018-05-06 18:22:00\",\"2018-05-06 18:23:00\",\"2018-05-06 18:24:00\",\"2018-05-06 18:25:00\",\"2018-05-06 18:26:00\",\"2018-05-06 18:27:00\",\"2018-05-06 18:28:00\",\"2018-05-06 18:29:00\",\"2018-05-06 18:30:00\",\"2018-05-06 18:31:00\",\"2018-05-06 18:32:00\",\"2018-05-06 18:33:00\",\"2018-05-06 18:34:00\",\"2018-05-06 18:35:00\",\"2018-05-06 18:36:00\",\"2018-05-06 18:37:00\",\"2018-05-06 18:38:00\",\"2018-05-06 18:39:00\",\"2018-05-06 18:40:00\",\"2018-05-06 18:41:00\",\"2018-05-06 18:42:00\",\"2018-05-06 18:43:00\",\"2018-05-06 18:44:00\",\"2018-05-06 18:45:00\",\"2018-05-06 18:46:00\",\"2018-05-06 18:47:00\",\"2018-05-06 18:48:00\",\"2018-05-06 18:49:00\",\"2018-05-06 18:50:00\",\"2018-05-06 18:51:00\",\"2018-05-06 18:52:00\",\"2018-05-06 18:53:00\",\"2018-05-06 18:54:00\",\"2018-05-06 18:55:00\",\"2018-05-06 18:56:00\",\"2018-05-06 18:57:00\",\"2018-05-06 18:58:00\",\"2018-05-06 18:59:00\",\"2018-05-06 19:00:00\",\"2018-05-06 19:01:00\",\"2018-05-06 19:02:00\",\"2018-05-06 19:03:00\",\"2018-05-06 19:04:00\",\"2018-05-06 19:05:00\",\"2018-05-06 19:06:00\",\"2018-05-06 19:07:00\",\"2018-05-06 19:08:00\",\"2018-05-06 19:09:00\",\"2018-05-06 19:10:00\",\"2018-05-06 19:11:00\",\"2018-05-06 19:12:00\",\"2018-05-06 19:13:00\",\"2018-05-06 19:14:00\",\"2018-05-06 19:15:00\",\"2018-05-06 19:16:00\",\"2018-05-06 19:17:00\",\"2018-05-06 19:18:00\",\"2018-05-06 19:19:00\",\"2018-05-06 19:20:00\",\"2018-05-06 19:21:00\",\"2018-05-06 19:22:00\",\"2018-05-06 19:23:00\",\"2018-05-06 19:24:00\",\"2018-05-06 19:25:00\",\"2018-05-06 19:26:00\",\"2018-05-06 19:27:00\",\"2018-05-06 19:28:00\",\"2018-05-06 19:29:00\",\"2018-05-06 19:30:00\",\"2018-05-06 19:31:00\",\"2018-05-06 19:32:00\",\"2018-05-06 19:33:00\",\"2018-05-06 19:34:00\",\"2018-05-06 19:35:00\",\"2018-05-06 19:36:00\",\"2018-05-06 19:37:00\",\"2018-05-06 19:38:00\",\"2018-05-06 19:39:00\",\"2018-05-06 19:40:00\",\"2018-05-06 19:41:00\",\"2018-05-06 19:42:00\",\"2018-05-06 19:43:00\",\"2018-05-06 19:44:00\",\"2018-05-06 19:45:00\",\"2018-05-06 19:46:00\",\"2018-05-06 19:47:00\",\"2018-05-06 19:48:00\",\"2018-05-06 19:49:00\",\"2018-05-06 19:50:00\",\"2018-05-06 19:51:00\",\"2018-05-06 19:52:00\",\"2018-05-06 19:53:00\",\"2018-05-06 19:54:00\",\"2018-05-06 19:55:00\",\"2018-05-06 19:56:00\",\"2018-05-06 19:57:00\",\"2018-05-06 19:58:00\",\"2018-05-06 19:59:00\",\"2018-05-06 20:00:00\",\"2018-05-06 20:01:00\",\"2018-05-06 20:02:00\",\"2018-05-06 20:03:00\",\"2018-05-06 20:04:00\",\"2018-05-06 20:05:00\",\"2018-05-06 20:06:00\",\"2018-05-06 20:07:00\",\"2018-05-06 20:08:00\",\"2018-05-06 20:09:00\",\"2018-05-06 20:10:00\",\"2018-05-06 20:11:00\",\"2018-05-06 20:12:00\",\"2018-05-06 20:13:00\",\"2018-05-06 20:14:00\",\"2018-05-06 20:15:00\",\"2018-05-06 20:16:00\",\"2018-05-06 20:17:00\",\"2018-05-06 20:18:00\",\"2018-05-06 20:19:00\",\"2018-05-06 20:20:00\",\"2018-05-06 20:21:00\",\"2018-05-06 20:22:00\",\"2018-05-06 20:23:00\",\"2018-05-06 20:24:00\",\"2018-05-06 20:25:00\",\"2018-05-06 20:26:00\",\"2018-05-06 20:27:00\",\"2018-05-06 20:28:00\",\"2018-05-06 20:29:00\",\"2018-05-06 20:30:00\",\"2018-05-06 20:31:00\",\"2018-05-06 20:32:00\",\"2018-05-06 20:33:00\",\"2018-05-06 20:34:00\",\"2018-05-06 20:35:00\",\"2018-05-06 20:36:00\",\"2018-05-06 20:37:00\",\"2018-05-06 20:38:00\",\"2018-05-06 20:39:00\",\"2018-05-06 20:40:00\",\"2018-05-06 20:41:00\",\"2018-05-06 20:42:00\",\"2018-05-06 20:43:00\",\"2018-05-06 20:44:00\",\"2018-05-06 20:45:00\",\"2018-05-06 20:46:00\",\"2018-05-06 20:47:00\",\"2018-05-06 20:48:00\",\"2018-05-06 20:49:00\",\"2018-05-06 20:50:00\",\"2018-05-06 20:51:00\",\"2018-05-06 20:52:00\",\"2018-05-06 20:53:00\",\"2018-05-06 20:54:00\",\"2018-05-06 20:55:00\",\"2018-05-06 20:56:00\",\"2018-05-06 20:57:00\",\"2018-05-06 20:58:00\",\"2018-05-06 20:59:00\",\"2018-05-06 21:00:00\",\"2018-05-06 21:01:00\",\"2018-05-06 21:02:00\",\"2018-05-06 21:03:00\",\"2018-05-06 21:04:00\",\"2018-05-06 21:05:00\",\"2018-05-06 21:06:00\",\"2018-05-06 21:07:00\",\"2018-05-06 21:08:00\",\"2018-05-06 21:09:00\",\"2018-05-06 21:10:00\",\"2018-05-06 21:11:00\",\"2018-05-06 21:12:00\",\"2018-05-06 21:13:00\",\"2018-05-06 21:14:00\",\"2018-05-06 21:15:00\",\"2018-05-06 21:16:00\",\"2018-05-06 21:17:00\",\"2018-05-06 21:18:00\",\"2018-05-06 21:19:00\",\"2018-05-06 21:20:00\",\"2018-05-06 21:21:00\",\"2018-05-06 21:22:00\",\"2018-05-06 21:23:00\",\"2018-05-06 21:24:00\",\"2018-05-06 21:25:00\",\"2018-05-06 21:26:00\",\"2018-05-06 21:27:00\",\"2018-05-06 21:28:00\",\"2018-05-06 21:29:00\",\"2018-05-06 21:30:00\",\"2018-05-06 21:31:00\",\"2018-05-06 21:32:00\",\"2018-05-06 21:33:00\",\"2018-05-06 21:34:00\",\"2018-05-06 21:35:00\",\"2018-05-06 21:36:00\",\"2018-05-06 21:37:00\",\"2018-05-06 21:38:00\",\"2018-05-06 21:39:00\",\"2018-05-06 21:40:00\",\"2018-05-06 21:41:00\",\"2018-05-06 21:42:00\",\"2018-05-06 21:43:00\",\"2018-05-06 21:44:00\",\"2018-05-06 21:45:00\",\"2018-05-06 21:46:00\",\"2018-05-06 21:47:00\",\"2018-05-06 21:48:00\",\"2018-05-06 21:49:00\",\"2018-05-06 21:50:00\",\"2018-05-06 21:51:00\",\"2018-05-06 21:52:00\",\"2018-05-06 21:53:00\",\"2018-05-06 21:54:00\",\"2018-05-06 21:55:00\",\"2018-05-06 21:56:00\",\"2018-05-06 21:57:00\",\"2018-05-06 21:58:00\",\"2018-05-06 21:59:00\",\"2018-05-06 22:00:00\",\"2018-05-06 22:01:00\",\"2018-05-06 22:02:00\",\"2018-05-06 22:03:00\",\"2018-05-06 22:04:00\",\"2018-05-06 22:05:00\",\"2018-05-06 22:06:00\",\"2018-05-06 22:07:00\",\"2018-05-06 22:08:00\",\"2018-05-06 22:09:00\",\"2018-05-06 22:10:00\",\"2018-05-06 22:11:00\",\"2018-05-06 22:12:00\",\"2018-05-06 22:13:00\",\"2018-05-06 22:14:00\",\"2018-05-06 22:15:00\",\"2018-05-06 22:16:00\",\"2018-05-06 22:17:00\",\"2018-05-06 22:18:00\",\"2018-05-06 22:19:00\",\"2018-05-06 22:20:00\",\"2018-05-06 22:21:00\",\"2018-05-06 22:22:00\",\"2018-05-06 22:23:00\",\"2018-05-06 22:24:00\",\"2018-05-06 22:25:00\",\"2018-05-06 22:26:00\",\"2018-05-06 22:27:00\",\"2018-05-06 22:28:00\",\"2018-05-06 22:29:00\",\"2018-05-06 22:30:00\",\"2018-05-06 22:31:00\",\"2018-05-06 22:32:00\",\"2018-05-06 22:33:00\",\"2018-05-06 22:34:00\",\"2018-05-06 22:35:00\",\"2018-05-06 22:36:00\",\"2018-05-06 22:37:00\",\"2018-05-06 22:38:00\",\"2018-05-06 22:39:00\",\"2018-05-06 22:40:00\",\"2018-05-06 22:41:00\",\"2018-05-06 22:42:00\",\"2018-05-06 22:43:00\",\"2018-05-06 22:44:00\",\"2018-05-06 22:45:00\",\"2018-05-06 22:46:00\",\"2018-05-06 22:47:00\",\"2018-05-06 22:48:00\",\"2018-05-06 22:49:00\",\"2018-05-06 22:50:00\",\"2018-05-06 22:51:00\",\"2018-05-06 22:52:00\",\"2018-05-06 22:53:00\",\"2018-05-06 22:54:00\",\"2018-05-06 22:55:00\",\"2018-05-06 22:56:00\",\"2018-05-06 22:57:00\",\"2018-05-06 22:58:00\",\"2018-05-06 22:59:00\",\"2018-05-06 23:00:00\",\"2018-05-06 23:01:00\",\"2018-05-06 23:02:00\",\"2018-05-06 23:03:00\",\"2018-05-06 23:04:00\",\"2018-05-06 23:05:00\",\"2018-05-06 23:06:00\",\"2018-05-06 23:07:00\",\"2018-05-06 23:08:00\",\"2018-05-06 23:09:00\",\"2018-05-06 23:10:00\",\"2018-05-06 23:11:00\",\"2018-05-06 23:12:00\",\"2018-05-06 23:13:00\",\"2018-05-06 23:14:00\",\"2018-05-06 23:15:00\",\"2018-05-06 23:16:00\",\"2018-05-06 23:17:00\",\"2018-05-06 23:18:00\",\"2018-05-06 23:19:00\",\"2018-05-06 23:20:00\",\"2018-05-06 23:21:00\",\"2018-05-06 23:22:00\",\"2018-05-06 23:23:00\",\"2018-05-06 23:24:00\",\"2018-05-06 23:25:00\",\"2018-05-06 23:26:00\",\"2018-05-06 23:27:00\",\"2018-05-06 23:28:00\",\"2018-05-06 23:29:00\",\"2018-05-06 23:30:00\",\"2018-05-06 23:31:00\",\"2018-05-06 23:32:00\",\"2018-05-06 23:33:00\",\"2018-05-06 23:34:00\",\"2018-05-06 23:35:00\",\"2018-05-06 23:36:00\",\"2018-05-06 23:37:00\",\"2018-05-06 23:38:00\",\"2018-05-06 23:39:00\",\"2018-05-06 23:40:00\",\"2018-05-06 23:41:00\",\"2018-05-06 23:42:00\",\"2018-05-06 23:43:00\",\"2018-05-06 23:44:00\",\"2018-05-06 23:45:00\",\"2018-05-06 23:46:00\",\"2018-05-06 23:47:00\",\"2018-05-06 23:48:00\",\"2018-05-06 23:49:00\",\"2018-05-06 23:50:00\",\"2018-05-06 23:51:00\",\"2018-05-06 23:52:00\",\"2018-05-06 23:53:00\",\"2018-05-06 23:54:00\",\"2018-05-06 23:55:00\",\"2018-05-06 23:56:00\",\"2018-05-06 23:57:00\",\"2018-05-06 23:58:00\",\"2018-05-06 23:59:00\"],\"xaxis\":\"x\",\"y\":[0.5450352589215754,0.55224731106204,0.5699658095305931,0.5841940309138821,0.5841940309138821,0.5699658095305931,0.5510542061400369,0.5539212194600749,0.5521582733812948,0.5521404658451451,0.5699123869221441,0.5519089678752056,0.5432366977704959,0.5517665075860114,0.5307714224659871,0.5308070375382865,0.5441626896502603,0.539532730251442,0.5414559441555661,0.5503597122302153,0.566689222879122,0.5717287556093733,0.578157276159271,0.5771956692072073,0.5781750836954207,0.5782106987677168,0.5781928912315671,0.59238549754256,0.5874528100292036,0.5831790013533726,0.5848351022152578,0.5930977989885313,0.5948785526034611,0.5930977989885313,0.5948607450673113,0.5941662511574899,0.610780682384785,0.5932224517415758,0.5932046442054262,0.6037645131419607,0.5859747845288119,0.5817722059975765,0.5809530593347103,0.5699658095305931,0.5806503312201721,0.5703753828620262,0.5646057411496539,0.559388133057909,0.5525144241042788,0.5614538072512274,0.5557019730750048,0.5578566849490683,0.5539390269962245,0.5521404658451451,0.5521582733812948,0.5502528670133204,0.5521226583089954,0.5466913597834607,0.5467982050003556,0.5449996438492761,0.5511966664292312,0.5826269677327452,0.6055452667568904,0.5966058836099419,0.5854583659804807,0.5948785526034611,0.5895184842225218,0.5877555381437418,0.5842118384500318,0.5842118384500318,0.5788517700690926,0.5859569769926622,0.5629140252154693,0.5775696274663442,0.5663864947645838,0.5663864947645838,0.5521404658451451,0.5563430443763806,0.5521404658451451,0.5610264263836446,0.5522829261343394,0.5523719638150846,0.5560937388702882,0.5588539069734313,0.5609730037751954,0.5574827266899346,0.5609908113113452,0.5609908113113452,0.5539212194600749,0.5609908113113452,0.5610442339197943,0.5681672483795136,0.5724944796637936,0.5770710164541628,0.5735273167604528,0.5700192321390422,0.5610442339197943,0.561062041455944,0.5521404658451451,0.546833820072655,0.5521226583089954,0.5467803974642059,0.5403518769143081,0.5432010826981966,0.5521404658451451,0.5521226583089954,0.5516418548329636,0.550377519766365,0.5451777192107696,0.5379478595341555,0.5376095163473179,0.5094201866229788,0.5111653251656092,0.48552247311062025,0.48552247311062025,0.4755858679393119,0.445295248949355,0.46523968943657046,0.4631027850986534,0.4684984685518919,0.47022579955837274,0.45802763729610274,0.443781608376664,0.42568915164897714,0.39311916803191216,0.3794073651969512,0.3864591495120718,0.4365517487000498,0.4274877128000567,0.4335600826269672,0.4061720920293478,0.4008654462568544,0.3899494265973359,0.40075860103995953,0.3900918868865302,0.3753294394187603,0.3553849989315481,0.34265261058480045,0.3242574257425754,0.3295640715150655,0.32954626397891584,0.32064249590426663,0.32160410285633034,0.3722843507372319,0.37584585796709147,0.3731213049362477,0.41564570126077394,0.3775375739012762,0.35271386850915337,0.34735380012821415,0.37406510435216167,0.3889343970368264,0.3776266115820214,0.39187264050146,0.39215756107984856,0.37406510435216167,0.3718035472612,0.38118811881188097,0.38118811881188097,0.3651435287413628,0.3509331148942235,0.34735380012821415,0.3366514709024855,0.30240757888738556,0.3028349597549683,0.3371144668423676,0.3259669492129065,0.30301303511646194,0.34557304651328435,0.34915236127929367,0.356275375739013,0.35625756820286336,0.327765510363986,0.32064249590426663,0.3208918014103558,0.30817722059975783,0.30853337132274505,0.31017166464848067,0.2921504380653893,0.2870752902628386,0.2695170596196327,0.2635871500819132,0.2494123513070733,0.2494123513070733,0.17841370467981937,0.15147090248593242,0.1936569556236211,0.22626255431298545,0.23114181921789279,0.21395754683382054,0.20389628890946762,0.2031127573188976,0.18023007336704858,0.17622337773345645,0.17579599686587366,0.0979414488211425,0.03370966593062391,0.1018412992378365,0.1087328157276164,0.07196025357931596,0.0836063822209554,0.1083944725407788,0.15316261842011702,0.14826554597906,0.14434788802621307,0.10310563430443836,0.1127751264335079,0.07523684023078711,0.04459007051784297,0.033246669990741745,0.020781394686232912,-0.012269392406867141,-0.01770069093240184,-0.012411852696061376,0.048489920934540215,0.035721917515493196,0.07689294109267239,0.05352945366479153,0.06953842866301035,0.09272384072939757,0.1247774057981346,0.12112686088752647,0.09865375026711379,0.09799487142958832,0.1247595982619849,0.15677754825842255,0.16213761663936171,0.1858750623263763,0.20487570339767774,0.19064748201438875,0.1782000142460296,0.15608305434860092,0.17462069948002024,0.18662297884464696,0.1817437139397396,0.1679250658878837,0.1693140537075301,0.17303582876273374,0.16927843863523073,0.17040031341263512,0.1693140537075301,0.12655815941306442,0.1301374741790738,0.14078638079635342,0.12582805043094344,0.1250623263765231,0.12467056058123971,0.12474179072583522,0.132309993589287,0.1483367761236555,0.13813305791010833,0.14780255003917786,0.14612864164114292,0.14969014887100257,0.15147090248593242,0.13606738371679,0.12395825913526518,0.1291936747631598,0.14769570482227973,0.15154213263053115,0.16393617779044123,0.1852517985611502,0.1852517985611502,0.19598974285917825,0.20489351093382743,0.20133200370396775,0.2188546192748776,0.21379727900847662,0.21929980767861004,0.23593204644205495,0.22474891374029443,0.2146876558159415,0.17818220670987991,0.17996296032480974,0.1693140537075301,0.16927843863523073,0.17230571978061276,0.16215542417551143,0.1853586437780483,0.19342545765367838,0.19342545765367838,0.19330080490063384,0.1870859747845291,0.1835422750908191,0.1782000142460296,0.16977704964741225,0.15220101146805337,0.16927843863523073,0.18530522116959924,0.18530522116959924,0.1852517985611502,0.19778830401025776,0.21379727900847662,0.22626255431298545,0.2245708383788008,0.23338556877270478,0.22049291260061316,0.21922857753401132,0.22804330792791527,0.23872782961749428,0.2068345323741012,0.2100576964171233,0.21379727900847662,0.22786523256642163,0.2305185554526667,0.2351663223876346,0.21557803262340644,0.20489351093382743,0.2084550181636871,0.18833250231498128,0.1883146947788316,0.17463850701616995,0.15147090248593242,0.15147090248593242,0.15147090248593242,0.1477491274307288,0.1426027494835826,0.13788375240401918,0.12470617565353584,0.1354441199515639,0.1105491844148456,0.13426882256571046,0.11954199017023995,0.11801054206139927,0.08601039960111131,0.04133129140252151,0.0677576750480805,0.07557518341762146,0.0891445259633882,0.07133698981408987,0.07488068950779986,0.07133698981408987,0.08382007265474839,0.0823064320820574,0.08734596481230869,0.08907329581878945,0.09147731319894539,0.1026960609730053,0.11704893510933884,0.10652468124510378,0.0945045943443274,0.09452240188047709,0.06360851912529414,0.06369755680603933,0.049967946434931854,-0.01770069093240184,-0.01770069093240184,-0.0256250445188409,-0.007906546050287733,-0.025642852054987342,-0.03908754184770952,-0.039069734311559856,-0.035508227081700205,0.012536505449105978,-0.01770069093240184,-0.02959612508013365,-0.01232281501531296,0.0035258921575619107,0.030433079279152758,0.04464349312629204,0.032391908255572976,-0.003436854476813467,0.01787876629389548,-0.00689151648977826,-0.00689151648977826,0.011628321105491363,0.035721917515493196,0.03748486359427333,0.023185412066385608,0.035721917515493196,0.044091459505664704,-0.008796922857752687,0.003490277085262533,0.03041527174300307,-0.003490277085262561,0.02484151292827086,0.04740366122943199,0.0656563857824628,0.05340480091174696,0.05174870004986171,0.08962532943942003,0.09053351378303465,0.08382007265474839,0.07199586865161534,0.05969086117244721,0.06407151506517628,0.06408932260132597,0.06457012607735779,0.062433221739440686,0.056200584087186284,0.05174870004986171,0.02859890305577384,0.035721917515493196,0.0410641783602827,0.05415271743001762,0.05417052496616731,0.05352945366479153,0.016151435287414695,-0.004523114181921695,-0.026159270603318574,-0.02478809031982182,-0.026568843934751618,-0.0319467198518405,-0.04437638008404998,-0.005235415627892981,-0.005235415627892981,-0.016952774414131178,-0.021066315264618163,0.011414630671701592,8.903768074680629e-05,0.009010613291545677,0.0027067454946925196,0.030433079279152758,0.03046869435144889,-0.0012999501388996082,0.00560937388702995,0.020710164541634157,0.04462568559014235,0.035935607949286186,0.026818149440844014,0.0464064392050722,0.05019944440487131,0.05379656670703034,0.0722095590854051,0.10695206211268654,0.10695206211268654,0.1087328157276164,0.08918014103568758,0.10340836241897658,0.09094308711446772,0.08905548828264301,0.09304437638008545,0.10623976066671525,0.10506446328086183,0.08205712657596825,0.08560082626967824,0.0891445259633882,0.09665930621839094,0.08736377234845838,0.08729254220385962,0.06230856898639614,0.05709096089465118,0.05881829190113197,0.07489849704394955,0.0639468623121317,0.0790654605028856,0.0963209630315566,0.0891445259633882,0.0838022651185987,0.08385568772704777,0.08148728541919123,0.08900206567419394,0.0891445259633882,0.10695206211268654,0.1247595982619849,0.12119809103212523,0.1158914452596351,0.10517130849775672,0.09806610157418708,0.0980304865018877,0.11587363772348541,0.13004843649832531,0.13620984400598424,0.1354441199515639,0.13549754256001295,0.1140750765724059,0.10082626967732702,0.0891445259633882,0.07135479735023956,0.062433221739440686,0.04462568559014235,0.05479378873139015,0.04793788731391288,0.04818719282000203,0.044518840373247465,0.02792221668210193,0.014103568630246033,0.012572120521405356,0.026818149440844014,0.035721917515493196,0.020585511788589583,-0.0014958330365397177,-0.021974499608232778,-0.039764228221381426,-0.03549041954555049,-0.035526034617849866,-0.029204359284846992,-0.05329795569484885,-0.05945936320250772,-0.07112329938029688,-0.07824631384001618,-0.02647980625400642,-0.006588788375240073,-0.021262198162261492,-0.01773630600470122,-0.023042951777191345,-0.020727972077783874,-0.01752261557090823,-0.008796922857752687,0.009010613291545677,0.02063893439703865,0.04268466414986857,0.021066315264621438,0.01793218890234452,-0.008796922857752687,-0.008743500249303593,-0.008743500249303593,-0.015919937317471988,-0.017682883396252125,-0.030593347104493462,-0.02587435002493005,0.0034190469406670254,-0.004487499109622317,-0.006838093881329221,0.0032053565068740353,-0.0016739083980333302,0.01791438136619483,0.026835956976993702,0.035721917515493196,0.035721917515493196,0.03570410997934351,0.0003383431868359543,0.0010150295605111104,-0.006125792435357935,-0.008796922857752687,-0.01770069093240184,-0.028153714652041417,-0.014299451527886142,-0.012857041099793853,-0.035508227081700205,-0.09251015029560455,-0.08893083552959519,-0.11754754612151713,-0.10485077284706884,-0.12456371536434158,-0.14107130137474194,-0.1522722416126489,-0.13344967590284107,-0.10613291544981712,-0.0890376807464901,-0.12426098724980339,-0.11209844005983272,-0.11386138613861291,-0.1156421397535427,-0.12098440059833221,-0.12098440059833221,-0.11386138613861291,-0.15659947289692888,-0.1655032409715781,-0.1601609801267886,-0.1779863238122366,-0.1868722843507361,-0.1779685162760869,-0.17974926989101675,-0.1993375596552449,-0.1994265973359901,-0.2402592777263317,-0.27062112686088735,-0.3055060901773631,-0.2669883894864289,-0.24921646840942996,-0.2100576964171233,-0.19290903910534718,-0.2152218819004192,-0.20466201296388475,-0.1922145451955256,-0.17795070873993724,-0.17440700904622725,-0.16539639575468318,-0.15973359925920583,-0.11920364698340241,-0.15375026711304052,-0.15481871928199908,-0.14769570482227973,-0.13888097442837577,-0.12456371536434158,-0.1235486858038321,-0.09781679606809468,-0.10075503953272824,-0.08697200655317172,-0.10139611083410405,-0.1156421397535427,-0.14233563644134056,-0.13726048863878987,-0.11386138613861291,-0.09071158914452504,-0.08182562860602555,-0.0962141178146585,-0.09781679606809468,-0.09427309637438469,-0.09251015029560455,-0.09427309637438469,-0.07876273238834741,-0.08002706745494603,-0.08127359498539821,-0.09605384998931454,-0.09436213405512989,-0.09338271956691979,-0.0889486430657449,-0.0978346036042444,-0.11473395540992809,-0.13337844575824231,-0.10673837167889355,-0.1102998789087532,-0.11948856756179088,-0.10673837167889355,-0.09379229289835289,-0.0819858964313695,-0.0757532587791151,-0.06405370752902662,-0.060420970154568154,-0.03728898069663,-0.03568630244319382,-0.035775340123939015,-0.033424745352232166,-0.04797350238620901,-0.026782534368544664,-0.03570410997934348,-0.03728898069663,-0.035508227081700205,-0.03721775055203125,-0.04414488211411055,-0.03898069663081466,-0.030771422465987075,-0.0055025286701318454,-0.006375097941447083,-0.008173659092526597,0.008832537930052037,-0.01770069093240184,-0.033709665930620636,-0.044340765011750605,-0.030522116959897927,-0.01796780397464065,-0.01773630600470122,-0.02484151292827086,-0.01960609730037627,-0.017095234703325413,3.5615072297767725e-05,0.033905548828263965,0.04462568559014235,0.06323456086616042,0.05940594059405868,0.05301303511646033,0.027779756392907667,-0.008601039960109358,0.008939383146946922,-0.006820286345179505,-0.0069093240259279765,-0.003258779115319854,-0.0016739083980333302,0.009010613291545677,0.0021190968017657796,0.012572120521405356,0.008209274164825947,0.010577676472682512,-0.011966664292328955,-0.026622266543200712,-0.035508227081700205,-0.06221953130564767,-0.05153500961606866,-0.049754256001138863,-0.03543699693710145,-0.0426846641498686,-0.04451884037324422,-0.05135693425457505,-0.05384998931547619,-0.06221953130564767,-0.07543272312842719,-0.06934254576536703,-0.08536932829973554,-0.08715008191466539,-0.08715008191466539,-0.09543058622408845,-0.08893083552959519,-0.06074150580525606,-0.053315763230998514,-0.030326234062254598,-0.0035971223021574183,-0.008796922857752687,-0.01689935180568214,-0.023470332644774106,-0.035508227081700205,-0.03606026070232754,-0.03728898069663,-0.0319467198518405,-0.02088823990312777,-0.01435287413633518,-0.014299451527886142,-0.0014067953557945212,-0.0069271315620776375,-0.01413918370254219,-0.01770069093240184,-0.015635016739083463,-0.024823705392121198,-0.03068238478524188,-0.04797350238620901,-0.05338699337559727,-0.06221953130564767,-0.053315763230998514,-0.02687157204928986,-0.02416482655459573,-0.01770069093240184,-0.023915521048506583,-0.012572120521405328,-0.012358430087612338,-0.02124439062611183,-0.0055025286701318454,-0.000979414488211705,0.02500178075361481,0.01789657383004517,0.01793218890234452,0.01793218890234452,0.03394116390056334,0.02685376451314339,0.016400740793503843,-0.000979414488211705,-0.017718498468551502,-0.043254505306645596,-0.023701830614716812,-0.029542702471684612,-0.010880404587220727,-0.004398461428877121,0.0026711304223963617,-0.008796922857752687,-0.024823705392121198,-0.01413918370254219,-0.02421824916304477,-0.05333357076714823,-0.0710876843079975,-0.07112329938029688,-0.07112329938029688,-0.07087399387420773,-0.06578103853550737,-0.07760524253864043,-0.08937602393332766,-0.1317579599686564,-0.11818861742289288,-0.1102998789087532,-0.10584799487142865,-0.08175439846142679,-0.0853871358358852,-0.08536932829973554,-0.07470261414630625,-0.08520906047439158,-0.08492413989600306,-0.08896645060189456,-0.10675617921504321,-0.11391480874706195,-0.11386138613861291,-0.1065781038535496,-0.11389700121091223,-0.12134055132131949,-0.1156421397535427,-0.1191858394472527,-0.1465025999002766,-0.1752439632452431,-0.14824773844290706,-0.1156421397535427,-0.12495548115962496,-0.11742289336847256,-0.09299095377163641,-0.1031234418405848,-0.08845003205356339,-0.09071158914452504,-0.09259918797634975,-0.09423748130208531,-0.09509224303725089,-0.10477954270247009,-0.09603604245316483,-0.10492200299166432,-0.10298098155139057,-0.11384357860246319,-0.10762874848635845,-0.12272953914096268,-0.12454590782819192,-0.11742289336847256,-0.12280076928556144,-0.14235344397749022,-0.1401987321034267,-0.13535508227081544,-0.13809744283780895,-0.13515919937317217,-0.12764441911816943,-0.12538286202720772,-0.10672056414274383,-0.10143172590640342,-0.09943728185768058,-0.08873495263195191,-0.06400028492057752,-0.04966521832039367,-0.04911318469976306,-0.04619274877127921,-0.03372747346677035,-0.008796922857752687,0.0010150295605111104,0.0464064392050722,0.028171522188191078,0.01794999643849421,-0.01105847994871434,-0.012358430087612338,0.011824204003134692,0.00012465275304618384,0.0036861599829058622,0.009010613291545677,0.010274948358144298,0.009046228363845055,0.016133627751265006,0.016133627751265006,0.026835956976993702,0.039283424745352846,0.01791438136619483,0.018270532089182112,0.02233065033122006,0.02859890305577384,0.029863238122372487,0.035721917515493196,0.033887741292114304,0.02688937958544277,0.015189828335351041,0.0009437994159123553,8.903768074680629e-05,-0.00037395825913533187,-0.00037395825913533187,0.00010684521689649507,0.015403518769144031,0.015403518769144031,-0.007283282285061643,0.03955053778759168,0.026800341904694325,0.035721917515493196,0.04462568559014235,0.03566849490704413,0.033923356364413654,0.028687940736519035,0.03216041028563352,0.019517059619631044,0.01791438136619483,0.017006197022580244,0.01791438136619483,0.016774699052640785,0.016133627751265006,0.00010684521689649507,0.014281643991736426,0.027494835814515922,0.02918655174870055,0.02918655174870055,0.029702970297031783,0.04464349312629204,0.05345822352019278,0.0454804473253079,0.039283424745352846,0.026818149440844014,0.03926561720920316,0.0472968160125371,0.06065246812451086,0.059940166678539575,0.06250445188403944,0.05710876843080087,0.06854120663865054,0.07130137474179049,0.0615250373958261,0.05352945366479153,0.057464919153784905,0.06189899565496304,0.0668672982406156,0.07993802977420084,0.08558301873352855,0.0884678395897163,0.0998468551891169,0.10205498967162951,0.08700762162547113,0.09671272882684001,0.08700762162547113,0.0891445259633882,0.08715008191466536,0.08706104423392017,0.08382007265474839,0.08859249234276087,0.08383788019089808,0.08382007265474839,0.08200370396751919,0.07988460716575177,0.07135479735023956,0.06036754754612236,0.04818719282000203,0.05340480091174696,0.062433221739440686,0.03752047866657271,0.05169527744141264,0.046388631668922514,0.035721917515493196,0.035775340123942234,0.062433221739440686,0.03809031982334973,0.035721917515493196,0.032178217821783206,0.035721917515493196,0.04886387919367394,0.04991452382648279,0.051784315122161056,0.05561293539425957,0.062237338841797385,0.062219531305647696,0.056627964954769044,0.0617209202934694,0.06672483795142134,0.07131918227794018,0.06950281359071098,0.06952062112686067,0.07236982691074903,0.07443550110406738,0.07151506517558351,0.07151506517558351,0.0731177434290197,0.07317116603746876,0.07147945010328413,0.06490846926419214,0.062433221739440686,0.056627964954769044,0.0464064392050722,0.035721917515493196,0.030290618989958495,0.00010684521689649507,-0.0034546620129631833,-0.015617209202933802,-0.03470688795498045,-0.04437638008404998,-0.03549041954555049,-0.035508227081700205,-0.027334567989172,8.903768074680629e-05,-0.008512002279364161,-0.010096872996650685,-0.012358430087612338,-0.019481444547331694,0.021137545409216946,0.04462568559014235,0.05319111047795394,0.05174870004986171,0.041188831113327246,0.039283424745352846,0.0017273310064823966,0.01789657383004517,0.01791438136619483,0.01435287413633518,0.012572120521405356,0.01435287413633518,0.01791438136619483,0.035721917515493196,0.030735807393690945,0.023274449747134024,0.0054669135978356875,0.009010613291545677,-0.002546477669348568,0.008992805755395988,0.005449106061685999,0.005449106061685999,-0.033015172020799066,-0.027886601609799333,-0.03068238478524188,-0.026604459007050996,-0.0265154213263058,-0.026586651470901335,-0.018608875276016457,-0.026390768573258006,-0.026390768573258006,-0.03086046014673227,-0.04863238122373448,-0.048667996296030636,-0.049772063537288525,-0.05153500961606866,-0.065745423463208,-0.04442980269249902,-0.02500178075361481,-0.038286202720989815,-0.017629460787803086,-0.01225158487071748,-0.012126932117672906,-0.019588289764226552,-0.035508227081700205,-0.039069734311559856,-0.035508227081700205,-0.032035757532585696,-0.02838521262198085,-0.03547261200940083,-0.05858679393118926,-0.03711090533513639,-0.03967519054063623,-0.06400028492057752,-0.06400028492057752,-0.06400028492057752,-0.06756179215043717,-0.05333357076714823,-0.04667355224731101,-0.05824845074435492,-0.07114110691644654,-0.07114110691644654,-0.07824631384001618,-0.0889486430657449,-0.08898425813804428,-0.09194030913882756,-0.09747845288125712,-0.09746064534511067,-0.11386138613861291,-0.13166892228791122,-0.11749412351307131,-0.11749412351307131,-0.10572334211838408,-0.08357076714865602,-0.07290405299522668,-0.08358857468480568,-0.07094522401880321,-0.06221953130564767,-0.062183916233348346,-0.05550609017736147,-0.06221953130564767,-0.06220172376949801,-0.06750836954198813,-0.08650901061328958,-0.07466699907400687,-0.04781323456086506,-0.035508227081700205,-0.0355972647624454,-0.04263124154141951,-0.05260346178502723,-0.04263124154141951,-0.01935679179428712,-0.01668566137189237,-0.026604459007050996,-0.018519837595267985,-0.014156991238691852,-0.0055915663508802615,-0.0019410214402721393,-0.017148657311774507,-0.035579457226298905,-0.04086829546263937,-0.046228363843578535,-0.053315763230998514,-0.05333357076714823,-0.035561649690149244,-0.035508227081700205,-0.05114324382078528,-0.0427202792221647,-0.05135693425457505,-0.054722558586794645,-0.06750836954198813,-0.07846000427380923,-0.08349953700406049,-0.08358857468480568,-0.07846000427380923,-0.04382434646342265,-0.03972861314908532,-0.03549041954555049,-0.03529453664790716,-0.012857041099793853,-0.03378089607521939,-0.03962176793218719,-0.03296174941234997,-0.02672911176009557,-0.01413918370254219,-0.01770069093240184,-0.01759384571550693,-0.02631953842866247,-0.012376237623761999,-0.014851485148513477,-0.01668566137189237,-0.012465275304507195,-0.012358430087612338,-0.013498112401166384,-0.03173302941804751,-0.033709665930620636,-0.03540138186480529,-0.018626682812166118,-0.018858180782105605,-0.012839233563644192,-0.015919937317471988,-0.012785810955195098,-0.02900847638720694,-0.07112329938029688,-0.06221953130564767,-0.056877270460858165,-0.05333357076714823,-0.05319111047795394,-0.04111760096872852,-0.06221953130564767,-0.07749839732174552,-0.07758743500249071,-0.07112329938029688,-0.07824631384001618,-0.07822850630386652,-0.07292186053137639,-0.07644775268893667,-0.08353515207635664,-0.08006268252724541,-0.08715008191466539,-0.08816511147517486,-0.045800982975995774,-0.06384001709523357,-0.04686943514495112,-0.05858679393118926,-0.05865802407578802,-0.06068808319680702,-0.06052781537146307,-0.045373602108413014,-0.05864021653963836,-0.04797350238620901,-0.04797350238620901,-0.04263124154141951,-0.02687157204928986,-0.04108198589642914,-0.016667853835742652,-0.015937744853621705,-0.028260559868936275,-0.026622266543200712,-0.03691502243749628,-0.040102571408219045,-0.03691502243749628,-0.03719994301588481,-0.03549041954555049,-0.0319467198518405,-0.029631740152433028,-0.033691858394470975,-0.03549041954555049,-0.0357575325877893,-0.03549041954555049,-0.0319467198518405,-0.030165966236910702,-0.04085048792648971,-0.033852126219814926,-0.051445971935323465,-0.046905050217250444,-0.049754256001138863,-0.046157133698979835,-0.05573758814730412,-0.053315763230998514,-0.0498076786095879,-0.05668138756321489,-0.03919438706460443,-0.035579457226298905,-0.051232281501530474,-0.039069734311559856,-0.04970083339268977,-0.03730678823277972,-0.03200014246028959,0.005449106061685999,0.06195241826340886,0.08024075788873905,0.07133698981408987,0.044251727331008656,0.053885604387778785,0.062433221739440686,0.062415414203291,0.07488068950779986,0.0670631811382589,0.07783674050858311,0.07133698981408987,0.07309993589287,0.0731177434290197,0.058871714509581036,0.058871714509581036,0.0659413063608513,0.06588788375240548,0.07124795213334467,0.09521689579029868,0.09806610157418708,0.10693425457653685,0.10543842153999555,0.10652468124510378,0.07634090747204181,0.07842438920150982,0.07197806111546565,0.07178217821782232,0.07794358572547799,0.0838022651185987,0.08978559726476398,0.1248486359427301,0.14790939525607272,0.14363558658024178,0.14457938599615253,0.14343970368259845,0.12283638435786079,0.12119809103212523,0.11047795427024684,0.10132488068950854,0.10080846214117734,0.10034546620129842,0.11744070090462225,0.11311346962034222,0.10657810385355285,0.0729040529952267,0.07112329938029685,0.037609516347317906,0.05206923570054958,0.05554170524966082,0.05352945366479153,0.05354726120094122,0.05356506873709091,0.08907329581878945,0.1118491345537436,0.1118491345537436,0.07133698981408987,0.0731177434290197,0.06777548258423019,0.060545622907615976,0.05890732958188041,0.05890732958188041,0.06081273594985481,0.0838022651185987,0.08918014103568758,0.0891445259633882,0.08063252368402243,0.07489849704394955,0.07133698981408987,0.0791544981836308,0.0802763729610384,0.08022295035258936,0.07578887385141445,0.08709665930621954,0.08709665930621954,0.09256357290405362,0.10696986964883623,0.11761877626611586,0.1301018591067744,0.14879977206353767,0.13610299878908938,0.13603176864449062,0.12570339767789887,0.1360139611083409,0.12744853622052932,0.13280860460146854,0.13006624403447503,0.11733385568772736,0.08982121233706011,0.08982121233706011,0.08898425813804425,0.08202151150366888,0.09795925635729219,0.0889486430657449,0.09804829403803739,0.09806610157418708,0.0945758244889229,0.0998468551891169,0.11683524467554585,0.11685305221169554,0.11685305221169554,0.12417194956905817,0.13190042025785392,0.13416197734881558,0.1354441199515639,0.15082983118455662,0.1354263124154142,0.1301018591067744,0.10098653750267095,0.10695206211268654,0.11943514495334509,0.1194173374171954,0.13699337559655428,0.13608519125293966,0.13604957618064029,0.12299665218320474,0.13606738371679,0.14256713441128324,0.1613718925849414,0.1674976850203009,0.15147090248593242,0.14278082484507626,0.14792720279222243,0.15943087114466759,0.15597620913170607,0.15147090248593242,0.1514530949497827,0.14969014887100257,0.15850487926490653,0.17390839803404895,0.16824560153857157,0.16927843863523073,0.16210200156706234,0.15236127929339732,0.1479450103283721,0.1241541420329085,0.09982904765296721,0.0926882256570982,0.08152290049148736,0.062415414203291,0.04462568559014235,0.026818149440844014,0.035721917515493196,0.03921219460075412,0.05351164612864184,0.07133698981408987,0.03926561720920316,0.03216041028563352,0.0410641783602827,0.04978987107343824,0.04432295747560416,0.03730678823277969,0.0410641783602827,0.04104637082413301,0.02131562077071056,-0.0016917159341829913,0.012981693852838427,-0.0034546620129631833,-0.017682883396252125,-0.04375311631882389,-0.04439418762019964,-0.056877270460858165,-0.08180782106987589,-0.056877270460858165,-0.07092741648265355,-0.07646556022508638,-0.08002706745494603,-0.08715008191466539,-0.12379799130992125,-0.1868722843507361,-0.16014317259063887,-0.15205855117885914,-0.13255929909537612,-0.14233563644134056,-0.17086330935251726,-0.20824132772989407,-0.24925208348172934,-0.27769071871215767,-0.29193674763159627,-0.2848493482441763,-0.26016810314124783,-0.19584728256998402,-0.26873352802905937,-0.24421255075147802,-0.25363273737445513,-0.24027708526248143,-0.2385141391837013,-0.23139112472398193,-0.17088111688866697,-0.2329403803689723,-0.22243393404088369,-0.22279008476387097,-0.2474357147945001,-0.3186480518555438,-0.3590711589144523,-0.38275518199301783,-0.39639575468338006,-0.37379799130991964,-0.4056556734810165,-0.42558230643207906,-0.44153785882185204,-0.4806966308141587,-0.41837025429161456,-0.4240686658593913,-0.4548044732530774,-0.4717928627395096,-0.41837025429161456,-0.40152432509437985,-0.39210413847139947,-0.40946648621696535,-0.40175582306431934,-0.3916767576038167,-0.39169456513996637,-0.4094486786808157,-0.427256214830114,-0.4628890946648604,-0.44513498112401106,-0.4672341334852901,-0.4806966308141587,-0.4805185554526651,-0.4735736163544394,-0.49688368117387116,-0.5075503953273005,-0.48602108412279854,-0.4676437068167232,-0.4664506018947201,-0.45012109124581334,-0.42549326875133386,-0.443941876202008,-0.4611083410499306,-0.4439240686658583,-0.41504024503169434,-0.41302799344682506,-0.3994942659733577,-0.4270603319324707,-0.42727402236626366,-0.4270603319324707,-0.4392584941947407,-0.45307714224659656,-0.5134624973288671,-0.46313840017094954,-0.5026177078139441,-0.5077997008333897,-0.4783816511147513,-0.4919688011966644,-0.4750694493909807,-0.4806610157418594,-0.47546121518626405,-0.4482156848778389,-0.44531305648550146,-0.4283602820713719,-0.4097514067953538,-0.4148265545979045,-0.4130458009829747,-0.39425885034546304,-0.39165895006766704,-0.4450815585155621,-0.46290690220101005,-0.47478452881259214,-0.44874991096231653,-0.4513854263124152,-0.45578388774129075,-0.4610905335137808,-0.45929197236270136,-0.4397392976707726,-0.43368473538001173,-0.42380155281714926,-0.43368473538001173,-0.43085333713227303,-0.4468623121304919,-0.45044162689650125,-0.46319182277939863,-0.5004095733314314,-0.4791829902414677,-0.47063537288980584,-0.5006766863736702,-0.498504166963457,-0.5133378445758224,-0.5426312415414195,-0.5683097086687079,-0.5316974143457481,-0.489653821497257,-0.5037039675190523,-0.5143528741363319,-0.5162582805043063,-0.4896003988888079,-0.48172946791081794,-0.4771351235842991,-0.48899494265973154,-0.49848635942730735,-0.4806966308141587,-0.46263978915877124,-0.4450815585155621,-0.4522045729752814,-0.4590070517843128,-0.46965595840159247],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"variable=train_predicted_close\\u003cbr\\u003eDate=%{x}\\u003cbr\\u003eStock price=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"train_predicted_close\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Train predicted close price\",\"showlegend\":true,\"x\":[\"2018-05-06 00:00:00\",\"2018-05-06 00:01:00\",\"2018-05-06 00:02:00\",\"2018-05-06 00:03:00\",\"2018-05-06 00:04:00\",\"2018-05-06 00:05:00\",\"2018-05-06 00:06:00\",\"2018-05-06 00:07:00\",\"2018-05-06 00:08:00\",\"2018-05-06 00:09:00\",\"2018-05-06 00:10:00\",\"2018-05-06 00:11:00\",\"2018-05-06 00:12:00\",\"2018-05-06 00:13:00\",\"2018-05-06 00:14:00\",\"2018-05-06 00:15:00\",\"2018-05-06 00:16:00\",\"2018-05-06 00:17:00\",\"2018-05-06 00:18:00\",\"2018-05-06 00:19:00\",\"2018-05-06 00:20:00\",\"2018-05-06 00:21:00\",\"2018-05-06 00:22:00\",\"2018-05-06 00:23:00\",\"2018-05-06 00:24:00\",\"2018-05-06 00:25:00\",\"2018-05-06 00:26:00\",\"2018-05-06 00:27:00\",\"2018-05-06 00:28:00\",\"2018-05-06 00:29:00\",\"2018-05-06 00:30:00\",\"2018-05-06 00:31:00\",\"2018-05-06 00:32:00\",\"2018-05-06 00:33:00\",\"2018-05-06 00:34:00\",\"2018-05-06 00:35:00\",\"2018-05-06 00:36:00\",\"2018-05-06 00:37:00\",\"2018-05-06 00:38:00\",\"2018-05-06 00:39:00\",\"2018-05-06 00:40:00\",\"2018-05-06 00:41:00\",\"2018-05-06 00:42:00\",\"2018-05-06 00:43:00\",\"2018-05-06 00:44:00\",\"2018-05-06 00:45:00\",\"2018-05-06 00:46:00\",\"2018-05-06 00:47:00\",\"2018-05-06 00:48:00\",\"2018-05-06 00:49:00\",\"2018-05-06 00:50:00\",\"2018-05-06 00:51:00\",\"2018-05-06 00:52:00\",\"2018-05-06 00:53:00\",\"2018-05-06 00:54:00\",\"2018-05-06 00:55:00\",\"2018-05-06 00:56:00\",\"2018-05-06 00:57:00\",\"2018-05-06 00:58:00\",\"2018-05-06 00:59:00\",\"2018-05-06 01:00:00\",\"2018-05-06 01:01:00\",\"2018-05-06 01:02:00\",\"2018-05-06 01:03:00\",\"2018-05-06 01:04:00\",\"2018-05-06 01:05:00\",\"2018-05-06 01:06:00\",\"2018-05-06 01:07:00\",\"2018-05-06 01:08:00\",\"2018-05-06 01:09:00\",\"2018-05-06 01:10:00\",\"2018-05-06 01:11:00\",\"2018-05-06 01:12:00\",\"2018-05-06 01:13:00\",\"2018-05-06 01:14:00\",\"2018-05-06 01:15:00\",\"2018-05-06 01:16:00\",\"2018-05-06 01:17:00\",\"2018-05-06 01:18:00\",\"2018-05-06 01:19:00\",\"2018-05-06 01:20:00\",\"2018-05-06 01:21:00\",\"2018-05-06 01:22:00\",\"2018-05-06 01:23:00\",\"2018-05-06 01:24:00\",\"2018-05-06 01:25:00\",\"2018-05-06 01:26:00\",\"2018-05-06 01:27:00\",\"2018-05-06 01:28:00\",\"2018-05-06 01:29:00\",\"2018-05-06 01:30:00\",\"2018-05-06 01:31:00\",\"2018-05-06 01:32:00\",\"2018-05-06 01:33:00\",\"2018-05-06 01:34:00\",\"2018-05-06 01:35:00\",\"2018-05-06 01:36:00\",\"2018-05-06 01:37:00\",\"2018-05-06 01:38:00\",\"2018-05-06 01:39:00\",\"2018-05-06 01:40:00\",\"2018-05-06 01:41:00\",\"2018-05-06 01:42:00\",\"2018-05-06 01:43:00\",\"2018-05-06 01:44:00\",\"2018-05-06 01:45:00\",\"2018-05-06 01:46:00\",\"2018-05-06 01:47:00\",\"2018-05-06 01:48:00\",\"2018-05-06 01:49:00\",\"2018-05-06 01:50:00\",\"2018-05-06 01:51:00\",\"2018-05-06 01:52:00\",\"2018-05-06 01:53:00\",\"2018-05-06 01:54:00\",\"2018-05-06 01:55:00\",\"2018-05-06 01:56:00\",\"2018-05-06 01:57:00\",\"2018-05-06 01:58:00\",\"2018-05-06 01:59:00\",\"2018-05-06 02:00:00\",\"2018-05-06 02:01:00\",\"2018-05-06 02:02:00\",\"2018-05-06 02:03:00\",\"2018-05-06 02:04:00\",\"2018-05-06 02:05:00\",\"2018-05-06 02:06:00\",\"2018-05-06 02:07:00\",\"2018-05-06 02:08:00\",\"2018-05-06 02:09:00\",\"2018-05-06 02:10:00\",\"2018-05-06 02:11:00\",\"2018-05-06 02:12:00\",\"2018-05-06 02:13:00\",\"2018-05-06 02:14:00\",\"2018-05-06 02:15:00\",\"2018-05-06 02:16:00\",\"2018-05-06 02:17:00\",\"2018-05-06 02:18:00\",\"2018-05-06 02:19:00\",\"2018-05-06 02:20:00\",\"2018-05-06 02:21:00\",\"2018-05-06 02:22:00\",\"2018-05-06 02:23:00\",\"2018-05-06 02:24:00\",\"2018-05-06 02:25:00\",\"2018-05-06 02:26:00\",\"2018-05-06 02:27:00\",\"2018-05-06 02:28:00\",\"2018-05-06 02:29:00\",\"2018-05-06 02:30:00\",\"2018-05-06 02:31:00\",\"2018-05-06 02:32:00\",\"2018-05-06 02:33:00\",\"2018-05-06 02:34:00\",\"2018-05-06 02:35:00\",\"2018-05-06 02:36:00\",\"2018-05-06 02:37:00\",\"2018-05-06 02:38:00\",\"2018-05-06 02:39:00\",\"2018-05-06 02:40:00\",\"2018-05-06 02:41:00\",\"2018-05-06 02:42:00\",\"2018-05-06 02:43:00\",\"2018-05-06 02:44:00\",\"2018-05-06 02:45:00\",\"2018-05-06 02:46:00\",\"2018-05-06 02:47:00\",\"2018-05-06 02:48:00\",\"2018-05-06 02:49:00\",\"2018-05-06 02:50:00\",\"2018-05-06 02:51:00\",\"2018-05-06 02:52:00\",\"2018-05-06 02:53:00\",\"2018-05-06 02:54:00\",\"2018-05-06 02:55:00\",\"2018-05-06 02:56:00\",\"2018-05-06 02:57:00\",\"2018-05-06 02:58:00\",\"2018-05-06 02:59:00\",\"2018-05-06 03:00:00\",\"2018-05-06 03:01:00\",\"2018-05-06 03:02:00\",\"2018-05-06 03:03:00\",\"2018-05-06 03:04:00\",\"2018-05-06 03:05:00\",\"2018-05-06 03:06:00\",\"2018-05-06 03:07:00\",\"2018-05-06 03:08:00\",\"2018-05-06 03:09:00\",\"2018-05-06 03:10:00\",\"2018-05-06 03:11:00\",\"2018-05-06 03:12:00\",\"2018-05-06 03:13:00\",\"2018-05-06 03:14:00\",\"2018-05-06 03:15:00\",\"2018-05-06 03:16:00\",\"2018-05-06 03:17:00\",\"2018-05-06 03:18:00\",\"2018-05-06 03:19:00\",\"2018-05-06 03:20:00\",\"2018-05-06 03:21:00\",\"2018-05-06 03:22:00\",\"2018-05-06 03:23:00\",\"2018-05-06 03:24:00\",\"2018-05-06 03:25:00\",\"2018-05-06 03:26:00\",\"2018-05-06 03:27:00\",\"2018-05-06 03:28:00\",\"2018-05-06 03:29:00\",\"2018-05-06 03:30:00\",\"2018-05-06 03:31:00\",\"2018-05-06 03:32:00\",\"2018-05-06 03:33:00\",\"2018-05-06 03:34:00\",\"2018-05-06 03:35:00\",\"2018-05-06 03:36:00\",\"2018-05-06 03:37:00\",\"2018-05-06 03:38:00\",\"2018-05-06 03:39:00\",\"2018-05-06 03:40:00\",\"2018-05-06 03:41:00\",\"2018-05-06 03:42:00\",\"2018-05-06 03:43:00\",\"2018-05-06 03:44:00\",\"2018-05-06 03:45:00\",\"2018-05-06 03:46:00\",\"2018-05-06 03:47:00\",\"2018-05-06 03:48:00\",\"2018-05-06 03:49:00\",\"2018-05-06 03:50:00\",\"2018-05-06 03:51:00\",\"2018-05-06 03:52:00\",\"2018-05-06 03:53:00\",\"2018-05-06 03:54:00\",\"2018-05-06 03:55:00\",\"2018-05-06 03:56:00\",\"2018-05-06 03:57:00\",\"2018-05-06 03:58:00\",\"2018-05-06 03:59:00\",\"2018-05-06 04:00:00\",\"2018-05-06 04:01:00\",\"2018-05-06 04:02:00\",\"2018-05-06 04:03:00\",\"2018-05-06 04:04:00\",\"2018-05-06 04:05:00\",\"2018-05-06 04:06:00\",\"2018-05-06 04:07:00\",\"2018-05-06 04:08:00\",\"2018-05-06 04:09:00\",\"2018-05-06 04:10:00\",\"2018-05-06 04:11:00\",\"2018-05-06 04:12:00\",\"2018-05-06 04:13:00\",\"2018-05-06 04:14:00\",\"2018-05-06 04:15:00\",\"2018-05-06 04:16:00\",\"2018-05-06 04:17:00\",\"2018-05-06 04:18:00\",\"2018-05-06 04:19:00\",\"2018-05-06 04:20:00\",\"2018-05-06 04:21:00\",\"2018-05-06 04:22:00\",\"2018-05-06 04:23:00\",\"2018-05-06 04:24:00\",\"2018-05-06 04:25:00\",\"2018-05-06 04:26:00\",\"2018-05-06 04:27:00\",\"2018-05-06 04:28:00\",\"2018-05-06 04:29:00\",\"2018-05-06 04:30:00\",\"2018-05-06 04:31:00\",\"2018-05-06 04:32:00\",\"2018-05-06 04:33:00\",\"2018-05-06 04:34:00\",\"2018-05-06 04:35:00\",\"2018-05-06 04:36:00\",\"2018-05-06 04:37:00\",\"2018-05-06 04:38:00\",\"2018-05-06 04:39:00\",\"2018-05-06 04:40:00\",\"2018-05-06 04:41:00\",\"2018-05-06 04:42:00\",\"2018-05-06 04:43:00\",\"2018-05-06 04:44:00\",\"2018-05-06 04:45:00\",\"2018-05-06 04:46:00\",\"2018-05-06 04:47:00\",\"2018-05-06 04:48:00\",\"2018-05-06 04:49:00\",\"2018-05-06 04:50:00\",\"2018-05-06 04:51:00\",\"2018-05-06 04:52:00\",\"2018-05-06 04:53:00\",\"2018-05-06 04:54:00\",\"2018-05-06 04:55:00\",\"2018-05-06 04:56:00\",\"2018-05-06 04:57:00\",\"2018-05-06 04:58:00\",\"2018-05-06 04:59:00\",\"2018-05-06 05:00:00\",\"2018-05-06 05:01:00\",\"2018-05-06 05:02:00\",\"2018-05-06 05:03:00\",\"2018-05-06 05:04:00\",\"2018-05-06 05:05:00\",\"2018-05-06 05:06:00\",\"2018-05-06 05:07:00\",\"2018-05-06 05:08:00\",\"2018-05-06 05:09:00\",\"2018-05-06 05:10:00\",\"2018-05-06 05:11:00\",\"2018-05-06 05:12:00\",\"2018-05-06 05:13:00\",\"2018-05-06 05:14:00\",\"2018-05-06 05:15:00\",\"2018-05-06 05:16:00\",\"2018-05-06 05:17:00\",\"2018-05-06 05:18:00\",\"2018-05-06 05:19:00\",\"2018-05-06 05:20:00\",\"2018-05-06 05:21:00\",\"2018-05-06 05:22:00\",\"2018-05-06 05:23:00\",\"2018-05-06 05:24:00\",\"2018-05-06 05:25:00\",\"2018-05-06 05:26:00\",\"2018-05-06 05:27:00\",\"2018-05-06 05:28:00\",\"2018-05-06 05:29:00\",\"2018-05-06 05:30:00\",\"2018-05-06 05:31:00\",\"2018-05-06 05:32:00\",\"2018-05-06 05:33:00\",\"2018-05-06 05:34:00\",\"2018-05-06 05:35:00\",\"2018-05-06 05:36:00\",\"2018-05-06 05:37:00\",\"2018-05-06 05:38:00\",\"2018-05-06 05:39:00\",\"2018-05-06 05:40:00\",\"2018-05-06 05:41:00\",\"2018-05-06 05:42:00\",\"2018-05-06 05:43:00\",\"2018-05-06 05:44:00\",\"2018-05-06 05:45:00\",\"2018-05-06 05:46:00\",\"2018-05-06 05:47:00\",\"2018-05-06 05:48:00\",\"2018-05-06 05:49:00\",\"2018-05-06 05:50:00\",\"2018-05-06 05:51:00\",\"2018-05-06 05:52:00\",\"2018-05-06 05:53:00\",\"2018-05-06 05:54:00\",\"2018-05-06 05:55:00\",\"2018-05-06 05:56:00\",\"2018-05-06 05:57:00\",\"2018-05-06 05:58:00\",\"2018-05-06 05:59:00\",\"2018-05-06 06:00:00\",\"2018-05-06 06:01:00\",\"2018-05-06 06:02:00\",\"2018-05-06 06:03:00\",\"2018-05-06 06:04:00\",\"2018-05-06 06:05:00\",\"2018-05-06 06:06:00\",\"2018-05-06 06:07:00\",\"2018-05-06 06:08:00\",\"2018-05-06 06:09:00\",\"2018-05-06 06:10:00\",\"2018-05-06 06:11:00\",\"2018-05-06 06:12:00\",\"2018-05-06 06:13:00\",\"2018-05-06 06:14:00\",\"2018-05-06 06:15:00\",\"2018-05-06 06:16:00\",\"2018-05-06 06:17:00\",\"2018-05-06 06:18:00\",\"2018-05-06 06:19:00\",\"2018-05-06 06:20:00\",\"2018-05-06 06:21:00\",\"2018-05-06 06:22:00\",\"2018-05-06 06:23:00\",\"2018-05-06 06:24:00\",\"2018-05-06 06:25:00\",\"2018-05-06 06:26:00\",\"2018-05-06 06:27:00\",\"2018-05-06 06:28:00\",\"2018-05-06 06:29:00\",\"2018-05-06 06:30:00\",\"2018-05-06 06:31:00\",\"2018-05-06 06:32:00\",\"2018-05-06 06:33:00\",\"2018-05-06 06:34:00\",\"2018-05-06 06:35:00\",\"2018-05-06 06:36:00\",\"2018-05-06 06:37:00\",\"2018-05-06 06:38:00\",\"2018-05-06 06:39:00\",\"2018-05-06 06:40:00\",\"2018-05-06 06:41:00\",\"2018-05-06 06:42:00\",\"2018-05-06 06:43:00\",\"2018-05-06 06:44:00\",\"2018-05-06 06:45:00\",\"2018-05-06 06:46:00\",\"2018-05-06 06:47:00\",\"2018-05-06 06:48:00\",\"2018-05-06 06:49:00\",\"2018-05-06 06:50:00\",\"2018-05-06 06:51:00\",\"2018-05-06 06:52:00\",\"2018-05-06 06:53:00\",\"2018-05-06 06:54:00\",\"2018-05-06 06:55:00\",\"2018-05-06 06:56:00\",\"2018-05-06 06:57:00\",\"2018-05-06 06:58:00\",\"2018-05-06 06:59:00\",\"2018-05-06 07:00:00\",\"2018-05-06 07:01:00\",\"2018-05-06 07:02:00\",\"2018-05-06 07:03:00\",\"2018-05-06 07:04:00\",\"2018-05-06 07:05:00\",\"2018-05-06 07:06:00\",\"2018-05-06 07:07:00\",\"2018-05-06 07:08:00\",\"2018-05-06 07:09:00\",\"2018-05-06 07:10:00\",\"2018-05-06 07:11:00\",\"2018-05-06 07:12:00\",\"2018-05-06 07:13:00\",\"2018-05-06 07:14:00\",\"2018-05-06 07:15:00\",\"2018-05-06 07:16:00\",\"2018-05-06 07:17:00\",\"2018-05-06 07:18:00\",\"2018-05-06 07:19:00\",\"2018-05-06 07:20:00\",\"2018-05-06 07:21:00\",\"2018-05-06 07:22:00\",\"2018-05-06 07:23:00\",\"2018-05-06 07:24:00\",\"2018-05-06 07:25:00\",\"2018-05-06 07:26:00\",\"2018-05-06 07:27:00\",\"2018-05-06 07:28:00\",\"2018-05-06 07:29:00\",\"2018-05-06 07:30:00\",\"2018-05-06 07:31:00\",\"2018-05-06 07:32:00\",\"2018-05-06 07:33:00\",\"2018-05-06 07:34:00\",\"2018-05-06 07:35:00\",\"2018-05-06 07:36:00\",\"2018-05-06 07:37:00\",\"2018-05-06 07:38:00\",\"2018-05-06 07:39:00\",\"2018-05-06 07:40:00\",\"2018-05-06 07:41:00\",\"2018-05-06 07:42:00\",\"2018-05-06 07:43:00\",\"2018-05-06 07:44:00\",\"2018-05-06 07:45:00\",\"2018-05-06 07:46:00\",\"2018-05-06 07:47:00\",\"2018-05-06 07:48:00\",\"2018-05-06 07:49:00\",\"2018-05-06 07:50:00\",\"2018-05-06 07:51:00\",\"2018-05-06 07:52:00\",\"2018-05-06 07:53:00\",\"2018-05-06 07:54:00\",\"2018-05-06 07:55:00\",\"2018-05-06 07:56:00\",\"2018-05-06 07:57:00\",\"2018-05-06 07:58:00\",\"2018-05-06 07:59:00\",\"2018-05-06 08:00:00\",\"2018-05-06 08:01:00\",\"2018-05-06 08:02:00\",\"2018-05-06 08:03:00\",\"2018-05-06 08:04:00\",\"2018-05-06 08:05:00\",\"2018-05-06 08:06:00\",\"2018-05-06 08:07:00\",\"2018-05-06 08:08:00\",\"2018-05-06 08:09:00\",\"2018-05-06 08:10:00\",\"2018-05-06 08:11:00\",\"2018-05-06 08:12:00\",\"2018-05-06 08:13:00\",\"2018-05-06 08:14:00\",\"2018-05-06 08:15:00\",\"2018-05-06 08:16:00\",\"2018-05-06 08:17:00\",\"2018-05-06 08:18:00\",\"2018-05-06 08:19:00\",\"2018-05-06 08:20:00\",\"2018-05-06 08:21:00\",\"2018-05-06 08:22:00\",\"2018-05-06 08:23:00\",\"2018-05-06 08:24:00\",\"2018-05-06 08:25:00\",\"2018-05-06 08:26:00\",\"2018-05-06 08:27:00\",\"2018-05-06 08:28:00\",\"2018-05-06 08:29:00\",\"2018-05-06 08:30:00\",\"2018-05-06 08:31:00\",\"2018-05-06 08:32:00\",\"2018-05-06 08:33:00\",\"2018-05-06 08:34:00\",\"2018-05-06 08:35:00\",\"2018-05-06 08:36:00\",\"2018-05-06 08:37:00\",\"2018-05-06 08:38:00\",\"2018-05-06 08:39:00\",\"2018-05-06 08:40:00\",\"2018-05-06 08:41:00\",\"2018-05-06 08:42:00\",\"2018-05-06 08:43:00\",\"2018-05-06 08:44:00\",\"2018-05-06 08:45:00\",\"2018-05-06 08:46:00\",\"2018-05-06 08:47:00\",\"2018-05-06 08:48:00\",\"2018-05-06 08:49:00\",\"2018-05-06 08:50:00\",\"2018-05-06 08:51:00\",\"2018-05-06 08:52:00\",\"2018-05-06 08:53:00\",\"2018-05-06 08:54:00\",\"2018-05-06 08:55:00\",\"2018-05-06 08:56:00\",\"2018-05-06 08:57:00\",\"2018-05-06 08:58:00\",\"2018-05-06 08:59:00\",\"2018-05-06 09:00:00\",\"2018-05-06 09:01:00\",\"2018-05-06 09:02:00\",\"2018-05-06 09:03:00\",\"2018-05-06 09:04:00\",\"2018-05-06 09:05:00\",\"2018-05-06 09:06:00\",\"2018-05-06 09:07:00\",\"2018-05-06 09:08:00\",\"2018-05-06 09:09:00\",\"2018-05-06 09:10:00\",\"2018-05-06 09:11:00\",\"2018-05-06 09:12:00\",\"2018-05-06 09:13:00\",\"2018-05-06 09:14:00\",\"2018-05-06 09:15:00\",\"2018-05-06 09:16:00\",\"2018-05-06 09:17:00\",\"2018-05-06 09:18:00\",\"2018-05-06 09:19:00\",\"2018-05-06 09:20:00\",\"2018-05-06 09:21:00\",\"2018-05-06 09:22:00\",\"2018-05-06 09:23:00\",\"2018-05-06 09:24:00\",\"2018-05-06 09:25:00\",\"2018-05-06 09:26:00\",\"2018-05-06 09:27:00\",\"2018-05-06 09:28:00\",\"2018-05-06 09:29:00\",\"2018-05-06 09:30:00\",\"2018-05-06 09:31:00\",\"2018-05-06 09:32:00\",\"2018-05-06 09:33:00\",\"2018-05-06 09:34:00\",\"2018-05-06 09:35:00\",\"2018-05-06 09:36:00\",\"2018-05-06 09:37:00\",\"2018-05-06 09:38:00\",\"2018-05-06 09:39:00\",\"2018-05-06 09:40:00\",\"2018-05-06 09:41:00\",\"2018-05-06 09:42:00\",\"2018-05-06 09:43:00\",\"2018-05-06 09:44:00\",\"2018-05-06 09:45:00\",\"2018-05-06 09:46:00\",\"2018-05-06 09:47:00\",\"2018-05-06 09:48:00\",\"2018-05-06 09:49:00\",\"2018-05-06 09:50:00\",\"2018-05-06 09:51:00\",\"2018-05-06 09:52:00\",\"2018-05-06 09:53:00\",\"2018-05-06 09:54:00\",\"2018-05-06 09:55:00\",\"2018-05-06 09:56:00\",\"2018-05-06 09:57:00\",\"2018-05-06 09:58:00\",\"2018-05-06 09:59:00\",\"2018-05-06 10:00:00\",\"2018-05-06 10:01:00\",\"2018-05-06 10:02:00\",\"2018-05-06 10:03:00\",\"2018-05-06 10:04:00\",\"2018-05-06 10:05:00\",\"2018-05-06 10:06:00\",\"2018-05-06 10:07:00\",\"2018-05-06 10:08:00\",\"2018-05-06 10:09:00\",\"2018-05-06 10:10:00\",\"2018-05-06 10:11:00\",\"2018-05-06 10:12:00\",\"2018-05-06 10:13:00\",\"2018-05-06 10:14:00\",\"2018-05-06 10:15:00\",\"2018-05-06 10:16:00\",\"2018-05-06 10:17:00\",\"2018-05-06 10:18:00\",\"2018-05-06 10:19:00\",\"2018-05-06 10:20:00\",\"2018-05-06 10:21:00\",\"2018-05-06 10:22:00\",\"2018-05-06 10:23:00\",\"2018-05-06 10:24:00\",\"2018-05-06 10:25:00\",\"2018-05-06 10:26:00\",\"2018-05-06 10:27:00\",\"2018-05-06 10:28:00\",\"2018-05-06 10:29:00\",\"2018-05-06 10:30:00\",\"2018-05-06 10:31:00\",\"2018-05-06 10:32:00\",\"2018-05-06 10:33:00\",\"2018-05-06 10:34:00\",\"2018-05-06 10:35:00\",\"2018-05-06 10:36:00\",\"2018-05-06 10:37:00\",\"2018-05-06 10:38:00\",\"2018-05-06 10:39:00\",\"2018-05-06 10:40:00\",\"2018-05-06 10:41:00\",\"2018-05-06 10:42:00\",\"2018-05-06 10:43:00\",\"2018-05-06 10:44:00\",\"2018-05-06 10:45:00\",\"2018-05-06 10:46:00\",\"2018-05-06 10:47:00\",\"2018-05-06 10:48:00\",\"2018-05-06 10:49:00\",\"2018-05-06 10:50:00\",\"2018-05-06 10:51:00\",\"2018-05-06 10:52:00\",\"2018-05-06 10:53:00\",\"2018-05-06 10:54:00\",\"2018-05-06 10:55:00\",\"2018-05-06 10:56:00\",\"2018-05-06 10:57:00\",\"2018-05-06 10:58:00\",\"2018-05-06 10:59:00\",\"2018-05-06 11:00:00\",\"2018-05-06 11:01:00\",\"2018-05-06 11:02:00\",\"2018-05-06 11:03:00\",\"2018-05-06 11:04:00\",\"2018-05-06 11:05:00\",\"2018-05-06 11:06:00\",\"2018-05-06 11:07:00\",\"2018-05-06 11:08:00\",\"2018-05-06 11:09:00\",\"2018-05-06 11:10:00\",\"2018-05-06 11:11:00\",\"2018-05-06 11:12:00\",\"2018-05-06 11:13:00\",\"2018-05-06 11:14:00\",\"2018-05-06 11:15:00\",\"2018-05-06 11:16:00\",\"2018-05-06 11:17:00\",\"2018-05-06 11:18:00\",\"2018-05-06 11:19:00\",\"2018-05-06 11:20:00\",\"2018-05-06 11:21:00\",\"2018-05-06 11:22:00\",\"2018-05-06 11:23:00\",\"2018-05-06 11:24:00\",\"2018-05-06 11:25:00\",\"2018-05-06 11:26:00\",\"2018-05-06 11:27:00\",\"2018-05-06 11:28:00\",\"2018-05-06 11:29:00\",\"2018-05-06 11:30:00\",\"2018-05-06 11:31:00\",\"2018-05-06 11:32:00\",\"2018-05-06 11:33:00\",\"2018-05-06 11:34:00\",\"2018-05-06 11:35:00\",\"2018-05-06 11:36:00\",\"2018-05-06 11:37:00\",\"2018-05-06 11:38:00\",\"2018-05-06 11:39:00\",\"2018-05-06 11:40:00\",\"2018-05-06 11:41:00\",\"2018-05-06 11:42:00\",\"2018-05-06 11:43:00\",\"2018-05-06 11:44:00\",\"2018-05-06 11:45:00\",\"2018-05-06 11:46:00\",\"2018-05-06 11:47:00\",\"2018-05-06 11:48:00\",\"2018-05-06 11:49:00\",\"2018-05-06 11:50:00\",\"2018-05-06 11:51:00\",\"2018-05-06 11:52:00\",\"2018-05-06 11:53:00\",\"2018-05-06 11:54:00\",\"2018-05-06 11:55:00\",\"2018-05-06 11:56:00\",\"2018-05-06 11:57:00\",\"2018-05-06 11:58:00\",\"2018-05-06 11:59:00\",\"2018-05-06 12:00:00\",\"2018-05-06 12:01:00\",\"2018-05-06 12:02:00\",\"2018-05-06 12:03:00\",\"2018-05-06 12:04:00\",\"2018-05-06 12:05:00\",\"2018-05-06 12:06:00\",\"2018-05-06 12:07:00\",\"2018-05-06 12:08:00\",\"2018-05-06 12:09:00\",\"2018-05-06 12:10:00\",\"2018-05-06 12:11:00\",\"2018-05-06 12:12:00\",\"2018-05-06 12:13:00\",\"2018-05-06 12:14:00\",\"2018-05-06 12:15:00\",\"2018-05-06 12:16:00\",\"2018-05-06 12:17:00\",\"2018-05-06 12:18:00\",\"2018-05-06 12:19:00\",\"2018-05-06 12:20:00\",\"2018-05-06 12:21:00\",\"2018-05-06 12:22:00\",\"2018-05-06 12:23:00\",\"2018-05-06 12:24:00\",\"2018-05-06 12:25:00\",\"2018-05-06 12:26:00\",\"2018-05-06 12:27:00\",\"2018-05-06 12:28:00\",\"2018-05-06 12:29:00\",\"2018-05-06 12:30:00\",\"2018-05-06 12:31:00\",\"2018-05-06 12:32:00\",\"2018-05-06 12:33:00\",\"2018-05-06 12:34:00\",\"2018-05-06 12:35:00\",\"2018-05-06 12:36:00\",\"2018-05-06 12:37:00\",\"2018-05-06 12:38:00\",\"2018-05-06 12:39:00\",\"2018-05-06 12:40:00\",\"2018-05-06 12:41:00\",\"2018-05-06 12:42:00\",\"2018-05-06 12:43:00\",\"2018-05-06 12:44:00\",\"2018-05-06 12:45:00\",\"2018-05-06 12:46:00\",\"2018-05-06 12:47:00\",\"2018-05-06 12:48:00\",\"2018-05-06 12:49:00\",\"2018-05-06 12:50:00\",\"2018-05-06 12:51:00\",\"2018-05-06 12:52:00\",\"2018-05-06 12:53:00\",\"2018-05-06 12:54:00\",\"2018-05-06 12:55:00\",\"2018-05-06 12:56:00\",\"2018-05-06 12:57:00\",\"2018-05-06 12:58:00\",\"2018-05-06 12:59:00\",\"2018-05-06 13:00:00\",\"2018-05-06 13:01:00\",\"2018-05-06 13:02:00\",\"2018-05-06 13:03:00\",\"2018-05-06 13:04:00\",\"2018-05-06 13:05:00\",\"2018-05-06 13:06:00\",\"2018-05-06 13:07:00\",\"2018-05-06 13:08:00\",\"2018-05-06 13:09:00\",\"2018-05-06 13:10:00\",\"2018-05-06 13:11:00\",\"2018-05-06 13:12:00\",\"2018-05-06 13:13:00\",\"2018-05-06 13:14:00\",\"2018-05-06 13:15:00\",\"2018-05-06 13:16:00\",\"2018-05-06 13:17:00\",\"2018-05-06 13:18:00\",\"2018-05-06 13:19:00\",\"2018-05-06 13:20:00\",\"2018-05-06 13:21:00\",\"2018-05-06 13:22:00\",\"2018-05-06 13:23:00\",\"2018-05-06 13:24:00\",\"2018-05-06 13:25:00\",\"2018-05-06 13:26:00\",\"2018-05-06 13:27:00\",\"2018-05-06 13:28:00\",\"2018-05-06 13:29:00\",\"2018-05-06 13:30:00\",\"2018-05-06 13:31:00\",\"2018-05-06 13:32:00\",\"2018-05-06 13:33:00\",\"2018-05-06 13:34:00\",\"2018-05-06 13:35:00\",\"2018-05-06 13:36:00\",\"2018-05-06 13:37:00\",\"2018-05-06 13:38:00\",\"2018-05-06 13:39:00\",\"2018-05-06 13:40:00\",\"2018-05-06 13:41:00\",\"2018-05-06 13:42:00\",\"2018-05-06 13:43:00\",\"2018-05-06 13:44:00\",\"2018-05-06 13:45:00\",\"2018-05-06 13:46:00\",\"2018-05-06 13:47:00\",\"2018-05-06 13:48:00\",\"2018-05-06 13:49:00\",\"2018-05-06 13:50:00\",\"2018-05-06 13:51:00\",\"2018-05-06 13:52:00\",\"2018-05-06 13:53:00\",\"2018-05-06 13:54:00\",\"2018-05-06 13:55:00\",\"2018-05-06 13:56:00\",\"2018-05-06 13:57:00\",\"2018-05-06 13:58:00\",\"2018-05-06 13:59:00\",\"2018-05-06 14:00:00\",\"2018-05-06 14:01:00\",\"2018-05-06 14:02:00\",\"2018-05-06 14:03:00\",\"2018-05-06 14:04:00\",\"2018-05-06 14:05:00\",\"2018-05-06 14:06:00\",\"2018-05-06 14:07:00\",\"2018-05-06 14:08:00\",\"2018-05-06 14:09:00\",\"2018-05-06 14:10:00\",\"2018-05-06 14:11:00\",\"2018-05-06 14:12:00\",\"2018-05-06 14:13:00\",\"2018-05-06 14:14:00\",\"2018-05-06 14:15:00\",\"2018-05-06 14:16:00\",\"2018-05-06 14:17:00\",\"2018-05-06 14:18:00\",\"2018-05-06 14:19:00\",\"2018-05-06 14:20:00\",\"2018-05-06 14:21:00\",\"2018-05-06 14:22:00\",\"2018-05-06 14:23:00\",\"2018-05-06 14:24:00\",\"2018-05-06 14:25:00\",\"2018-05-06 14:26:00\",\"2018-05-06 14:27:00\",\"2018-05-06 14:28:00\",\"2018-05-06 14:29:00\",\"2018-05-06 14:30:00\",\"2018-05-06 14:31:00\",\"2018-05-06 14:32:00\",\"2018-05-06 14:33:00\",\"2018-05-06 14:34:00\",\"2018-05-06 14:35:00\",\"2018-05-06 14:36:00\",\"2018-05-06 14:37:00\",\"2018-05-06 14:38:00\",\"2018-05-06 14:39:00\",\"2018-05-06 14:40:00\",\"2018-05-06 14:41:00\",\"2018-05-06 14:42:00\",\"2018-05-06 14:43:00\",\"2018-05-06 14:44:00\",\"2018-05-06 14:45:00\",\"2018-05-06 14:46:00\",\"2018-05-06 14:47:00\",\"2018-05-06 14:48:00\",\"2018-05-06 14:49:00\",\"2018-05-06 14:50:00\",\"2018-05-06 14:51:00\",\"2018-05-06 14:52:00\",\"2018-05-06 14:53:00\",\"2018-05-06 14:54:00\",\"2018-05-06 14:55:00\",\"2018-05-06 14:56:00\",\"2018-05-06 14:57:00\",\"2018-05-06 14:58:00\",\"2018-05-06 14:59:00\",\"2018-05-06 15:00:00\",\"2018-05-06 15:01:00\",\"2018-05-06 15:02:00\",\"2018-05-06 15:03:00\",\"2018-05-06 15:04:00\",\"2018-05-06 15:05:00\",\"2018-05-06 15:06:00\",\"2018-05-06 15:07:00\",\"2018-05-06 15:08:00\",\"2018-05-06 15:09:00\",\"2018-05-06 15:10:00\",\"2018-05-06 15:11:00\",\"2018-05-06 15:12:00\",\"2018-05-06 15:13:00\",\"2018-05-06 15:14:00\",\"2018-05-06 15:15:00\",\"2018-05-06 15:16:00\",\"2018-05-06 15:17:00\",\"2018-05-06 15:18:00\",\"2018-05-06 15:19:00\",\"2018-05-06 15:20:00\",\"2018-05-06 15:21:00\",\"2018-05-06 15:22:00\",\"2018-05-06 15:23:00\",\"2018-05-06 15:24:00\",\"2018-05-06 15:25:00\",\"2018-05-06 15:26:00\",\"2018-05-06 15:27:00\",\"2018-05-06 15:28:00\",\"2018-05-06 15:29:00\",\"2018-05-06 15:30:00\",\"2018-05-06 15:31:00\",\"2018-05-06 15:32:00\",\"2018-05-06 15:33:00\",\"2018-05-06 15:34:00\",\"2018-05-06 15:35:00\",\"2018-05-06 15:36:00\",\"2018-05-06 15:37:00\",\"2018-05-06 15:38:00\",\"2018-05-06 15:39:00\",\"2018-05-06 15:40:00\",\"2018-05-06 15:41:00\",\"2018-05-06 15:42:00\",\"2018-05-06 15:43:00\",\"2018-05-06 15:44:00\",\"2018-05-06 15:45:00\",\"2018-05-06 15:46:00\",\"2018-05-06 15:47:00\",\"2018-05-06 15:48:00\",\"2018-05-06 15:49:00\",\"2018-05-06 15:50:00\",\"2018-05-06 15:51:00\",\"2018-05-06 15:52:00\",\"2018-05-06 15:53:00\",\"2018-05-06 15:54:00\",\"2018-05-06 15:55:00\",\"2018-05-06 15:56:00\",\"2018-05-06 15:57:00\",\"2018-05-06 15:58:00\",\"2018-05-06 15:59:00\",\"2018-05-06 16:00:00\",\"2018-05-06 16:01:00\",\"2018-05-06 16:02:00\",\"2018-05-06 16:03:00\",\"2018-05-06 16:04:00\",\"2018-05-06 16:05:00\",\"2018-05-06 16:06:00\",\"2018-05-06 16:07:00\",\"2018-05-06 16:08:00\",\"2018-05-06 16:09:00\",\"2018-05-06 16:10:00\",\"2018-05-06 16:11:00\",\"2018-05-06 16:12:00\",\"2018-05-06 16:13:00\",\"2018-05-06 16:14:00\",\"2018-05-06 16:15:00\",\"2018-05-06 16:16:00\",\"2018-05-06 16:17:00\",\"2018-05-06 16:18:00\",\"2018-05-06 16:19:00\",\"2018-05-06 16:20:00\",\"2018-05-06 16:21:00\",\"2018-05-06 16:22:00\",\"2018-05-06 16:23:00\",\"2018-05-06 16:24:00\",\"2018-05-06 16:25:00\",\"2018-05-06 16:26:00\",\"2018-05-06 16:27:00\",\"2018-05-06 16:28:00\",\"2018-05-06 16:29:00\",\"2018-05-06 16:30:00\",\"2018-05-06 16:31:00\",\"2018-05-06 16:32:00\",\"2018-05-06 16:33:00\",\"2018-05-06 16:34:00\",\"2018-05-06 16:35:00\",\"2018-05-06 16:36:00\",\"2018-05-06 16:37:00\",\"2018-05-06 16:38:00\",\"2018-05-06 16:39:00\",\"2018-05-06 16:40:00\",\"2018-05-06 16:41:00\",\"2018-05-06 16:42:00\",\"2018-05-06 16:43:00\",\"2018-05-06 16:44:00\",\"2018-05-06 16:45:00\",\"2018-05-06 16:46:00\",\"2018-05-06 16:47:00\",\"2018-05-06 16:48:00\",\"2018-05-06 16:49:00\",\"2018-05-06 16:50:00\",\"2018-05-06 16:51:00\",\"2018-05-06 16:52:00\",\"2018-05-06 16:53:00\",\"2018-05-06 16:54:00\",\"2018-05-06 16:55:00\",\"2018-05-06 16:56:00\",\"2018-05-06 16:57:00\",\"2018-05-06 16:58:00\",\"2018-05-06 16:59:00\",\"2018-05-06 17:00:00\",\"2018-05-06 17:01:00\",\"2018-05-06 17:02:00\",\"2018-05-06 17:03:00\",\"2018-05-06 17:04:00\",\"2018-05-06 17:05:00\",\"2018-05-06 17:06:00\",\"2018-05-06 17:07:00\",\"2018-05-06 17:08:00\",\"2018-05-06 17:09:00\",\"2018-05-06 17:10:00\",\"2018-05-06 17:11:00\",\"2018-05-06 17:12:00\",\"2018-05-06 17:13:00\",\"2018-05-06 17:14:00\",\"2018-05-06 17:15:00\",\"2018-05-06 17:16:00\",\"2018-05-06 17:17:00\",\"2018-05-06 17:18:00\",\"2018-05-06 17:19:00\",\"2018-05-06 17:20:00\",\"2018-05-06 17:21:00\",\"2018-05-06 17:22:00\",\"2018-05-06 17:23:00\",\"2018-05-06 17:24:00\",\"2018-05-06 17:25:00\",\"2018-05-06 17:26:00\",\"2018-05-06 17:27:00\",\"2018-05-06 17:28:00\",\"2018-05-06 17:29:00\",\"2018-05-06 17:30:00\",\"2018-05-06 17:31:00\",\"2018-05-06 17:32:00\",\"2018-05-06 17:33:00\",\"2018-05-06 17:34:00\",\"2018-05-06 17:35:00\",\"2018-05-06 17:36:00\",\"2018-05-06 17:37:00\",\"2018-05-06 17:38:00\",\"2018-05-06 17:39:00\",\"2018-05-06 17:40:00\",\"2018-05-06 17:41:00\",\"2018-05-06 17:42:00\",\"2018-05-06 17:43:00\",\"2018-05-06 17:44:00\",\"2018-05-06 17:45:00\",\"2018-05-06 17:46:00\",\"2018-05-06 17:47:00\",\"2018-05-06 17:48:00\",\"2018-05-06 17:49:00\",\"2018-05-06 17:50:00\",\"2018-05-06 17:51:00\",\"2018-05-06 17:52:00\",\"2018-05-06 17:53:00\",\"2018-05-06 17:54:00\",\"2018-05-06 17:55:00\",\"2018-05-06 17:56:00\",\"2018-05-06 17:57:00\",\"2018-05-06 17:58:00\",\"2018-05-06 17:59:00\",\"2018-05-06 18:00:00\",\"2018-05-06 18:01:00\",\"2018-05-06 18:02:00\",\"2018-05-06 18:03:00\",\"2018-05-06 18:04:00\",\"2018-05-06 18:05:00\",\"2018-05-06 18:06:00\",\"2018-05-06 18:07:00\",\"2018-05-06 18:08:00\",\"2018-05-06 18:09:00\",\"2018-05-06 18:10:00\",\"2018-05-06 18:11:00\",\"2018-05-06 18:12:00\",\"2018-05-06 18:13:00\",\"2018-05-06 18:14:00\",\"2018-05-06 18:15:00\",\"2018-05-06 18:16:00\",\"2018-05-06 18:17:00\",\"2018-05-06 18:18:00\",\"2018-05-06 18:19:00\",\"2018-05-06 18:20:00\",\"2018-05-06 18:21:00\",\"2018-05-06 18:22:00\",\"2018-05-06 18:23:00\",\"2018-05-06 18:24:00\",\"2018-05-06 18:25:00\",\"2018-05-06 18:26:00\",\"2018-05-06 18:27:00\",\"2018-05-06 18:28:00\",\"2018-05-06 18:29:00\",\"2018-05-06 18:30:00\",\"2018-05-06 18:31:00\",\"2018-05-06 18:32:00\",\"2018-05-06 18:33:00\",\"2018-05-06 18:34:00\",\"2018-05-06 18:35:00\",\"2018-05-06 18:36:00\",\"2018-05-06 18:37:00\",\"2018-05-06 18:38:00\",\"2018-05-06 18:39:00\",\"2018-05-06 18:40:00\",\"2018-05-06 18:41:00\",\"2018-05-06 18:42:00\",\"2018-05-06 18:43:00\",\"2018-05-06 18:44:00\",\"2018-05-06 18:45:00\",\"2018-05-06 18:46:00\",\"2018-05-06 18:47:00\",\"2018-05-06 18:48:00\",\"2018-05-06 18:49:00\",\"2018-05-06 18:50:00\",\"2018-05-06 18:51:00\",\"2018-05-06 18:52:00\",\"2018-05-06 18:53:00\",\"2018-05-06 18:54:00\",\"2018-05-06 18:55:00\",\"2018-05-06 18:56:00\",\"2018-05-06 18:57:00\",\"2018-05-06 18:58:00\",\"2018-05-06 18:59:00\",\"2018-05-06 19:00:00\",\"2018-05-06 19:01:00\",\"2018-05-06 19:02:00\",\"2018-05-06 19:03:00\",\"2018-05-06 19:04:00\",\"2018-05-06 19:05:00\",\"2018-05-06 19:06:00\",\"2018-05-06 19:07:00\",\"2018-05-06 19:08:00\",\"2018-05-06 19:09:00\",\"2018-05-06 19:10:00\",\"2018-05-06 19:11:00\",\"2018-05-06 19:12:00\",\"2018-05-06 19:13:00\",\"2018-05-06 19:14:00\",\"2018-05-06 19:15:00\",\"2018-05-06 19:16:00\",\"2018-05-06 19:17:00\",\"2018-05-06 19:18:00\",\"2018-05-06 19:19:00\",\"2018-05-06 19:20:00\",\"2018-05-06 19:21:00\",\"2018-05-06 19:22:00\",\"2018-05-06 19:23:00\",\"2018-05-06 19:24:00\",\"2018-05-06 19:25:00\",\"2018-05-06 19:26:00\",\"2018-05-06 19:27:00\",\"2018-05-06 19:28:00\",\"2018-05-06 19:29:00\",\"2018-05-06 19:30:00\",\"2018-05-06 19:31:00\",\"2018-05-06 19:32:00\",\"2018-05-06 19:33:00\",\"2018-05-06 19:34:00\",\"2018-05-06 19:35:00\",\"2018-05-06 19:36:00\",\"2018-05-06 19:37:00\",\"2018-05-06 19:38:00\",\"2018-05-06 19:39:00\",\"2018-05-06 19:40:00\",\"2018-05-06 19:41:00\",\"2018-05-06 19:42:00\",\"2018-05-06 19:43:00\",\"2018-05-06 19:44:00\",\"2018-05-06 19:45:00\",\"2018-05-06 19:46:00\",\"2018-05-06 19:47:00\",\"2018-05-06 19:48:00\",\"2018-05-06 19:49:00\",\"2018-05-06 19:50:00\",\"2018-05-06 19:51:00\",\"2018-05-06 19:52:00\",\"2018-05-06 19:53:00\",\"2018-05-06 19:54:00\",\"2018-05-06 19:55:00\",\"2018-05-06 19:56:00\",\"2018-05-06 19:57:00\",\"2018-05-06 19:58:00\",\"2018-05-06 19:59:00\",\"2018-05-06 20:00:00\",\"2018-05-06 20:01:00\",\"2018-05-06 20:02:00\",\"2018-05-06 20:03:00\",\"2018-05-06 20:04:00\",\"2018-05-06 20:05:00\",\"2018-05-06 20:06:00\",\"2018-05-06 20:07:00\",\"2018-05-06 20:08:00\",\"2018-05-06 20:09:00\",\"2018-05-06 20:10:00\",\"2018-05-06 20:11:00\",\"2018-05-06 20:12:00\",\"2018-05-06 20:13:00\",\"2018-05-06 20:14:00\",\"2018-05-06 20:15:00\",\"2018-05-06 20:16:00\",\"2018-05-06 20:17:00\",\"2018-05-06 20:18:00\",\"2018-05-06 20:19:00\",\"2018-05-06 20:20:00\",\"2018-05-06 20:21:00\",\"2018-05-06 20:22:00\",\"2018-05-06 20:23:00\",\"2018-05-06 20:24:00\",\"2018-05-06 20:25:00\",\"2018-05-06 20:26:00\",\"2018-05-06 20:27:00\",\"2018-05-06 20:28:00\",\"2018-05-06 20:29:00\",\"2018-05-06 20:30:00\",\"2018-05-06 20:31:00\",\"2018-05-06 20:32:00\",\"2018-05-06 20:33:00\",\"2018-05-06 20:34:00\",\"2018-05-06 20:35:00\",\"2018-05-06 20:36:00\",\"2018-05-06 20:37:00\",\"2018-05-06 20:38:00\",\"2018-05-06 20:39:00\",\"2018-05-06 20:40:00\",\"2018-05-06 20:41:00\",\"2018-05-06 20:42:00\",\"2018-05-06 20:43:00\",\"2018-05-06 20:44:00\",\"2018-05-06 20:45:00\",\"2018-05-06 20:46:00\",\"2018-05-06 20:47:00\",\"2018-05-06 20:48:00\",\"2018-05-06 20:49:00\",\"2018-05-06 20:50:00\",\"2018-05-06 20:51:00\",\"2018-05-06 20:52:00\",\"2018-05-06 20:53:00\",\"2018-05-06 20:54:00\",\"2018-05-06 20:55:00\",\"2018-05-06 20:56:00\",\"2018-05-06 20:57:00\",\"2018-05-06 20:58:00\",\"2018-05-06 20:59:00\",\"2018-05-06 21:00:00\",\"2018-05-06 21:01:00\",\"2018-05-06 21:02:00\",\"2018-05-06 21:03:00\",\"2018-05-06 21:04:00\",\"2018-05-06 21:05:00\",\"2018-05-06 21:06:00\",\"2018-05-06 21:07:00\",\"2018-05-06 21:08:00\",\"2018-05-06 21:09:00\",\"2018-05-06 21:10:00\",\"2018-05-06 21:11:00\",\"2018-05-06 21:12:00\",\"2018-05-06 21:13:00\",\"2018-05-06 21:14:00\",\"2018-05-06 21:15:00\",\"2018-05-06 21:16:00\",\"2018-05-06 21:17:00\",\"2018-05-06 21:18:00\",\"2018-05-06 21:19:00\",\"2018-05-06 21:20:00\",\"2018-05-06 21:21:00\",\"2018-05-06 21:22:00\",\"2018-05-06 21:23:00\",\"2018-05-06 21:24:00\",\"2018-05-06 21:25:00\",\"2018-05-06 21:26:00\",\"2018-05-06 21:27:00\",\"2018-05-06 21:28:00\",\"2018-05-06 21:29:00\",\"2018-05-06 21:30:00\",\"2018-05-06 21:31:00\",\"2018-05-06 21:32:00\",\"2018-05-06 21:33:00\",\"2018-05-06 21:34:00\",\"2018-05-06 21:35:00\",\"2018-05-06 21:36:00\",\"2018-05-06 21:37:00\",\"2018-05-06 21:38:00\",\"2018-05-06 21:39:00\",\"2018-05-06 21:40:00\",\"2018-05-06 21:41:00\",\"2018-05-06 21:42:00\",\"2018-05-06 21:43:00\",\"2018-05-06 21:44:00\",\"2018-05-06 21:45:00\",\"2018-05-06 21:46:00\",\"2018-05-06 21:47:00\",\"2018-05-06 21:48:00\",\"2018-05-06 21:49:00\",\"2018-05-06 21:50:00\",\"2018-05-06 21:51:00\",\"2018-05-06 21:52:00\",\"2018-05-06 21:53:00\",\"2018-05-06 21:54:00\",\"2018-05-06 21:55:00\",\"2018-05-06 21:56:00\",\"2018-05-06 21:57:00\",\"2018-05-06 21:58:00\",\"2018-05-06 21:59:00\",\"2018-05-06 22:00:00\",\"2018-05-06 22:01:00\",\"2018-05-06 22:02:00\",\"2018-05-06 22:03:00\",\"2018-05-06 22:04:00\",\"2018-05-06 22:05:00\",\"2018-05-06 22:06:00\",\"2018-05-06 22:07:00\",\"2018-05-06 22:08:00\",\"2018-05-06 22:09:00\",\"2018-05-06 22:10:00\",\"2018-05-06 22:11:00\",\"2018-05-06 22:12:00\",\"2018-05-06 22:13:00\",\"2018-05-06 22:14:00\",\"2018-05-06 22:15:00\",\"2018-05-06 22:16:00\",\"2018-05-06 22:17:00\",\"2018-05-06 22:18:00\",\"2018-05-06 22:19:00\",\"2018-05-06 22:20:00\",\"2018-05-06 22:21:00\",\"2018-05-06 22:22:00\",\"2018-05-06 22:23:00\",\"2018-05-06 22:24:00\",\"2018-05-06 22:25:00\",\"2018-05-06 22:26:00\",\"2018-05-06 22:27:00\",\"2018-05-06 22:28:00\",\"2018-05-06 22:29:00\",\"2018-05-06 22:30:00\",\"2018-05-06 22:31:00\",\"2018-05-06 22:32:00\",\"2018-05-06 22:33:00\",\"2018-05-06 22:34:00\",\"2018-05-06 22:35:00\",\"2018-05-06 22:36:00\",\"2018-05-06 22:37:00\",\"2018-05-06 22:38:00\",\"2018-05-06 22:39:00\",\"2018-05-06 22:40:00\",\"2018-05-06 22:41:00\",\"2018-05-06 22:42:00\",\"2018-05-06 22:43:00\",\"2018-05-06 22:44:00\",\"2018-05-06 22:45:00\",\"2018-05-06 22:46:00\",\"2018-05-06 22:47:00\",\"2018-05-06 22:48:00\",\"2018-05-06 22:49:00\",\"2018-05-06 22:50:00\",\"2018-05-06 22:51:00\",\"2018-05-06 22:52:00\",\"2018-05-06 22:53:00\",\"2018-05-06 22:54:00\",\"2018-05-06 22:55:00\",\"2018-05-06 22:56:00\",\"2018-05-06 22:57:00\",\"2018-05-06 22:58:00\",\"2018-05-06 22:59:00\",\"2018-05-06 23:00:00\",\"2018-05-06 23:01:00\",\"2018-05-06 23:02:00\",\"2018-05-06 23:03:00\",\"2018-05-06 23:04:00\",\"2018-05-06 23:05:00\",\"2018-05-06 23:06:00\",\"2018-05-06 23:07:00\",\"2018-05-06 23:08:00\",\"2018-05-06 23:09:00\",\"2018-05-06 23:10:00\",\"2018-05-06 23:11:00\",\"2018-05-06 23:12:00\",\"2018-05-06 23:13:00\",\"2018-05-06 23:14:00\",\"2018-05-06 23:15:00\",\"2018-05-06 23:16:00\",\"2018-05-06 23:17:00\",\"2018-05-06 23:18:00\",\"2018-05-06 23:19:00\",\"2018-05-06 23:20:00\",\"2018-05-06 23:21:00\",\"2018-05-06 23:22:00\",\"2018-05-06 23:23:00\",\"2018-05-06 23:24:00\",\"2018-05-06 23:25:00\",\"2018-05-06 23:26:00\",\"2018-05-06 23:27:00\",\"2018-05-06 23:28:00\",\"2018-05-06 23:29:00\",\"2018-05-06 23:30:00\",\"2018-05-06 23:31:00\",\"2018-05-06 23:32:00\",\"2018-05-06 23:33:00\",\"2018-05-06 23:34:00\",\"2018-05-06 23:35:00\",\"2018-05-06 23:36:00\",\"2018-05-06 23:37:00\",\"2018-05-06 23:38:00\",\"2018-05-06 23:39:00\",\"2018-05-06 23:40:00\",\"2018-05-06 23:41:00\",\"2018-05-06 23:42:00\",\"2018-05-06 23:43:00\",\"2018-05-06 23:44:00\",\"2018-05-06 23:45:00\",\"2018-05-06 23:46:00\",\"2018-05-06 23:47:00\",\"2018-05-06 23:48:00\",\"2018-05-06 23:49:00\",\"2018-05-06 23:50:00\",\"2018-05-06 23:51:00\",\"2018-05-06 23:52:00\",\"2018-05-06 23:53:00\",\"2018-05-06 23:54:00\",\"2018-05-06 23:55:00\",\"2018-05-06 23:56:00\",\"2018-05-06 23:57:00\",\"2018-05-06 23:58:00\",\"2018-05-06 23:59:00\"],\"xaxis\":\"x\",\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.07273798435926437,0.07346320897340775,0.07839473336935043,0.0761810690164566,0.07725405693054199,0.08062282204627991,0.08679318428039551,0.08834432065486908,0.09093552082777023,0.09040738642215729,0.09093835204839706,0.09090685844421387,0.09092118591070175,0.09648334980010986,0.0940069928765297,0.09274616092443466,0.09347319602966309,0.09659209102392197,0.09698954224586487,0.09634815156459808,0.09713172912597656,0.09676861017942429,0.10333032160997391,0.09578153491020203,0.09673551470041275,0.10058383643627167,0.09324333071708679,0.09243648499250412,0.09199541807174683,0.08768434822559357,0.09223820269107819,0.08765939623117447,0.08593007177114487,0.08391955494880676,0.08132561296224594,0.08496865630149841,0.08231127262115479,0.08347273617982864,0.08177437633275986,0.08123473823070526,0.08123651146888733,0.08046381920576096,0.08125393837690353,0.07903682440519333,0.079274483025074,0.07848374545574188,0.08097231388092041,0.09310388565063477,0.10102880001068115,0.09709960967302322,0.0934571847319603,0.09745025634765625,0.09484108537435532,0.09450875967741013,0.09309618920087814,0.09321226924657822,0.09105930477380753,0.09403929114341736,0.08469852805137634,0.09135624021291733,0.08610136806964874,0.0867232009768486,0.08096443861722946,0.08308448642492294,0.08108016848564148,0.08476293832063675,0.08097115904092789,0.0814218744635582,0.08274348825216293,0.08371233940124512,0.08450113236904144,0.08310484141111374,0.08462933450937271,0.08446229249238968,0.08175075054168701,0.08475055545568466,0.0844322070479393,0.08732981234788895,0.08877220749855042,0.09052418172359467,0.08903728425502777,0.08786732703447342,0.08443097025156021,0.0846942812204361,0.08106663078069687,0.07927253842353821,0.08137144148349762,0.07903028279542923,0.0767473354935646,0.07797303795814514,0.08130216598510742,0.08105053007602692,0.08099106699228287,0.08051266521215439,0.07851594686508179,0.07582582533359528,0.07582945376634598,0.06470920145511627,0.0660819560289383,0.055582690984010696,0.056099630892276764,0.05180104449391365,0.03451944515109062,0.044870950281620026,0.04452880099415779,0.047711972147226334,0.04874337464570999,0.0424814336001873,0.03390035778284073,0.021707026287913322,-0.0011062540579587221,-0.012535035610198975,-0.009737320244312286,0.02177758887410164,0.016743779182434082,0.0221941489726305,0.004373755306005478,0.0005315418820828199,-0.0077432626858353615,-0.0010199424577876925,-0.008711181581020355,-0.019260214641690254,-0.03416742756962776,-0.04450884088873863,-0.05920817703008652,-0.056724295020103455,-0.05766867846250534,-0.0648040920495987,-0.06463982909917831,-0.027844475582242012,-0.02486480213701725,-0.025650719180703163,0.004772354383021593,-0.02054581791162491,-0.03752145543694496,-0.04229889437556267,-0.023887326940894127,-0.013337587006390095,-0.020524317398667336,-0.01016082614660263,-0.009632074274122715,-0.021750906482338905,-0.02361220121383667,-0.017449574545025826,-0.017494168132543564,-0.02871342934668064,-0.03918831795454025,-0.04250779375433922,-0.050956860184669495,-0.07699587196111679,-0.07814924418926239,-0.05361030995845795,-0.06195979192852974,-0.07902611792087555,-0.04783283546566963,-0.04517048969864845,-0.03932245075702667,-0.03884262964129448,-0.05913880839943886,-0.0647595003247261,-0.06521096080541611,-0.07506924122571945,-0.07527318596839905,-0.07440431416034698,-0.08826583623886108,-0.09261556714773178,-0.10661166161298752,-0.11185242235660553,-0.1235114336013794,-0.12407305091619492,-0.1810973435640335,-0.20420609414577484,-0.16975420713424683,-0.14383843541145325,-0.14039607346057892,-0.15426762402057648,-0.16245262324810028,-0.1631338745355606,-0.1817663311958313,-0.18507324159145355,-0.185387521982193,-0.24971213936805725,-0.3028830885887146,-0.24272356927394867,-0.23757463693618774,-0.26930782198905945,-0.25906842947006226,-0.2380574345588684,-0.2014380693435669,-0.20683680474758148,-0.21073126792907715,-0.24517174065113068,-0.2364705353975296,-0.26751235127449036,-0.29232072830200195,-0.3000360429286957,-0.3089684844017029,-0.33522242307662964,-0.33750876784324646,-0.33150598406791687,-0.28035950660705566,-0.29355552792549133,-0.2603611648082733,-0.2815530002117157,-0.26861143112182617,-0.24961552023887634,-0.22388043999671936,-0.2282802015542984,-0.2477215975522995,-0.24807098507881165,-0.2253972440958023,-0.19930903613567352,-0.19581861793994904,-0.17680636048316956,-0.1617271900177002,-0.17355850338935852,-0.18374942243099213,-0.2018224596977234,-0.1862974911928177,-0.1764904409646988,-0.18066741526126862,-0.19204077124595642,-0.19078463315963745,-0.1876518428325653,-0.19077953696250916,-0.18987439572811127,-0.19076843559741974,-0.2261018604040146,-0.22274285554885864,-0.21350641548633575,-0.22602778673171997,-0.22654087841510773,-0.22671279311180115,-0.22659878432750702,-0.22027185559272766,-0.2070726752281189,-0.2158905416727066,-0.20793549716472626,-0.20942364633083344,-0.206541046500206,-0.20512598752975464,-0.21793140470981598,-0.22784385085105896,-0.22313036024570465,-0.2076171487569809,-0.2047412097454071,-0.1947459727525711,-0.1774519979953766,-0.17778369784355164,-0.16915537416934967,-0.16198240220546722,-0.1649119108915329,-0.15068665146827698,-0.15475961565971375,-0.1502620428800583,-0.1368490606546402,-0.14568792283535004,-0.1536823809146881,-0.1832437515258789,-0.18184241652488708,-0.19056396186351776,-0.1906070113182068,-0.18812693655490875,-0.19654688239097595,-0.17743881046772003,-0.17103692889213562,-0.1712152659893036,-0.1713647097349167,-0.17643558979034424,-0.17931191623210907,-0.18363916873931885,-0.19050197303295135,-0.20488762855529785,-0.19058890640735626,-0.1774812787771225,-0.17771242558956146,-0.1778615117073059,-0.16763357818126678,-0.15471936762332916,-0.1447526514530182,-0.1460886001586914,-0.13893535733222961,-0.14914153516292572,-0.15008676052093506,-0.1429770141839981,-0.13440340757369995,-0.15981461107730865,-0.1573045551776886,-0.15434487164020538,-0.14306442439556122,-0.14096608757972717,-0.1372263878583908,-0.15284103155136108,-0.16149559617042542,-0.15866482257843018,-0.17503412067890167,-0.17509609460830688,-0.18630319833755493,-0.2053736299276352,-0.2052289992570877,-0.2050778865814209,-0.20815955102443695,-0.21241265535354614,-0.21626688539981842,-0.2271253764629364,-0.21792131662368774,-0.2386564165353775,-0.21850578486919403,-0.2309315800666809,-0.23218652606010437,-0.2587645351886749,-0.29543954133987427,-0.27123308181762695,-0.26437318325042725,-0.2534313499927521,-0.2689138352870941,-0.26579535007476807,-0.26861438155174255,-0.2580360472202301,-0.25960075855255127,-0.2555682361125946,-0.2543192207813263,-0.25247424840927124,-0.24322648346424103,-0.23158061504364014,-0.24092021584510803,-0.2510814368724823,-0.25073549151420593,-0.2763937711715698,-0.27540308237075806,-0.2862064838409424,-0.3418335020542145,-0.33847296237945557,-0.34271228313446045,-0.32682690024375916,-0.3417097330093384,-0.3521651029586792,-0.35088014602661133,-0.3472875654697418,-0.30757632851600647,-0.33488911390304565,-0.34493502974510193,-0.3296826481819153,-0.3169460892677307,-0.295726478099823,-0.2856404483318329,-0.29741308093070984,-0.3275783956050873,-0.30833128094673157,-0.32883381843566895,-0.32802730798721313,-0.3119405210018158,-0.2924700081348419,-0.2924532890319824,-0.3052905797958374,-0.2946419417858124,-0.2879171371459961,-0.33251044154167175,-0.3204718828201294,-0.29716289043426514,-0.3263843059539795,-0.3020962178707123,-0.28375035524368286,-0.26993295550346375,-0.2815808057785034,-0.2833390235900879,-0.251530259847641,-0.2519906759262085,-0.25848543643951416,-0.268545538187027,-0.2785334885120392,-0.2742399275302887,-0.2740088403224945,-0.27357885241508484,-0.2753608226776123,-0.28050872683525085,-0.28397539258003235,-0.3030059039592743,-0.29600295424461365,-0.29112115502357483,-0.2803129255771637,-0.2808728814125061,-0.28177130222320557,-0.31308791041374207,-0.32892176508903503,-0.34479832649230957,-0.3415045738220215,-0.3419017195701599,-0.3458176553249359,-0.35543495416641235,-0.32224947214126587,-0.3237232565879822,-0.33451560139656067,-0.3377375602722168,-0.31042394042015076,-0.321165531873703,-0.3142603635787964,-0.31989210844039917,-0.29683926701545715,-0.29793450236320496,-0.3251611888408661,-0.318394273519516,-0.30531585216522217,-0.28595778346061707,-0.2945607602596283,-0.30266502499580383,-0.28600072860717773,-0.283394455909729,-0.2809962034225464,-0.2659653425216675,-0.23767410218715668,-0.23913919925689697,-0.23851504921913147,-0.2552219033241272,-0.2430349886417389,-0.25355803966522217,-0.25502949953079224,-0.251467227935791,-0.24042688310146332,-0.24177652597427368,-0.26123979687690735,-0.25778093934059143,-0.2544936239719391,-0.248227059841156,-0.2562480568885803,-0.25622567534446716,-0.2770187556743622,-0.28063058853149414,-0.2784329950809479,-0.2646692991256714,-0.27426877617836,-0.2615830898284912,-0.24745890498161316,-0.2542221248149872,-0.25895896553993225,-0.25879836082458496,-0.2607021927833557,-0.2543213963508606,-0.2543533146381378,-0.23957456648349762,-0.22519882023334503,-0.22887995839118958,-0.23362997174263,-0.24257194995880127,-0.24825747311115265,-0.24794290959835052,-0.23282507061958313,-0.22134988009929657,-0.216763436794281,-0.21778200566768646,-0.21789447963237762,-0.2357824146747589,-0.24652764201164246,-0.2557440400123596,-0.27005451917648315,-0.2767045199871063,-0.29083049297332764,-0.2812812328338623,-0.28677934408187866,-0.2863537073135376,-0.28924331068992615,-0.3029119372367859,-0.31367215514183044,-0.3138371706008911,-0.3012818694114685,-0.294182687997818,-0.30744922161102295,-0.3255529999732971,-0.3411938548088074,-0.3539760112762451,-0.3485018312931061,-0.3477560579776764,-0.34232351183891296,-0.36218568682670593,-0.3660150468349457,-0.374226838350296,-0.37870872020721436,-0.3356054425239563,-0.3216569721698761,-0.33631715178489685,-0.33401352167129517,-0.33858588337898254,-0.33661144971847534,-0.3340015411376953,-0.3270215094089508,-0.31282901763916016,-0.3043188154697418,-0.2871183454990387,-0.30659380555152893,-0.3092867136001587,-0.3310920000076294,-0.32968348264694214,-0.32878175377845764,-0.33438071608543396,-0.3353276252746582,-0.3455357551574707,-0.3407953977584839,-0.3163209557533264,-0.3242567479610443,-0.3267851769924164,-0.3184351623058319,-0.3229273557662964,-0.30676698684692383,-0.3001856803894043,-0.2937423586845398,-0.294573575258255,-0.29504019021987915,-0.32466986775398254,-0.32272961735725403,-0.32765358686447144,-0.32917866110801697,-0.3360130190849304,-0.34391844272613525,-0.33154183626174927,-0.33054253458976746,-0.3494999408721924,-0.39454981684684753,-0.3874204754829407,-0.40778452157974243,-0.3951460123062134,-0.40992528200149536,-0.4212862253189087,-0.4278019368648529,-0.4116474688053131,-0.39091381430625916,-0.3796117305755615,-0.40947920083999634,-0.399011492729187,-0.40024834871292114,-0.40172722935676575,-0.40576204657554626,-0.40533408522605896,-0.3995371460914612,-0.4327615201473236,-0.4368187189102173,-0.43050023913383484,-0.44323787093162537,-0.4484008848667145,-0.4404158890247345,-0.4417119324207306,-0.45572060346603394,-0.45486900210380554,-0.47892194986343384,-0.49578216671943665,-0.5116331577301025,-0.492735356092453,-0.4820891320705414,-0.457425594329834,-0.44703230261802673,-0.46370184421539307,-0.4574107527732849,-0.44837749004364014,-0.43867912888526917,-0.4373410642147064,-0.43151456117630005,-0.42819491028785706,-0.3980448544025421,-0.4273030161857605,-0.4278092682361603,-0.42160335183143616,-0.4150569438934326,-0.40477922558784485,-0.40528932213783264,-0.3859495222568512,-0.3901270925998688,-0.3802243173122406,-0.39278754591941833,-0.4038107693195343,-0.4232475161552429,-0.41685324907302856,-0.39775535464286804,-0.380794495344162,-0.37591826915740967,-0.3890407085418701,-0.3902818560600281,-0.3871591091156006,-0.3858731985092163,-0.38748109340667725,-0.3751344084739685,-0.37704429030418396,-0.3785667419433594,-0.39041566848754883,-0.3881930708885193,-0.38695594668388367,-0.3833611011505127,-0.3906477093696594,-0.40353924036026,-0.41661784052848816,-0.39382514357566833,-0.39733922481536865,-0.40497714281082153,-0.39448925852775574,-0.38477131724357605,-0.37659117579460144,-0.37296685576438904,-0.36465245485305786,-0.36291632056236267,-0.3450152575969696,-0.3453496992588043,-0.3465346693992615,-0.34507429599761963,-0.35727864503860474,-0.3393577039241791,-0.34735971689224243,-0.3488045036792755,-0.34715408086776733,-0.3485623300075531,-0.3541613817214966,-0.349515825510025,-0.3428106904029846,-0.3225342333316803,-0.32480764389038086,-0.32722461223602295,-0.31339332461357117,-0.3362126350402832,-0.34878095984458923,-0.35599538683891296,-0.3433113694190979,-0.33308351039886475,-0.3337540626525879,-0.34009090065956116,-0.33560624718666077,-0.33364138007164,-0.31974464654922485,-0.2925373911857605,-0.28562667965888977,-0.27168384194374084,-0.2762683629989624,-0.28229907155036926,-0.30343249440193176,-0.3327634632587433,-0.3158579468727112,-0.32841137051582336,-0.32780125737190247,-0.3242231607437134,-0.32286232709884644,-0.31408658623695374,-0.3203330338001251,-0.3116917610168457,-0.3156980872154236,-0.31384652853012085,-0.33261388540267944,-0.3437364399433136,-0.34956714510917664,-0.3700798451900482,-0.35923805832862854,-0.3571855425834656,-0.345540314912796,-0.35222727060317993,-0.3538353145122528,-0.359214723110199,-0.3607756793498993,-0.36713311076164246,-0.37709441781044006,-0.3710038661956787,-0.3835518956184387,-0.3839748799800873,-0.38320496678352356,-0.3894656002521515,-0.38365399837493896,-0.3610958456993103,-0.3568542003631592,-0.33965423703193665,-0.3195636570453644,-0.3262035846710205,-0.33401763439178467,-0.3394452929496765,-0.3489365875720978,-0.3485414385795593,-0.3490177094936371,-0.34436821937561035,-0.3354337215423584,-0.33074378967285156,-0.33143937587738037,-0.32116469740867615,-0.32649660110473633,-0.33270198106765747,-0.33530914783477783,-0.33321234583854675,-0.34069114923477173,-0.34503424167633057,-0.3585333228111267,-0.36165034770965576,-0.36773091554641724,-0.35950398445129395,-0.33791086077690125,-0.33722686767578125,-0.3330141603946686,-0.33889028429985046,-0.32966187596321106,-0.3300197422504425,-0.33775192499160767,-0.32448115944862366,-0.32128679752349854,-0.3003612458705902,-0.3077008128166199,-0.3083072006702423,-0.3084550201892853,-0.29519209265708923,-0.3018103539943695,-0.31073933839797974,-0.32473617792129517,-0.33750465512275696,-0.3569967746734619,-0.3387366831302643,-0.3434004485607147,-0.32795417308807373,-0.3233708143234253,-0.31838172674179077,-0.3286041021347046,-0.34169185161590576,-0.3318726420402527,-0.3401218056678772,-0.363576203584671,-0.3760257959365845,-0.3737788200378418,-0.372665673494339,-0.37203025817871094,-0.36774107813835144,-0.3774474561214447,-0.3862900137901306,-0.4184054434299469,-0.40437230467796326,-0.39722850918769836,-0.3941158354282379,-0.3755474090576172,-0.3801281452178955,-0.3809542655944824,-0.3726971745491028,-0.3818516433238983,-0.3814910352230072,-0.3845028579235077,-0.3982667028903961,-0.40256381034851074,-0.4012623429298401,-0.39498263597488403,-0.400951623916626,-0.4064720571041107,-0.401306688785553,-0.4040564298629761,-0.4249686598777771,-0.44465065002441406,-0.4211166799068451,-0.39637497067451477,-0.40617263317108154,-0.4012424051761627,-0.382725328207016,-0.392598420381546,-0.3815595507621765,-0.3842824399471283,-0.3862817883491516,-0.38762176036834717,-0.38819605112075806,-0.3957294821739197,-0.38816037774086,-0.3953035771846771,-0.39340734481811523,-0.4017504155635834,-0.39615240693092346,-0.4078851044178009,-0.4083944857120514,-0.40214329957962036,-0.40650197863578796,-0.4213939905166626,-0.4182628095149994,-0.4138428568840027,-0.41605526208877563,-0.4137229323387146,-0.4080447256565094,-0.406878262758255,-0.3928301930427551,-0.39005813002586365,-0.38965436816215515,-0.3818461000919342,-0.3630160689353943,-0.3533935844898224,-0.35487377643585205,-0.3535289466381073,-0.34395521879196167,-0.3244394063949585,-0.3181295692920685,-0.2818816900253296,-0.29959192872047424,-0.30911770462989807,-0.3329443633556366,-0.3325301706790924,-0.31143635511398315,-0.3219021260738373,-0.31903478503227234,-0.3145989775657654,-0.3138450086116791,-0.31510940194129944,-0.3092690110206604,-0.30958741903305054,-0.30089613795280457,-0.29103904962539673,-0.30968788266181946,-0.3090496361255646,-0.30525439977645874,-0.30007433891296387,-0.2993471622467041,-0.2947045862674713,-0.2965739071369171,-0.30255600810050964,-0.3120647668838501,-0.323239803314209,-0.3228893280029297,-0.32262933254241943,-0.32234683632850647,-0.3218127191066742,-0.3090589940547943,-0.30972808599472046,-0.3290114402770996,-0.2891342341899872,-0.30120885372161865,-0.2944639027118683,-0.28742682933807373,-0.29553794860839844,-0.2970356345176697,-0.30124539136886597,-0.2980715334415436,-0.3085891306400299,-0.30944734811782837,-0.30977070331573486,-0.30879250168800354,-0.309675008058548,-0.31013721227645874,-0.3233765661716461,-0.31083160638809204,-0.2999568283557892,-0.29935142397880554,-0.2998814582824707,-0.2996692657470703,-0.2872999906539917,-0.2805684506893158,-0.2879883348941803,-0.29328975081443787,-0.30342867970466614,-0.2923668324947357,-0.28574708104133606,-0.2750624418258667,-0.27638834714889526,-0.27464818954467773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"variable=test_predicted_close\\u003cbr\\u003eDate=%{x}\\u003cbr\\u003eStock price=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"test_predicted_close\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Test predicted close price\",\"showlegend\":true,\"x\":[\"2018-05-06 00:00:00\",\"2018-05-06 00:01:00\",\"2018-05-06 00:02:00\",\"2018-05-06 00:03:00\",\"2018-05-06 00:04:00\",\"2018-05-06 00:05:00\",\"2018-05-06 00:06:00\",\"2018-05-06 00:07:00\",\"2018-05-06 00:08:00\",\"2018-05-06 00:09:00\",\"2018-05-06 00:10:00\",\"2018-05-06 00:11:00\",\"2018-05-06 00:12:00\",\"2018-05-06 00:13:00\",\"2018-05-06 00:14:00\",\"2018-05-06 00:15:00\",\"2018-05-06 00:16:00\",\"2018-05-06 00:17:00\",\"2018-05-06 00:18:00\",\"2018-05-06 00:19:00\",\"2018-05-06 00:20:00\",\"2018-05-06 00:21:00\",\"2018-05-06 00:22:00\",\"2018-05-06 00:23:00\",\"2018-05-06 00:24:00\",\"2018-05-06 00:25:00\",\"2018-05-06 00:26:00\",\"2018-05-06 00:27:00\",\"2018-05-06 00:28:00\",\"2018-05-06 00:29:00\",\"2018-05-06 00:30:00\",\"2018-05-06 00:31:00\",\"2018-05-06 00:32:00\",\"2018-05-06 00:33:00\",\"2018-05-06 00:34:00\",\"2018-05-06 00:35:00\",\"2018-05-06 00:36:00\",\"2018-05-06 00:37:00\",\"2018-05-06 00:38:00\",\"2018-05-06 00:39:00\",\"2018-05-06 00:40:00\",\"2018-05-06 00:41:00\",\"2018-05-06 00:42:00\",\"2018-05-06 00:43:00\",\"2018-05-06 00:44:00\",\"2018-05-06 00:45:00\",\"2018-05-06 00:46:00\",\"2018-05-06 00:47:00\",\"2018-05-06 00:48:00\",\"2018-05-06 00:49:00\",\"2018-05-06 00:50:00\",\"2018-05-06 00:51:00\",\"2018-05-06 00:52:00\",\"2018-05-06 00:53:00\",\"2018-05-06 00:54:00\",\"2018-05-06 00:55:00\",\"2018-05-06 00:56:00\",\"2018-05-06 00:57:00\",\"2018-05-06 00:58:00\",\"2018-05-06 00:59:00\",\"2018-05-06 01:00:00\",\"2018-05-06 01:01:00\",\"2018-05-06 01:02:00\",\"2018-05-06 01:03:00\",\"2018-05-06 01:04:00\",\"2018-05-06 01:05:00\",\"2018-05-06 01:06:00\",\"2018-05-06 01:07:00\",\"2018-05-06 01:08:00\",\"2018-05-06 01:09:00\",\"2018-05-06 01:10:00\",\"2018-05-06 01:11:00\",\"2018-05-06 01:12:00\",\"2018-05-06 01:13:00\",\"2018-05-06 01:14:00\",\"2018-05-06 01:15:00\",\"2018-05-06 01:16:00\",\"2018-05-06 01:17:00\",\"2018-05-06 01:18:00\",\"2018-05-06 01:19:00\",\"2018-05-06 01:20:00\",\"2018-05-06 01:21:00\",\"2018-05-06 01:22:00\",\"2018-05-06 01:23:00\",\"2018-05-06 01:24:00\",\"2018-05-06 01:25:00\",\"2018-05-06 01:26:00\",\"2018-05-06 01:27:00\",\"2018-05-06 01:28:00\",\"2018-05-06 01:29:00\",\"2018-05-06 01:30:00\",\"2018-05-06 01:31:00\",\"2018-05-06 01:32:00\",\"2018-05-06 01:33:00\",\"2018-05-06 01:34:00\",\"2018-05-06 01:35:00\",\"2018-05-06 01:36:00\",\"2018-05-06 01:37:00\",\"2018-05-06 01:38:00\",\"2018-05-06 01:39:00\",\"2018-05-06 01:40:00\",\"2018-05-06 01:41:00\",\"2018-05-06 01:42:00\",\"2018-05-06 01:43:00\",\"2018-05-06 01:44:00\",\"2018-05-06 01:45:00\",\"2018-05-06 01:46:00\",\"2018-05-06 01:47:00\",\"2018-05-06 01:48:00\",\"2018-05-06 01:49:00\",\"2018-05-06 01:50:00\",\"2018-05-06 01:51:00\",\"2018-05-06 01:52:00\",\"2018-05-06 01:53:00\",\"2018-05-06 01:54:00\",\"2018-05-06 01:55:00\",\"2018-05-06 01:56:00\",\"2018-05-06 01:57:00\",\"2018-05-06 01:58:00\",\"2018-05-06 01:59:00\",\"2018-05-06 02:00:00\",\"2018-05-06 02:01:00\",\"2018-05-06 02:02:00\",\"2018-05-06 02:03:00\",\"2018-05-06 02:04:00\",\"2018-05-06 02:05:00\",\"2018-05-06 02:06:00\",\"2018-05-06 02:07:00\",\"2018-05-06 02:08:00\",\"2018-05-06 02:09:00\",\"2018-05-06 02:10:00\",\"2018-05-06 02:11:00\",\"2018-05-06 02:12:00\",\"2018-05-06 02:13:00\",\"2018-05-06 02:14:00\",\"2018-05-06 02:15:00\",\"2018-05-06 02:16:00\",\"2018-05-06 02:17:00\",\"2018-05-06 02:18:00\",\"2018-05-06 02:19:00\",\"2018-05-06 02:20:00\",\"2018-05-06 02:21:00\",\"2018-05-06 02:22:00\",\"2018-05-06 02:23:00\",\"2018-05-06 02:24:00\",\"2018-05-06 02:25:00\",\"2018-05-06 02:26:00\",\"2018-05-06 02:27:00\",\"2018-05-06 02:28:00\",\"2018-05-06 02:29:00\",\"2018-05-06 02:30:00\",\"2018-05-06 02:31:00\",\"2018-05-06 02:32:00\",\"2018-05-06 02:33:00\",\"2018-05-06 02:34:00\",\"2018-05-06 02:35:00\",\"2018-05-06 02:36:00\",\"2018-05-06 02:37:00\",\"2018-05-06 02:38:00\",\"2018-05-06 02:39:00\",\"2018-05-06 02:40:00\",\"2018-05-06 02:41:00\",\"2018-05-06 02:42:00\",\"2018-05-06 02:43:00\",\"2018-05-06 02:44:00\",\"2018-05-06 02:45:00\",\"2018-05-06 02:46:00\",\"2018-05-06 02:47:00\",\"2018-05-06 02:48:00\",\"2018-05-06 02:49:00\",\"2018-05-06 02:50:00\",\"2018-05-06 02:51:00\",\"2018-05-06 02:52:00\",\"2018-05-06 02:53:00\",\"2018-05-06 02:54:00\",\"2018-05-06 02:55:00\",\"2018-05-06 02:56:00\",\"2018-05-06 02:57:00\",\"2018-05-06 02:58:00\",\"2018-05-06 02:59:00\",\"2018-05-06 03:00:00\",\"2018-05-06 03:01:00\",\"2018-05-06 03:02:00\",\"2018-05-06 03:03:00\",\"2018-05-06 03:04:00\",\"2018-05-06 03:05:00\",\"2018-05-06 03:06:00\",\"2018-05-06 03:07:00\",\"2018-05-06 03:08:00\",\"2018-05-06 03:09:00\",\"2018-05-06 03:10:00\",\"2018-05-06 03:11:00\",\"2018-05-06 03:12:00\",\"2018-05-06 03:13:00\",\"2018-05-06 03:14:00\",\"2018-05-06 03:15:00\",\"2018-05-06 03:16:00\",\"2018-05-06 03:17:00\",\"2018-05-06 03:18:00\",\"2018-05-06 03:19:00\",\"2018-05-06 03:20:00\",\"2018-05-06 03:21:00\",\"2018-05-06 03:22:00\",\"2018-05-06 03:23:00\",\"2018-05-06 03:24:00\",\"2018-05-06 03:25:00\",\"2018-05-06 03:26:00\",\"2018-05-06 03:27:00\",\"2018-05-06 03:28:00\",\"2018-05-06 03:29:00\",\"2018-05-06 03:30:00\",\"2018-05-06 03:31:00\",\"2018-05-06 03:32:00\",\"2018-05-06 03:33:00\",\"2018-05-06 03:34:00\",\"2018-05-06 03:35:00\",\"2018-05-06 03:36:00\",\"2018-05-06 03:37:00\",\"2018-05-06 03:38:00\",\"2018-05-06 03:39:00\",\"2018-05-06 03:40:00\",\"2018-05-06 03:41:00\",\"2018-05-06 03:42:00\",\"2018-05-06 03:43:00\",\"2018-05-06 03:44:00\",\"2018-05-06 03:45:00\",\"2018-05-06 03:46:00\",\"2018-05-06 03:47:00\",\"2018-05-06 03:48:00\",\"2018-05-06 03:49:00\",\"2018-05-06 03:50:00\",\"2018-05-06 03:51:00\",\"2018-05-06 03:52:00\",\"2018-05-06 03:53:00\",\"2018-05-06 03:54:00\",\"2018-05-06 03:55:00\",\"2018-05-06 03:56:00\",\"2018-05-06 03:57:00\",\"2018-05-06 03:58:00\",\"2018-05-06 03:59:00\",\"2018-05-06 04:00:00\",\"2018-05-06 04:01:00\",\"2018-05-06 04:02:00\",\"2018-05-06 04:03:00\",\"2018-05-06 04:04:00\",\"2018-05-06 04:05:00\",\"2018-05-06 04:06:00\",\"2018-05-06 04:07:00\",\"2018-05-06 04:08:00\",\"2018-05-06 04:09:00\",\"2018-05-06 04:10:00\",\"2018-05-06 04:11:00\",\"2018-05-06 04:12:00\",\"2018-05-06 04:13:00\",\"2018-05-06 04:14:00\",\"2018-05-06 04:15:00\",\"2018-05-06 04:16:00\",\"2018-05-06 04:17:00\",\"2018-05-06 04:18:00\",\"2018-05-06 04:19:00\",\"2018-05-06 04:20:00\",\"2018-05-06 04:21:00\",\"2018-05-06 04:22:00\",\"2018-05-06 04:23:00\",\"2018-05-06 04:24:00\",\"2018-05-06 04:25:00\",\"2018-05-06 04:26:00\",\"2018-05-06 04:27:00\",\"2018-05-06 04:28:00\",\"2018-05-06 04:29:00\",\"2018-05-06 04:30:00\",\"2018-05-06 04:31:00\",\"2018-05-06 04:32:00\",\"2018-05-06 04:33:00\",\"2018-05-06 04:34:00\",\"2018-05-06 04:35:00\",\"2018-05-06 04:36:00\",\"2018-05-06 04:37:00\",\"2018-05-06 04:38:00\",\"2018-05-06 04:39:00\",\"2018-05-06 04:40:00\",\"2018-05-06 04:41:00\",\"2018-05-06 04:42:00\",\"2018-05-06 04:43:00\",\"2018-05-06 04:44:00\",\"2018-05-06 04:45:00\",\"2018-05-06 04:46:00\",\"2018-05-06 04:47:00\",\"2018-05-06 04:48:00\",\"2018-05-06 04:49:00\",\"2018-05-06 04:50:00\",\"2018-05-06 04:51:00\",\"2018-05-06 04:52:00\",\"2018-05-06 04:53:00\",\"2018-05-06 04:54:00\",\"2018-05-06 04:55:00\",\"2018-05-06 04:56:00\",\"2018-05-06 04:57:00\",\"2018-05-06 04:58:00\",\"2018-05-06 04:59:00\",\"2018-05-06 05:00:00\",\"2018-05-06 05:01:00\",\"2018-05-06 05:02:00\",\"2018-05-06 05:03:00\",\"2018-05-06 05:04:00\",\"2018-05-06 05:05:00\",\"2018-05-06 05:06:00\",\"2018-05-06 05:07:00\",\"2018-05-06 05:08:00\",\"2018-05-06 05:09:00\",\"2018-05-06 05:10:00\",\"2018-05-06 05:11:00\",\"2018-05-06 05:12:00\",\"2018-05-06 05:13:00\",\"2018-05-06 05:14:00\",\"2018-05-06 05:15:00\",\"2018-05-06 05:16:00\",\"2018-05-06 05:17:00\",\"2018-05-06 05:18:00\",\"2018-05-06 05:19:00\",\"2018-05-06 05:20:00\",\"2018-05-06 05:21:00\",\"2018-05-06 05:22:00\",\"2018-05-06 05:23:00\",\"2018-05-06 05:24:00\",\"2018-05-06 05:25:00\",\"2018-05-06 05:26:00\",\"2018-05-06 05:27:00\",\"2018-05-06 05:28:00\",\"2018-05-06 05:29:00\",\"2018-05-06 05:30:00\",\"2018-05-06 05:31:00\",\"2018-05-06 05:32:00\",\"2018-05-06 05:33:00\",\"2018-05-06 05:34:00\",\"2018-05-06 05:35:00\",\"2018-05-06 05:36:00\",\"2018-05-06 05:37:00\",\"2018-05-06 05:38:00\",\"2018-05-06 05:39:00\",\"2018-05-06 05:40:00\",\"2018-05-06 05:41:00\",\"2018-05-06 05:42:00\",\"2018-05-06 05:43:00\",\"2018-05-06 05:44:00\",\"2018-05-06 05:45:00\",\"2018-05-06 05:46:00\",\"2018-05-06 05:47:00\",\"2018-05-06 05:48:00\",\"2018-05-06 05:49:00\",\"2018-05-06 05:50:00\",\"2018-05-06 05:51:00\",\"2018-05-06 05:52:00\",\"2018-05-06 05:53:00\",\"2018-05-06 05:54:00\",\"2018-05-06 05:55:00\",\"2018-05-06 05:56:00\",\"2018-05-06 05:57:00\",\"2018-05-06 05:58:00\",\"2018-05-06 05:59:00\",\"2018-05-06 06:00:00\",\"2018-05-06 06:01:00\",\"2018-05-06 06:02:00\",\"2018-05-06 06:03:00\",\"2018-05-06 06:04:00\",\"2018-05-06 06:05:00\",\"2018-05-06 06:06:00\",\"2018-05-06 06:07:00\",\"2018-05-06 06:08:00\",\"2018-05-06 06:09:00\",\"2018-05-06 06:10:00\",\"2018-05-06 06:11:00\",\"2018-05-06 06:12:00\",\"2018-05-06 06:13:00\",\"2018-05-06 06:14:00\",\"2018-05-06 06:15:00\",\"2018-05-06 06:16:00\",\"2018-05-06 06:17:00\",\"2018-05-06 06:18:00\",\"2018-05-06 06:19:00\",\"2018-05-06 06:20:00\",\"2018-05-06 06:21:00\",\"2018-05-06 06:22:00\",\"2018-05-06 06:23:00\",\"2018-05-06 06:24:00\",\"2018-05-06 06:25:00\",\"2018-05-06 06:26:00\",\"2018-05-06 06:27:00\",\"2018-05-06 06:28:00\",\"2018-05-06 06:29:00\",\"2018-05-06 06:30:00\",\"2018-05-06 06:31:00\",\"2018-05-06 06:32:00\",\"2018-05-06 06:33:00\",\"2018-05-06 06:34:00\",\"2018-05-06 06:35:00\",\"2018-05-06 06:36:00\",\"2018-05-06 06:37:00\",\"2018-05-06 06:38:00\",\"2018-05-06 06:39:00\",\"2018-05-06 06:40:00\",\"2018-05-06 06:41:00\",\"2018-05-06 06:42:00\",\"2018-05-06 06:43:00\",\"2018-05-06 06:44:00\",\"2018-05-06 06:45:00\",\"2018-05-06 06:46:00\",\"2018-05-06 06:47:00\",\"2018-05-06 06:48:00\",\"2018-05-06 06:49:00\",\"2018-05-06 06:50:00\",\"2018-05-06 06:51:00\",\"2018-05-06 06:52:00\",\"2018-05-06 06:53:00\",\"2018-05-06 06:54:00\",\"2018-05-06 06:55:00\",\"2018-05-06 06:56:00\",\"2018-05-06 06:57:00\",\"2018-05-06 06:58:00\",\"2018-05-06 06:59:00\",\"2018-05-06 07:00:00\",\"2018-05-06 07:01:00\",\"2018-05-06 07:02:00\",\"2018-05-06 07:03:00\",\"2018-05-06 07:04:00\",\"2018-05-06 07:05:00\",\"2018-05-06 07:06:00\",\"2018-05-06 07:07:00\",\"2018-05-06 07:08:00\",\"2018-05-06 07:09:00\",\"2018-05-06 07:10:00\",\"2018-05-06 07:11:00\",\"2018-05-06 07:12:00\",\"2018-05-06 07:13:00\",\"2018-05-06 07:14:00\",\"2018-05-06 07:15:00\",\"2018-05-06 07:16:00\",\"2018-05-06 07:17:00\",\"2018-05-06 07:18:00\",\"2018-05-06 07:19:00\",\"2018-05-06 07:20:00\",\"2018-05-06 07:21:00\",\"2018-05-06 07:22:00\",\"2018-05-06 07:23:00\",\"2018-05-06 07:24:00\",\"2018-05-06 07:25:00\",\"2018-05-06 07:26:00\",\"2018-05-06 07:27:00\",\"2018-05-06 07:28:00\",\"2018-05-06 07:29:00\",\"2018-05-06 07:30:00\",\"2018-05-06 07:31:00\",\"2018-05-06 07:32:00\",\"2018-05-06 07:33:00\",\"2018-05-06 07:34:00\",\"2018-05-06 07:35:00\",\"2018-05-06 07:36:00\",\"2018-05-06 07:37:00\",\"2018-05-06 07:38:00\",\"2018-05-06 07:39:00\",\"2018-05-06 07:40:00\",\"2018-05-06 07:41:00\",\"2018-05-06 07:42:00\",\"2018-05-06 07:43:00\",\"2018-05-06 07:44:00\",\"2018-05-06 07:45:00\",\"2018-05-06 07:46:00\",\"2018-05-06 07:47:00\",\"2018-05-06 07:48:00\",\"2018-05-06 07:49:00\",\"2018-05-06 07:50:00\",\"2018-05-06 07:51:00\",\"2018-05-06 07:52:00\",\"2018-05-06 07:53:00\",\"2018-05-06 07:54:00\",\"2018-05-06 07:55:00\",\"2018-05-06 07:56:00\",\"2018-05-06 07:57:00\",\"2018-05-06 07:58:00\",\"2018-05-06 07:59:00\",\"2018-05-06 08:00:00\",\"2018-05-06 08:01:00\",\"2018-05-06 08:02:00\",\"2018-05-06 08:03:00\",\"2018-05-06 08:04:00\",\"2018-05-06 08:05:00\",\"2018-05-06 08:06:00\",\"2018-05-06 08:07:00\",\"2018-05-06 08:08:00\",\"2018-05-06 08:09:00\",\"2018-05-06 08:10:00\",\"2018-05-06 08:11:00\",\"2018-05-06 08:12:00\",\"2018-05-06 08:13:00\",\"2018-05-06 08:14:00\",\"2018-05-06 08:15:00\",\"2018-05-06 08:16:00\",\"2018-05-06 08:17:00\",\"2018-05-06 08:18:00\",\"2018-05-06 08:19:00\",\"2018-05-06 08:20:00\",\"2018-05-06 08:21:00\",\"2018-05-06 08:22:00\",\"2018-05-06 08:23:00\",\"2018-05-06 08:24:00\",\"2018-05-06 08:25:00\",\"2018-05-06 08:26:00\",\"2018-05-06 08:27:00\",\"2018-05-06 08:28:00\",\"2018-05-06 08:29:00\",\"2018-05-06 08:30:00\",\"2018-05-06 08:31:00\",\"2018-05-06 08:32:00\",\"2018-05-06 08:33:00\",\"2018-05-06 08:34:00\",\"2018-05-06 08:35:00\",\"2018-05-06 08:36:00\",\"2018-05-06 08:37:00\",\"2018-05-06 08:38:00\",\"2018-05-06 08:39:00\",\"2018-05-06 08:40:00\",\"2018-05-06 08:41:00\",\"2018-05-06 08:42:00\",\"2018-05-06 08:43:00\",\"2018-05-06 08:44:00\",\"2018-05-06 08:45:00\",\"2018-05-06 08:46:00\",\"2018-05-06 08:47:00\",\"2018-05-06 08:48:00\",\"2018-05-06 08:49:00\",\"2018-05-06 08:50:00\",\"2018-05-06 08:51:00\",\"2018-05-06 08:52:00\",\"2018-05-06 08:53:00\",\"2018-05-06 08:54:00\",\"2018-05-06 08:55:00\",\"2018-05-06 08:56:00\",\"2018-05-06 08:57:00\",\"2018-05-06 08:58:00\",\"2018-05-06 08:59:00\",\"2018-05-06 09:00:00\",\"2018-05-06 09:01:00\",\"2018-05-06 09:02:00\",\"2018-05-06 09:03:00\",\"2018-05-06 09:04:00\",\"2018-05-06 09:05:00\",\"2018-05-06 09:06:00\",\"2018-05-06 09:07:00\",\"2018-05-06 09:08:00\",\"2018-05-06 09:09:00\",\"2018-05-06 09:10:00\",\"2018-05-06 09:11:00\",\"2018-05-06 09:12:00\",\"2018-05-06 09:13:00\",\"2018-05-06 09:14:00\",\"2018-05-06 09:15:00\",\"2018-05-06 09:16:00\",\"2018-05-06 09:17:00\",\"2018-05-06 09:18:00\",\"2018-05-06 09:19:00\",\"2018-05-06 09:20:00\",\"2018-05-06 09:21:00\",\"2018-05-06 09:22:00\",\"2018-05-06 09:23:00\",\"2018-05-06 09:24:00\",\"2018-05-06 09:25:00\",\"2018-05-06 09:26:00\",\"2018-05-06 09:27:00\",\"2018-05-06 09:28:00\",\"2018-05-06 09:29:00\",\"2018-05-06 09:30:00\",\"2018-05-06 09:31:00\",\"2018-05-06 09:32:00\",\"2018-05-06 09:33:00\",\"2018-05-06 09:34:00\",\"2018-05-06 09:35:00\",\"2018-05-06 09:36:00\",\"2018-05-06 09:37:00\",\"2018-05-06 09:38:00\",\"2018-05-06 09:39:00\",\"2018-05-06 09:40:00\",\"2018-05-06 09:41:00\",\"2018-05-06 09:42:00\",\"2018-05-06 09:43:00\",\"2018-05-06 09:44:00\",\"2018-05-06 09:45:00\",\"2018-05-06 09:46:00\",\"2018-05-06 09:47:00\",\"2018-05-06 09:48:00\",\"2018-05-06 09:49:00\",\"2018-05-06 09:50:00\",\"2018-05-06 09:51:00\",\"2018-05-06 09:52:00\",\"2018-05-06 09:53:00\",\"2018-05-06 09:54:00\",\"2018-05-06 09:55:00\",\"2018-05-06 09:56:00\",\"2018-05-06 09:57:00\",\"2018-05-06 09:58:00\",\"2018-05-06 09:59:00\",\"2018-05-06 10:00:00\",\"2018-05-06 10:01:00\",\"2018-05-06 10:02:00\",\"2018-05-06 10:03:00\",\"2018-05-06 10:04:00\",\"2018-05-06 10:05:00\",\"2018-05-06 10:06:00\",\"2018-05-06 10:07:00\",\"2018-05-06 10:08:00\",\"2018-05-06 10:09:00\",\"2018-05-06 10:10:00\",\"2018-05-06 10:11:00\",\"2018-05-06 10:12:00\",\"2018-05-06 10:13:00\",\"2018-05-06 10:14:00\",\"2018-05-06 10:15:00\",\"2018-05-06 10:16:00\",\"2018-05-06 10:17:00\",\"2018-05-06 10:18:00\",\"2018-05-06 10:19:00\",\"2018-05-06 10:20:00\",\"2018-05-06 10:21:00\",\"2018-05-06 10:22:00\",\"2018-05-06 10:23:00\",\"2018-05-06 10:24:00\",\"2018-05-06 10:25:00\",\"2018-05-06 10:26:00\",\"2018-05-06 10:27:00\",\"2018-05-06 10:28:00\",\"2018-05-06 10:29:00\",\"2018-05-06 10:30:00\",\"2018-05-06 10:31:00\",\"2018-05-06 10:32:00\",\"2018-05-06 10:33:00\",\"2018-05-06 10:34:00\",\"2018-05-06 10:35:00\",\"2018-05-06 10:36:00\",\"2018-05-06 10:37:00\",\"2018-05-06 10:38:00\",\"2018-05-06 10:39:00\",\"2018-05-06 10:40:00\",\"2018-05-06 10:41:00\",\"2018-05-06 10:42:00\",\"2018-05-06 10:43:00\",\"2018-05-06 10:44:00\",\"2018-05-06 10:45:00\",\"2018-05-06 10:46:00\",\"2018-05-06 10:47:00\",\"2018-05-06 10:48:00\",\"2018-05-06 10:49:00\",\"2018-05-06 10:50:00\",\"2018-05-06 10:51:00\",\"2018-05-06 10:52:00\",\"2018-05-06 10:53:00\",\"2018-05-06 10:54:00\",\"2018-05-06 10:55:00\",\"2018-05-06 10:56:00\",\"2018-05-06 10:57:00\",\"2018-05-06 10:58:00\",\"2018-05-06 10:59:00\",\"2018-05-06 11:00:00\",\"2018-05-06 11:01:00\",\"2018-05-06 11:02:00\",\"2018-05-06 11:03:00\",\"2018-05-06 11:04:00\",\"2018-05-06 11:05:00\",\"2018-05-06 11:06:00\",\"2018-05-06 11:07:00\",\"2018-05-06 11:08:00\",\"2018-05-06 11:09:00\",\"2018-05-06 11:10:00\",\"2018-05-06 11:11:00\",\"2018-05-06 11:12:00\",\"2018-05-06 11:13:00\",\"2018-05-06 11:14:00\",\"2018-05-06 11:15:00\",\"2018-05-06 11:16:00\",\"2018-05-06 11:17:00\",\"2018-05-06 11:18:00\",\"2018-05-06 11:19:00\",\"2018-05-06 11:20:00\",\"2018-05-06 11:21:00\",\"2018-05-06 11:22:00\",\"2018-05-06 11:23:00\",\"2018-05-06 11:24:00\",\"2018-05-06 11:25:00\",\"2018-05-06 11:26:00\",\"2018-05-06 11:27:00\",\"2018-05-06 11:28:00\",\"2018-05-06 11:29:00\",\"2018-05-06 11:30:00\",\"2018-05-06 11:31:00\",\"2018-05-06 11:32:00\",\"2018-05-06 11:33:00\",\"2018-05-06 11:34:00\",\"2018-05-06 11:35:00\",\"2018-05-06 11:36:00\",\"2018-05-06 11:37:00\",\"2018-05-06 11:38:00\",\"2018-05-06 11:39:00\",\"2018-05-06 11:40:00\",\"2018-05-06 11:41:00\",\"2018-05-06 11:42:00\",\"2018-05-06 11:43:00\",\"2018-05-06 11:44:00\",\"2018-05-06 11:45:00\",\"2018-05-06 11:46:00\",\"2018-05-06 11:47:00\",\"2018-05-06 11:48:00\",\"2018-05-06 11:49:00\",\"2018-05-06 11:50:00\",\"2018-05-06 11:51:00\",\"2018-05-06 11:52:00\",\"2018-05-06 11:53:00\",\"2018-05-06 11:54:00\",\"2018-05-06 11:55:00\",\"2018-05-06 11:56:00\",\"2018-05-06 11:57:00\",\"2018-05-06 11:58:00\",\"2018-05-06 11:59:00\",\"2018-05-06 12:00:00\",\"2018-05-06 12:01:00\",\"2018-05-06 12:02:00\",\"2018-05-06 12:03:00\",\"2018-05-06 12:04:00\",\"2018-05-06 12:05:00\",\"2018-05-06 12:06:00\",\"2018-05-06 12:07:00\",\"2018-05-06 12:08:00\",\"2018-05-06 12:09:00\",\"2018-05-06 12:10:00\",\"2018-05-06 12:11:00\",\"2018-05-06 12:12:00\",\"2018-05-06 12:13:00\",\"2018-05-06 12:14:00\",\"2018-05-06 12:15:00\",\"2018-05-06 12:16:00\",\"2018-05-06 12:17:00\",\"2018-05-06 12:18:00\",\"2018-05-06 12:19:00\",\"2018-05-06 12:20:00\",\"2018-05-06 12:21:00\",\"2018-05-06 12:22:00\",\"2018-05-06 12:23:00\",\"2018-05-06 12:24:00\",\"2018-05-06 12:25:00\",\"2018-05-06 12:26:00\",\"2018-05-06 12:27:00\",\"2018-05-06 12:28:00\",\"2018-05-06 12:29:00\",\"2018-05-06 12:30:00\",\"2018-05-06 12:31:00\",\"2018-05-06 12:32:00\",\"2018-05-06 12:33:00\",\"2018-05-06 12:34:00\",\"2018-05-06 12:35:00\",\"2018-05-06 12:36:00\",\"2018-05-06 12:37:00\",\"2018-05-06 12:38:00\",\"2018-05-06 12:39:00\",\"2018-05-06 12:40:00\",\"2018-05-06 12:41:00\",\"2018-05-06 12:42:00\",\"2018-05-06 12:43:00\",\"2018-05-06 12:44:00\",\"2018-05-06 12:45:00\",\"2018-05-06 12:46:00\",\"2018-05-06 12:47:00\",\"2018-05-06 12:48:00\",\"2018-05-06 12:49:00\",\"2018-05-06 12:50:00\",\"2018-05-06 12:51:00\",\"2018-05-06 12:52:00\",\"2018-05-06 12:53:00\",\"2018-05-06 12:54:00\",\"2018-05-06 12:55:00\",\"2018-05-06 12:56:00\",\"2018-05-06 12:57:00\",\"2018-05-06 12:58:00\",\"2018-05-06 12:59:00\",\"2018-05-06 13:00:00\",\"2018-05-06 13:01:00\",\"2018-05-06 13:02:00\",\"2018-05-06 13:03:00\",\"2018-05-06 13:04:00\",\"2018-05-06 13:05:00\",\"2018-05-06 13:06:00\",\"2018-05-06 13:07:00\",\"2018-05-06 13:08:00\",\"2018-05-06 13:09:00\",\"2018-05-06 13:10:00\",\"2018-05-06 13:11:00\",\"2018-05-06 13:12:00\",\"2018-05-06 13:13:00\",\"2018-05-06 13:14:00\",\"2018-05-06 13:15:00\",\"2018-05-06 13:16:00\",\"2018-05-06 13:17:00\",\"2018-05-06 13:18:00\",\"2018-05-06 13:19:00\",\"2018-05-06 13:20:00\",\"2018-05-06 13:21:00\",\"2018-05-06 13:22:00\",\"2018-05-06 13:23:00\",\"2018-05-06 13:24:00\",\"2018-05-06 13:25:00\",\"2018-05-06 13:26:00\",\"2018-05-06 13:27:00\",\"2018-05-06 13:28:00\",\"2018-05-06 13:29:00\",\"2018-05-06 13:30:00\",\"2018-05-06 13:31:00\",\"2018-05-06 13:32:00\",\"2018-05-06 13:33:00\",\"2018-05-06 13:34:00\",\"2018-05-06 13:35:00\",\"2018-05-06 13:36:00\",\"2018-05-06 13:37:00\",\"2018-05-06 13:38:00\",\"2018-05-06 13:39:00\",\"2018-05-06 13:40:00\",\"2018-05-06 13:41:00\",\"2018-05-06 13:42:00\",\"2018-05-06 13:43:00\",\"2018-05-06 13:44:00\",\"2018-05-06 13:45:00\",\"2018-05-06 13:46:00\",\"2018-05-06 13:47:00\",\"2018-05-06 13:48:00\",\"2018-05-06 13:49:00\",\"2018-05-06 13:50:00\",\"2018-05-06 13:51:00\",\"2018-05-06 13:52:00\",\"2018-05-06 13:53:00\",\"2018-05-06 13:54:00\",\"2018-05-06 13:55:00\",\"2018-05-06 13:56:00\",\"2018-05-06 13:57:00\",\"2018-05-06 13:58:00\",\"2018-05-06 13:59:00\",\"2018-05-06 14:00:00\",\"2018-05-06 14:01:00\",\"2018-05-06 14:02:00\",\"2018-05-06 14:03:00\",\"2018-05-06 14:04:00\",\"2018-05-06 14:05:00\",\"2018-05-06 14:06:00\",\"2018-05-06 14:07:00\",\"2018-05-06 14:08:00\",\"2018-05-06 14:09:00\",\"2018-05-06 14:10:00\",\"2018-05-06 14:11:00\",\"2018-05-06 14:12:00\",\"2018-05-06 14:13:00\",\"2018-05-06 14:14:00\",\"2018-05-06 14:15:00\",\"2018-05-06 14:16:00\",\"2018-05-06 14:17:00\",\"2018-05-06 14:18:00\",\"2018-05-06 14:19:00\",\"2018-05-06 14:20:00\",\"2018-05-06 14:21:00\",\"2018-05-06 14:22:00\",\"2018-05-06 14:23:00\",\"2018-05-06 14:24:00\",\"2018-05-06 14:25:00\",\"2018-05-06 14:26:00\",\"2018-05-06 14:27:00\",\"2018-05-06 14:28:00\",\"2018-05-06 14:29:00\",\"2018-05-06 14:30:00\",\"2018-05-06 14:31:00\",\"2018-05-06 14:32:00\",\"2018-05-06 14:33:00\",\"2018-05-06 14:34:00\",\"2018-05-06 14:35:00\",\"2018-05-06 14:36:00\",\"2018-05-06 14:37:00\",\"2018-05-06 14:38:00\",\"2018-05-06 14:39:00\",\"2018-05-06 14:40:00\",\"2018-05-06 14:41:00\",\"2018-05-06 14:42:00\",\"2018-05-06 14:43:00\",\"2018-05-06 14:44:00\",\"2018-05-06 14:45:00\",\"2018-05-06 14:46:00\",\"2018-05-06 14:47:00\",\"2018-05-06 14:48:00\",\"2018-05-06 14:49:00\",\"2018-05-06 14:50:00\",\"2018-05-06 14:51:00\",\"2018-05-06 14:52:00\",\"2018-05-06 14:53:00\",\"2018-05-06 14:54:00\",\"2018-05-06 14:55:00\",\"2018-05-06 14:56:00\",\"2018-05-06 14:57:00\",\"2018-05-06 14:58:00\",\"2018-05-06 14:59:00\",\"2018-05-06 15:00:00\",\"2018-05-06 15:01:00\",\"2018-05-06 15:02:00\",\"2018-05-06 15:03:00\",\"2018-05-06 15:04:00\",\"2018-05-06 15:05:00\",\"2018-05-06 15:06:00\",\"2018-05-06 15:07:00\",\"2018-05-06 15:08:00\",\"2018-05-06 15:09:00\",\"2018-05-06 15:10:00\",\"2018-05-06 15:11:00\",\"2018-05-06 15:12:00\",\"2018-05-06 15:13:00\",\"2018-05-06 15:14:00\",\"2018-05-06 15:15:00\",\"2018-05-06 15:16:00\",\"2018-05-06 15:17:00\",\"2018-05-06 15:18:00\",\"2018-05-06 15:19:00\",\"2018-05-06 15:20:00\",\"2018-05-06 15:21:00\",\"2018-05-06 15:22:00\",\"2018-05-06 15:23:00\",\"2018-05-06 15:24:00\",\"2018-05-06 15:25:00\",\"2018-05-06 15:26:00\",\"2018-05-06 15:27:00\",\"2018-05-06 15:28:00\",\"2018-05-06 15:29:00\",\"2018-05-06 15:30:00\",\"2018-05-06 15:31:00\",\"2018-05-06 15:32:00\",\"2018-05-06 15:33:00\",\"2018-05-06 15:34:00\",\"2018-05-06 15:35:00\",\"2018-05-06 15:36:00\",\"2018-05-06 15:37:00\",\"2018-05-06 15:38:00\",\"2018-05-06 15:39:00\",\"2018-05-06 15:40:00\",\"2018-05-06 15:41:00\",\"2018-05-06 15:42:00\",\"2018-05-06 15:43:00\",\"2018-05-06 15:44:00\",\"2018-05-06 15:45:00\",\"2018-05-06 15:46:00\",\"2018-05-06 15:47:00\",\"2018-05-06 15:48:00\",\"2018-05-06 15:49:00\",\"2018-05-06 15:50:00\",\"2018-05-06 15:51:00\",\"2018-05-06 15:52:00\",\"2018-05-06 15:53:00\",\"2018-05-06 15:54:00\",\"2018-05-06 15:55:00\",\"2018-05-06 15:56:00\",\"2018-05-06 15:57:00\",\"2018-05-06 15:58:00\",\"2018-05-06 15:59:00\",\"2018-05-06 16:00:00\",\"2018-05-06 16:01:00\",\"2018-05-06 16:02:00\",\"2018-05-06 16:03:00\",\"2018-05-06 16:04:00\",\"2018-05-06 16:05:00\",\"2018-05-06 16:06:00\",\"2018-05-06 16:07:00\",\"2018-05-06 16:08:00\",\"2018-05-06 16:09:00\",\"2018-05-06 16:10:00\",\"2018-05-06 16:11:00\",\"2018-05-06 16:12:00\",\"2018-05-06 16:13:00\",\"2018-05-06 16:14:00\",\"2018-05-06 16:15:00\",\"2018-05-06 16:16:00\",\"2018-05-06 16:17:00\",\"2018-05-06 16:18:00\",\"2018-05-06 16:19:00\",\"2018-05-06 16:20:00\",\"2018-05-06 16:21:00\",\"2018-05-06 16:22:00\",\"2018-05-06 16:23:00\",\"2018-05-06 16:24:00\",\"2018-05-06 16:25:00\",\"2018-05-06 16:26:00\",\"2018-05-06 16:27:00\",\"2018-05-06 16:28:00\",\"2018-05-06 16:29:00\",\"2018-05-06 16:30:00\",\"2018-05-06 16:31:00\",\"2018-05-06 16:32:00\",\"2018-05-06 16:33:00\",\"2018-05-06 16:34:00\",\"2018-05-06 16:35:00\",\"2018-05-06 16:36:00\",\"2018-05-06 16:37:00\",\"2018-05-06 16:38:00\",\"2018-05-06 16:39:00\",\"2018-05-06 16:40:00\",\"2018-05-06 16:41:00\",\"2018-05-06 16:42:00\",\"2018-05-06 16:43:00\",\"2018-05-06 16:44:00\",\"2018-05-06 16:45:00\",\"2018-05-06 16:46:00\",\"2018-05-06 16:47:00\",\"2018-05-06 16:48:00\",\"2018-05-06 16:49:00\",\"2018-05-06 16:50:00\",\"2018-05-06 16:51:00\",\"2018-05-06 16:52:00\",\"2018-05-06 16:53:00\",\"2018-05-06 16:54:00\",\"2018-05-06 16:55:00\",\"2018-05-06 16:56:00\",\"2018-05-06 16:57:00\",\"2018-05-06 16:58:00\",\"2018-05-06 16:59:00\",\"2018-05-06 17:00:00\",\"2018-05-06 17:01:00\",\"2018-05-06 17:02:00\",\"2018-05-06 17:03:00\",\"2018-05-06 17:04:00\",\"2018-05-06 17:05:00\",\"2018-05-06 17:06:00\",\"2018-05-06 17:07:00\",\"2018-05-06 17:08:00\",\"2018-05-06 17:09:00\",\"2018-05-06 17:10:00\",\"2018-05-06 17:11:00\",\"2018-05-06 17:12:00\",\"2018-05-06 17:13:00\",\"2018-05-06 17:14:00\",\"2018-05-06 17:15:00\",\"2018-05-06 17:16:00\",\"2018-05-06 17:17:00\",\"2018-05-06 17:18:00\",\"2018-05-06 17:19:00\",\"2018-05-06 17:20:00\",\"2018-05-06 17:21:00\",\"2018-05-06 17:22:00\",\"2018-05-06 17:23:00\",\"2018-05-06 17:24:00\",\"2018-05-06 17:25:00\",\"2018-05-06 17:26:00\",\"2018-05-06 17:27:00\",\"2018-05-06 17:28:00\",\"2018-05-06 17:29:00\",\"2018-05-06 17:30:00\",\"2018-05-06 17:31:00\",\"2018-05-06 17:32:00\",\"2018-05-06 17:33:00\",\"2018-05-06 17:34:00\",\"2018-05-06 17:35:00\",\"2018-05-06 17:36:00\",\"2018-05-06 17:37:00\",\"2018-05-06 17:38:00\",\"2018-05-06 17:39:00\",\"2018-05-06 17:40:00\",\"2018-05-06 17:41:00\",\"2018-05-06 17:42:00\",\"2018-05-06 17:43:00\",\"2018-05-06 17:44:00\",\"2018-05-06 17:45:00\",\"2018-05-06 17:46:00\",\"2018-05-06 17:47:00\",\"2018-05-06 17:48:00\",\"2018-05-06 17:49:00\",\"2018-05-06 17:50:00\",\"2018-05-06 17:51:00\",\"2018-05-06 17:52:00\",\"2018-05-06 17:53:00\",\"2018-05-06 17:54:00\",\"2018-05-06 17:55:00\",\"2018-05-06 17:56:00\",\"2018-05-06 17:57:00\",\"2018-05-06 17:58:00\",\"2018-05-06 17:59:00\",\"2018-05-06 18:00:00\",\"2018-05-06 18:01:00\",\"2018-05-06 18:02:00\",\"2018-05-06 18:03:00\",\"2018-05-06 18:04:00\",\"2018-05-06 18:05:00\",\"2018-05-06 18:06:00\",\"2018-05-06 18:07:00\",\"2018-05-06 18:08:00\",\"2018-05-06 18:09:00\",\"2018-05-06 18:10:00\",\"2018-05-06 18:11:00\",\"2018-05-06 18:12:00\",\"2018-05-06 18:13:00\",\"2018-05-06 18:14:00\",\"2018-05-06 18:15:00\",\"2018-05-06 18:16:00\",\"2018-05-06 18:17:00\",\"2018-05-06 18:18:00\",\"2018-05-06 18:19:00\",\"2018-05-06 18:20:00\",\"2018-05-06 18:21:00\",\"2018-05-06 18:22:00\",\"2018-05-06 18:23:00\",\"2018-05-06 18:24:00\",\"2018-05-06 18:25:00\",\"2018-05-06 18:26:00\",\"2018-05-06 18:27:00\",\"2018-05-06 18:28:00\",\"2018-05-06 18:29:00\",\"2018-05-06 18:30:00\",\"2018-05-06 18:31:00\",\"2018-05-06 18:32:00\",\"2018-05-06 18:33:00\",\"2018-05-06 18:34:00\",\"2018-05-06 18:35:00\",\"2018-05-06 18:36:00\",\"2018-05-06 18:37:00\",\"2018-05-06 18:38:00\",\"2018-05-06 18:39:00\",\"2018-05-06 18:40:00\",\"2018-05-06 18:41:00\",\"2018-05-06 18:42:00\",\"2018-05-06 18:43:00\",\"2018-05-06 18:44:00\",\"2018-05-06 18:45:00\",\"2018-05-06 18:46:00\",\"2018-05-06 18:47:00\",\"2018-05-06 18:48:00\",\"2018-05-06 18:49:00\",\"2018-05-06 18:50:00\",\"2018-05-06 18:51:00\",\"2018-05-06 18:52:00\",\"2018-05-06 18:53:00\",\"2018-05-06 18:54:00\",\"2018-05-06 18:55:00\",\"2018-05-06 18:56:00\",\"2018-05-06 18:57:00\",\"2018-05-06 18:58:00\",\"2018-05-06 18:59:00\",\"2018-05-06 19:00:00\",\"2018-05-06 19:01:00\",\"2018-05-06 19:02:00\",\"2018-05-06 19:03:00\",\"2018-05-06 19:04:00\",\"2018-05-06 19:05:00\",\"2018-05-06 19:06:00\",\"2018-05-06 19:07:00\",\"2018-05-06 19:08:00\",\"2018-05-06 19:09:00\",\"2018-05-06 19:10:00\",\"2018-05-06 19:11:00\",\"2018-05-06 19:12:00\",\"2018-05-06 19:13:00\",\"2018-05-06 19:14:00\",\"2018-05-06 19:15:00\",\"2018-05-06 19:16:00\",\"2018-05-06 19:17:00\",\"2018-05-06 19:18:00\",\"2018-05-06 19:19:00\",\"2018-05-06 19:20:00\",\"2018-05-06 19:21:00\",\"2018-05-06 19:22:00\",\"2018-05-06 19:23:00\",\"2018-05-06 19:24:00\",\"2018-05-06 19:25:00\",\"2018-05-06 19:26:00\",\"2018-05-06 19:27:00\",\"2018-05-06 19:28:00\",\"2018-05-06 19:29:00\",\"2018-05-06 19:30:00\",\"2018-05-06 19:31:00\",\"2018-05-06 19:32:00\",\"2018-05-06 19:33:00\",\"2018-05-06 19:34:00\",\"2018-05-06 19:35:00\",\"2018-05-06 19:36:00\",\"2018-05-06 19:37:00\",\"2018-05-06 19:38:00\",\"2018-05-06 19:39:00\",\"2018-05-06 19:40:00\",\"2018-05-06 19:41:00\",\"2018-05-06 19:42:00\",\"2018-05-06 19:43:00\",\"2018-05-06 19:44:00\",\"2018-05-06 19:45:00\",\"2018-05-06 19:46:00\",\"2018-05-06 19:47:00\",\"2018-05-06 19:48:00\",\"2018-05-06 19:49:00\",\"2018-05-06 19:50:00\",\"2018-05-06 19:51:00\",\"2018-05-06 19:52:00\",\"2018-05-06 19:53:00\",\"2018-05-06 19:54:00\",\"2018-05-06 19:55:00\",\"2018-05-06 19:56:00\",\"2018-05-06 19:57:00\",\"2018-05-06 19:58:00\",\"2018-05-06 19:59:00\",\"2018-05-06 20:00:00\",\"2018-05-06 20:01:00\",\"2018-05-06 20:02:00\",\"2018-05-06 20:03:00\",\"2018-05-06 20:04:00\",\"2018-05-06 20:05:00\",\"2018-05-06 20:06:00\",\"2018-05-06 20:07:00\",\"2018-05-06 20:08:00\",\"2018-05-06 20:09:00\",\"2018-05-06 20:10:00\",\"2018-05-06 20:11:00\",\"2018-05-06 20:12:00\",\"2018-05-06 20:13:00\",\"2018-05-06 20:14:00\",\"2018-05-06 20:15:00\",\"2018-05-06 20:16:00\",\"2018-05-06 20:17:00\",\"2018-05-06 20:18:00\",\"2018-05-06 20:19:00\",\"2018-05-06 20:20:00\",\"2018-05-06 20:21:00\",\"2018-05-06 20:22:00\",\"2018-05-06 20:23:00\",\"2018-05-06 20:24:00\",\"2018-05-06 20:25:00\",\"2018-05-06 20:26:00\",\"2018-05-06 20:27:00\",\"2018-05-06 20:28:00\",\"2018-05-06 20:29:00\",\"2018-05-06 20:30:00\",\"2018-05-06 20:31:00\",\"2018-05-06 20:32:00\",\"2018-05-06 20:33:00\",\"2018-05-06 20:34:00\",\"2018-05-06 20:35:00\",\"2018-05-06 20:36:00\",\"2018-05-06 20:37:00\",\"2018-05-06 20:38:00\",\"2018-05-06 20:39:00\",\"2018-05-06 20:40:00\",\"2018-05-06 20:41:00\",\"2018-05-06 20:42:00\",\"2018-05-06 20:43:00\",\"2018-05-06 20:44:00\",\"2018-05-06 20:45:00\",\"2018-05-06 20:46:00\",\"2018-05-06 20:47:00\",\"2018-05-06 20:48:00\",\"2018-05-06 20:49:00\",\"2018-05-06 20:50:00\",\"2018-05-06 20:51:00\",\"2018-05-06 20:52:00\",\"2018-05-06 20:53:00\",\"2018-05-06 20:54:00\",\"2018-05-06 20:55:00\",\"2018-05-06 20:56:00\",\"2018-05-06 20:57:00\",\"2018-05-06 20:58:00\",\"2018-05-06 20:59:00\",\"2018-05-06 21:00:00\",\"2018-05-06 21:01:00\",\"2018-05-06 21:02:00\",\"2018-05-06 21:03:00\",\"2018-05-06 21:04:00\",\"2018-05-06 21:05:00\",\"2018-05-06 21:06:00\",\"2018-05-06 21:07:00\",\"2018-05-06 21:08:00\",\"2018-05-06 21:09:00\",\"2018-05-06 21:10:00\",\"2018-05-06 21:11:00\",\"2018-05-06 21:12:00\",\"2018-05-06 21:13:00\",\"2018-05-06 21:14:00\",\"2018-05-06 21:15:00\",\"2018-05-06 21:16:00\",\"2018-05-06 21:17:00\",\"2018-05-06 21:18:00\",\"2018-05-06 21:19:00\",\"2018-05-06 21:20:00\",\"2018-05-06 21:21:00\",\"2018-05-06 21:22:00\",\"2018-05-06 21:23:00\",\"2018-05-06 21:24:00\",\"2018-05-06 21:25:00\",\"2018-05-06 21:26:00\",\"2018-05-06 21:27:00\",\"2018-05-06 21:28:00\",\"2018-05-06 21:29:00\",\"2018-05-06 21:30:00\",\"2018-05-06 21:31:00\",\"2018-05-06 21:32:00\",\"2018-05-06 21:33:00\",\"2018-05-06 21:34:00\",\"2018-05-06 21:35:00\",\"2018-05-06 21:36:00\",\"2018-05-06 21:37:00\",\"2018-05-06 21:38:00\",\"2018-05-06 21:39:00\",\"2018-05-06 21:40:00\",\"2018-05-06 21:41:00\",\"2018-05-06 21:42:00\",\"2018-05-06 21:43:00\",\"2018-05-06 21:44:00\",\"2018-05-06 21:45:00\",\"2018-05-06 21:46:00\",\"2018-05-06 21:47:00\",\"2018-05-06 21:48:00\",\"2018-05-06 21:49:00\",\"2018-05-06 21:50:00\",\"2018-05-06 21:51:00\",\"2018-05-06 21:52:00\",\"2018-05-06 21:53:00\",\"2018-05-06 21:54:00\",\"2018-05-06 21:55:00\",\"2018-05-06 21:56:00\",\"2018-05-06 21:57:00\",\"2018-05-06 21:58:00\",\"2018-05-06 21:59:00\",\"2018-05-06 22:00:00\",\"2018-05-06 22:01:00\",\"2018-05-06 22:02:00\",\"2018-05-06 22:03:00\",\"2018-05-06 22:04:00\",\"2018-05-06 22:05:00\",\"2018-05-06 22:06:00\",\"2018-05-06 22:07:00\",\"2018-05-06 22:08:00\",\"2018-05-06 22:09:00\",\"2018-05-06 22:10:00\",\"2018-05-06 22:11:00\",\"2018-05-06 22:12:00\",\"2018-05-06 22:13:00\",\"2018-05-06 22:14:00\",\"2018-05-06 22:15:00\",\"2018-05-06 22:16:00\",\"2018-05-06 22:17:00\",\"2018-05-06 22:18:00\",\"2018-05-06 22:19:00\",\"2018-05-06 22:20:00\",\"2018-05-06 22:21:00\",\"2018-05-06 22:22:00\",\"2018-05-06 22:23:00\",\"2018-05-06 22:24:00\",\"2018-05-06 22:25:00\",\"2018-05-06 22:26:00\",\"2018-05-06 22:27:00\",\"2018-05-06 22:28:00\",\"2018-05-06 22:29:00\",\"2018-05-06 22:30:00\",\"2018-05-06 22:31:00\",\"2018-05-06 22:32:00\",\"2018-05-06 22:33:00\",\"2018-05-06 22:34:00\",\"2018-05-06 22:35:00\",\"2018-05-06 22:36:00\",\"2018-05-06 22:37:00\",\"2018-05-06 22:38:00\",\"2018-05-06 22:39:00\",\"2018-05-06 22:40:00\",\"2018-05-06 22:41:00\",\"2018-05-06 22:42:00\",\"2018-05-06 22:43:00\",\"2018-05-06 22:44:00\",\"2018-05-06 22:45:00\",\"2018-05-06 22:46:00\",\"2018-05-06 22:47:00\",\"2018-05-06 22:48:00\",\"2018-05-06 22:49:00\",\"2018-05-06 22:50:00\",\"2018-05-06 22:51:00\",\"2018-05-06 22:52:00\",\"2018-05-06 22:53:00\",\"2018-05-06 22:54:00\",\"2018-05-06 22:55:00\",\"2018-05-06 22:56:00\",\"2018-05-06 22:57:00\",\"2018-05-06 22:58:00\",\"2018-05-06 22:59:00\",\"2018-05-06 23:00:00\",\"2018-05-06 23:01:00\",\"2018-05-06 23:02:00\",\"2018-05-06 23:03:00\",\"2018-05-06 23:04:00\",\"2018-05-06 23:05:00\",\"2018-05-06 23:06:00\",\"2018-05-06 23:07:00\",\"2018-05-06 23:08:00\",\"2018-05-06 23:09:00\",\"2018-05-06 23:10:00\",\"2018-05-06 23:11:00\",\"2018-05-06 23:12:00\",\"2018-05-06 23:13:00\",\"2018-05-06 23:14:00\",\"2018-05-06 23:15:00\",\"2018-05-06 23:16:00\",\"2018-05-06 23:17:00\",\"2018-05-06 23:18:00\",\"2018-05-06 23:19:00\",\"2018-05-06 23:20:00\",\"2018-05-06 23:21:00\",\"2018-05-06 23:22:00\",\"2018-05-06 23:23:00\",\"2018-05-06 23:24:00\",\"2018-05-06 23:25:00\",\"2018-05-06 23:26:00\",\"2018-05-06 23:27:00\",\"2018-05-06 23:28:00\",\"2018-05-06 23:29:00\",\"2018-05-06 23:30:00\",\"2018-05-06 23:31:00\",\"2018-05-06 23:32:00\",\"2018-05-06 23:33:00\",\"2018-05-06 23:34:00\",\"2018-05-06 23:35:00\",\"2018-05-06 23:36:00\",\"2018-05-06 23:37:00\",\"2018-05-06 23:38:00\",\"2018-05-06 23:39:00\",\"2018-05-06 23:40:00\",\"2018-05-06 23:41:00\",\"2018-05-06 23:42:00\",\"2018-05-06 23:43:00\",\"2018-05-06 23:44:00\",\"2018-05-06 23:45:00\",\"2018-05-06 23:46:00\",\"2018-05-06 23:47:00\",\"2018-05-06 23:48:00\",\"2018-05-06 23:49:00\",\"2018-05-06 23:50:00\",\"2018-05-06 23:51:00\",\"2018-05-06 23:52:00\",\"2018-05-06 23:53:00\",\"2018-05-06 23:54:00\",\"2018-05-06 23:55:00\",\"2018-05-06 23:56:00\",\"2018-05-06 23:57:00\",\"2018-05-06 23:58:00\",\"2018-05-06 23:59:00\"],\"xaxis\":\"x\",\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.06099749356508255,0.06119997799396515,0.060234446078538895,0.05925334244966507,0.05513564869761467,0.04982326552271843,0.04158788174390793,0.04512935131788254,0.04985954239964485,0.031932756304740906,0.04205106943845749,0.038440316915512085,0.030690062791109085,0.030531110242009163,0.04659209027886391,0.029740946367383003,0.02949037216603756,0.026546930894255638,0.02937278337776661,0.03915571793913841,0.04083731025457382,0.043270401656627655,0.04603166505694389,0.049775753170251846,0.05004008486866951,0.04755222424864769,0.05032370239496231,0.052684418857097626,0.054950863122940063,0.05408451706171036,0.05422953516244888,0.05559476837515831,0.05653800442814827,0.05512339621782303,0.05523315444588661,0.055965498089790344,0.05595346540212631,0.05515754967927933,0.052011359483003616,0.050922177731990814,0.04789061099290848,0.04056413099169731,0.03196142241358757,0.026921818032860756,0.0013029929250478745,-0.003559121396392584,-0.01578589715063572,-0.03394016623497009,-0.0444590300321579,-0.03831670805811882,-0.03927113488316536,-0.03247707337141037,-0.00860151182860136,-0.015385705977678299,-0.01601855456829071,-0.017837688326835632,-0.023952094838023186,0.010902553796768188,0.030309602618217468,0.0390503816306591,0.04025573655962944,0.03346879780292511,0.032613690942525864,0.0020625432953238487,0.014193718321621418,0.013145681470632553,0.010117830708622932,0.008339795283973217,0.009485557675361633,0.012240493670105934,0.02691429853439331,0.02339467965066433,0.017936835065484047,0.003118720604106784,0.005295443814247847,-0.005108305253088474,0.004049920942634344,0.0007323899189941585,0.0007000949699431658,-0.03246716409921646,-0.029559114947915077,-0.03343680873513222,-0.030587952584028244,-0.03096279501914978,-0.031243495643138885,-0.024392632767558098,-0.031107105314731598,-0.031142938882112503,-0.03526855260133743,-0.051359087228775024,-0.052144430577754974,-0.05383544787764549,-0.05577995628118515,-0.06906671822071075,-0.05016054958105087,-0.03282630071043968,-0.043984778225421906,-0.025223098695278168,-0.020123595371842384,-0.01913974992930889,-0.025054987519979477,-0.038890670984983444,-0.04251168668270111,-0.03989885002374649,-0.03706180676817894,-0.03383195772767067,-0.03999900817871094,-0.060876186937093735,-0.042327385395765305,-0.0449090339243412,-0.06682536005973816,-0.06759849190711975,-0.06832224875688553,-0.07198096066713333,-0.05918092280626297,-0.05308036506175995,-0.0632871612906456,-0.07518447935581207,-0.07567434757947922,-0.08267580717802048,-0.09307778626680374,-0.09366143494844437,-0.09688610583543777,-0.10244707763195038,-0.1027236208319664,-0.11870156228542328,-0.13644573092460632,-0.1231953352689743,-0.12351351231336594,-0.112226203083992,-0.09098878502845764,-0.08062697947025299,-0.09010784327983856,-0.07790862768888474,-0.06949787586927414,-0.06895076483488083,-0.0623583048582077,-0.06812158226966858,-0.0678747221827507,-0.07268670946359634,-0.09040000289678574,-0.07981093227863312,-0.055184800177812576,-0.04361299052834511,-0.04284755513072014,-0.04847864434123039,-0.057214826345443726,-0.048342298716306686,-0.027485957369208336,-0.024470582604408264,-0.03227817267179489,-0.024834364652633667,-0.02076754719018936,-0.012825822457671165,-0.00904749147593975,-0.021574920043349266,-0.03778441622853279,-0.043371882289648056,-0.04905690252780914,-0.056160684674978256,-0.05691717937588692,-0.041446130722761154,-0.04137074574828148,-0.055119194090366364,-0.047818589955568314,-0.05583954602479935,-0.05910266190767288,-0.07118818163871765,-0.08188772201538086,-0.08731627464294434,-0.0880320742726326,-0.08364301174879074,-0.0516950897872448,-0.0475754477083683,-0.04290524497628212,-0.04210539162158966,-0.02163442224264145,-0.03928232565522194,-0.044079363346099854,-0.038402047008275986,-0.032841961830854416,-0.02142910659313202,-0.023942096158862114,-0.023323802277445793,-0.030743321403861046,-0.01864032819867134,-0.02065402828156948,-0.0219147689640522,-0.01817837730050087,-0.01799089089035988,-0.018757695332169533,-0.034599073231220245,-0.03690829500555992,-0.0391058549284935,-0.02471230737864971,-0.024812908843159676,-0.019192129373550415,-0.021548686549067497,-0.018606794998049736,-0.03262978792190552,-0.0707026943564415,-0.06448773294687271,-0.060872115194797516,-0.05808347091078758,-0.05811784416437149,-0.04724975675344467,-0.06622560322284698,-0.08066307753324509,-0.0816044956445694,-0.07618987560272217,-0.08306466788053513,-0.08330781012773514,-0.0785692110657692,-0.08187966793775558,-0.08851402252912521,-0.08548183739185333,-0.09229881316423416,-0.09344134479761124,-0.0540631040930748,-0.07021941989660263,-0.054048728197813034,-0.0643983706831932,-0.06416743993759155,-0.06604974716901779,-0.06588225811719894,-0.05201781541109085,-0.06380817294120789,-0.05394431948661804,-0.05384916067123413,-0.0487472228705883,-0.03432841598987579,-0.04647556319832802,-0.024430325254797935,-0.023371580988168716,-0.03335120528936386,-0.03175663203001022,-0.04093534126877785,-0.044012296944856644,-0.04158380627632141,-0.04200412705540657,-0.04054054617881775,-0.03740563616156578,-0.03525850921869278,-0.038736630231142044,-0.04029545933008194,-0.04068587347865105,-0.04054903984069824,-0.03741191700100899,-0.035762663930654526,-0.045123904943466187,-0.03903086856007576,-0.054922327399253845,-0.05122512951493263,-0.05421542003750801,-0.051171425729990005,-0.059990864247083664,-0.058041930198669434,-0.05509238317608833,-0.06137339770793915,-0.04561293125152588,-0.042209442704916,-0.05582897365093231,-0.04489744454622269,-0.05449514836072922,-0.04328853636980057,-0.03844977915287018,-0.005080036353319883,0.035573411732912064,0.0497174896299839,0.04899762198328972,0.03284979984164238,0.04169932007789612,0.047543685883283615,0.04869851469993591,0.055709440261125565,0.05207271873950958,0.05803830176591873,0.05466427654027939,0.05596284195780754,0.055861666798591614,0.0482022799551487,0.04882774129509926,0.05225034058094025,0.05216009169816971,0.05494488775730133,0.06655248999595642,0.06737304478883743,0.07205421477556229,0.07112482935190201,0.07190220803022385,0.05729569494724274,0.0591399148106575,0.05542701110243797,0.05549076199531555,0.05834311246871948,0.0610191710293293,0.06387103348970413,0.08090551197528839,0.09091490507125854,0.08851561695337296,0.089608334004879,0.08897127956151962,0.07914547622203827,0.07914654165506363,0.07365613430738449,0.06957228481769562,0.06940598785877228,0.0690215453505516,0.0773145779967308,0.074587382376194,0.07188832014799118,0.05495280772447586,0.05517997965216637,0.031292252242565155,0.04189937189221382,0.04465740546584129,0.04453441873192787,0.04531799256801605,0.04573322460055351,0.063393734395504,0.07369975745677948,0.07368555665016174,0.052811432629823685,0.0555502213537693,0.05274325981736183,0.04962285980582237,0.04899664595723152,0.04897616431117058,0.04991023987531662,0.0611090213060379,0.06318806111812592,0.06345650553703308,0.05946870148181915,0.056951820850372314,0.05522598698735237,0.059002459049224854,0.05927214398980141,0.0593460276722908,0.05721907317638397,0.06283600628376007,0.0624510757625103,0.06530740857124329,0.07215548306703568,0.07696022093296051,0.08290107548236847,0.09168148785829544,0.0849829912185669,0.08585512638092041,0.08065042644739151,0.08608093112707138,0.08131720125675201,0.08444707095623016,0.08273163437843323,0.07680246233940125,0.06394822895526886,0.0645609050989151,0.06365416944026947,0.060268335044384,0.0681609958410263,0.06318328529596329,0.06814245879650116,0.06771271675825119,0.0661943256855011,0.06885910034179688,0.07689385861158371,0.07639395445585251,0.07670637220144272,0.08026536554098129,0.08374720066785812,0.08466880023479462,0.08534204214811325,0.09279217571020126,0.08470746874809265,0.08308130502700806,0.06898818910121918,0.07278311252593994,0.07809841632843018,0.077723927795887,0.08645404875278473,0.0852881520986557,0.08565012365579605,0.07933659851551056,0.08620471507310867,0.08856507390737534,0.097638800740242,0.09979477524757385,0.09214919060468674,0.08882316946983337,0.09141561388969421,0.09659828245639801,0.09446903318166733,0.09266785532236099,0.09280049055814743,0.09187835454940796,0.09622083604335785,0.10320459306240082,0.09985405951738358,0.1009335070848465,0.0973106324672699,0.09301389753818512,0.09120060503482819,0.07977072149515152,0.06889647990465164,0.06580819934606552,0.060168616473674774,0.05018364265561104,0.03822336718440056,0.024040400981903076,0.03040303662419319,0.03269164264202118,0.04242117702960968,0.05252276733517647,0.030834903940558434,0.026848912239074707,0.0337410494685173,0.04050808027386665,0.036920420825481415,0.03181658312678337,0.03474511206150055,0.034686096012592316,0.018798314034938812,-0.0010190577013418078,0.00948816817253828,-0.005268408451229334,-0.018220847472548485,-0.04250022768974304,-0.04518827423453331,-0.05804458260536194,-0.08226605504751205,-0.06097687780857086,-0.07465887069702148,-0.08031827211380005,-0.08430691808462143,-0.09150205552577972,-0.12694287300109863,-0.19034670293331146,-0.1651228815317154,-0.15772734582424164,-0.13884255290031433,-0.14878235757350922,-0.17736218869686127,-0.21543429791927338,-0.2574557662010193,-0.2858530580997467,-0.2987406849861145,-0.28967639803886414,-0.2636088728904724,-0.19814157485961914,-0.275307297706604,-0.24999545514583588,-0.2596341669559479,-0.24580465257167816,-0.2443051040172577,-0.23727010190486908,-0.17542918026447296,-0.24010758101940155,-0.2294912487268448,-0.22953537106513977,-0.25492188334465027,-0.3277394771575928,-0.3655073940753937,-0.3838505148887634,-0.3926961421966553,-0.36704355478286743,-0.3986687958240509,-0.4158756732940674,-0.42779332399368286,-0.4589216411113739,-0.39845383167266846,-0.40678125619888306,-0.4373112916946411,-0.450670063495636,-0.3979133665561676,-0.3847307860851288,-0.37893146276474,-0.3980938196182251,-0.3904845714569092,-0.380863219499588,-0.38192060589790344,-0.39983293414115906,-0.41581255197525024,-0.4465983808040619,-0.426153302192688,-0.44590821862220764,-0.4561479985713959,-0.4537295699119568,-0.44642317295074463,-0.46538299322128296,-0.47334572672843933,-0.45527195930480957,-0.4394281506538391,-0.440193235874176,-0.42626404762268066,-0.40480759739875793,-0.42498254776000977,-0.4411650002002716,-0.42351034283638,-0.3966062068939209,-0.3973422646522522,-0.3859851360321045,-0.4142279624938965,-0.4132944643497467,-0.41206881403923035,-0.4232840836048126,-0.43504148721694946,-0.48133447766304016,-0.4376591444015503,-0.4701603055000305,-0.47479379177093506,-0.44917407631874084,-0.46128731966018677,-0.44700098037719727,-0.4527699947357178,-0.4481273591518402,-0.4234580397605896,-0.423034131526947,-0.4087422490119934,-0.39289364218711853,-0.40024927258491516,-0.3995411694049835,-0.38174399733543396,-0.3807942271232605,-0.432910293340683,-0.44616204500198364,-0.45282530784606934,-0.4260733723640442,-0.4294672906398773,-0.43412521481513977,-0.4387652277946472,-0.43651503324508667,-0.4182097315788269,-0.4140687584877014,-0.40615206956863403,-0.4169648587703705,-0.4143015146255493,-0.42940983176231384,-0.43152838945388794,-0.44220760464668274,-0.47073063254356384,-0.45197510719299316,-0.4438989758491516,-0.4685007333755493,-0.4673101007938385,-0.4769497215747833,-0.4968738853931427,-0.5115554928779602,-0.48901960253715515,-0.45565465092658997,-0.4686519503593445,-0.4777916669845581,-0.47917473316192627,-0.4576808512210846,-0.45182788372039795,-0.448901504278183,-0.45986175537109375,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Date\"},\"showgrid\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Stock price\"},\"showgrid\":false},\"legend\":{\"title\":{\"text\":\"Close Price\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Comparision between original close price vs predicted close price\"},\"font\":{\"size\":15,\"color\":\"black\"},\"plot_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5847b7e8-60ca-4c3e-a13c-eedd4705a738');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FNV2xtI6vAX"
      },
      "source": [
        "### Prueba piloto\n",
        "\n",
        "A continuación elaboro pruebas con dias que no han sido utilizados para entrenar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqzB35yt-N0c"
      },
      "source": [
        "17/01: El modelo se comporta zarpado\n",
        "\n",
        "Predice ligeramente tarde los cambios, por lo que hay que tomar en cuenta predicciones relativamente lejanas (10 a 30 minutos) para saber lo que va a pasar en los proximos 2 o 3 minutos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalizar(df, 593)"
      ],
      "metadata": {
        "id": "7sc3tAfWJMLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "a4bad3be-e6b0-4ef7-f241-86b1a96fc170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Open     High      Low    Close\n",
              "Time                                                   \n",
              "2019-04-24 00:00:00  5520.43  5522.28  5520.43  5522.28\n",
              "2019-04-24 00:01:00  5522.26  5523.49  5520.80  5523.00\n",
              "2019-04-24 00:02:00  5523.28  5523.28  5520.50  5522.25\n",
              "2019-04-24 00:03:00  5522.27  5523.99  5522.26  5523.07\n",
              "2019-04-24 00:04:00  5523.92  5529.14  5520.53  5525.10\n",
              "...                      ...      ...      ...      ...\n",
              "2019-04-24 23:55:00  5407.93  5409.04  5405.05  5405.20\n",
              "2019-04-24 23:56:00  5405.63  5406.57  5400.00  5401.34\n",
              "2019-04-24 23:57:00  5402.13  5404.31  5400.01  5401.99\n",
              "2019-04-24 23:58:00  5401.97  5403.80  5399.74  5400.00\n",
              "2019-04-24 23:59:00  5399.58  5405.10  5399.54  5404.70\n",
              "\n",
              "[1440 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3561bd0-1696-425c-b095-92f0cf5dccfb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-04-24 00:00:00</th>\n",
              "      <td>5520.43</td>\n",
              "      <td>5522.28</td>\n",
              "      <td>5520.43</td>\n",
              "      <td>5522.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 00:01:00</th>\n",
              "      <td>5522.26</td>\n",
              "      <td>5523.49</td>\n",
              "      <td>5520.80</td>\n",
              "      <td>5523.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 00:02:00</th>\n",
              "      <td>5523.28</td>\n",
              "      <td>5523.28</td>\n",
              "      <td>5520.50</td>\n",
              "      <td>5522.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 00:03:00</th>\n",
              "      <td>5522.27</td>\n",
              "      <td>5523.99</td>\n",
              "      <td>5522.26</td>\n",
              "      <td>5523.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 00:04:00</th>\n",
              "      <td>5523.92</td>\n",
              "      <td>5529.14</td>\n",
              "      <td>5520.53</td>\n",
              "      <td>5525.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 23:55:00</th>\n",
              "      <td>5407.93</td>\n",
              "      <td>5409.04</td>\n",
              "      <td>5405.05</td>\n",
              "      <td>5405.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 23:56:00</th>\n",
              "      <td>5405.63</td>\n",
              "      <td>5406.57</td>\n",
              "      <td>5400.00</td>\n",
              "      <td>5401.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 23:57:00</th>\n",
              "      <td>5402.13</td>\n",
              "      <td>5404.31</td>\n",
              "      <td>5400.01</td>\n",
              "      <td>5401.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 23:58:00</th>\n",
              "      <td>5401.97</td>\n",
              "      <td>5403.80</td>\n",
              "      <td>5399.74</td>\n",
              "      <td>5400.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-24 23:59:00</th>\n",
              "      <td>5399.58</td>\n",
              "      <td>5405.10</td>\n",
              "      <td>5399.54</td>\n",
              "      <td>5404.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3561bd0-1696-425c-b095-92f0cf5dccfb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3561bd0-1696-425c-b095-92f0cf5dccfb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3561bd0-1696-425c-b095-92f0cf5dccfb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a55e2f9-a52a-4fe5-88d9-fc3578594ce8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a55e2f9-a52a-4fe5-88d9-fc3578594ce8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a55e2f9-a52a-4fe5-88d9-fc3578594ce8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_20bed5d5-0403-48c9-b7c8-e241cf87af7f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_20bed5d5-0403-48c9-b7c8-e241cf87af7f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.47969571408403,\n        \"min\": 5343.42,\n        \"max\": 5582.0,\n        \"num_unique_values\": 1271,\n        \"samples\": [\n          5415.43,\n          5425.58,\n          5435.92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.31719959112456,\n        \"min\": 5349.65,\n        \"max\": 5582.2,\n        \"num_unique_values\": 1171,\n        \"samples\": [\n          5434.0,\n          5562.73,\n          5426.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.75302817632787,\n        \"min\": 5333.35,\n        \"max\": 5578.33,\n        \"num_unique_values\": 1122,\n        \"samples\": [\n          5404.63,\n          5389.66,\n          5562.85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.42985351491421,\n        \"min\": 5344.46,\n        \"max\": 5582.0,\n        \"num_unique_values\": 1283,\n        \"samples\": [\n          5430.02,\n          5430.13,\n          5493.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = df_normal[['Close']]"
      ],
      "metadata": {
        "id": "78s_oUS0LzhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9df0aac9-b81d-41df-c53e-6b3c14302db4",
        "id": "WbhfDjyYLljq"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Close\n",
              "Time                         \n",
              "2019-04-25 00:00:00  0.384798\n",
              "2019-04-25 00:01:00  0.377410\n",
              "2019-04-25 00:02:00  0.368570\n",
              "2019-04-25 00:03:00  0.363644\n",
              "2019-04-25 00:04:00  0.352530"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5794f8a6-811d-4d5a-987d-851a5eeb614d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-04-25 00:00:00</th>\n",
              "      <td>0.384798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-25 00:01:00</th>\n",
              "      <td>0.377410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-25 00:02:00</th>\n",
              "      <td>0.368570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-25 00:03:00</th>\n",
              "      <td>0.363644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-25 00:04:00</th>\n",
              "      <td>0.352530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5794f8a6-811d-4d5a-987d-851a5eeb614d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5794f8a6-811d-4d5a-987d-851a5eeb614d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5794f8a6-811d-4d5a-987d-851a5eeb614d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2d5fa2e-3513-4d04-a1c1-e46f88baa2b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2d5fa2e-3513-4d04-a1c1-e46f88baa2b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2d5fa2e-3513-4d04-a1c1-e46f88baa2b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16464168788149858,\n        \"min\": -0.17839100783026113,\n        \"max\": 0.5526437652605872,\n        \"num_unique_values\": 1267,\n        \"samples\": [\n          0.1774858971120657,\n          -0.0690620527069124,\n          0.4471036457017773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba4e851-dc78-4082-aaaf-d64f6c0d4f6f",
        "id": "AP30vQECLljr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1440, 1)\n"
          ]
        }
      ],
      "source": [
        "train_data=scaler.fit_transform(np.array(train_data).reshape(-1,1))\n",
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKT9Y_1TMkRj",
        "outputId": "4d420e9a-2f71-49eb-8214-e90dcb5908d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77040023],\n",
              "       [0.76029369],\n",
              "       [0.7482004 ],\n",
              "       ...,\n",
              "       [0.79093003],\n",
              "       [0.71016412],\n",
              "       [0.71396487]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M05bUGzLLljs"
      },
      "outputs": [],
      "source": [
        "time_step = 15\n",
        "X_train, y_train = create_dataset(train_data, time_step)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z09l1BOtRoHg",
        "outputId": "fed6811a-7258-4364-cf02-98834b4a9a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1419, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pruebapiloto(df,minuto):\n",
        "  mi_array = np.array([X_train[minuto]])\n",
        "  mi_array_comparacion = np.array([X_train[minuto+15][0:5]])\n",
        "  valorf = model.predict(mi_array)\n",
        "\n",
        "  return valorf , mi_array_comparacion\n"
      ],
      "metadata": {
        "id": "7I1Q_NHMJWSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion , comparacion = pruebapiloto(X_train, 764)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgRvCXCAOkv4",
        "outputId": "3ab1dab5-8b01-4ce9-9a20-ab2369eb6ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediccion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k545JHFS3m6",
        "outputId": "aeda25b8-7ade-4c12-f47d-96343655b631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.84436864 0.83849025 0.83383095 0.8310629  0.82967114]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(comparacion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GppZVImETU_Q",
        "outputId": "be4149f1-2144-46af-e911-1ac1d119ec2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.83806507 0.84177944 0.84500432 0.84523467 0.84670314]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de ejemplo (puedes reemplazarlos con tus propios datos)\n",
        "tiempo = np.arange(0, 5, 1)\n",
        "activo1 = prediccion[0]\n",
        "activo2 = comparacion[0]\n",
        "\n",
        "# Crear el gráfico de líneas\n",
        "plt.plot(tiempo, activo1, label='Prediccion', marker='o')\n",
        "plt.plot(tiempo, activo2, label='Valor Real', marker='s')\n",
        "\n",
        "# Configurar el gráfico\n",
        "plt.title('Comparación entre la predicción a mediano plazo y el valor real')\n",
        "plt.xlabel('Tiempo (minutos)')\n",
        "plt.ylabel('Valor (normalizado)')\n",
        "plt.legend()  # Mostrar leyenda\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vifRyeuyTy8F",
        "outputId": "3c382701-6790-4b1a-d109-e2ec210d29c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAHHCAYAAADzrV8YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACzhklEQVR4nOzdeXxM1/vA8c/MZLIvIiILkSCKSGyJxE7tRdBqqSWJvXblq609tWv9qlr7TotSdKFVe9W+L7XvRG0RKiGRde7vjzTDSMKExCTxvF+veTHnnjn3ObM+uffcc1SKoigIIYQQQgiTUJs6ACGEEEKIN5kkY0IIIYQQJiTJmBBCCCGECUkyJoQQQghhQpKMCSGEEEKYkCRjQgghhBAmJMmYEEIIIYQJSTImhBBCCGFCkoyJXGfhwoXMmTPH1GGIN9SRI0cYPXo0d+7cMXUoQog3hCRj4rWqW7cudevWzXT7qlWrGDBgAFWqVHl9QeUhKpWKzz//3NRhZCsvLy86deqkv799+3ZUKhXbt2/P9n0tXrwYlUrF1atXM9x+7949WrVqRUJCAi4uLtm+/7zq6tWrqFQqFi9erC/7/PPPUalUpgsqG73ofZHfZfT6vg45+Vk3pZf5bEgyZoRLly7x0UcfUaJECSwtLbG3t6dGjRp88803PH782NTh5RsXLlygZ8+e/Pjjj1SuXNnU4bzQ+vXr811i9CZTFIXQ0FDq1KnD+PHjTR2OEOINIsnYC/z+++/4+fnx448/EhwczLRp05g4cSLFihXjk08+YcCAAaYOMU/ZtGkTmzZtynDb8ePHWbRoEe+8885rjurlrF+/ntGjR5s6jHyndu3aPH78mNq1a2d72yEhITx+/BhPT8902y5dukStWrVYsGBBvjnik5NGjBghf4wKkU3MTB1AbnblyhU+/PBDPD092bZtG25ubvptffr04eLFi/z+++8mjDDn6HQ6EhMTsbS0zNZ2zc3NM932/vvvZ+u+cpPk5GR0Ot1z+5/XxMbGYmNjk+3tqtXqbH/fpdFoNGg0mgy3eXt7M2TIkBzZb35kZmaGmZn8hIjcI6vfSTn1HfYy5MjYc3z55Zc8evSIBQsWGCRiaby9vQ2OjCUnJzN27FhKliyJhYUFXl5eDBs2jISEBIPHeXl50bx5c7Zv305AQABWVlb4+fnpz5v/9NNP+Pn5YWlpib+/P0ePHjV4fKdOnbC1teXy5cs0btwYGxsb3N3dGTNmDIqiGNT9v//7P6pXr46TkxNWVlb4+/uzevXqdH1RqVT07duXZcuWUa5cOSwsLNiwYUOW2gBYunQpgYGBWFtb4+joSO3atQ2OhGU0ZiwyMpKuXbvi4uKCpaUlFSpUYMmSJQZ10sY0/N///R9z587VP8dVqlTh4MGDGcbyrAcPHvDxxx/j4eGBhYUF3t7efPHFF+h0uizvp1OnTsyYMUP/3KXdnm1j6tSp+jZOnz4NwNmzZ3n//fcpWLAglpaWBAQEsHbtWqP68Kxr167Ru3dvSpcujZWVFU5OTnzwwQdGjX15Os6vv/4aT09PrKysqFOnDidPnjSom/aeu3TpEk2bNsXOzo4OHToAqYn71KlTKVeuHJaWlri4uPDRRx/x77//GrShKArjxo2jaNGiWFtb8/bbb3Pq1Kl0cWU2jmT//v00bdoUR0dHbGxsKF++PN98841BnbNnz9KmTRucnZ2xsrKidOnSDB8+XL89s7FBM2fO1L/v3d3d6dOnDw8ePDCoU7duXXx9fTl9+jRvv/021tbWFClShC+//PKFzzXAokWLqFevHoULF8bCwgIfHx9mzZpl1GPTnv+IiAiaN2+Ora0tRYoU0b8HT5w4Qb169bCxscHT05Ply5ena8OY939avU6dOuHg4ECBAgUICwtL91xAxuNijO1j2nfgrl27CAwMxNLSkhIlSvDdd9+lq3v58mU++OADChYsiLW1NVWrVjX6j+Cnv9dKly6t/07dsWPHCx/766+/0qxZM9zd3bGwsKBkyZKMHTuWlJQUfZ2091NGt6e/54z9bXjWokWLUKlU6X4DACZMmIBGo+HGjRvPbePGjRt06dIFFxcXLCwsKFeuHAsXLnxh/5916NAhVCpVuu9mgI0bN6JSqfjtt9+AV/tegtSxw/7+/lhZWVGoUCE6duyYrp/P+07KSNr79fTp07Rv3x5HR0dq1qyp37506VL9PgsWLMiHH37I9evXDdrYuXMnH3zwAcWKFcPCwgIPDw8GDhyYPUeIFZGpIkWKKCVKlDC6flhYmAIo77//vjJjxgwlNDRUAZRWrVoZ1PP09FRKly6tuLm5KZ9//rny9ddfK0WKFFFsbW2VpUuXKsWKFVMmTZqkTJo0SXFwcFC8vb2VlJQUg/1YWloqpUqVUkJCQpTp06crzZs3VwBl5MiRBvsqWrSo0rt3b2X69OnKlClTlMDAQAVQfvvtN4N6gFK2bFnF2dlZGT16tDJjxgzl6NGjWWrj888/VwClevXqyuTJk5VvvvlGad++vfLZZ5/p69SpU0epU6eO/n5cXJxStmxZRavVKgMHDlS+/fZbpVatWgqgTJ06VV/vypUrCqBUqlRJ8fb2Vr744gvlyy+/VAoVKqQULVpUSUxMfO5rExsbq5QvX15xcnJShg0bpsyePVsJDQ1VVCqVMmDAgCzvZ8+ePUrDhg0VQPn+++/1t6fb8PHxUUqUKKFMmjRJ+frrr5Vr164pJ0+eVBwcHBQfHx/liy++UKZPn67Url1bUalUyk8//fTcPqS9TuHh4fr7q1atUipUqKCMGjVKmTt3rjJs2DDF0dFR8fT0VGJjY5/bVlqcfn5+ipeXl/LFF18oo0ePVgoWLKg4Ozsrt2/f1tcNCwtTLCwslJIlSyphYWHK7Nmzle+++05RFEXp1q2bYmZmpnTv3l2ZPXu28tlnnyk2NjZKlSpVDF6XESNGKIDStGlTZfr06UqXLl0Ud3d3pVChQkpYWJi+3p9//qkAyp9//qkv27Rpk2Jubq54enoq4eHhyqxZs5T+/fsrDRo00Nc5fvy4Ym9vrzg5OSlDhw5V5syZo3z66aeKn5+fvs6iRYsUQLly5Yq+LDw8XAGUBg0aKNOmTVP69u2raDSadPHXqVNHcXd3Vzw8PJQBAwYoM2fOVOrVq6cAyvr161/42lWpUkXp1KmT8vXXXyvTpk1TGjVqpADK9OnTX/jYtM+8j4+P0rNnT2XGjBlK9erVFUBZtGiR4u7urnzyySfKtGnTlHLlyikajUa5fPmy/vHGvv91Op1Su3ZtRa1WK71791amTZum1KtXTylfvrx+X88+by/Tx7TvQBcXF2XYsGHK9OnTlcqVKysqlUo5efKkvt7t27cVFxcXxc7OThk+fLgyZcoUpUKFCoparTb68+Lr66sUKlRIGTNmjPLFF18onp6eipWVlXLixAl9vYzeF61atVLatGmjTJ48WZk1a5bywQcfKIAyePBgfZ1Lly4ZfP6///57Zdy4cQqgfPDBBwavnzG/Dc+KiYlRrKyslP/973/ptvn4+Cj16tV77uNv376tFC1aVPHw8FDGjBmjzJo1S2nRooUCKF9//bW+Xtp3wdOvb0ZKlCihNG3aNF15586dFUdHR/3nxdjvpYw+62mvRZUqVZSvv/5aGTJkiGJlZaV4eXkp//77r77e876TMpL2fvXx8VFatmypzJw5U5kxY4aiKIoybtw4RaVSKW3btlVmzpypjB49WilUqFC6ffbr109p2rSpMmHCBGXOnDlK165dFY1Go7z//vsZ7isrJBnLRHR0tAIoLVu2NKr+sWPHFEDp1q2bQfngwYMVQNm2bZu+zNPTUwGUPXv26Ms2btyoAIqVlZVy7do1ffmcOXPSvVnTPtj9+vXTl+l0OqVZs2aKubm5cvfuXX15XFycQTyJiYmKr69vug8xoKjVauXUqVPp+mZMGxcuXFDUarXy7rvvGiSOabGleTYZmzp1qgIoS5cuNWi/WrVqiq2trRITE6MoypMvCycnJ+X+/fv6ur/++qsCKOvWrUsX99PGjh2r2NjYKOfPnzcoHzJkiKLRaJSIiIgs76dPnz4ZfuDS2rC3t1ciIyMNttWvX1/x8/NT4uPjDZ6f6tWrK6VKlXpuHxQlfTL27GujKIqyd+9eBXjuF9PTcVpZWSn//POPvnz//v0KoAwcOFBflvaeGzJkiEEbO3fuVABl2bJlBuUbNmwwKI+MjFTMzc2VZs2aGbwfhg0bpgDPTcaSk5OV4sWLK56engZfjIpi+N6qXbu2YmdnZ/D5ebbOsz+6aXE1atTI4H07ffp0BVAWLlyoL6tTp0665zUhIUFxdXVVWrdurbxIRq9V48aNjfqDL+35nzBhgr7s33//VaysrBSVSqWsWLFCX3727Nl07xNj3/+//PKLAihffvmlvk5ycrL+D6QXJWPG9jHtO3DHjh36ssjISMXCwsIg8fj4448VQNm5c6e+7OHDh0rx4sUVLy+vdN81zwIUQDl06JC+7Nq1a4qlpaXy7rvv6ssySsYy6stHH32kWFtbG3x+n/b48WPF399fcXd3V27duqUoStZ+GzLSrl07xd3d3aCvR44cMSp56tq1q+Lm5qZERUUZlH/44YeKg4ODvo/GJmNDhw5VtFqtwXdjQkKCUqBAAaVLly76MmO/l579rCcmJiqFCxdWfH19lcePH+vr/fbbbwqgjBo1Sl+W2XdSZtLer+3atTMov3r1qqLRaJTx48cblJ84cUIxMzMzKM+oXxMnTlRUKpXB987LJGNymjITMTExANjZ2RlVf/369QAMGjTIoPx///sfQLrD6j4+PlSrVk1/PygoCIB69epRrFixdOWXL19Ot8++ffvq/592OD4xMZEtW7boy62srPT///fff4mOjqZWrVocOXIkXXt16tTBx8cnXbkxbfzyyy/odDpGjRqFWm34tnreYOj169fj6upKu3bt9GVarZb+/fvz6NEj/vrrL4P6bdu2xdHRUX+/Vq1aQMbPz9NWrVpFrVq1cHR0JCoqSn9r0KABKSkp6U5bvOx+nta6dWucnZ319+/fv8+2bdto06YNDx8+1Mdw7949GjduzIULF154yuFZT782SUlJ3Lt3D29vbwoUKJDha5yRVq1aUaRIEf39wMBAgoKC9O/pp/Xq1cvg/qpVq3BwcKBhw4YGz6u/vz+2trb8+eefAGzZsoXExET69etn8H74+OOPXxjf0aNHuXLlCh9//DEFChQw2JbW1t27d9mxYwddunQx+Pw8XScjaXF9/PHHBu/b7t27Y29vn+5za2trS8eOHfX3zc3NCQwMNOp98fRrFR0dTVRUFHXq1OHy5ctER0e/8PEA3bp10/+/QIEClC5dGhsbG9q0aaMvL126NAUKFDCIydj3//r16zEzMzN4nTUaDf369TMqvqz00cfHR/+5AnB2dqZ06dIGca9fv57AwECD00m2trb06NGDq1ev6k/9P0+1atXw9/fX3y9WrBgtW7Zk48aNBqccn9eXtM9rrVq1iIuL4+zZsxk+pnfv3pw4cYI1a9bg6uqq7wMY/9vwrNDQUG7evKn/LAEsW7YMKysrWrdunenjFEVhzZo1BAcHoyiKweveuHFjoqOjjf6OSNO2bVuSkpL46aef9GWbNm3iwYMHtG3bVl/2st9Lhw4dIjIykt69exuMG23WrBllypTJ8Ll69jvpRXr27Glw/6effkKn09GmTRuD58jV1ZVSpUoZPO9P9ys2NpaoqCiqV6+OoigZnkrOChl9mQl7e3sg9UNojGvXrqFWq/H29jYod3V1pUCBAly7ds2g/NkfDAcHBwA8PDwyLH92/I1araZEiRIGZW+99RaAwXn53377jXHjxnHs2DGD8QkZ/UAVL148w74Z08alS5dQq9UZJnPPc+3aNUqVKpUugStbtqx++9Oefd7SEqZnn59nXbhwgb///tsgOXpaZGRktuznac8+nxcvXkRRFEaOHMnIkSMzjePpxOhFHj9+zMSJE1m0aBE3btwwGDNo7A98qVKl0pW99dZb/PjjjwZlZmZmFC1a1KDswoULREdHU7hw4QzbTnte017HZ/fl7OxskPRm5NKlSwD4+vpmWiftB/x5dTKSFlfp0qUNys3NzSlRokS691/RokXTfXYcHR35+++/X7iv3bt3Ex4ezt69e4mLizPYFh0drf+sZ8bS0jLd+9fBwSHDmBwcHAzeq8a+/69du4abmxu2trYG2599fjKTlT4++xmD1Ofy6bivXbum/4P0aU9/P7zoNc/s/R0XF8fdu3f1SdOzTp06xYgRI9i2bZv+j/On+/KsOXPmsGjRIubMmUPVqlUN+pCV34ZnNWzYEDc3N5YtW0b9+vXR6XT88MMPtGzZ8rkHC+7evcuDBw+YO3cuc+fOzbDOs997L1KhQgXKlCnDypUr6dq1KwArV66kUKFC1KtXT1/vZb+XMvs8ApQpU4Zdu3YZlGX0nfQiz34vX7hwAUVRMnyfQOrBgTQRERGMGjWKtWvXpvstMPb7NjOSjGXC3t4ed3f3dAOZX8TYS+Izu6Irs/Kn38zG2rlzJy1atKB27drMnDkTNzc3tFotixYtynCA79NZ/8u2kdNe9vnR6XQ0bNiQTz/9NMPtaYnsq+7nac8+n2kDpQcPHkzjxo0zfMyzX9gv0q9fPxYtWsTHH39MtWrVcHBwQKVS8eGHH6YbmP2qLCws0iXNOp2OwoULs2zZsgwfk9mPf171su+LS5cuUb9+fcqUKcOUKVPw8PDA3Nyc9evX8/XXXxv1Wr3Kd0ZW3/8vI6t9zM7vuuz24MED6tSpg729PWPGjKFkyZJYWlpy5MgRPvvss3R9OXDgAAMGDKBbt2706NEjwzZfdroUjUZD+/btmTdvHjNnzmT37t3cvHnT4AhtRtJi7NixI2FhYRnWKV++fJbjadu2LePHjycqKgo7OzvWrl1Lu3btDK6sfV3fSxl9J71IRt/LKpWKP/74I8P3ZNofJikpKTRs2JD79+/z2WefUaZMGWxsbLhx4wadOnV65X5JMvYczZs3Z+7cuezdu9fglGJGPD090el0XLhwQf9XG8CdO3d48OBBhvMavQqdTsfly5cNvkTPnz8PpF6pBLBmzRosLS3ZuHEjFhYW+nqLFi0yej/GtlGyZEl0Oh2nT5+mYsWKRrfv6enJ33//jU6nM/hQpZ0GyK7nrWTJkjx69IgGDRpkS3uQ9S/XtCOZWq022+JYvXo1YWFhfPXVV/qy+Pj4DK9+y8yFCxfSlZ0/f17/PnqekiVLsmXLFmrUqJFhMp8m7XW8cOGCwRHdu3fvvvBoY8mSJQE4efJkps9bWptZ/eMpLa5z584ZxJWYmMiVK1ey7XVat24dCQkJrF271uCI0NOnQHKSse9/T09Ptm7dyqNHjwyOjp07d+6F+8iJPnp6ema476x8P2T2/ra2ts70j4Xt27dz7949fvrpJ4P57q5cuZKu7t27d3n//fepWLGi/urWZ/vwqr8NoaGhfPXVV6xbt44//vgDZ2fnTP+gS+Ps7IydnR0pKSnZ+r3Xtm1bRo8ezZo1a3BxcSEmJoYPP/zQoM7Lfi89/Xl8+khbWll2/45C6mdDURSKFy/+3D9KTpw4wfnz51myZAmhoaH68s2bN2dLHDJm7Dk+/fRTbGxs6NatW4br1F26dEl/aX3Tpk0BmDp1qkGdKVOmAKnnvLPb9OnT9f9XFIXp06ej1WqpX78+kPoXlUqlMhgXcfXqVX755Rej92FsG61atUKtVjNmzJh0fyE87y/dpk2bcvv2bVauXKkvS05OZtq0adja2lKnTh2jY32eNm3asHfvXjZu3Jhu24MHD0hOTs5ym2nz0xib+BQuXJi6desyZ84cbt26lW773bt3sxyDRqNJ9/xOmzbtuWNhnvXLL78YjFU7cOAA+/fvN2ry3TZt2pCSksLYsWPTbUtOTtY/Nw0aNECr1TJt2jSDeJ/9vGSkcuXKFC9enKlTp6Z7rtPacnZ2pnbt2ixcuJCIiIgM62SkQYMGmJub8+233xrUW7BgAdHR0dn2uU37i/vZ0zVZ+cPoVRj7/m/atCnJyckG01GkpKQwbdq0F+4jJ/rYtGlTDhw4wN69e/VlsbGxzJ07Fy8vL6OGRezdu9dgnNL169f59ddfadSo0QuPNj7dl8TERGbOnGlQLyUlhQ8//JDExETWrFmT4TyC2fHbUL58ecqXL8/8+fNZs2YNH3744QvneNNoNLRu3Zo1a9Zk+EfKy3zfQOopYj8/P1auXMnKlStxc3NLN0Hzy34vBQQEULhwYWbPnm0wJOaPP/7gzJkzOfI7+t5776HRaBg9enS6mBVF4d69e0DG7wlFUdJNr/Oy5MjYc5QsWZLly5fTtm1bypYtS2hoKL6+viQmJrJnzx5WrVqlX1OvQoUKhIWFMXfuXP0h7gMHDrBkyRJatWrF22+/na2xWVpasmHDBsLCwggKCuKPP/7g999/Z9iwYfq/9po1a8aUKVNo0qQJ7du3JzIykhkzZuDt7W3UGJestOHt7c3w4cMZO3YstWrV4r333sPCwoKDBw/i7u7OxIkTM2y/R48ezJkzh06dOnH48GG8vLxYvXo1u3fvZurUqUZfQPEin3zyCWvXrqV58+Z06tQJf39/YmNjOXHiBKtXr+bq1asUKlQoS22mDQru378/jRs3RqPRpPsL8VkzZsygZs2a+Pn50b17d0qUKMGdO3fYu3cv//zzD8ePH89SDM2bN+f777/HwcEBHx8f9u7dy5YtW3BycjK6DW9vb2rWrEmvXr1ISEhg6tSpODk5ZXpK62l16tTho48+YuLEiRw7doxGjRqh1Wq5cOECq1at4ptvvuH999/H2dmZwYMHM3HiRJo3b07Tpk05evQof/zxxwufd7VazaxZswgODqZixYp07twZNzc3zp49y6lTp/QJxrfffkvNmjWpXLkyPXr0oHjx4ly9epXff/+dY8eOZdi2s7MzQ4cOZfTo0TRp0oQWLVpw7tw5Zs6cSZUqVV54KshYjRo1wtzcnODgYD766CMePXrEvHnzKFy4cIaJeXYz9v0fHBxMjRo1GDJkCFevXsXHx4effvrJqPEwOdHHIUOG8MMPP/DOO+/Qv39/ChYsyJIlS7hy5Qpr1qwx6hSVr68vjRs3pn///lhYWOgTquetnlG9enUcHR0JCwujf//+qFQqvv/++3Q/1rNnz2bbtm307Nkz3RFAFxcXGjZsmG2/DaGhoQwePBjA6PflpEmT+PPPPwkKCqJ79+74+Phw//59jhw5wpYtW7h//75R7Tyrbdu2jBo1CktLS7p27ZrudXjZ7yWtVssXX3xB586dqVOnDu3atePOnTt88803eHl5MXDgwJeK93lKlizJuHHjGDp0KFevXqVVq1bY2dlx5coVfv75Z3r06MHgwYMpU6YMJUuWZPDgwdy4cQN7e3vWrFmTpXHEz5Wlay/fUOfPn1e6d++ueHl5Kebm5oqdnZ1So0YNZdq0aQaXOCclJSmjR49Wihcvrmi1WsXDw0MZOnRousugPT09lWbNmqXbD6D06dPHoCztkuPJkyfry8LCwhQbGxvl0qVLSqNGjRRra2vFxcVFCQ8PT3ep94IFC5RSpUopFhYWSpkyZZRFixZleNltRvvOahuKoigLFy5UKlWqpFhYWCiOjo5KnTp1lM2bN+u3Pzu1haIoyp07d5TOnTsrhQoVUszNzRU/P790l1hn9Dw8HfvTl/Fn5uHDh8rQoUMVb29vxdzcXClUqJBSvXp15f/+7//08+NkZT/JyclKv379FGdnZ0WlUumfj+e1oSipcxOFhoYqrq6uilarVYoUKaI0b95cWb169Qv78GwM//77r/65s7W1VRo3bqycPXtW8fT0NJguIiNPx/nVV18pHh4eioWFhVKrVi3l+PHjBnXT3nOZmTt3ruLv769YWVkpdnZ2ip+fn/Lpp58qN2/e1NdJSUlRRo8erbi5uSlWVlZK3bp1lZMnT6aLNaO5hxRFUXbt2qU0bNhQsbOzU2xsbJTy5csr06ZNM6hz8uRJ5d1331UKFCigWFpaKqVLlzaYey+jKQwUJXUqizJlyiharVZxcXFRevXqlW4ajTp16ijlypVL1/ewsDDF09Mz0+cmzdq1a5Xy5csrlpaW+nndFi5cmGE8Ge0jo+c/s5gy+o4x5v2vKIpy7949JSQkRLG3t1ccHByUkJAQ5ejRo0ZNbWFsHzP7Dszo++HSpUvK+++/r39NAwMD081xmJm077WlS5fqv8MqVaqU7r2V0fti9+7dStWqVRUrKyvF3d1d+fTTT/VTEKU9Pu05yOj2dD+M/W14nlu3bikajUZ56623jH6MoqR+v/bp00fx8PBQtFqt4urqqtSvX1+ZO3euvo6xU1ukuXDhgr6fu3btSrfd2O+lzD7rK1eu1P+OFCxYUOnQoYPB9DuK8uLvpGelvVZPT/30tDVr1ig1a9ZUbGxsFBsbG6VMmTJKnz59lHPnzunrnD59WmnQoIFia2urFCpUSOnevbty/Phxoz4bL6JSlFwwWlJkSadOnVi9ejWPHj0ydSgiD7t69SrFixdn8uTJ+r+4hchPVCoVffr0MRjSkVdFRUXh5ubGqFGjMr0aW+RdMmZMCCGEyOUWL15MSkoKISEhpg5F5AAZMyaEEELkUtu2beP06dOMHz+eVq1aGXWVs8h7JBkTQgghcqkxY8awZ88eatSoYdRVrSJvkjFjQgghhBAmZPIxYzNmzMDLywtLS0uCgoI4cODAc+tPnTqV0qVLY2VlhYeHBwMHDiQ+Pj7DupMmTUKlUhmsf3f16lVUKlWGt1WrVunrZbR9xYoV2dJnIYQQQog0Jj1NuXLlSgYNGsTs2bMJCgpi6tSpNG7cmHPnzmW41t3y5csZMmQICxcupHr16pw/f55OnTqhUqn0E+ilOXjwIHPmzEm33IOHh0e6OW/mzp3L5MmT001yuWjRIpo0aaK//+wixUIIIYQQr8qkydiUKVPo3r07nTt3BlIn0Pv9999ZuHAhQ4YMSVc/7bx5+/btgdRlf9q1a8f+/fsN6j169IgOHTowb948xo0bZ7BNo9GkWxj2559/pk2bNukWxy1QoECmi8gaQ6fTcfPmTezs7F56XTIhhBBCvF6KovDw4UPc3d2zvP7ly+7QJBISEhSNRqP8/PPPBuWhoaFKixYtMnzMsmXLFAcHB2X//v2KoqROBlimTBll/Pjx6dr4+OOPFUVJnURwwIABmcZx6NAhBVB2795tUA4o7u7uipOTk1KlShVlwYIFik6ne26f4uPjlejoaP3t9OnTmU4IKDe5yU1ucpOb3HL37fr168/93c8uJjsyFhUVRUpKCi4uLgblLi4u+kVgn9W+fXuioqKoWbMmiqKQnJxMz549GTZsmL7OihUrOHLkCAcPHjQqjgULFlC2bFmqV69uUD5mzBjq1auHtbU1mzZtonfv3jx69Ij+/ftn2tbEiRMzXGJj/vz5WFtbGxWPEEIIIUwrLi6Obt26ZduSfC+Sp6a22L59OxMmTGDmzJkEBQVx8eJFBgwYwNixYxk5ciTXr19nwIABbN68GUtLyxe29/jxY5YvX57hbMZPl1WqVInY2FgmT5783GRs6NChDBo0SH8/JiYGDw8PWrVqhb29fRZ7m7mkpCQ2b95Mw4YN0Wq12dZubpHf+wf5v4/5vX+Q//so/cv78nsfc7J/MTExdOvW7bUNMTJZMlaoUCE0Gg137twxKL9z506m47RGjhxJSEgI3bp1A8DPz4/Y2Fh69OjB8OHDOXz4MJGRkVSuXFn/mJSUFHbs2MH06dNJSEjQr7wOsHr1auLi4ggNDX1hvEFBQYwdO5aEhAQsLCwyrGNhYZHhNq1WmyMfhJxqN7fI7/2D/N/H/N4/yP99lP7lffm9jznRv9f9fJlsagtzc3P8/f3ZunWrvkyn07F161aqVauW4WPi4uLSDaRLS64URaF+/fqcOHGCY8eO6W8BAQF06NCBY8eOGSRikHqKskWLFjg7O78w3mPHjuHo6JhpIiaEEEII8TJMeppy0KBBhIWFERAQQGBgIFOnTiU2NlZ/dWVoaChFihRh4sSJAAQHBzNlyhQqVaqkP005cuRIgoOD0Wg02NnZ4evra7APGxsbnJyc0pVfvHiRHTt2sH79+nRxrVu3jjt37lC1alUsLS3ZvHkzEyZMkMWUhRBCCJHtTJqMtW3blrt37zJq1Chu375NxYoV2bBhg35Qf0REhMGRsBEjRqBSqRgxYgQ3btzA2dmZ4OBgxo8fn+V9L1y4kKJFi9KoUaN027RaLTNmzGDgwIEoioK3t7d+Go7slpKSQlJSUpYek5SUhJmZGfHx8aSkpGR7TKaWH/qn1WrTHYkVQgghMmLyAfx9+/alb9++GW7bvn27wX0zMzPCw8MJDw83uv1n20gzYcIEJkyYkOG2Jk2aGEz2mhMUReH27ds8ePDgpR7r6urK9evX8+X8Zfmlf2nz1OXlPgghhMh5Jk/G3lRpiVjhwoWxtrbO0g+2Tqfj0aNH2Nravp7J6F6zvN4/RVGIi4sjMjISADc3NxNHJIQQIjeTZMwEUlJS9ImYk5NTlh+v0+lITEzE0tIyTyYrL5If+mdlZQVAZGQkhQsXllOWQgghMpU3f+nyuLQxYjIRbP6W9vpmdUygEEKIN4skYyYkY4nyN3l9hRBCGENOUwohhBAib3hwHeLupf4/ORmHuKtw6ziY/ZfOWDtBAQ+ThfeyJBkTuVLv3r2JjY3l119/BaBu3bpUrFiRqVOnvnLbnTp14sGDB/zyyy+v3JYQQojX5MF1mO4PyQkAaIG6AOeeqmNmAX0P57mETJKxPC5Fp3Dgyn0iH8ZT2M6SwOIF0ahz7vRYp06dWLJkCZA6l1axYsUIDQ1l2LBhmJnl3Nvpp59+yrblKb755hsURcmWtoQQQrwmcff0iVimkhNS60kyJl6XDSdvM/b3M9yKjteXuTlYEh7sQxPfnJtOoUmTJixatIiEhATWr19Pnz590Gq1DB061KBeYmIi5ubm2bLPggULZks7AA4ODtnWlhBCCPGqZAB/HrX13D36LD9qkIgB3I6Op9fSI2w4eSvH9m1hYYGrqyuenp706tWLBg0asHbtWjp16kSrVq0YP3487u7ulC5dGoDr16/Tpk0bChQoQMGCBWnZsiVXr17Vt5eSksKgQYMoUKAATk5OfPbZZ+mOXNWtW5ePP/5Yfz8hIYHPPvsMDw8PLCws8Pb2ZsGCBfrtp06donnz5tjb22NnZ0etWrW4dOkSgD7Op9vq378/hQsXxtLSkpo1a3Lw4EH99u3bt6NSqdi6dSsBAQFYW1tTvXp1zp17+ti4EEKIHPWio2J5mCRjuYSiKMQlJht1exifxBebL5PRiba0ss/XnuZhfJJR7b3qKTsrKysSExMB2Lp1K+fOnWPz5s389ttvJCUl0bhxY+zs7Ni5cye7d+/G1taWJk2a6B/z1VdfsXjxYhYuXMiuXbu4f/8+v//++3P3GRoayg8//MC3337LmTNnmDNnDra2tgDcuHGD2rVrY2FhwbZt2zh8+DBdunQhOTk5w7Y+/fRT1qxZw5IlSzhy5Aje3t40btyY+/fvG9QbPnw4X331FYcOHcLMzIwuXbq80vMmhBDiOZIT4dpe2P4FLGoGi5uaOqIcI6cpc4nHSSn4jNqYLW0pwO2YePw+32RU/dNjGmNtnvW3gqIobN26lY0bN9KvXz/u3r2LjY0N8+fP15+eXLp0KTqdjvnz5+uneli0aBEFChRg+/btNGrUiKlTpzJ06FDee+89AGbNmsWGDRsy3e/58+f58ccf2bx5Mw0aNACgRIkS+u0zZszAwcGBFStW6MeZvfXWWxm2FRsby6xZs1i8eDHvvPMOAPPmzWPz5s0sWLCATz75RF93/Pjx1KlTB4AhQ4bQrFkz4uPjsbS0zPJzJ4QQ4hm6FLh1DK7sSL1F7IOkOFNH9VpIMiay7LfffsPW1pakpCR0Oh3t27fn888/p0+fPvj5+RmMEzt+/DgXL17Ezs7OoI34+HguXbpEdHQ0t27dIigoSL/NzMyMSpUqZbr/Y8eOodFo9IlRRttr1apl1ID/S5cukZSURI0aNfRlWq2WwMBAzpw5Y1C3fPny+v+nLXEUGRlJsWLFXrgfIYQQz9DpIPJ0auJ1dSdc3Q0J0YZ1rJ2geG3wqgU2heHHjqaJNYdJMpZLWGk1nB7T2Ki6+y5F0WXJ4RfWW9y5CoHFXzzw3UqbtaV63n77bWbNmoW5uTnu7u4GV1Ha2NgY1H306BH+/v4sW7YsXTvOzs5Z2q8+3v+WGnrZ7S/r6eQu7SifTqfLkX0JIUS+oyhw7+KTI19Xdz6ZMyyNhQN41YTitVKTMOeykLYs3s1jrz3k10WSsVxCpVIZfaqwVilnXOzMiXyYmOG4MRXg6mBJrVLOOTLNhY2NDd7e3kbVrVy5MitXrqRw4cLY29tnWMfNzY39+/dTu3ZtAJKTkzl27Bj+/v4Z1vfz80On0/HXX3/pT1M+rXz58ixZsoSkpKQXHh0rWbIk5ubm7N69G09PTyB1+aKDBw8aXDAghBDiJTyIeJJ8XdkBD5+5uExrDcWqpSZexWuDWwVQZ3KAwNopdR6x5w3kN7NIrZfHSDKWB2nUKj5tUILBP59FBQYJWVrqFR7sk6PzjRmrQ4cOTJ48mZYtWzJmzBiKFi3KtWvX+Omnn/j0008pWrQoAwYMYNKkSZQqVYoyZcrw1VdfERMTk2mbXl5ehIWF0aVLF7799lsqVKjAtWvXiIyMpE2bNvTt25dp06bx4YcfMnToUBwcHNi3bx+BgYH6KzzT2NjY0KtXLz755BMKFixIsWLF+PLLL4mLi6Nr1645/fQIIUT+8vA2XNkJV/5KTb4eXDPcrjEHj6AnyZd7ZTAzcgqkAh6pE7r+dzQtKTmZ3bt3U6NGDbQyA78whfqlnZjRvlK6ecZcX8M8Y1lhbW3Njh07+Oyzz3jvvfd4+PAhRYoUoX79+vojZf/73/+4desWYWFhqNVqOnfuTLNmzYiLy3zg5qxZsxg2bBi9e/fm3r17FCtWjGHDhgHg5OTEtm3b+OSTT6hTpw4ajYaKFSsajAt72qRJk9DpdISEhPDw4UMCAgLYuHEjjo6O2f+ECCFEfhJ3P/V0Y9qRr6jzhttVGiji/yT58ggE7SsMJSng8STZSkoi2vpG6tG0bJoU3FRUikxFnmNiYmJwcHAgOjra4BRdfHw8V65coXjx4i91JZ5OpyMmJgZ7e3sUVK91Bv7X4en+qdV5d/aV573OSUlJrF+/nqZNm2bbygK5SX7vH+T/Pkr/8r4c6WN8DFzb8yT5unPimQoqcCv/36D72uBZDSzsMmzqVeXka5jZ73dOkSNjeZxGraJaybx3flwIIUQekBgH1/f9l3zthJtHQUkxrONc9smAe88aYJ19K6a8KSQZE0IIIUSq5AT459CTU4/XD4AuybCOY/Enpx29aoGdi2lizUckGRNCCCHeVCnJcOv4kwH3Efsg+bFhHfsihslXHhwgn9tJMiaEEEK8KXQ6iDz1ZMzXtT2Q8MzV69aFniRfxWtDwRKgyttjkXM7ScaEEEKI/EpRIOoCXN/930Sru+Cx4bq7WDqkHvHy+m/cV+Gykny9ZpKMCSGEEPnJv1fhyg40l/+i8dktaI89MNyutUm9yjHtyJdr+cwnWhWvhSRjQgghRF4Wc+u/AfdpE61GAKAGLAFFY4HKIxCK10lNvopUBk3+nM4jr5JkTAghhMhLYu8ZTrR674LhdrUZFPEnpVhN9t3REti6L1qrnJnrS2QPScaEEEKI3Cw++pmJVk8+U0GVOgt98dqpR7+KVQULW3RJSUStXw9mWZ9cXLxekoyJ165u3bpUrFiRqVOnmjqUl3L16lWKFy/O0aNHqVixoqnDEULkN4mxqVNMXNmRegTs5lFQdIZ1Cvs8mWrCqwZYyfJteZkkY3mUKuYGxF7J/IqXHFgsNTg4mKSkJDZs2JBu286dO6lduzbHjx+nfPny2bpfY6UlSWkcHR3x8/Nj3Lhx1KpVyyQxCSHECyUnwD8Hn8xy/8/B9BOtFiz5ZJZ7r1pgW9g0sYocIclYXhR9Hfslb6NKSci8jplF6ur22ZiQde3aldatW/PPP/9QtGhRg22LFi0iICDgtSRiKSkpqFSqTNet3LJlC+XKlSMqKorx48fTvHlzzp8/j4uLzBIthMgFUpJTj3Zd3fHURKvxhnXsiz4111ctcCiacVsiX8i7qzC/yeLuPz8Rg9S/tOLuZetumzdvjrOzM4sXLzYof/ToEatWraJr167cu3ePdu3aUaRIEaytrfHz8+OHH354brv//vsvoaGhODo6Ym1tTdOmTbl06ZJ+++LFiylQoABr167Fx8cHCwsLIiIiMm3PyckJV1dXfH19GTZsGDExMezfv1+//eTJk7zzzjvY2tri4uJCSEgIUVFR+u0bNmygZs2aFChQACcnJ5o3b24QjxBCZIlOB7f+hj3TYVkb+MILFjSArWPg8vbURMzGGXxbQ/A30P8oDDwJ786Ciu0kEXsDSDKWWyhK6jgBY25Jj1/cHqQuaWFMe4piVHNmZmaEhoayePFilKces2rVKlJSUmjXrh3x8fH4+/vz+++/c/LkSXr06EFISAgHDhzItN1OnTpx6NAh1q5dy969e1EUhTZt2pCU9OQwfVxcHF988QXz58/n1KlTFC784kP0jx8/5rvvvgPA3NwcgAcPHlCvXj0qVarEoUOH2LBhA3fu3KFNmzb6x8XGxjJo0CAOHTrE1q1bUavVvPvuu+h0ugz3I4QQBhQF7p6DA/NgZUeYXALm1IJNw+HCRkh8CJYFoExzeGcy9N4Hgy/A+wvBv5PMeP8GktOUuUVSHExwN6qq0Rn0wibG1Rt2E8xtjKrapUsXJk+ezF9//UXdunWB1FOUrVu3xsHBAQcHBwYPHqyv369fPzZu3MiPP/5IYGBguvYuXLjA2rVr2b17N9WrVwdg6dKleHp68ssvv9C2bVsAkpKSmDlzJhUqVHhhjNWrV0etVhMXF4eiKPj7+1O/fn0Apk+fTqVKlZgwYYK+/sKFC/Hw8OD8+fO89dZbtG7d2qC9hQsX4uzszOnTp/H19TXqeRJCvEEURT/Rqn7Q/aM7hnXMbcGz+pNZ7l39ZKJVoSfJmMiSMmXKUL16dRYuXEjdunW5ePEiO3fuZMyYMUDqeK4JEybw448/cuPGDRITE0lISMDa2jrD9s6cOYOZmRlBQUH6MicnJ7y9vTl79qy+zNzc3OjxaCtXrqRMmTKcPHmSTz/9lMWLF6PVpk5wePz4cf78809sbW3TPe7SpUu89dZbXLhwgVGjRrF//36ioqL0R8QiIiIkGRNCpIq5+WTA/ZUdEP3M0AkzS/AIfDLdhHslmWhVZEqSsdxCa516hMoIupvHUS9+58UVu2xIXebCmH1nQdeuXenXrx8zZsxg0aJFlCxZkjp16gAwefJkvvnmG6ZOnYqfnx82NjZ8/PHHJCYmZmkfz7KyskJl5GF7Dw8PSpUqRalSpUhOTubdd9/l5MmTWFhY8OjRI4KDg/niiy/SPc7NzQ1IvWrU09OTefPm4e7ujk6nw9fX95X7IIQwsQfXn4ylTU7GIe4q3DoOZv/9FD7vKvTYqGcmWr1ouF1tBkUCngy6L1oFtDK/lzCOJGO5hUpl9KlCtFbG1TOzMr7NLGjTpg0DBgxg+fLlfPfdd/Tq1UufKO3evZuWLVvSsWNHAHQ6HefPn8fHxyfDtsqWLUtycjL79+/Xn6a8d+8eFy9epGzZsq8c6/vvv8+oUaOYOXMmAwcOpHLlyqxZswYvLy/MzNK//e/du8e5c+eYN2+efjqMXbt2vXIcQggTe3AdpvunXtwEaIG6AOeeqvP0VeiPHxhOtBp5yrA9lfqpiVZrg0fqRKtCvAxJxkSW2dra0rZtW4YOHUpMTAydOnXSbytVqhSrV69mz549ODo6MmXKFO7cuZNpMlaqVClatmxJ9+7dmTNnDnZ2dnz22We4ubnRsmXLV45VpVLRv39/Pv/8cz766CP69OnDvHnzaNeuHZ9++ikFCxbk4sWLrFixgvnz5+Po6IiTkxNz587Fzc2NiIgIhgwZ8spxCCFMLO6ePhHLVHIC/Dke7p5NPWKWbqLVck+SL8/qYFUgx8IVbxa5mjIvsi6IorF4fh0zi9RD7jmka9eu/PvvvzRu3Bh39ycXHowYMYLKlSvTuHFj6tati6urK61atXpuW4sWLcLf35/mzZtTrVo1FEXhxx9/1I/zelVhYWEkJSUxffp03N3d2b17NykpKTRq1Ag/Pz8+/vhjChQogFqtRq1Ws2LFCg4fPoyvry8DBw5k8uTJ2RKHECIPOP7DkxnvnbwhoAt8sBg+uQS998A7k6BMU0nERLaSI2N5kYMHMWF/YqdJRP0aZ+B/WlrS9KyCBQvyyy+/PPex27dvN7jv6Oion4ICUk9txsTE6O936tTJ4OhbZry8vDKMydramvv37+vvlypVip9++inTdho0aMDp06cNyp5uN7P9iDfAq4w5Es+nKKnzbSU9fjKFT1Lcf/+m3X92W9yT/yc+cz/t/2nlibHGxfHWO1CuVepVjw5FcrTLQqSRZCyPUuyLgL09ZDILvRAim2V1zFF+oiiQkvhU0vN0whP36olSWjm54I+cukPAvaKpoxBvGJMnYzNmzGDy5Mncvn2bChUqMG3atAzno0ozdepUZs2aRUREBIUKFeL9999n4sSJWFqmv2pl0qRJDB06lAEDBhgsSl23bl3++usvg7offfQRs2fP1t+PiIigV69e+mkQwsLCmDhxYoaDvoUQbwBjxxzF3Xv9yVhK0guSnqeOLD2bRGXyGLPEWBo/eoDZqd6p25SU19cfjXnqVd5a69QLlsyf+r/W5r9/rVLLDLY9/Zin69nAv1fghw9fXx+EyAKTZhYrV65k0KBBzJ49m6CgIKZOnUrjxo05d+5chjOsL1++nCFDhrBw4UKqV6/O+fPn6dSpEyqViilTphjUPXjwIHPmzMl0bqru3bvr58YCDObBSklJoVmzZri6urJnzx5u3bpFaGgoWq3WYLJQIYR4IV2KkYnSs9ufTZQyOlX3X7kuOdvDVgEZTsygNjNMiJ5NegySpGcSpOclT2nbzKxAkwM/Tc+u/ShELmLSZGzKlCl0796dzp07AzB79mx+//13Fi5cmOEVbHv27KFGjRq0b98eSB27065dO4N1ByF1rcQOHTowb948xo0bl+G+ra2tcXV1zXDbpk2bOH36NFu2bMHFxYWKFSsyduxYPvvsMz7//HP90jpCCJHOig6pg7/TkquU1zg/nUr9JCF6UdJjUJ7+CFSy2oKd+w5R8+1GaK0dntSXiUuFyHYmS8YSExM5fPgwQ4cO1Zep1WoaNGjA3r17M3xM9erVWbp0KQcOHCAwMJDLly+zfv16QkJCDOr16dOHZs2a0aBBg0yTsWXLlrF06VJcXV0JDg5m5MiR+qNje/fuxc/PDxcXF339xo0b06tXL06dOkWlSpUybDMhIYGEhCenMdIGoSclJRmss5icnIyiKKSkpLzUeodpg8cVRcmX6yXml/6lpKSgKArJyckGrz+gv/9seX6RL/uXnIxRaUjMPxkWK6ieSY6sUDJIlJSnT8Hp6/233exJMqWYPXs0yir19F42rWmYlJREjFUkSXYekHZlsw7Q5dHX1NwBM40FqpTMTzUrGguSzR0gn7xv8+Xn8Ck52b/X/ZyZLBmLiooiJSXFIOEBcHFxMVgG52nt27cnKiqKmjVr6n/kevbsybBhw/R1VqxYwZEjRzh48GCm+27fvj2enp64u7vz999/89lnn3Hu3Dn9FXa3b9/OMK60bZmZOHEio0ePTle+adMmg9OgKpUKNzc37t+/j52dXabtvcjDhw9f+rF5QV7v38OHD4mNjWXbtm2ZXn25efPm1xzV65Vf+qfRJVDun+UUN6LuEY8uxFh7kaK2IFltToranBS1BTqV1rhESQES/7tlKO6/2+uRX15DAKsyEzFPfpTp9kQzWx7v/hv4+/UF9Rrkp9cwIznRv7i41/cZg1wwgD8rtm/fzoQJE5g5cyZBQUFcvHiRAQMGMHbsWEaOHMn169cZMGAAmzdvznBAf5oePXro/+/n54ebmxv169fn0qVLlCxZ8qXjGzp0KIMGDdLfj4mJwcPDg0aNGmFvb29Q986dO8TExGBpaYm1tbXRS/1A6hGj2NhYbGxssvS4vCKv909RFOLi4nj48CFubm5UrFgxXZ2kpCQ2b95Mw4YNs20+tdwk3/RP0aE6uRrNn2NRPbxl1EP8GnZInZk9j8s3r2Em8nv/IP/3MSf79/T0Sq+DyZKxQoUKodFouHPHcGX7O3fuZDqWa+TIkYSEhNCtWzcgNZGKjY2lR48eDB8+nMOHDxMZGUnlypX1j0lJSWHHjh1Mnz6dhIQENBpNunbTFqm+ePEiJUuWxNXVlQMHDqSLC8g0NgALCwssLNJPxqrVatO9UYoUKYJGoyEqKirT9jKjKAqPHz/O0nqNeUl+6Z+joyOurq7P7UNG7438JE/379oe2DgsdQJQAFtXeJT5kfE0WjOzJ6f18oE8/RoaIb/3D/J/H3Oif6/7+TJZMmZubo6/vz9bt27Vz9Cu0+nYunUrffv2zfAxcXFxqJ+ZVystuVIUhfr163PixAmD7Z07d6ZMmTJ89tlnGSZiAMeOHQOeLBRdrVo1xo8fT2RkpP6qzs2bN2Nvb5/psj5ZlXaqsnDhwlk+N52UlMSOHTuoXbt2vvyA5Yf+abXaTN9vIpe7fwU2j4Iza1Pvm9tB7f9BmWCYXf3501vk8MoXQoj8yaSnKQcNGkRYWBgBAQEEBgYydepUYmNj9VdXhoaGUqRIESZOnAhAcHAwU6ZMoVKlSvrTlCNHjiQ4OBiNRoOdnR2+vr4G+7CxscHJyUlffunSJZYvX07Tpk1xcnLi77//ZuDAgdSuXVs/DUajRo3w8fEhJCSEL7/8ktu3bzNixAj69OmT4ZGvV6HRaLL8o63RaEhOTsbS0jLPJivPk9/7J3Kp+GjYMRn2z0m9AlKlhsph8PYwsP1vqp2+h/Uz8CclJ7N7925q1KiRejQMZAZ+IcRLMWky1rZtW+7evcuoUaO4ffs2FStWZMOGDfrB8hEREQZHwkaMGIFKpWLEiBHcuHEDZ2dngoODGT9+vNH7NDc3Z8uWLfrEz8PDg9atWzNixAh9HY1Gw2+//UavXr2oVq0aNjY2hIWFGcxLJoTIJ1KS4fAi2D7xyVJHJd6GxuPBpZxh3QIeT5KtpCSirW+kjg+TPxqEEK/A5AP4+/btm+lpyWfXMDQzMyM8PJzw8HCj23+2DQ8Pj3Sz72fE09OT9evXG70fIUQedGEzbBwOUf+taVToLWg0Hko1zLYpIoQQ4kVMnoyJrEnRKey/cp/DUSqcrtynmndhNGr50RAiS+6chk0j4NLW1PtWBVNPR/p3kklNhRCvnSRjeciGk7cYve40t6LjAQ3fXTiEm4Ml4cE+NPF1M3V4QuR+j+7C9glweHHqLPlqLQR9BLU/AasCpo5OCPGGkmQsj9hw8ha9lh7h2alDb0fH02vpEWZ1rCwJmRCZSYqH/bNh51eQ8N/8QWVbQMPRULCEaWMTQrzxJBnLA1J0CqPXnU6XiEHqZN0qYPS60zT0cZVTlkI8TVHg9C+wORweXEstc6sIjSeAVw1TRiaEEHqSjOUBB67c/+/UZMYU4FZ0PAeu3KdaSZnjSAgA/jkMG4fC9f2p9+3coH44lG8Lz8xXKIQQpiTJWB4Q+TDzROxl6gmRr0X/A1tGw4kfU+9rraHGAKjeD8xtTBubEEJkQJKxPKCwXebrbL5MPSHypYRHsHsq7JkGyf/9YVKhPdQfCfbuJg1NCCGeR5KxPCCweEHcHCy5HR2f4bgxgMJ2FgQWL/ha4xIiV9ClwLHlsG0sPPpvrVvPGqmTtrpXMm1sQghhBBk4kQdo1CrCg1PXxHze8Px7j56zZp4Q+dGVHTC3Dqztm5qIORaHtkuh0++SiAkh8gxJxvKIJr5uzOpYGVcHw1ORhe0scLIxJ/JhAu3n7ydKEjLxJoi6CD+0gyXBcPsEWDikzpzfZz+UDZbZ84UQeYqcpsxDmvi60dDHlb0XI9m0cz+NagVRzbswNx88ps2cvVyMfETH+fv5oXtVHG3MTR2uENkv7j789SUcnAe6ZFBpoEpXqDMEbORKYiFE3iRHxvIYjVpFUPGC+BdSCCpeEI1ahUdBa5Z3r0phOwvO3n5IxwX7iY5LMnWoQmSflCTYNwu+rQT7Z6UmYqUaQ+990HSyJGJCiDxNkrF8onghG5Z3D6KQrTmnbsYQuugAD+MlIRN5nKLA2fUwsypsGALxD6BwOQj5GTr8CM5vmTpCIYR4ZZKM5SPehe1Y2i0IR2stx68/oPOig8QmJJs6LCFezq2/4bsWsKId3LsINs7QfCr03Akl65k6OiGEyDaSjOUzZVzt+b5rEPaWZhy69i9dlxzkcWKKqcMSwngPb8OvfWFO7dSrJTUWUHMQ9DsCAZ1BrTF1hEIIka0kGcuHfIs48F3XIGwtzNh3+T49vj9EfJIkZCKXS3oMOybDt5Xh6PeAAr6toe9BaBAOlvamjlAIIXKEJGP5VEWPAizuXAVrcw07L0TRe9kREpN1pg5LiPR0Ovh7FUwLgG3jICkWigRA183w/kJw9DR1hEIIkaMkGcvHArwKsiCsCpZaNdvORtJ3+RGSUiQhE7lIxH5Y0AB+6gYx/4CDB7ReAN22gEegqaMTQojXQpKxfK5aSSfmhQZgbqZm0+k7fLzyGMmSkAlT+/carOoECxvBjcNgbgv1RqaekvR7XyZtFUK8UWTS1zdArVLOzOnoT4/vD/H737cw16j5vw8qoFHLD554zeJjYOdXqXOGpSQAKqgcAm+PADsXU0cnhBAmIcnYG+LtMoWZ3r4yfZYd4eejNzDXqJn4nh9qScjE65CSDEe/g23jIS4qtax4ndTFvF39TBubEEKYmJymfIM0LufKNx9WQq2ClYeuM2rtSRRFMXVYIr+7uBXm1ILfBqYmYk6loN1KCP1VEjEhhECOjL1xmpV3IymlIgN/PMbSfRGYazSMbF4WlYzREdnMNv4GmhUfwqUtqQVWjlB3KAR0AY3WtMEJIUQuIsnYG6hVpSIkJuv4dM3fLNx9BXMzNZ81KS0JmcgesfdQbxvP22cWoUYHajMI/AjqfJKakAkhhDAgydgbqk0VDxJSdIz85SSz/7qEuZmaQQ1lnT/xCpITYP8c2PF/aBKiAdC91RR143HgVNLEwQkhRO4lydgbLKSqJ0nJOsb8dppvt17AwkxNn7e9TR2WyGsUBc6sg82j4N8rqUUufuy2a07QB/9DrZVTkkII8TySjL3hutQsTmKKjkl/nGXyxnOYa9R0r13C1GGJvOLGEdg4HCL2pN63dYX6o0j2ac29DRtNG5sQQuQRkowJetYpSWKyjimbzzN+/RnMzdSEVfcydVgiN4u+AdvGwvEfUu+bWUGN/lC9P1jYQlKSaeMTQog8RJIxAUD/+qVITNYx/c+LhK89hVajpn1QMVOHJXKbxFjY/S3s/gaSH6eWlW8L9UeBQ1HTxiaEEHmUJGNC73+N3iIxRcfcHZcZ/ssJzM3UvO8vP7CC/xbzXgFbx8DDW6llxaqlTtpaxN+0sQkhRB4nyZjQU6lUDH2nDInJOhbvucqnq4+j1ahoWbGIqUMTpnR1F2wcBreOp94v4AkNx4BPS1lDUgghsoEkY8KASqUiPNiHhGQdPxyIYNCPxzHXqHnHz83UoYnX7d6l1Cskz/6Wet/CHmoPhqCeYGZh2tiEECIfkWRMpKNSqRjfypekFB2rD/9Dvx+OMkujpqGPLOT8Rnj8AHZMTp0zTJcEKjX4d4a3h4FNIVNHJ4QQ+Y4kYyJDarWKL1qXJylFx6/HbtJn2RHmhvpTt3RhU4cmckpKEhxaBNsnwuP7qWXeDaDROChc1rSxCSFEPiYLhYtMadQqvvqgAk39XElM0fHR94fZfTHK1GGJ7KYocH4jzKoOf3ySmog5l4EOa6DjGknEhBAih0kyJp7LTKPmmw8r0aCsCwnJOrotOcSBK/dNHZbILndOwffvwvI2EHUerAtBsynQczeUamDq6IQQ4o0gyZh4Ia1GzYwOlahb2pnHSSl0XnSAw9f+NXVY4lU8ioR1A2B2Tbj8J2jMocYA6H8EqnQFjYxgEEKI10WSMWEUCzMNszv6U8PbidjEFDotPMDf/zwwdVgiq5LiYecU+LYyHF4Mig58WkGfA6nTVVg6mDpCIYR445g8GZsxYwZeXl5YWloSFBTEgQMHnlt/6tSplC5dGisrKzw8PBg4cCDx8fEZ1p00aRIqlYqPP/5YX3b//n369eunb6NYsWL079+f6Ohog8eqVKp0txUrVrxyf/MyS62GeaEBBHoV5GFCMiELDnDqZvSLHyhMT1HgxGqYXgW2jobEh+BeCTpvgDZLoGBxU0cohBBvLJMmYytXrmTQoEGEh4dz5MgRKlSoQOPGjYmMjMyw/vLlyxkyZAjh4eGcOXOGBQsWsHLlSoYNG5au7sGDB5kzZw7ly5c3KL958yY3b97k//7v/zh58iSLFy9mw4YNdO3aNV0bixYt4tatW/pbq1atsqXfeZm1uRkLO1ehcrECRD9OImTBAc7dfmjqsMTzXD8ICxrCmq4QHQH2ReDdudBtG3hWM3V0QgjxxjNpMjZlyhS6d+9O586d8fHxYfbs2VhbW7Nw4cIM6+/Zs4caNWrQvn17vLy8aNSoEe3atUt3NO3Ro0d06NCBefPm4ejoaLDN19eXNWvWEBwcTMmSJalXrx7jx49n3bp1JCcnG9QtUKAArq6u+pulpWX2PgF5lK2FGYu7BFK+qAP3YxPpMH8/l+4+MnVY4lkPImB1V1jQAP45CFobeHsE9D0EFdqC2uQHxoUQQmDCecYSExM5fPgwQ4cO1Zep1WoaNGjA3r17M3xM9erVWbp0KQcOHCAwMJDLly+zfv16QkJCDOr16dOHZs2a0aBBA8aNG/fCWKKjo7G3t8fMzPDp6NOnD926daNEiRL07NmTzp07o3rO8i8JCQkkJCTo78fExACQlJREUlLSC+MwVlpb2dlmVllpYEFIZUIXHeLM7Ye0n7uPZd2q4FnQ+pXbzg39y2k52seEh6j3fIv6wCxUyfEoqFDKtyOl7lCwc0sLIPv3+xR5DfM+6V/el9/7mJP9e93PmcmSsaioKFJSUnBxMZzV3cXFhbNnz2b4mPbt2xMVFUXNmjVRFIXk5GR69uxpcJpyxYoVHDlyhIMHDxodx9ixY+nRo4dB+ZgxY6hXrx7W1tZs2rSJ3r178+jRI/r3759pWxMnTmT06NHpyjdt2oS19asnKc/avHlztreZVR2LwrRoDbcfJvDBjJ30902hYDatlJMb+pfTsrWPio5i93ZQ9tYatMmpY/nu2pblVJF2RGu8YOdR4Gj27c8I8hrmfdK/vC+/9zEn+hcXF5ftbT5Pnrp+ffv27UyYMIGZM2cSFBTExYsXGTBgAGPHjmXkyJFcv36dAQMGsHnzZqNOKcbExNCsWTN8fHz4/PPPDbaNHDlS//9KlSoRGxvL5MmTn5uMDR06lEGDBhm07+HhQaNGjbC3t896hzORlJTE5s2badiwIVqtNtvafVn16ifQYcFBLkfFseCKHcu7VsHN4eVP6ea2/uWE7O6j6soONFtGooo8BYDiWJyU+qMp8NY71DDBYt7yGuZ90r+8L7/3MSf7l3Zm63UxWTJWqFAhNBoNd+7cMSi/c+cOrq6uGT5m5MiRhISE0K1bNwD8/PyIjY2lR48eDB8+nMOHDxMZGUnlypX1j0lJSWHHjh1Mnz6dhIQENBoNAA8fPqRJkybY2dnx888/v/CFDAoKYuzYsSQkJGBhkfGhHwsLiwy3abXaHPkg5FS7WeXmqGV592q0nbuXa/fiCFt8mJU9qlLY/tXG2OWW/uWkV+5j1AXYNALOb0i9b+kAdYagqtINMzPz7AnyFchrmPdJ//K+/N7HnOjf636+TDaC19zcHH9/f7Zu3aov0+l0bN26lWrVMr7CKy4uDvUzg47TkitFUahfvz4nTpzg2LFj+ltAQAAdOnTg2LFj+roxMTE0atQIc3Nz1q5da9RRtGPHjuHo6JhpIvamc3WwZHn3qhQpYMWVqFjaz99P1KOEFz9QvJy4+7D+U5hZNTURU5tBUE/ofwyq9YZckIgJIYQwjklPUw4aNIiwsDACAgIIDAxk6tSpxMbG0rlzZwBCQ0MpUqQIEydOBCA4OJgpU6ZQqVIl/WnKkSNHEhwcjEajwc7ODl9fX4N92NjY4OTkpC9PS8Ti4uJYunQpMTEx+sORzs7OaDQa1q1bx507d6hatSqWlpZs3ryZCRMmMHjw4Nf47OQ9RQpY8UP3qrSdu5eLkY/oOH8/P3SviqONJAbZJjkRDs6Dv76A+P/meHvrHWg0FgqVMm1sQgghXopJk7G2bdty9+5dRo0axe3bt6lYsSIbNmzQD+qPiIgwOBI2YsQIVCoVI0aM4MaNGzg7OxMcHMz48eON3ueRI0fYv38/AN7e3gbbrly5gpeXF1qtlhkzZjBw4EAURcHb21s/DYd4vmJO1izvXpU2c/Zy9vZDQhbuZ1m3qjhY5d9D5K+FosDZ32HzSLh/ObXMxRcaj4cSdU0amhBCiFdj8gH8ffv2pW/fvhlu2759u8F9MzMzwsPDCQ8PN7r9Z9uoW7cuiqI89zFNmjShSZMmRu9DGCpeyIbl3YL4cO4+Tt6IIWzhAb7vGoidpSRkL+XWcdg4HK7uTL1vUxjqj4SKHUCtMW1sQgghXpnM+ihyRCkXO5Z2C6KAtZZj1x/QZfFBYhOSX/xA8UTMLfilN8ypk5qImVlCrcGpi3lXDpVETAgh8glJxkSOKetmz9KuQdhZmnHw6r90W3KIx4kppg4r90uMg7++hGn+cGwZoIDfB6kz59cfCRZ2po5QCCFENjL5aUqRv/kWceC7LoGELDjA3sv36PH9IeaFBmCpfQOP6jy4DnH3Uv+fnIxD3NXUU5BpKz9YOULEvtSFvGNupJYVDYQmE6FogElCFkIIkfMkGRM5rlIxRxZ1rkLYwgPsvBBF72VHmN3RH3OzN+jA7IPrMN0fklOn+9ACdQHOPV1JBfw3ntGhGDT8HMq9ByaYtFUIIcTr8wb9GgpTquJVkPlhAViYqdl2NpJ+PxwhKUVn6rBen7h7+kQscwqYWUP9cOh7EHxbSyImhBBvAEnGxGtTvWQh5oUGYK5Rs/HUHQauPEaK7vlXtr5x2i2HWoNA+2qrFwghhMg7JBkTr1Xtt5yZHVIZrUbFb3/f4pPVx9FJQvaElaOpIxBCCPGaSTImXrt6ZVyY1q4yGrWKn47cYNjPJyQhE0II8caSZEyYRBNfV6a2rYhaBSsOXid87akXTsabZykKnFln6iiEEELkUnI1pTCZ4AruJKXo+N+q43y/7xrmZmpGNCtr6rCy1/3LsLb/k9nzhRBCiGdIMiZM6r3KRUlK0fHZmhMs2HUFczM1A+uVMHVYr06XAvtmwbZxkPw4dfb85HhTRyWEECIXkmRMmFzbKsVITNYx8tdTzNp+Ca0KSpo6qFdx5zSs7Qs3DqfeL14b6g6F71s9f3oLMwuwdnotIQohhMg9XioZS0pK4vbt28TFxeHs7EzBggWzOy7xhgmp5kViisLY307z7Z+XaF5MRVNTB5VVyYmwawrs+D/QJYGFPTQal7qOpEoFfQ/rZ+BPSk5m9+7d1KhRA23aDPzWTlDAw4QdEEIIYQpGJ2MPHz5k6dKlrFixggMHDpCYmIiiKKhUKooWLUqjRo3o0aMHVapUycl4RT7WtWZxEpN1fLHhLL9FaCi/5xo96nibOizj3DgMv/aFyNOp90s3hWZfgb37kzoFPJ4kW0lJRFvfALcKoNW+/niFEELkGkZdTTllyhS8vLxYtGgRDRo04JdffuHYsWOcP3+evXv3Eh4eTnJyMo0aNaJJkyZcuHAhp+MW+VSvuiXpXy/1JOWEP87x3d6rpg3oRRLjYONwmN8gNRGzLgTvL4QPlxsmYkIIIUQmjDoydvDgQXbs2EG5cuUy3B4YGEiXLl2YPXs2ixYtYufOnZQqVSpbAxVvjr51S3Dm3AU231Az6tdTaDVq2gUWM3VY6V3ZCev6p14xCVC+LTSeCDYy7ksIIYTxjErGfvjhB6Mas7CwoGfPnq8UkBAqlYpmHjo8PIuzcM81hv18Aq1Gzfv+RU0dWqr4aNgcDocXpd63LwLNv4a3Gps2LiGEEHnSK11N+c8//wBQtGgu+ZEU+YZKBUOavEWKAkv2XuPT1ccxN1PTooKJT/2d3wjrPoaHN1PvB3SBBqPB0t6kYQkhhMi7sjwDv06nY8yYMTg4OODp6YmnpycFChRg7Nix6HS6nIhRvKFUKhXhweVoF+iBToGBK4+x4eQt0wQTGwVrusHyNqmJWMES0On31CNikogJIYR4BVk+MjZ8+HAWLFjApEmTqFGjBgC7du3i888/Jz4+nvHjx2d7kOLNpVarGN/Kj8RkhTVH/qHfD0eZ3VFN/bIurycARYGTa+CPT1OnpVCpoVrf1HnDzK1fTwxCCCHytSwnY0uWLGH+/Pm0aNFCX1a+fHmKFClC7969JRkT2U6tVvHl++VJStGx9vhNei09wrywAOq85ZyzO465Cb8NgvN/pN4vXA5aTocilXN2v0IIId4oWT5Nef/+fcqUKZOuvEyZMty/fz9bghLiWRq1iiltKvCOryuJKTp6fHeIPRejcmZnigKHF8OMoNRETK2Ft4dDj+2SiAkhhMh2WU7GKlSowPTp09OVT58+nQoVKmRLUEJkxEyj5psPK9GgbGESknV0XXKIA1ey+Q+A+5dhSTCsGwAJMVAkAHruhDqfgpl59u5LCCGE4CVOU3755Zc0a9aMLVu2UK1aNQD27t3L9evXWb9+fbYHKMTTzM3UzOhQme7fHWbH+bt0XnSA77sFUbmY46s1nG5hbyuoPxKCeoJakz3BCyGEEBnI8pGxOnXqcP78ed59910ePHjAgwcPeO+99zh37hy1atXKiRiFMGBhpmFuiD/VSzoRm5hC2MIDnPgn+uUbvHMaFjSETcNTE7HitaH3XqjWRxIxIYQQOe6l5hlzd3eXgfrCpCy1GuaHBdBp4UEOXL1PxwX7+aF7VXzcszDNxIsW9hZCCCFeA6OSsb///tvoBsuXL//SwQiRFdbmZizsXIWQBfs5GvGAjgv2s7JHVUq52L34wcYs7C2EEEK8BkYlYxUrVkSlUqEoCqqnjhgoigJgUJaSkpLNIQqROVsLMxZ3DqTj/P2cuBFN+/mpCVkJZ9uMH5AYB3+Oh30zQdGlLuzd9Eso954cDRNCCGESRo0Zu3LlCpcvX+bKlSusWbOG4sWLM3PmTI4dO8axY8eYOXMmJUuWZM2aNTkdrxDpOFhp+b5rIGXd7Ln7MIH28/Zz7V5s+opXdsLsGrB3emoiVr4t9DkAvq0lERNCCGEyRh0Z8/T01P//gw8+4Ntvv6Vp06b6svLly+Ph4cHIkSNp1apVtgcpxIsUsDZnaddAPpy7jwuRj2g/bz8rP6pKUUdrWdhbCCFErpblqylPnDhB8eLF05UXL16c06dPZ0tQQrwMJ1sLlnUPokQhG248eEz7efu5f3QtzKj6JBEL6AK990kiJoQQItfIcjJWtmxZJk6cSGJior4sMTGRiRMnUrZs2WwNToisKmxnyfLuVfFzTGLQwy8p+GuILOwthBAiV8vy1BazZ88mODiYokWL6q+c/Pvvv1GpVKxbty7bAxQiSxQF14jf+IVP0Gjuk6KoWG3RigYhX+Pk+IoTwwohhBA5IMvJWGBgIJcvX2bZsmWcPXsWgLZt29K+fXtsbGyyPUAhjPbUwt4aINGpLD2iO7M9pihlvzvJD92DKGAtSxoJIYTIXV5q0lcbGxt69OiR3bEI8XIUBY4sgU0jU9eTVGuhzqeY1/iYUf8mcmruPs7ciiFkwQGWdgvCwUpr6oiFEEIIvZdKxgBOnz5NRESEwdgxgBYtWrxyUEIY7f5lWNsfru5MvV8kAFpOh8Kp4xdLOJuzvFsQH87dx4kb0XRadIDvuwZha/HSb30hhBAiW2X5F+ny5cu8++67nDhxQj8RLDyZ+FUmfRWvRRYW9i7lYsfSbkG0m7ePoxEP6LzoAEu6BGJtLgmZEEII08vy1ZQDBgygePHiREZGYm1tzalTp9ixYwcBAQFs3749B0IU4hkvsbB3WTd7vu8ShJ2lGQev/ku3JYeIT5I/HIQQQphelpOxvXv3MmbMGAoVKoRarUatVlOzZk0mTpxI//79sxzAjBkz8PLywtLSkqCgIA4cOPDc+lOnTqV06dJYWVnh4eHBwIEDiY+Pz7DupEmTUKlUfPzxxwbl8fHx9OnTBycnJ2xtbWndujV37twxqBMREUGzZs2wtramcOHCfPLJJyQnJ2e5fyIbJSfC9kkwp3bq2pIW9hD8LYSuhYLp5757ll9RB5Z0CcTGXMOeS/fo8f1hEpIlIRNCCGFaWU7GUlJSsLNLXYi5UKFC3Lx5E0idpf/cuXNZamvlypUMGjSI8PBwjhw5QoUKFWjcuDGRkZEZ1l++fDlDhgwhPDycM2fOsGDBAlauXMmwYcPS1T148CBz5szJcOHygQMHsm7dOlatWsVff/3FzZs3ee+99wz62KxZMxITE9mzZw9Llixh8eLFjBo1Kkv9E9noxmGYWwe2TwRdUurC3n32g39YlpYyqlzMkcVdArHSathx/i59lh0hMVmXg4ELIYQQz5flZMzX15fjx48DEBQUxJdffsnu3bsZM2YMJUqUyFJbU6ZMoXv37nTu3BkfHx9mz56NtbU1CxcuzLD+nj17qFGjBu3bt8fLy4tGjRrRrl27dEfTHj16RIcOHZg3bx6Oz8wtFR0dzYIFC5gyZQr16tXD39+fRYsWsWfPHvbt2wfApk2bOH36NEuXLqVixYq88847jB07lhkzZqS7YEHksMQ42Dgc5jeAyNOpC3u/vxA+XA727i/VZBWvgiwIC8DCTM2WM5EMWHGU5BRJyIQQQphGlkcwjxgxgtjY1EWYx4wZQ/PmzalVqxZOTk6sXLnS6HYSExM5fPgwQ4cO1Zep1WoaNGjA3r17M3xM9erVWbp0KQcOHNDPd7Z+/XpCQkIM6vXp04dmzZrRoEEDxo0bZ7Dt8OHDJCUl0aBBA31ZmTJlKFasGHv37qVq1ars3bsXPz8/XFxc9HUaN25Mr169OHXqFJUqVcowvoSEBBISEvT3Y2JiAEhKSiIpKcnIZ+bF0trKzjZzk7R+pVz6C7ONg1H9ewUAne8HpDQcB9ZO8IqnjKt4OjCrfUU+WnaUP07eZsCKo3z1vh8a9etZMPxNeQ3za/8g//dR+pf35fc+5mT/XvdzluVkrHHjJ2v6eXt7c/bsWe7fv4+jo6P+ikpjREVFkZKSYpDwALi4uOgnk31W+/btiYqKombNmiiKQnJyMj179jQ4TblixQqOHDnCwYMHM2zj9u3bmJubU6BAgXT7vX37tr5ORnGlbcvMxIkTGT16dLryTZs2YW1tnenjXtbmzZuzvc3cwCwljvI3VmJ59E8AHmsLctyjE3e0FWH7/mzdV6dSKhaeU/P7idvcvX2TdiV1vKZ8DMi/r2Ga/N4/yP99lP7lffm9jznRv7i4uGxv83mynIx99913BAQE4OPjoy8rWLAg8fHx/Pjjj4SGhmZrgE/bvn07EyZMYObMmQQFBXHx4kUGDBjA2LFjGTlyJNevX2fAgAFs3rwZS0vLHIsjM0OHDmXQoEH6+zExMXh4eNCoUSPs7bNvPcSkpCQ2b95Mw4YN0Wrz1wSmqgubUK8fjfrRLQBSKnfCrF44/hZ2ObK/pkCFU3cY8OPfHLirprinB2OCfVDncEaWn19DyP/9g/zfR+lf3pff+5iT/Us7s/W6ZDkZ69SpEzY2NixevJjWrVvry6Ojo+ncubPRyVihQoXQaDTprmK8c+cOrq6uGT5m5MiRhISE0K1bNwD8/PyIjY2lR48eDB8+nMOHDxMZGUnlypX1j0lJSWHHjh1Mnz6dhIQEXF1dSUxM5MGDBwZHx57er6ura7pxaGlxZhYbgIWFBRYWFunKtVptjnwQcqpdk4iNgg1D4MQqAB5ZuGD5wVzMvOuS8WQV2ad5xaLoVGo+XnGUlYduYKE1Y3SLclk60vuy8tVrmIH83j/I/32U/uV9+b2POdG/1/18ZXkAP8Do0aMJCQnh888/f+kdm5ub4+/vz9atW/VlOp2OrVu3Uq1atQwfExcXh1ptGLJGk/pTrSgK9evX58SJExw7dkx/CwgIoEOHDhw7dgyNRoO/vz9ardZgv+fOnSMiIkK/32rVqnHixAmDqzo3b96Mvb29wRFBkQ0UBU6shhmBqYmYSk1K1b5sLzMOxbPGawujRQV3Jr9fAZUKvtt7jfG/n9FPaCyEEELkpJeagrxjx45Ur16dd999l5MnT/L999+/1M4HDRpEWFgYAQEBBAYGMnXqVGJjY+ncuTMAoaGhFClShIkTJwIQHBzMlClTqFSpkv405ciRIwkODkaj0WBnZ4evr6/BPmxsbHByctKXOzg40LVrVwYNGkTBggWxt7enX79+VKtWjapVqwLQqFEjfHx8CAkJ4csvv+T27duMGDGCPn36ZHjkS7ykpxb2BqBwOWg5HV1hP1LWr3/t4bT2L0pSio4hP51g/q4rWGjVDG5U+rUcIRNCCPHmynIylvbDVLVqVfbv30+LFi2oXr06s2fPzvLO27Zty927dxk1ahS3b9+mYsWKbNiwQT9YPiIiwuBI2IgRI1CpVIwYMYIbN27g7OxMcHAw48ePz9J+v/76a9RqNa1btyYhIYHGjRszc+ZM/XaNRsNvv/1Gr169qFatGjY2NoSFhTFmzJgs91FkIJOFvanxMZiZgwmv/PkwsBiJKTpG/XqKGX9ewlyjYUCDUiaLRwghRP6X5WTs6VM3xYoVY8+ePXTo0IGGDRu+VAB9+/alb9++GW57dnklMzMzwsPDCQ8PN7r9jJZosrS0ZMaMGcyYMSPTx3l6erLeBEdn8r0XLOydG4RW8yIxWce438/w9ZbzmJup6VW3pKnDEkIIkU9lORkLDw/H1tZWf9/a2pqff/6Z8PBwduzYka3BiXwkCwt75wbdapUgMUXHlxvO8cWGs2g1KrrVytqkxkIIIYQxXioZy0hG82sJAaQu7L22b+qSRpC6sHfwt0atJ2lKvet6k5Ck45utFxj3+xkszNSEVPMydVhCCCHyGaOSsbVr1/LOO++g1WpZu3ZtpvVUKhXBwcHZFpzI45ITYdcU2PF/qetJWthDo3FQOTRL60ma0scNSpGYomPW9kuM/PUUWo2aDwOLmTosIYQQ+YhRyVirVq24ffs2hQsXplWrVpnWU6lUpKSkZFdsIi+7cRh+7Zu6niSkLuzd7KuXXk/SVFQqFZ82Lk1iso4Fu64w9OcTmJupea9yUVOHJoQQIp8wKhnT6XQZ/l+IdBLj4M/xsG8mKLrUhb2bfgnl3sszR8OepVKpGNGsLEkpOr7be43Bq46j1agJrpC3EkshhBC500vNMyZEhq7shHX9U6+YBCjfFhpPBBsn08aVDVQqFZ8HlyMxWceKg9f5eOUxtBo1TXwzX5FBCCGEMIZRydi3335rdIP9+/d/6WBEHhUfDZvD4fCi1Pv2RaD51/BW4+c/Lo9Rq1VMeNePxBQdPx25Qb8fjjC7oz/1y7q8+MFCCCFEJoxKxr7++mujGlOpVJKMvWnOb4R1H8PDm6n3A7pAg9FgmX0Lo+cmarWKye9XIClFYd3xm/RaeoT5YQHUfsvZ1KEJIYTIo4xKxq5cuZLTcYi85pmFvSlYAlpMA6+apo3rNdCoVUxpU4HE5BQ2nrpD9+8OsahzFaqXLGTq0IQQQuRBL7VQuHiDZbCwN9X7Q8/db0QilkarUTOtXWXqlylMQrKOrosPcfDqfVOHJYQQIg96qQH8//zzD2vXriUiIoLExESDbVOmTMmWwEQulMnC3hSpbNq4TMTcTM2MDpXp/t0hdl6IovOig3zfNZBKxRxNHZoQQog8JMvJ2NatW2nRogUlSpTg7Nmz+Pr6cvXqVRRFoXLlN/NHOd970cLebzBLrYZ5oQF0XnSQvZfvEbrwAD90r4pvEQdThyaEECKPyPJpyqFDhzJ48GBOnDiBpaUla9as4fr169SpU4cPPvggJ2IUpnT/MiwJhnUDUhOxIgHQc2dqMvaGJ2JpLLUaFnQKoIqXIw/jk+m4YD9nbsWYOiwhhBB5RJaTsTNnzhAaGgqAmZkZjx8/xtbWljFjxvDFF19ke4DCRHQpsGc6zKwOV3emLuzdeAJ03QSFy5o6ulzH2tyMhZ2qUNGjAA/ikug4fz8X7jw0dVhCCCHygCwnYzY2NvpxYm5ubly6dEm/LSoqKvsiE6Zz5zQsaAibhkPy49SFvXvvhWp9QK0xdXS5lp2lliVdAvEtYs+92ETaz9/P5buPTB2WEEKIXC7LyVjVqlXZtWsXAE2bNuV///sf48ePp0uXLlStWjXbAxSvUXIibJ8Ec2qnri1pYQ/B30LoWihY3NTR5QkOVlq+7xJEGVc77j5MoP28/UTcizN1WEIIIXKxLCdjU6ZMISgoCIDRo0dTv359Vq5ciZeXFwsWLMj2AMVrcuMwzK0D2yeCLil1Ye8++8E/LM+uKWkqjjbmLO0WRKnCttyOiafdvH3cePDY1GEJIYTIpbJ8NWWJEiX0/7exsWH27NnZGpB4zRLjYPsE2Dsj3yzsnRsUsrVgWbcg2s7dx5WoWNrP28fKHtVwdbA0dWhCCCFymVea9PXRo0fExMQY3EQecmUnzK4Be6alJmJ+baDPAfBtLYlYNihsb8ny7kEUK2jNtXtxtJ+/j8iH8aToFPZfuc/hKBX7r9wnRaeYOlQhhBAmlOUjY1euXKFv375s376d+Ph4fbmiKKhUKlJSUrI1QJED3pCFvXMDNwcrlncPou2cfVy+G0vL6btJ0SlEPkwANHx34RBuDpaEB/vQxNfN1OEKIYQwgSwnYx07dkRRFBYuXIiLiwsqOYKSt7xhC3vnBkUdrVnePYiW03dzKzo+3fbb0fH0WnqEWR0rS0ImhBBvoCwnY8ePH+fw4cOULl06J+IROeUNXtg7NyjqaI1Wk/EfLgqgAkavO01DH1c0avkDRwgh3iRZHjNWpUoVrl+/nhOxiJwgC3vnCgeu3Ofuo8RMtyvAreh4DlyRxcaFEOJNk+UjY/Pnz6dnz57cuHEDX19ftFqtwfby5ctnW3DiFcnC3rlG5MP0pydfpZ4QQoj8I8vJ2N27d7l06RKdO3fWl6lUKhnAn5vIwt65TmE746a0MLaeEEKI/CPLyViXLl2oVKkSP/zwgwzgz43uX4a1/VPXk4TUhb1bTpf1JE0ssHhB3BwsuR0dT2YTWViba6hUrMDrDEsIIUQukOVk7Nq1a6xduxZvb++ciEdk5sF1iLuX+v/kZBzirsKt42D230to5Qhn1sG2canrSZpZQf2RENRT1pPMBTRqFeHBPvRaegQVZJiQxSWm0GXxQWa0r4yjjRzBFEKIN0WWk7F69epx/PhxScZepwfXYbo/JCcAoAXqApx7utJTP/HFa6euKSnrSeYqTXzdmNWxMqPXnTaY4sLNwZIWFd1Zuvcaey7do8WMXcwLDaCMq0w3IoQQb4IsJ2PBwcEMHDiQEydO4Ofnl24Af4sWLbItOPGfuHv6RCxzCmhtoMlEqBwqM+jnUk183Wjo48rei5Fs2rmfRrWCqOZdGI1axXuVitLtu4Ncv/+Y92buYUqbijTxdTV1yEIIIXJYlpOxnj17AjBmzJh022QAv4m1WQKlGpo6CvECGrWKoOIFuXdGIah4Qf28YqVd7VjbpyZ9lh9hz6V79Fx6mIEN3qJfPW/UMveYEELkW1meZ0yn02V6k0TMxGycTR2BeEWONuZ81yWQTtW9APh6y3n6LD9CbEKyaQMTQgiRY7KUjCUlJWFmZsbJkydzKh4h3nhmGjWftyjHl63Lo9Wo+OPkbVrP2sP1+3GmDk0IIUQOyFIyptVqKVasmBwBE+I1aFPFgxU9qlLI1oKztx/SYvou9lyKMnVYQgghslmWT1MOHz6cYcOGcf++LNsiRE7z9yzIun418CviwL9xSYQsOMB3e6+iKJnNViaEECKvyfIA/unTp3Px4kXc3d3x9PTExsbGYPuRI0eyLTghBLg5WLGqZzU+W/M3vx67yahfT3HmVgyjW/hibpblv6eEEELkMllOxlq1apUDYYjnsnYCM4vnT29hZpFaT+RLlloNU9tWxMfNnkkbzvLDgetcuPOIWR39cbazMHV4QgghXkGWk7Hw8PCciEM8TwEP6HtYPwN/UnIyu3fvpkaNGmjTZuC3dkqtJ/ItlUrFR3VK8parHf1/OMqha//Scvou5oYG4FvEwdThCSGEeElZTsbSHD58mDNnzgBQrlw5KlWqlG1BiQwU8HiSbCUlEW19A9wqwDOT7or87+3ShfmlTw26LznE5ahY3p+9hy/fr0CLCu6mDk0IIcRLyHIyFhkZyYcffsj27dspUKAAAA8ePODtt99mxYoVODvLXFdC5LSSzrb83KcG/X84yl/n79L/h6OcuRXD4Eal9ZPICiGEyBuyPPq3X79+PHz4kFOnTnH//n3u37/PyZMniYmJoX///lkOYMaMGXh5eWFpaUlQUBAHDhx4bv2pU6dSunRprKys8PDwYODAgcTHP1nnb9asWZQvXx57e3vs7e2pVq0af/zxh3771atXUalUGd5WrVqlr5fR9hUrVmS5f0LkFAcrLQs7VeGj2iUAmLX9Et2/O0RMfJKJIxNCCJEVWU7GNmzYwMyZMylbtqy+zMfHhxkzZhgkPcZYuXIlgwYNIjw8nCNHjlChQgUaN25MZGRkhvWXL1/OkCFDCA8P58yZMyxYsICVK1cybNgwfZ2iRYsyadIkDh8+zKFDh6hXrx4tW7bk1KlTAHh4eHDr1i2D2+jRo7G1teWdd94x2N+iRYsM6snFCyK30ahVDG1alqltK2Jhpmbb2UjenbGbK1Gxpg5NCCGEkbJ8mlKn06VbHBxSJ4TV6XRZamvKlCl0796dzp07AzB79mx+//13Fi5cyJAhQ9LV37NnDzVq1KB9+/YAeHl50a5dO/bv36+vExwcbPCY8ePHM2vWLPbt20e5cuXQaDS4uhouvvzzzz/Tpk0bbG1tDcoLFCiQru7zJCQkkJDw5IrHmJgYIHXlgqSk7DtakdZWdraZm+T3/kH297GZb2GKOVah1/JjXLobS8vpu5japjy1ShXKlvazSl7DvE/6l/fl9z7mZP9e93OmUrI4e2TLli158OABP/zwA+7uqQOGb9y4QYcOHXB0dOTnn382qp3ExESsra1ZvXq1wRGnsLAwHjx4wK+//pruMcuXL6d3795s2rSJwMBALl++TLNmzQgJCTE4OpYmJSWFVatWERYWxtGjR/Hx8UlX5/DhwwQEBLB7926qV6+uL1epVLi7u5OQkECJEiXo2bMnnTt3RqXKfDzO559/zujRozOM29ra+kVPiRCvLDoRFp7TcPWRChUKLT111HVTeM7bVgghxDPi4uJo37490dHR2Nvb5/j+XmrS1xYtWuDl5YWHR+rVfdevX8fX15elS5ca3U5UVBQpKSm4uLgYlLu4uHD27NkMH9O+fXuioqKoWbMmiqKQnJxMz5490yViJ06coFq1asTHx2Nra8vPP/+cYSIGsGDBAsqWLWuQiAGMGTOGevXqYW1tzaZNm+jduzePHj167ri4oUOHMmjQIP39mJgYPDw8aNSoUba+mElJSWzevJmGDRtmeJQyr8vv/YOc7eN7yTo+X3eG1Udu8Ms1DSpHN8a28MFCq8nW/TyPvIZ5n/Qv78vvfczJ/qWd2XpdspyMeXh4cOTIEbZs2aJPmsqWLUuDBg2yPbhnbd++nQkTJjBz5kyCgoK4ePEiAwYMYOzYsYwcOVJfr3Tp0hw7dozo6GhWr15NWFgYf/31V7qE7PHjxyxfvtzgsWmeLqtUqRKxsbFMnjz5ucmYhYUFFhbpJ+DUarU58kHIqXZzi/zeP8iZPmq1MPmDCpQr4sC438/w87FbXL73mLkh/rjYW2brvl4ci7yGeZ30L+/L733Mme/R1/t8vdQ8YyqVioYNG9KwYcOX3nGhQoXQaDTcuXPHoPzOnTuZjtMaOXIkISEhdOvWDQA/Pz9iY2Pp0aMHw4cPR61OvR7B3Nwcb29vAPz9/Tl48CDffPMNc+bMMWhv9erVxMXFERoa+sJ4g4KCGDt2LAkJCRkmXELkJiqVis41ivOWix29lx3h+PUHBE/bxZwQfyoVczR1eEIIIZ7yUsnY1q1b2bp1K5GRkekG7S9cuNCoNszNzfH392fr1q36MWM6nY6tW7fSt2/fDB8TFxenT7jSaDSpp16eN/RNp9MZDKxPs2DBAlq0aGHU3GjHjh3D0dFREjGRp9TwLsTavjXo/t0hzt95RNs5+5jwnh/v+xc1dWhCCCH+k+VkbPTo0YwZM4aAgADc3NyeO6D9RQYNGkRYWBgBAQEEBgYydepUYmNj9VdXhoaGUqRIESZOnAikXik5ZcoUKlWqpD9NOXLkSIKDg/VJ2dChQ3nnnXcoVqwYDx8+ZPny5Wzfvp2NGzca7PvixYvs2LGD9evXp4tr3bp13Llzh6pVq2JpacnmzZuZMGECgwcPfum+CmEqnk42/NS7BgNXHmPz6TsMXnWcM7diGPpOGcw0stC4EEKYWpaTsdmzZ7N48WJCQkJeeedt27bl7t27jBo1itu3b1OxYkU2bNigH9QfERFhcCRsxIgRqFQqRowYwY0bN3B2diY4OJjx48fr60RGRhIaGsqtW7dwcHCgfPnybNy4Md0p1YULF1K0aFEaNWqULi6tVsuMGTMYOHAgiqLg7e2tn4ZDiLzI1sKMOR39mbr1At9uvcCCXVc4f+ch09tVxsE6/44lEUKIvCDLyVhiYmK6Kw9fRd++fTM9Lbl9+3aD+2ZmZoSHhz93sfIFCxYYtd8JEyYwYcKEDLc1adKEJk2aGNWOEHmFWq1iUMO3KONqx/9+PM7OC1G0nLGLeaEBlHKxM3V4QgjxxsryOYpu3bqxfPnynIhFCPEaNPVzY02v6hQpYMXVe3G8O3MPW07fefEDhRBC5IgsHxmLj49n7ty5bNmyhfLly6e7/HPKlCnZFpwQImf4uNuztm8Nei87wv4r9+n+/SEGNypN77olX2kcqBBCiKzLcjL2999/U7FiRQBOnjxpsE2+xIXIO5xsLVjaLYgx607z/b5rTN54jtO3Ypj8fnmszV/qQmshhBAvIcvfuH/++WdOxCGEMAGtRs3YVr6UdbNn1K8n+f3vW1y5G8u8sACKFLAydXhCCPFGkOvahRC0DyrG8u5VcbIx5/StGFpM28WBK/dNHZYQQrwRjErGevbsyT///GNUgytXrmTZsmWvFJQQ4vULLF6Qtf1qUs7dnnuxibSft49l+6+ZOiwhhMj3jDpN6ezsTLly5ahRowbBwcEEBATg7u6OpaUl//77L6dPn2bXrl2sWLECd3d35s6dm9NxCyFyQJECVqzuWZ1PVh/nt79vMfznk5y5FUN4cDm0MkGsEELkCKOSsbFjx9K3b1/mz5/PzJkzOX36tMF2Ozs7GjRowNy5c2V+LiHyOCtzDdPaVaKsmz3/t+kcS/dFcP7OI2Z1qIyTrSwHJoQQ2c3oAfwuLi4MHz6c4cOH8++//xIREcHjx48pVKgQJUvK5fBC5CcqlYo+b3tT2sWOj1ce48CV+7SYvpt5oQH4uNubOjwhhMhXXuq8g6OjIxUqVKBq1ap4e3tLIiZEPtXAx4Wfe1fHy8maGw8e03rWHtafuGXqsIQQIl+RQSBCiOcq5WLHr31qUqtUIR4npdB72RGmbDqHTqeYOjQhhMgXJBkTQryQg7WWRZ2q0K1mcQC+3XaRj5Ye5lFCsokjE0KIvE+SMSGEUcw0akY09+GrDypgbqZm8+k7vDdzN9fuxZo6NCGEyNOylIwpikJERATx8fE5FY8QIpdr7V+UlT2qUtjOgvN3HtFyxm52X4wydVhCCJFnZTkZ8/b25vr16zkVjxAiD6hUzJF1/WpSwaMAD+KSCF14gEW7r6AoMo5MCCGyKkvJmFqtplSpUty7dy+n4hFC5BEu9pas7FGV9yoXIUWnMHrdaT5b8zcJySmmDk0IIfKULI8ZmzRpEp988gknT57MiXiEEHmIpVbDVx9UYESzsqhV8OOhf2g3dx93HyaYOjQhhMgzjJ70NU1oaChxcXFUqFABc3NzrKysDLbfvy+LCwvxJlGpVHSrVYJSLnb0W36EIxEPeHf2Pjp6mjoyIYTIG7KcjE2dOjUHwhBC5HV13nLm17416f7dIS5GPuLbkxrcSt/i/YBipg5NCCFytSwnY2FhYTkRhxAiHyheyIafe1en/w9H+PNcFINXn+BCZCyfNimDRi0rdQghREaynIwBpKSk8Msvv3DmzBkAypUrR4sWLdBoNNkanBAi77Gz1DKrfSX6zt3Ilhtq5uy4zLk7D/nmw0o4WGlNHZ4QQuQ6WR7Af/HiRcqWLUtoaCg//fQTP/30Ex07dqRcuXJcunQpJ2IUQuQxGrWK4GI6prYpj6VWzfZzd3l3xm4u3X1k6tCEECLXyXIy1r9/f0qWLMn169c5cuQIR44cISIiguLFi9O/f/+ciFEIkUc183Nldc/quDtYcjkqllbTd/Pn2UhThyWEELlKlpOxv/76iy+//JKCBQvqy5ycnJg0aRJ//fVXtgYnhMj7fIs48GvfmlTxcuRhQjJdlhxk9l+XZIJYIYT4T5aTMQsLCx4+fJiu/NGjR5ibm2dLUEKI/MXZzoJl3arSLrAYigKT/jjLxyuPEZ8kE8QKIUSWk7HmzZvTo0cP9u/fj6IoKIrCvn376NmzJy1atMiJGIUQ+YC5mZoJ7/oytmU5zNQqfj12kw9m7+VW9GNThyaEECaV5WTs22+/pWTJklSrVg1LS0ssLS2pUaMG3t7efPPNNzkRoxAin1CpVIRU8+L7rkE4Wms5cSOa4Gm7OXxNJosWQry5sjy1RYECBfj111+5cOECZ8+eBaBs2bJ4e3tne3BCiPypWkkn1v43QezZ2w/5cO4+xrXypW0VmSBWCPHmeal5xgBKlSpFqVKlsjMWIcQbxKOgNWt6VWfwquP8cfI2n605wZlbDxnerCxaTZYP2gshRJ5lVDI2aNAgoxucMmXKSwcjhHiz2FiYMaN9Zab/eZEpm8+zeM9Vzt95yIz2lXG0kQuChBBvBqOSsaNHjxrVmEoly50IIbJGrVbRv34pSrvaMWjlMfZcukeLGbuYFxpAGVd7U4cnhBA5zqhk7M8//8zpOIQQb7jG5Vz5qXcNun13kOv3H/PezD183bYijcu5mjo0IYTIUTIwQwiRa5R2tWNtn5pUL+lEXGIKH31/mG+2XECnkwlihRD510sN4D906BA//vgjERERJCYmGmz76aefsiUwIcSbydHGnO+6BDLu9zMs3nOVr7ec5+ztGP7vgwrYWLz0NUdCCJFrZfnI2IoVK6hevTpnzpzh559/JikpiVOnTrFt2zYcHBxyIkYhxBvGTKPm8xbl+LJ1ebQaFX+cvE3rWXu4fj/O1KEJIUS2y3IyNmHCBL7++mvWrVuHubk533zzDWfPnqVNmzYUKyZzBAkhsk+bKh6s6FGVQrYWnL39kBbTd7H30j1ThyWEENkqy8nYpUuXaNasGQDm5ubExsaiUqkYOHAgc+fOzfYAhRBvNn/PgqzrVwO/Ig78G5dEyIL9fL/3qiw0LoTIN7KcjDk6OuoXCi9SpAgnT54E4MGDB8TFySkEIUT2c3OwYlXParSs6E6yTmHkr6cY9vNJEpN1pg5NCCFeWZaTsdq1a7N582YAPvjgAwYMGED37t1p164d9evXz3IAM2bMwMvLC0tLS4KCgjhw4MBz60+dOpXSpUtjZWWFh4cHAwcOJD4+Xr991qxZlC9fHnt7e+zt7alWrRp//PGHQRt169ZFpVIZ3Hr27GlQJyIigmbNmmFtbU3hwoX55JNPSE5OznL/hBDZw1KrYWrbigx9pwwqFfxwIIIO8/cR9SjB1KEJIcQrMfrSpJMnT+Lr68v06dP1yc/w4cPRarXs2bOH1q1bM2LEiCztfOXKlQwaNIjZs2cTFBTE1KlTady4MefOnaNw4cLp6i9fvpwhQ4awcOFCqlevzvnz5+nUqRMqlUo/83/RokWZNGkSpUqVQlEUlixZQsuWLTl69CjlypXTt9W9e3fGjBmjv29tba3/f0pKCs2aNcPV1ZU9e/Zw69YtQkND0Wq1TJgwIUt9FEJkH5VKxUd1SvKWqx39fzjKwav/0mLaLuaGBuBbRC4gEkLkTUYfGStfvjxBQUGsWbMGOzu71Aer1QwZMoS1a9fy1Vdf4ejomKWdT5kyhe7du9O5c2d8fHyYPXs21tbWLFy4MMP6e/bsoUaNGrRv3x4vLy8aNWpEu3btDI6mBQcH07RpU0qVKsVbb73F+PHjsbW1Zd++fQZtWVtb4+rqqr/Z2z+Z6XvTpk2cPn2apUuXUrFiRd555x3Gjh3LjBkz0k3lIYR4/d4uXZhf+tSgRCEbbkbH8/7sPaw7ftPUYQkhxEsx+sjYX3/9xaJFi/jf//7HwIEDad26Nd26daNWrVovtePExEQOHz7M0KFD9WVqtZoGDRqwd+/eDB9TvXp1li5dyoEDBwgMDOTy5cusX7+ekJCQDOunpKSwatUqYmNjqVatmsG2ZcuWsXTpUlxdXQkODmbkyJH6o2N79+7Fz88PFxcXff3GjRvTq1cvTp06RaVKlTLcX0JCAgkJT06ZxMTEAJCUlERSUpIRz4px0trKzjZzk/zeP8j/fXwd/StWwIJVPQIZtOoEf12Iot8PRzl14wED63ujVuf80mzyGuZt+b1/kP/7mJP9e93PmUrJ4iVJsbGx/PjjjyxevJidO3fi7e1N165dCQsLw9XV+GVLbt68SZEiRdizZ49BovTpp5/y119/sX///gwf9+233zJ48GAURSE5OZmePXsya9YsgzonTpygWrVqxMfHY2try/Lly2natKl++9y5c/H09MTd3Z2///6bzz77jMDAQP2EtT169ODatWts3LhR/5i4uDhsbGxYv34977zzToaxff7554wePTpd+fLlyw1Ogwohso9Ogd8i1Gy9mXqgv5yjjlBvHZYyP6wQ4iXFxcXRvn17oqOjDc6c5ZQsJ2NPu3jxIosWLeL777/n9u3bNGnShLVr1xr12JdJxrZv386HH37IuHHjCAoK4uLFi/oLCEaOHKmvl5iYSEREBNHR0axevZr58+fz119/4ePjk2Es27Zto379+ly8eJGSJUu+dDKW0ZExDw8PoqKisvXFTEpKYvPmzTRs2BCtVptt7eYW+b1/kP/7aIr+/Xr8FsN/OUVCso6SzjbM7lARLyebHNufvIZ5W37vH+T/PuZk/2JiYihUqNBrS8Ze6W9Hb29vhg0bhqenJ0OHDuX33383+rGFChVCo9Fw584dg/I7d+5keoRt5MiRhISE0K1bNwD8/PyIjY2lR48eDB8+HLU69S9jc3NzvL29AfD39+fgwYN88803zJkzJ8N2g4KCAPTJmKura7qrOtPifN7RPwsLCywsLNKVa7XaHPkg5FS7uUV+7x/k/z6+zv69H1CMt1zt6fHdYS7djaX17P1Mb1+Z2m855+h+5TXM2/J7/yD/9zEn+ve6n6+XXih8x44ddOrUCVdXVz755BPee+89du/ebfTjzc3N8ff3Z+vWrfoynU7H1q1b043vShMXF6dPuNJoNBqA504AqdPpDI5YPevYsWMAuLm5AVCtWjVOnDhBZGSkvs7mzZuxt7fP9OiaEML0yhctwNq+NahcrAAx8cl0WnSA+TsvywSxQohcLUtHxm7evMnixYtZvHgxFy9epHr16nz77be0adMGG5usnw4YNGgQYWFhBAQEEBgYyNSpU4mNjaVz584AhIaGUqRIESZOnAikXik5ZcoUKlWqpD9NOXLkSIKDg/VJ2dChQ3nnnXcoVqwYDx8+ZPny5Wzfvl1/yvHSpUv6MWROTk78/fffDBw4kNq1a1O+fHkAGjVqhI+PDyEhIXz55Zfcvn2bESNG0KdPnwyPfAkhco/C9pb80KMqI385yY+H/mHc72c4fSuGCe/6YanVmDo8IYRIx+hk7J133mHLli0UKlSI0NBQunTpQunSpV9p523btuXu3buMGjWK27dvU7FiRTZs2KC/ijEiIsLgSNiIESNQqVSMGDGCGzdu4OzsTHBwMOPHj9fXiYyMJDQ0lFu3buHg4ED58uXZuHEjDRs2BFKPyG3ZskWf+Hl4eKSbI02j0fDbb7/Rq1cvqlWrho2NDWFhYQbzkgkhci8LMw1ftC5PWTd7xv1+hp+O3ODS3VjmhvjjYm9p6vCEEMKA0cmYVqtl9erVNG/eXH8UKjv07duXvn37Zrht+/btBvfNzMwIDw8nPDw80/YWLFjw3P15eHjw119/vTAuT09P1q9f/8J6QojcSaVS0blGcd5ysaP3siMcv/6A4Gm7mBPiT6ViWZsTUQghcpLRY8bWrl1Ly5YtszURE0KInFbDuxBr+9bgLRdbIh8m0HbOPlYf/sfUYQkhhN5LD+AXQoi8wtPJhp9616ChjwuJKToGrzrO2N9Ok5wiC40LIUxPkjEhxBvB1sKMOR396V+/FAALdl2h8+KDRMflz9nJhRB5hyRjQog3hlqtYlDDt5jZoTJWWg07L0TRcsYuLkY+NHVoQog3mCRjQog3TlM/N9b0qk6RAlZcvRdHqxl72HrmzosfKIQQOUCSMSHEG8nH3Z61fWsQVLwgjxKS6fbdIWb8eVEmiBVCvHaSjAkh3lhOthYs7RZESFVPFAUmbzxHvx+O8jgxxdShCSHeIJKMCSHeaFqNmrGtfJnwrh9mahW//X2L92fv4caDx6YOTQjxhpBkTAghgPZBxVjevSpONuacuhlDi2m7OHDlvqnDEkK8ASQZE0KI/wQWL8jafjUp527PvdhEOszfx/L9EaYOSwiRz0kyJoQQTylSwIrVPavTvLwbSSkKw34+wchfTpIkE8QKIXKIJGNCCPEMK3MN09pV4pPGpVGp4Pt91+g4fz/3HiUAkKJT2H/lPoejVOy/cp8UnVyBKYR4eUYvFC6EEG8SlUpFn7e9Ke1ix8crj7H/yn1aTN9Np+peLNx9hVvR8YCG7y4cws3BkvBgH5r4upk6bCFEHiRHxoQQ4jka+Ljwc+/qeDlZc+PBY8avP/NfIvbE7eh4ei09woaTt0wUpRAiL5NkTAghXqCUix0/9aqBuVnGX5lpJylHrzstpyyFEFkmyZgQQhjh3J2HJCZnPohfAW5Fx8t0GEKILJNkTAghjBD5MP7FlbJQTwgh0kgyJoQQRihsZ2lUvb//eUBCsiynJIQwniRjQghhhMDiBXFzsET1gnoLdl2l9pd/snDXFVnjUghhFEnGhBDCCBq1ivBgH4B0CZnqv1ubgKK4OVhyJyaBMb+dpuYX25i1/RIP45Ned7hCiDxEkjEhhDBSE183ZnWsjKuD4SlLVwdLZnWszJfvV2D7J3WZ+J4fHgWtuBebyBcbzlLziz+ZuuU8D+ISTRS5ECI3k0lfhRAiC5r4utHQx5W9FyPZtHM/jWoFUc27MBp16vEyCzMN7QKL8YF/UdYev8mMPy9y6W4sU7dcYP7OK4RU86RrzeIUsrUwcU+EELmFHBkTQogs0qhVBBUviH8hhaDiBfWJ2NPMNGreq1yUTQPrMKN9Zcq42vEoIZlZ2y9R84ttjFl3mtvRcuWlEEKSMSGEyFEatYpm5d34Y0At5ocGUMGjAPFJOhbuvkLtL/9k+M8nuH4/ztRhCiFMSE5TCiHEa6BSqWjg40L9soXZdTGKadsucuDKfZbtj2DFweu8W6kIveuWpISzralDFUK8ZpKMCSHEa6RSqahVyplapZzZf/ke0/+8yM4LUaw+/A9rjvxD8/Lu9Hm7JGVc7U0dqhDiNZFkTAgh/r+9O4+K4kwXP/7tbmgW2ZFNQRZRAm4oCqJJRFwwcRi9yZwkGhUziWaRxOWaRCcqZhxD4p2f0VGizjUanYzR0VyzjPsGxhUVSVxREEVlE1BAEGSp3x+EnqDgCjTdPp9z+hy66q3q5+nXkoeqt97SkxAfR0J8HEm+fIPFu1PZeSaHH3/O5MefMxkc4EJ0uC9d3e30HaYQoonJmDEhhNCzQA87lkf1ZPN7zzC0qxsqFWw/ncPvF+8nakUiRy/K8y6FMGZyZkwIIVqIgDY2xI3sQWruTb6IT+X75EwSzl0j4dw1evs48G54B/q0d0Slut9zAIQQhkTOjAkhRAvj62zF/JcC2fPfYYwIboepRsWhCwW8uvwwLyw5wO6zOSiKou8whRCNRIoxIYRoodo5WhL7Qhf2ftCfsX28MDNRczzjBn/86ihD/7aPLSeyqK6WokwIQyfFmBBCtHButhbM/n0n9n0Yzpv9fGil1XA6q4i3/5nE4AV7+e74VSqrqvUdphDiEUkxJoQQBsLJ2ozpz/mz78Nw3hvQARtzE1JzbzJpXTID5iew7kgGtyulKBPC0EgxJoQQBsa+lZYpgzqyb1o470f44dBKy6X8Uj789gRh/7OH1QcvUlZRpe8whRAPSIoxIYQwUDbmpkzo78u+D/szY6g/ztZmZBaWMev7Uzwzbw//u/cCJeWV+g5TCHEfUowJIYSBs9Sa8MYzPuz9oD9zhnemrZ0F14rLmbv5DE9/tpvFu89TVFah7zCFEA2QYkwIIYyEuamG0b09iX8/jHl/6IqXoyXXSyv46/Zz9P10N/9vewoFJbf1HaYQ4g5SjAkhhJEx1ah5qacHO6f0Y+ErgXR0saK4rJJFu1N5+rPdfLL5DLnFZfoOUwjxK70XY3FxcXh5eWFubk5ISAiJiYn3bL9gwQL8/PywsLDAw8ODyZMnU1b2n/9UlixZQteuXbGxscHGxobQ0FC2bNmiW19QUMC7776r20e7du147733KCwsrPM5KpXqrtfatWsbN3khhGhCJho1wwLbsnXisywdFUTntjaU3q7i73sv8PRne4j5/iRXb9zSd5hCPPH0+jikdevWMWXKFJYuXUpISAgLFiwgIiKClJQUnJ2d72q/Zs0apk2bxooVK+jTpw/nzp1j7NixqFQq5s+fD4C7uzuffvopHTp0QFEUVq1axbBhwzh+/DidOnUiMzOTzMxM/vrXvxIQEMClS5d46623yMzMZMOGDXU+b+XKlQwZMkT33s7Orkm/DyGEaApqtYohnV2J6ORC/LlrLNp1nqSMG6w6eIk1iRm82MOdt8Pa4+nYSt+hCvFE0msxNn/+fMaNG8drr70GwNKlS9m0aRMrVqxg2rRpd7U/cOAAffv2ZeTIkQB4eXkxYsQIDh8+rGsTGRlZZ5u5c+eyZMkSDh06RKdOnejcuTPffvutbn379u2ZO3cuo0aNorKyEhOT/3wldnZ2uLq6NmrOQgihLyqViv5+zoR1dOLghXwW707lQFo+a49c5l9HLzMssC3vhLWng4u1vkMV4omit2Ls9u3bHDt2jOnTp+uWqdVqBg4cyMGDB+vdpk+fPnz99dckJiYSHBzMhQsX2Lx5M6NHj663fVVVFevXr6ekpITQ0NAGYyksLMTGxqZOIQYwYcIE3njjDXx8fHjrrbd47bXX7vmA3vLycsrLy3Xvi4qKAKioqKCiovHuZKrdV2PusyUx9vzA+HM09vzA8HPs1c6WVWODSMq4wRcJF0g4l8fG41f5LvkqEQEujOvrARhufvdj6P33IIw9x6bMr7m/M5Wip6fNZmZm0rZtWw4cOFCnUPrggw9ISEioc7brt/72t78xdepUFEWhsrKSt956iyVLltRpc+LECUJDQykrK8PKyoo1a9bw/PPP17u/vLw8goKCGDVqFHPnztUtnzNnDuHh4VhaWrJ9+3ZiYmKYN28e7733XoM5zZ49m48//viu5WvWrMHS0vKe34cQQujT5Zuw/aqaXwr+M5S4k301g9tW4yUnysQTprS0lJEjR+pO1jQ1gyrG4uPjeeWVV/jLX/5CSEgIqampTJw4kXHjxjFz5kxdu9u3b5ORkUFhYSEbNmxg+fLlJCQkEBAQUGd/RUVFDBo0CAcHB3744QdMTU0bjHfWrFmsXLmSy5cvN9imvjNjHh4e5OXlNWpnVlRUsGPHDgYNGnTPmA2VsecHxp+jsecHxpvjuZxilu5NZ9OJbGqfQd6nvQPv9PMh2Mv+nlcHDImx9t9vGXuOTZlfUVERrVu3brZiTG+XKVu3bo1GoyEnJ6fO8pycnAbHac2cOZPRo0fzxhtvANClSxdKSkoYP348H330EWp1zV90Wq0WX19fAIKCgjhy5AgLFy5k2bJlun0VFxczZMgQrK2t2bhx4307MiQkhDlz5lBeXo6ZmVm9bczMzOpdZ2pq2iQHQlPtt6Uw9vzA+HM09vzA+HLs5O7AopEOvJd9gxn//Ilj+RoOpBVwIK2AXl72RId34NkOrY2mKDO2/quPsefYFPk19/elt6kttFotQUFB7Nq1S7esurqaXbt2NTi+q7S0VFdw1dJoNADc6wRfdXX1XWesBg8ejFar5YcffsDc3Py+8SYnJ2Nvb99gISaEEMbEy7EVI32r2Tn5aUb39kRroubIxetErUhkWNx+tp/KprpaLxdWhDA6er2bcsqUKURFRdGzZ0+Cg4NZsGABJSUlursrx4wZQ9u2bYmNjQVq7pScP38+3bt3112mnDlzJpGRkbqibPr06Tz33HO0a9eO4uJi1qxZQ3x8PNu2bQP+U4iVlpby9ddfU1RUpBto7+TkhEaj4ccffyQnJ4fevXtjbm7Ojh07+OSTT5g6daoeviUhhNCftnYWzBnemehwX/537wX+eTiDX64UMv4fx3jK1ZoJ/X15vosbGrVxnCkTQh/0Woy9/PLLXLt2jVmzZpGdnU1gYCBbt27FxcUFgIyMjDpnwmbMmIFKpWLGjBlcvXoVJycnIiMj6wy8z83NZcyYMWRlZWFra0vXrl3Ztm0bgwYNAiApKUk3Hq32Umat9PR0vLy8MDU1JS4ujsmTJ6MoCr6+vrppOIQQ4knkYmPOjN8F8HZYe1bsT2fVgUuczS7m3W+O8/mOc7zT35dhgW0w1eh9LnEhDI5eizGA6OhooqOj610XHx9f572JiQkxMTHExMQ0uL8vv/zynp8XFhZ2z0uaAEOGDKkz2asQQogajlZmvB/xFOOfac+qgxdZsT+dC3klTF3/Mwt2nuPtsPb8IcgdMxONvkMVwmDInzBCCCEemq2lKe8N6MC+D8OZ/txTtLbScuX6LT7aeJJn5+1hxb50bt2u0neYQhgEKcaEEEI8MiszE97s1559H4YzOzIAVxtzcorK+fO/T/P0Z7tZEp9GcZlxTjoqRGORYkwIIcRjMzfVMLavNwkfhBH7Qhc8HCzIL7nNZ1vP8vRne1iw8xyFpVKUCVEfKcaEEEI0GjMTDSOC27Hnv8OY/1I3fJxaUXirggU7z9P3s918tvUseTfL778jIZ4gUowJIYRodCYaNS/0cGfH5H7EjezBU67W3CyvZEl8Gk9/tps//3ia7MIyfYcpRIsgxZgQQogmo1GrGNrVjS0Tn2H5mJ50c7elrKKaFfvTeXbeHj7aeILLBaX6DlMIvdL71BZCCCGMn0qlYmCACwP8ndmXmsei3akkphfwz8MZrD1ymf/q3pZ3wtrj42Sl71CFaHZSjAkhhGg2KpWKZzo48UwHJw5fyGfxnlR+Op/HhmNX+L+kKwzt2oYJ/dvzlGvTP5xZiJZCijEhhBB6EeLjSIiPI8mXb7B4dyo7z+Tw48+Z/PhzJoMDXIgO96Wru52+wxSiycmYMSGEEHoV6GHH8qiebH7vGYZ2dUOlgu2nc/j94v1ErUjk6MUCfYcoRJOSM2NCCCFahIA2NsSN7EFq7k2+iE/l++RMEs5dI+HcNXr7OPBueAf6tHdEpZKHkgvjImfGhBBCtCi+zlbMfymQPf8dxojgdphqVBy6UMCryw/zwpID7D6bc99nDAthSKQYE0II0SK1c7Qk9oUuJLzfn7F9vDAzUXM84wZ//OooQ/+2jy0nsqiulqJMGD4pxoQQQrRobewsmP37Tuz7MJw3+/lgqdVwOquIt/+ZRMSCvXx3/CqVVdX6DlOIRybFmBBCCIPgZG3G9Of82f9hOO+F+2JtbsL53JtMWpfMgPkJrDuSwe1KKcqE4ZFiTAghhEGxb6VlymA/9k8L5/0IPxxaabmUX8qH354g7H/2sPrgRcoqqvQdphAPTIoxIYQQBsnG3JQJ/X3Z92F/Zgz1x8najMzCMmZ9f4pn5u3hf/deoKS88q7tqqoVDqcXcCxPxeH0Aqpk3JnQM5naQgghhEGz1JrwxjM+jOrtyfqjl1macIGrN24xd/MZvohP5fWnvRnTxwsbc1O2nszi4x9Pk1VYBmhYff4obrbmxEQGMKSzm75TEU8oKcaEEEIYBXNTDaNDvXi5Vzu+O36VL+JTuZhfyl+3n2PZ3gs87duarSezufM8WHZhGW9/ncSSUT2kIBN6IZcphRBCGBWtiZqXenmwc0o/Fr4SSEcXK4rLKtlSTyEG6JZ9/ONpuWQp9EKKMSGEEEbJRKNmWGBbtk58lskDO9yzrQJkFZaRmC6PXhLNT4oxIYQQRk2tVuHVutUDtd1+KptrxeVNHJEQdcmYMSGEEEbP2dr8gdqtPHCRlQcu4uPUihBvB0K8HQn2dqCNnUUTRyieZFKMCSGEMHrB3g642ZqTXVhW77gxAEuthnYOlqTkFHPhWgkXrpXwTeJlANztLQjxdiTE24Fgbwc8HS3lgeWi0UgxJoQQwuhp1CpiIgN4++skVFCnIKstqea/1I0hnd0oLK3gyMUCEi8WcPhCPiczi7hy/RZXrl/h26QrALjYmBH8a3EW4u2Ar7OVFGfikUkxJoQQ4okwpLMbS0b1+M08YzVc75hnzNbSlIEBLgwMcAHgZnklSZeuczg9n8T0An6+XEhOUTk//pzJjz9nAuDQSkuwV81Zs2BvB/zdbNCopTgTD0aKMSGEEE+MIZ3dGBTgysHUXLb/dJjBz4QQ6ut8z8LJysyEZzs68WxHJwDKKqo4nnGDxPQCEi/mc+zSdQpKbrP1VDZbT2UDYG1uQq9fi7MQbwc6t7XFVCP3zIn6STEmhBDiiaJRqwjxdiD/jEKIt8NDn8EyN9UQ2t6R0PaOQAduV1Zz4mqh7szZ0YvXKS6rZPfZXHafzQXAwlRDkKe9bsxZNw87zE01TZCdMERSjAkhhBCPQWuiJsjTniBPe94Jg8qqas5kFeuKs8SLBdworWBfah77UvN02wR62Onu2OzhaYelVn4lP6mk54UQQohGZKJR08Xdli7utrzxjA/V1Qrnc2+SmJ7PofQCEtMLuFZcXlOopRewiFRM1Co6t7UlxKfmsmaQpwO2Fqb6TkU0EynGhBBCiCakVqvwc7XGz9Wa0aFeKIrCxfxSDl+oOXN2OL2AqzdukXz5BsmXb7As4QIqFQS42ejGnPXycsDRykzfqYgmIsWYEEII0YxUKhXerVvh3boVrwS3A+DK9dKawuxCzWXN9LwSTmUWcSqziJX7LwLQwdmqpjjzqZlSw8XmwSayFS2fFGNCCCGEnrnbW+Jub8kLPdwByC0q4/CvlzET0wtIySnmfO5Nzufe5J+HMwDwdLT89YaAmuLM3d5C5jozUFKMCSGEEC2Ms405kd3aENmtDQAFJbdrJqJNL+Bwej6nM4u4lF/KpfxS/nW0ZiLaNrbmv85z5kiIjwMetlp9piAeghRjQgghRAvn0EpLRCdXIjq5AlBUVsGxS9drLmum5/PLlUIyC8v4LjmT75JrJqJtbaXF3UxNvkMGob5O+LlYo5aJaFskKcaEEEIIA2Njbkp/P2f6+zkDUHq7kuMZNzicXvMIp+OXb5B38zZ5N9UkbzoLnMXWwpReXjU3BIT4OBDgZoOJTETbIkgxJoQQQhg4S60JfX1b09e3NQDllVUkXczn622HKDRzJinjBoW3Kth5JoedZ3IAaKXVEFRbnHk70MXdFjMTmYhWH6QYE0IIIYyMmYmGnp725LorPP98EKg1nMosIrF2Itr0AorKKtl77hp7z137dRs1PdrZ/3rHpgPdPeyx0Epx1hykGBNCCCGMnKmmZsb/QA87xj/bnqpqhZTs3zwlIL2A/JLbHLyQz8EL+bALTDUqurrb6R7hFORpj7W5TETbFPR+sTguLg4vLy/Mzc0JCQkhMTHxnu0XLFiAn58fFhYWeHh4MHnyZMrKynTrlyxZQteuXbGxscHGxobQ0FC2bNlSZx9lZWVMmDABR0dHrKysePHFF8nJyanTJiMjg6FDh2JpaYmzszPvv/8+lZWVjZe4EEIIoScatYqANja81tebJaOCODpjIDunPMvc/+rMsMA2uNqYU1GlcOzSdb6IT2PsyiN0+3g7v1+8j7/8+zTbT2Vzo/S2vtMwGno9M7Zu3TqmTJnC0qVLCQkJYcGCBURERJCSkoKzs/Nd7desWcO0adNYsWIFffr04dy5c4wdOxaVSsX8+fMBcHd359NPP6VDhw4oisKqVasYNmwYx48fp1OnTgBMnjyZTZs2sX79emxtbYmOjuaFF15g//79AFRVVTF06FBcXV05cOAAWVlZjBkzBlNTUz755JPm+4KEEEKIZqBSqfB1tsbX2ZpXQzxRFIXLBbc4nJ6vm+8so6CUX64U8suVQpbvSwfgKVfrX58S4Egvb3ucrWUi2keh12Js/vz5jBs3jtdeew2ApUuXsmnTJlasWMG0adPuan/gwAH69u3LyJEjAfDy8mLEiBEcPnxY1yYyMrLONnPnzmXJkiUcOnSITp06UVhYyJdffsmaNWsIDw8HYOXKlfj7+3Po0CF69+7N9u3bOX36NDt37sTFxYXAwEDmzJnDhx9+yOzZs9Fq65+7pby8nPLyct37oqIiACoqKqioqHiMb6qu2n015j5bEmPPD4w/R2PPD4w/R8nP8D1ujm42pgzv5srwbjXTaWQVlnHk4nWOXLpOYvp1LuSVcDa7mLPZxaw+eAkAb0dLgr3t6eVpTy8ve9rYWTROMvVoyj5s7n8XKkVRlGb9xF/dvn0bS0tLNmzYwPDhw3XLo6KiuHHjBt9///1d26xZs4Z33nmH7du3ExwczIULFxg6dCijR4/mT3/6013tq6qqWL9+PVFRURw/fpyAgAB2797NgAEDuH79OnZ2drq2np6eTJo0icmTJzNr1ix++OEHkpOTdevT09Px8fEhKSmJ7t2715vT7Nmz+fjjj+uN29LS8sG/HCGEEKKFK66AtCKV7pVZCgp15zFzMFNob6PQ3lrB10ahtTkYwkMCSktLGTlyJIWFhdjY2DT55+ntzFheXh5VVVW4uLjUWe7i4sLZs2fr3WbkyJHk5eXx9NNPoygKlZWVvPXWW3cVYidOnCA0NJSysjKsrKzYuHEjAQEBAGRnZ6PVausUYrWfm52drWtTX1y16xoyffp0pkyZontfVFSEh4cHgwcPbtTOrKioYMeOHQwaNAhTU+MbTGns+YHx52js+YHx5yj5Gb7mzrHwVgVHL13XnT07lVlMQTkUXFNxpOaGTZytzWrOmnnbE+xpj69zq0d+hFNT5ld7Zau5GNTdlPHx8XzyySd88cUXhISEkJqaysSJE5kzZw4zZ87UtfPz8yM5OZnCwkI2bNhAVFQUCQkJuoKsqZiZmWFmZnbXclNT0yY5EJpqvy2FsecHxp+jsecHxp+j5Gf4mivH1qamDOliyZAubQG4WV5J0qXrukc4/Xy5kNzicjadzGbTyZoTGw6ttPTystc9X9PfzQbNAzwloKpaISm9gGN5KhyvFBPq6/xA2z2o5v43obdirHXr1mg0mrvuYszJycHV1bXebWbOnMno0aN54403AOjSpQslJSWMHz+ejz76CLW65uZQrVaLr68vAEFBQRw5coSFCxeybNkyXF1duX37Njdu3Khzduy3n+vq6nrXXZ21cTYUmxBCCCH+w8rMhGc7OvFsRycAyiqqSL58o+YRThfzOXbpOgUlt9l2Kodtp2p+x1qbmdDTy54QH0eCvR3o0tYW0zueErD1ZBYf/3iarMIyQMPq80dxszUnJjKAIZ3dmjvNRqG3Ykyr1RIUFMSuXbt0Y8aqq6vZtWsX0dHR9W5TWlqqK7hqaTQ1E9Lda+hbdXW1bmB9UFAQpqam7Nq1ixdffBGAlJQUMjIyCA0NBSA0NJS5c+eSm5uru6tzx44d2NjYNPnZNSGEEMIYmZtq6O3jSG8fR6ADtyurOXG18Nd5zvI5evE6xeWV7Em5xp6UmuuaFqYagjztf30AugO5RWVMXJvMnb/xswvLePvrJJaM6mGQBZleL1NOmTKFqKgoevbsSXBwMAsWLKCkpER3d+WYMWNo27YtsbGxQM2dkvPnz6d79+66y5QzZ84kMjJSV5RNnz6d5557jnbt2lFcXMyaNWuIj49n27ZtANja2vL6668zZcoUHBwcsLGx4d133yU0NJTevXsDMHjwYAICAhg9ejTz5s0jOzubGTNmMGHChHovQwohhBDi4WhN1AR52hPkac/bYTUT0Z7JKtI9XzPxYgE3SivYl5rHvtS8e+5LAVTAxz+eZlCAa6NesmwOei3GXn75Za5du8asWbPIzs4mMDCQrVu36gbLZ2Rk1DkTNmPGDFQqFTNmzODq1as4OTkRGRnJ3LlzdW1yc3MZM2YMWVlZ2Nra0rVrV7Zt28agQYN0bT7//HPUajUvvvgi5eXlRERE8MUXX+jWazQa/v3vf/P2228TGhpKq1atiIqK4s9//nMzfCtCCCHEk0ejVtG5rS2d29ry+tPeVFcrnM+9SeKvc539dD6PwlsNTzmhUDP9RmJ6AaHtHZsv8Eag9wH80dHRDV6WjI+Pr/PexMSEmJgYYmJiGtzfl19+ed/PNDc3Jy4ujri4uAbbeHp6snnz5vvuSwghhBCNT61W4edqjZ+rNaNDvfj++FUmrku+73a5xWX3bdPS6P1xSEIIIYQQ9+Ns82Cz+xviUwCkGBNCCCFEixfs7YCbrTkNjQZTAW625gR7OzRnWI1CijEhhBBCtHgatYqYyJoZDe4syGrfx0QGGNzgfZBiTAghhBAGYkhnN5aM6oGrbd1Lka625gY7rQW0gAH8QgghhBAPakhnNwYFuHIwNZftPx1m8DMhjT4Df3OTYkwIIYQQBkWjVhHi7UD+GYUQbweDLsRALlMKIYQQQuiVFGNCCCGEEHokxZgQQgghhB5JMSaEEEIIoUdSjAkhhBBC6JEUY0IIIYQQeiTFmBBCCCGEHkkxJoQQQgihR1KMCSGEEELokczA34QURQGgqKioUfdbUVFBaWkpRUVFmJqaNuq+WwJjzw+MP0djzw+MP0fJz/AZe45NmV/t7+3a3+NNTYqxJlRcXAyAh4eHniMRQgghxMMqLi7G1ta2yT9HpTRX2fcEqq6uJjMzE2tra1SqxntuVlFRER4eHly+fBkbG5tG229LYez5gfHnaOz5gfHnKPkZPmPPsSnzUxSF4uJi2rRpg1rd9CO65MxYE1Kr1bi7uzfZ/m1sbIzyAKtl7PmB8edo7PmB8eco+Rk+Y8+xqfJrjjNitWQAvxBCCCGEHkkxJoQQQgihR1KMGSAzMzNiYmIwMzPTdyhNwtjzA+PP0djzA+PPUfIzfMaeozHlJwP4hRBCCCH0SM6MCSGEEELokRRjQgghhBB6JMWYEEIIIYQeSTEmhBBCCKFHUoy1UHFxcXh5eWFubk5ISAiJiYn3bL9+/XqeeuopzM3N6dKlC5s3b26mSB/Nw+T31VdfoVKp6rzMzc2bMdqHs3fvXiIjI2nTpg0qlYrvvvvuvtvEx8fTo0cPzMzM8PX15auvvmryOB/Hw+YYHx9/Vx+qVCqys7ObJ+CHFBsbS69evbC2tsbZ2Znhw4eTkpJy3+0M5Th8lPwM6ThcsmQJXbt21U0GGhoaypYtW+65jaH0Xa2HzdGQ+q8+n376KSqVikmTJt2znaH1Yy0pxlqgdevWMWXKFGJiYkhKSqJbt25ERESQm5tbb/sDBw4wYsQIXn/9dY4fP87w4cMZPnw4J0+ebObIH8zD5gc1MyxnZWXpXpcuXWrGiB9OSUkJ3bp1Iy4u7oHap6enM3ToUPr3709ycjKTJk3ijTfeYNu2bU0c6aN72BxrpaSk1OlHZ2fnJorw8SQkJDBhwgQOHTrEjh07qKioYPDgwZSUlDS4jSEdh4+SHxjOceju7s6nn37KsWPHOHr0KOHh4QwbNoxTp07V296Q+q7Ww+YIhtN/dzpy5AjLli2ja9eu92xniP2oo4gWJzg4WJkwYYLufVVVldKmTRslNja23vYvvfSSMnTo0DrLQkJClDfffLNJ43xUD5vfypUrFVtb22aKrnEBysaNG+/Z5oMPPlA6depUZ9nLL7+sRERENGFkjedBctyzZ48CKNevX2+WmBpbbm6uAigJCQkNtjG04/C3HiQ/Qz4OFUVR7O3tleXLl9e7zpD77rfulaOh9l9xcbHSoUMHZceOHUq/fv2UiRMnNtjWkPtRzoy1MLdv3+bYsWMMHDhQt0ytVjNw4EAOHjxY7zYHDx6s0x4gIiKiwfb69Cj5Ady8eRNPT088PDzu+9efoTGk/ntcgYGBuLm5MWjQIPbv36/vcB5YYWEhAA4ODg22MeR+fJD8wDCPw6qqKtauXUtJSQmhoaH1tjHkvoMHyxEMs/8mTJjA0KFD7+qf+hhyP0ox1sLk5eVRVVWFi4tLneUuLi4Njq/Jzs5+qPb69Cj5+fn5sWLFCr7//nu+/vprqqur6dOnD1euXGmOkJtcQ/1XVFTErVu39BRV43Jzc2Pp0qV8++23fPvtt3h4eBAWFkZSUpK+Q7uv6upqJk2aRN++fencuXOD7QzpOPytB83P0I7DEydOYGVlhZmZGW+99RYbN24kICCg3raG2ncPk6Oh9R/A2rVrSUpKIjY29oHaG2o/ApjoOwAh7ic0NLTOX3t9+vTB39+fZcuWMWfOHD1GJh6Un58ffn5+uvd9+vQhLS2Nzz//nH/84x96jOz+JkyYwMmTJ9m3b5++Q2kSD5qfoR2Hfn5+JCcnU1hYyIYNG4iKiiIhIaHBYsUQPUyOhtZ/ly9fZuLEiezYscOgbjR4VFKMtTCtW7dGo9GQk5NTZ3lOTg6urq71buPq6vpQ7fXpUfK7k6mpKd27dyc1NbUpQmx2DfWfjY0NFhYWeoqq6QUHB7f4Aic6Opp///vf7N27F3d393u2NaTjsNbD5Henln4carVafH19AQgKCuLIkSMsXLiQZcuW3dXWEPsOHi7HO7X0/jt27Bi5ubn06NFDt6yqqoq9e/eyePFiysvL0Wg0dbYx1H4EuUzZ4mi1WoKCgti1a5duWXV1Nbt27WpwLEBoaGid9gA7duy459gBfXmU/O5UVVXFiRMncHNza6owm5Uh9V9jSk5ObrF9qCgK0dHRbNy4kd27d+Pt7X3fbQypHx8lvzsZ2nFYXV1NeXl5vesMqe/u5V453qml99+AAQM4ceIEycnJulfPnj159dVXSU5OvqsQAwPvR33fQSDutnbtWsXMzEz56quvlNOnTyvjx49X7OzslOzsbEVRFGX06NHKtGnTdO3379+vmJiYKH/961+VM2fOKDExMYqpqaly4sQJfaVwTw+b38cff6xs27ZNSUtLU44dO6a88sorirm5uXLq1Cl9pXBPxcXFyvHjx5Xjx48rgDJ//nzl+PHjyqVLlxRFUZRp06Ypo0eP1rW/cOGCYmlpqbz//vvKmTNnlLi4OEWj0Shbt27VVwr39bA5fv7558p3332nnD9/Xjlx4oQyceJERa1WKzt37tRXCvf09ttvK7a2tkp8fLySlZWle5WWluraGPJx+Cj5GdJxOG3aNCUhIUFJT09XfvnlF2XatGmKSqVStm/friiKYfddrYfN0ZD6ryF33k1pDP1YS4qxFmrRokVKu3btFK1WqwQHByuHDh3SrevXr58SFRVVp/2//vUvpWPHjopWq1U6deqkbNq0qZkjfjgPk9+kSZN0bV1cXJTnn39eSUpK0kPUD6Z2Goc7X7U5RUVFKf369btrm8DAQEWr1So+Pj7KypUrmz3uh/GwOX722WdK+/btFXNzc8XBwUEJCwtTdu/erZ/gH0B9uQF1+sWQj8NHyc+QjsM//vGPiqenp6LVahUnJydlwIABuiJFUQy772o9bI6G1H8NubMYM4Z+rKVSFEVpvvNwQgghhBDit2TMmBBCCCGEHkkxJoQQQgihR1KMCSGEEELokRRjQgghhBB6JMWYEEIIIYQeSTEmhBBCCKFHUowJIYQQQuiRFGNCCCGEEHokxZgQolmMHTuW4cOH6zuMx7Jr1y78/f2pqqp6rP2oVCq+++67xgmqCS1dupTIyEh9hyGE0ZMZ+IUQj02lUt1zfUxMDJMnT0ZRFOzs7JonqCYQFBTElClTePXVVx9rP9nZ2djb22NmZtZIkdUUuzdu3GjUIu/27dt4e3uzdu1annnmmUbbrxCiLhN9ByCEMHxZWVm6n9etW8esWbNISUnRLbOyssLKykofoTWaffv2kZaWxosvvvjY+3J1dW2EiJqeVqtl5MiR/O1vf5NiTIgmJJcphRCPzdXVVfeytbVFpVLVWWZlZXXXZcrq6mpiY2Px9vbGwsKCbt26sWHDBt36+Ph4VCoV27Zto3v37lhYWBAeHk5ubi5btmzB398fGxsbRo4cSWlpqW67sLAwoqOjiY6OxtbWltatWzNz5kx+exHg+vXrjBkzBnt7eywtLXnuuec4f/78PXNcu3YtgwYNwtzcXLds9uzZBAYGsmLFCtq1a4eVlRXvvPMOVVVVzJs3D1dXV5ydnZk7d26dff32MuXFixdRqVT83//9H/3798fS0pJu3bpx8ODBuz7ntxYsWICXl5du/apVq/j+++9RqVSoVCri4+MBOHHiBOHh4VhYWODo6Mj48eO5efNmne85ODiYVq1aYWdnR9++fbl06ZJufWRkJD/88AO3bt265/cjhHh0UowJIfQiNjaW1atXs3TpUk6dOsXkyZMZNWoUCQkJddrNnj2bxYsXc+DAAS5fvsxLL73EggULWLNmDZs2bWL79u0sWrSozjarVq3CxMSExMREFi5cyPz581m+fLlu/dixYzl69Cg//PADBw8eRFEUnn/+eSoqKhqM96effqJnz553LU9LS2PLli1s3bqVb775hi+//JKhQ4dy5coVEhIS+Oyzz5gxYwaHDx++5/fx0UcfMXXqVJKTk+nYsSMjRoygsrLyQb5Kpk6dyksvvcSQIUPIysoiKyuLPn36UFJSQkREBPb29hw5coT169ezc+dOoqOjAaisrGT48OH069ePX375hYMHDzJ+/Pg6l5179uxJZWXlfeMXQjwGRQghGtHKlSsVW1vbu5ZHRUUpw4YNUxRFUcrKyhRLS0vlwIEDddq8/vrryogRIxRFUZQ9e/YogLJz507d+tjYWAVQ0tLSdMvefPNNJSIiQve+X79+ir+/v1JdXa1b9uGHHyr+/v6KoijKuXPnFEDZv3+/bn1eXp5iYWGh/Otf/2owL1tbW2X16tV1lsXExCiWlpZKUVGRbllERITi5eWlVFVV6Zb5+fkpsbGxuveAsnHjRkVRFCU9PV0BlOXLl+vWnzp1SgGUM2fO6D6nW7dudT77888/Vzw9PXXvf/v91vr73/+u2NvbKzdv3tQt27Rpk6JWq5Xs7GwlPz9fAZT4+PgG81YURbG3t1e++uqre7YRQjw6OTMmhGh2qamplJaWMmjQIN14MisrK1avXk1aWlqdtl27dtX97OLigqWlJT4+PnWW5ebm1tmmd+/edc7uhIaGcv78eaqqqjhz5gwmJiaEhITo1js6OuLn58eZM2cajPnWrVt1LlHW8vLywtrauk48AQEBqNXqOsvujPFOv83Tzc0N4L7b3M+ZM2fo1q0brVq10i3r27cv1dXVpKSk4ODgwNixY4mIiCAyMpKFCxfWGf9Xy8LCos6lYCFE45IB/EKIZlc7ZmnTpk20bdu2zro77zA0NTXV/axSqeq8r11WXV3dRJH+R+vWrbl+/fpdy+uL51FivDNPQLeNWq2uM+YNuOcl1YexcuVK3nvvPbZu3cq6deuYMWMGO3bsoHfv3ro2BQUFODk5NcrnCSHuJmfGhBDNLiAgADMzMzIyMvD19a3z8vDweOz93zm+6dChQ3To0AGNRoO/v/9dY6Dy8/NJSUkhICCgwX12796d06dPP3Zsj8LJyYns7Ow6BVlycnKdNlqt9q75z/z9/fn5558pKSnRLdu/fz9qtRo/Pz/dsu7duzN9+nQOHDhA586dWbNmjW5dWloaZWVldO/evZGzEkLUkmJMCNHsrK2tmTp1KpMnT2bVqlWkpaWRlJTEokWLWLVq1WPvPyMjgylTppCSksI333zDokWLmDhxIgAdOnRg2LBhjBs3jn379vHzzz8zatQo2rZty7BhwxrcZ0REBPv27Xvs2B5FWFgY165dY968eaSlpREXF8eWLVvqtPHy8uKXX34hJSWFvLw8KioqePXVVzE3NycqKoqTJ0+yZ88e3n33XUaPHo2Liwvp6elMnz6dgwcPcunSJbZv38758+fx9/fX7fenn37Cx8eH9u3bN3faQjwxpBgTQujFnDlzmDlzJrGxsfj7+zNkyBA2bdqEt7f3Y+97zJgx3Lp1i+DgYCZMmMDEiRMZP368bv3KlSsJCgrid7/7HaGhoSiKwubNm++6vPhbr776KqdOnaozf1pz8ff354svviAuLo5u3bqRmJjI1KlT67QZN24cfn5+9OzZEycnJ/bv34+lpSXbtm2joKCAXr168Yc//IEBAwawePFiACwtLTl79iwvvvgiHTt2ZPz48UyYMIE333xTt99vvvmGcePGNWu+QjxpZAZ+IYRRCQsLIzAwkAULFjT6vt9//32KiopYtmxZo++7JTp16hTh4eGcO3cOW1tbfYcjhNGSM2NCCPGAPvroIzw9PZvlhoGWICsri9WrV0shJkQTk7sphRDiAdnZ2fGnP/1J32E0m4EDB+o7BCGeCHKZUgghhBBCj+QypRBCCCGEHkkxJoQQQgihR1KMCSGEEELokRRjQgghhBB6JMWYEEIIIYQeSTEmhBBCCKFHUowJIYQQQuiRFGNCCCGEEHr0/wExUwNZW3a/bgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "largo = df.shape[0]\n",
        "dias = largo / 1440\n",
        "\n",
        "print('Hay', dias, 'dias en el dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF6BMpebyChX",
        "outputId": "991947f0-517e-40bf-ee79-1f4ea2844815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 2223.0 dias en el dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimento: RSI"
      ],
      "metadata": {
        "id": "Wp7mMTRSvBKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int(len(df_completo)/dia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYiVDulz2l4t",
        "outputId": "3c2c9eca-0d02-4a99-f328-31bad373989e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1986"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dia = 1440\n",
        "dias = []\n",
        "for i in range(int((len(df_completo))/dia)):\n",
        "  dias.append(i * dia)\n",
        "\n",
        "print(dias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADSjCp0C2LTa",
        "outputId": "f543c0ee-b596-482e-e071-d615235d4995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1440, 2880, 4320, 5760, 7200, 8640, 10080, 11520, 12960, 14400, 15840, 17280, 18720, 20160, 21600, 23040, 24480, 25920, 27360, 28800, 30240, 31680, 33120, 34560, 36000, 37440, 38880, 40320, 41760, 43200, 44640, 46080, 47520, 48960, 50400, 51840, 53280, 54720, 56160, 57600, 59040, 60480, 61920, 63360, 64800, 66240, 67680, 69120, 70560, 72000, 73440, 74880, 76320, 77760, 79200, 80640, 82080, 83520, 84960, 86400, 87840, 89280, 90720, 92160, 93600, 95040, 96480, 97920, 99360, 100800, 102240, 103680, 105120, 106560, 108000, 109440, 110880, 112320, 113760, 115200, 116640, 118080, 119520, 120960, 122400, 123840, 125280, 126720, 128160, 129600, 131040, 132480, 133920, 135360, 136800, 138240, 139680, 141120, 142560, 144000, 145440, 146880, 148320, 149760, 151200, 152640, 154080, 155520, 156960, 158400, 159840, 161280, 162720, 164160, 165600, 167040, 168480, 169920, 171360, 172800, 174240, 175680, 177120, 178560, 180000, 181440, 182880, 184320, 185760, 187200, 188640, 190080, 191520, 192960, 194400, 195840, 197280, 198720, 200160, 201600, 203040, 204480, 205920, 207360, 208800, 210240, 211680, 213120, 214560, 216000, 217440, 218880, 220320, 221760, 223200, 224640, 226080, 227520, 228960, 230400, 231840, 233280, 234720, 236160, 237600, 239040, 240480, 241920, 243360, 244800, 246240, 247680, 249120, 250560, 252000, 253440, 254880, 256320, 257760, 259200, 260640, 262080, 263520, 264960, 266400, 267840, 269280, 270720, 272160, 273600, 275040, 276480, 277920, 279360, 280800, 282240, 283680, 285120, 286560, 288000, 289440, 290880, 292320, 293760, 295200, 296640, 298080, 299520, 300960, 302400, 303840, 305280, 306720, 308160, 309600, 311040, 312480, 313920, 315360, 316800, 318240, 319680, 321120, 322560, 324000, 325440, 326880, 328320, 329760, 331200, 332640, 334080, 335520, 336960, 338400, 339840, 341280, 342720, 344160, 345600, 347040, 348480, 349920, 351360, 352800, 354240, 355680, 357120, 358560, 360000, 361440, 362880, 364320, 365760, 367200, 368640, 370080, 371520, 372960, 374400, 375840, 377280, 378720, 380160, 381600, 383040, 384480, 385920, 387360, 388800, 390240, 391680, 393120, 394560, 396000, 397440, 398880, 400320, 401760, 403200, 404640, 406080, 407520, 408960, 410400, 411840, 413280, 414720, 416160, 417600, 419040, 420480, 421920, 423360, 424800, 426240, 427680, 429120, 430560, 432000, 433440, 434880, 436320, 437760, 439200, 440640, 442080, 443520, 444960, 446400, 447840, 449280, 450720, 452160, 453600, 455040, 456480, 457920, 459360, 460800, 462240, 463680, 465120, 466560, 468000, 469440, 470880, 472320, 473760, 475200, 476640, 478080, 479520, 480960, 482400, 483840, 485280, 486720, 488160, 489600, 491040, 492480, 493920, 495360, 496800, 498240, 499680, 501120, 502560, 504000, 505440, 506880, 508320, 509760, 511200, 512640, 514080, 515520, 516960, 518400, 519840, 521280, 522720, 524160, 525600, 527040, 528480, 529920, 531360, 532800, 534240, 535680, 537120, 538560, 540000, 541440, 542880, 544320, 545760, 547200, 548640, 550080, 551520, 552960, 554400, 555840, 557280, 558720, 560160, 561600, 563040, 564480, 565920, 567360, 568800, 570240, 571680, 573120, 574560, 576000, 577440, 578880, 580320, 581760, 583200, 584640, 586080, 587520, 588960, 590400, 591840, 593280, 594720, 596160, 597600, 599040, 600480, 601920, 603360, 604800, 606240, 607680, 609120, 610560, 612000, 613440, 614880, 616320, 617760, 619200, 620640, 622080, 623520, 624960, 626400, 627840, 629280, 630720, 632160, 633600, 635040, 636480, 637920, 639360, 640800, 642240, 643680, 645120, 646560, 648000, 649440, 650880, 652320, 653760, 655200, 656640, 658080, 659520, 660960, 662400, 663840, 665280, 666720, 668160, 669600, 671040, 672480, 673920, 675360, 676800, 678240, 679680, 681120, 682560, 684000, 685440, 686880, 688320, 689760, 691200, 692640, 694080, 695520, 696960, 698400, 699840, 701280, 702720, 704160, 705600, 707040, 708480, 709920, 711360, 712800, 714240, 715680, 717120, 718560, 720000, 721440, 722880, 724320, 725760, 727200, 728640, 730080, 731520, 732960, 734400, 735840, 737280, 738720, 740160, 741600, 743040, 744480, 745920, 747360, 748800, 750240, 751680, 753120, 754560, 756000, 757440, 758880, 760320, 761760, 763200, 764640, 766080, 767520, 768960, 770400, 771840, 773280, 774720, 776160, 777600, 779040, 780480, 781920, 783360, 784800, 786240, 787680, 789120, 790560, 792000, 793440, 794880, 796320, 797760, 799200, 800640, 802080, 803520, 804960, 806400, 807840, 809280, 810720, 812160, 813600, 815040, 816480, 817920, 819360, 820800, 822240, 823680, 825120, 826560, 828000, 829440, 830880, 832320, 833760, 835200, 836640, 838080, 839520, 840960, 842400, 843840, 845280, 846720, 848160, 849600, 851040, 852480, 853920, 855360, 856800, 858240, 859680, 861120, 862560, 864000, 865440, 866880, 868320, 869760, 871200, 872640, 874080, 875520, 876960, 878400, 879840, 881280, 882720, 884160, 885600, 887040, 888480, 889920, 891360, 892800, 894240, 895680, 897120, 898560, 900000, 901440, 902880, 904320, 905760, 907200, 908640, 910080, 911520, 912960, 914400, 915840, 917280, 918720, 920160, 921600, 923040, 924480, 925920, 927360, 928800, 930240, 931680, 933120, 934560, 936000, 937440, 938880, 940320, 941760, 943200, 944640, 946080, 947520, 948960, 950400, 951840, 953280, 954720, 956160, 957600, 959040, 960480, 961920, 963360, 964800, 966240, 967680, 969120, 970560, 972000, 973440, 974880, 976320, 977760, 979200, 980640, 982080, 983520, 984960, 986400, 987840, 989280, 990720, 992160, 993600, 995040, 996480, 997920, 999360, 1000800, 1002240, 1003680, 1005120, 1006560, 1008000, 1009440, 1010880, 1012320, 1013760, 1015200, 1016640, 1018080, 1019520, 1020960, 1022400, 1023840, 1025280, 1026720, 1028160, 1029600, 1031040, 1032480, 1033920, 1035360, 1036800, 1038240, 1039680, 1041120, 1042560, 1044000, 1045440, 1046880, 1048320, 1049760, 1051200, 1052640, 1054080, 1055520, 1056960, 1058400, 1059840, 1061280, 1062720, 1064160, 1065600, 1067040, 1068480, 1069920, 1071360, 1072800, 1074240, 1075680, 1077120, 1078560, 1080000, 1081440, 1082880, 1084320, 1085760, 1087200, 1088640, 1090080, 1091520, 1092960, 1094400, 1095840, 1097280, 1098720, 1100160, 1101600, 1103040, 1104480, 1105920, 1107360, 1108800, 1110240, 1111680, 1113120, 1114560, 1116000, 1117440, 1118880, 1120320, 1121760, 1123200, 1124640, 1126080, 1127520, 1128960, 1130400, 1131840, 1133280, 1134720, 1136160, 1137600, 1139040, 1140480, 1141920, 1143360, 1144800, 1146240, 1147680, 1149120, 1150560, 1152000, 1153440, 1154880, 1156320, 1157760, 1159200, 1160640, 1162080, 1163520, 1164960, 1166400, 1167840, 1169280, 1170720, 1172160, 1173600, 1175040, 1176480, 1177920, 1179360, 1180800, 1182240, 1183680, 1185120, 1186560, 1188000, 1189440, 1190880, 1192320, 1193760, 1195200, 1196640, 1198080, 1199520, 1200960, 1202400, 1203840, 1205280, 1206720, 1208160, 1209600, 1211040, 1212480, 1213920, 1215360, 1216800, 1218240, 1219680, 1221120, 1222560, 1224000, 1225440, 1226880, 1228320, 1229760, 1231200, 1232640, 1234080, 1235520, 1236960, 1238400, 1239840, 1241280, 1242720, 1244160, 1245600, 1247040, 1248480, 1249920, 1251360, 1252800, 1254240, 1255680, 1257120, 1258560, 1260000, 1261440, 1262880, 1264320, 1265760, 1267200, 1268640, 1270080, 1271520, 1272960, 1274400, 1275840, 1277280, 1278720, 1280160, 1281600, 1283040, 1284480, 1285920, 1287360, 1288800, 1290240, 1291680, 1293120, 1294560, 1296000, 1297440, 1298880, 1300320, 1301760, 1303200, 1304640, 1306080, 1307520, 1308960, 1310400, 1311840, 1313280, 1314720, 1316160, 1317600, 1319040, 1320480, 1321920, 1323360, 1324800, 1326240, 1327680, 1329120, 1330560, 1332000, 1333440, 1334880, 1336320, 1337760, 1339200, 1340640, 1342080, 1343520, 1344960, 1346400, 1347840, 1349280, 1350720, 1352160, 1353600, 1355040, 1356480, 1357920, 1359360, 1360800, 1362240, 1363680, 1365120, 1366560, 1368000, 1369440, 1370880, 1372320, 1373760, 1375200, 1376640, 1378080, 1379520, 1380960, 1382400, 1383840, 1385280, 1386720, 1388160, 1389600, 1391040, 1392480, 1393920, 1395360, 1396800, 1398240, 1399680, 1401120, 1402560, 1404000, 1405440, 1406880, 1408320, 1409760, 1411200, 1412640, 1414080, 1415520, 1416960, 1418400, 1419840, 1421280, 1422720, 1424160, 1425600, 1427040, 1428480, 1429920, 1431360, 1432800, 1434240, 1435680, 1437120, 1438560, 1440000, 1441440, 1442880, 1444320, 1445760, 1447200, 1448640, 1450080, 1451520, 1452960, 1454400, 1455840, 1457280, 1458720, 1460160, 1461600, 1463040, 1464480, 1465920, 1467360, 1468800, 1470240, 1471680, 1473120, 1474560, 1476000, 1477440, 1478880, 1480320, 1481760, 1483200, 1484640, 1486080, 1487520, 1488960, 1490400, 1491840, 1493280, 1494720, 1496160, 1497600, 1499040, 1500480, 1501920, 1503360, 1504800, 1506240, 1507680, 1509120, 1510560, 1512000, 1513440, 1514880, 1516320, 1517760, 1519200, 1520640, 1522080, 1523520, 1524960, 1526400, 1527840, 1529280, 1530720, 1532160, 1533600, 1535040, 1536480, 1537920, 1539360, 1540800, 1542240, 1543680, 1545120, 1546560, 1548000, 1549440, 1550880, 1552320, 1553760, 1555200, 1556640, 1558080, 1559520, 1560960, 1562400, 1563840, 1565280, 1566720, 1568160, 1569600, 1571040, 1572480, 1573920, 1575360, 1576800, 1578240, 1579680, 1581120, 1582560, 1584000, 1585440, 1586880, 1588320, 1589760, 1591200, 1592640, 1594080, 1595520, 1596960, 1598400, 1599840, 1601280, 1602720, 1604160, 1605600, 1607040, 1608480, 1609920, 1611360, 1612800, 1614240, 1615680, 1617120, 1618560, 1620000, 1621440, 1622880, 1624320, 1625760, 1627200, 1628640, 1630080, 1631520, 1632960, 1634400, 1635840, 1637280, 1638720, 1640160, 1641600, 1643040, 1644480, 1645920, 1647360, 1648800, 1650240, 1651680, 1653120, 1654560, 1656000, 1657440, 1658880, 1660320, 1661760, 1663200, 1664640, 1666080, 1667520, 1668960, 1670400, 1671840, 1673280, 1674720, 1676160, 1677600, 1679040, 1680480, 1681920, 1683360, 1684800, 1686240, 1687680, 1689120, 1690560, 1692000, 1693440, 1694880, 1696320, 1697760, 1699200, 1700640, 1702080, 1703520, 1704960, 1706400, 1707840, 1709280, 1710720, 1712160, 1713600, 1715040, 1716480, 1717920, 1719360, 1720800, 1722240, 1723680, 1725120, 1726560, 1728000, 1729440, 1730880, 1732320, 1733760, 1735200, 1736640, 1738080, 1739520, 1740960, 1742400, 1743840, 1745280, 1746720, 1748160, 1749600, 1751040, 1752480, 1753920, 1755360, 1756800, 1758240, 1759680, 1761120, 1762560, 1764000, 1765440, 1766880, 1768320, 1769760, 1771200, 1772640, 1774080, 1775520, 1776960, 1778400, 1779840, 1781280, 1782720, 1784160, 1785600, 1787040, 1788480, 1789920, 1791360, 1792800, 1794240, 1795680, 1797120, 1798560, 1800000, 1801440, 1802880, 1804320, 1805760, 1807200, 1808640, 1810080, 1811520, 1812960, 1814400, 1815840, 1817280, 1818720, 1820160, 1821600, 1823040, 1824480, 1825920, 1827360, 1828800, 1830240, 1831680, 1833120, 1834560, 1836000, 1837440, 1838880, 1840320, 1841760, 1843200, 1844640, 1846080, 1847520, 1848960, 1850400, 1851840, 1853280, 1854720, 1856160, 1857600, 1859040, 1860480, 1861920, 1863360, 1864800, 1866240, 1867680, 1869120, 1870560, 1872000, 1873440, 1874880, 1876320, 1877760, 1879200, 1880640, 1882080, 1883520, 1884960, 1886400, 1887840, 1889280, 1890720, 1892160, 1893600, 1895040, 1896480, 1897920, 1899360, 1900800, 1902240, 1903680, 1905120, 1906560, 1908000, 1909440, 1910880, 1912320, 1913760, 1915200, 1916640, 1918080, 1919520, 1920960, 1922400, 1923840, 1925280, 1926720, 1928160, 1929600, 1931040, 1932480, 1933920, 1935360, 1936800, 1938240, 1939680, 1941120, 1942560, 1944000, 1945440, 1946880, 1948320, 1949760, 1951200, 1952640, 1954080, 1955520, 1956960, 1958400, 1959840, 1961280, 1962720, 1964160, 1965600, 1967040, 1968480, 1969920, 1971360, 1972800, 1974240, 1975680, 1977120, 1978560, 1980000, 1981440, 1982880, 1984320, 1985760, 1987200, 1988640, 1990080, 1991520, 1992960, 1994400, 1995840, 1997280, 1998720, 2000160, 2001600, 2003040, 2004480, 2005920, 2007360, 2008800, 2010240, 2011680, 2013120, 2014560, 2016000, 2017440, 2018880, 2020320, 2021760, 2023200, 2024640, 2026080, 2027520, 2028960, 2030400, 2031840, 2033280, 2034720, 2036160, 2037600, 2039040, 2040480, 2041920, 2043360, 2044800, 2046240, 2047680, 2049120, 2050560, 2052000, 2053440, 2054880, 2056320, 2057760, 2059200, 2060640, 2062080, 2063520, 2064960, 2066400, 2067840, 2069280, 2070720, 2072160, 2073600, 2075040, 2076480, 2077920, 2079360, 2080800, 2082240, 2083680, 2085120, 2086560, 2088000, 2089440, 2090880, 2092320, 2093760, 2095200, 2096640, 2098080, 2099520, 2100960, 2102400, 2103840, 2105280, 2106720, 2108160, 2109600, 2111040, 2112480, 2113920, 2115360, 2116800, 2118240, 2119680, 2121120, 2122560, 2124000, 2125440, 2126880, 2128320, 2129760, 2131200, 2132640, 2134080, 2135520, 2136960, 2138400, 2139840, 2141280, 2142720, 2144160, 2145600, 2147040, 2148480, 2149920, 2151360, 2152800, 2154240, 2155680, 2157120, 2158560, 2160000, 2161440, 2162880, 2164320, 2165760, 2167200, 2168640, 2170080, 2171520, 2172960, 2174400, 2175840, 2177280, 2178720, 2180160, 2181600, 2183040, 2184480, 2185920, 2187360, 2188800, 2190240, 2191680, 2193120, 2194560, 2196000, 2197440, 2198880, 2200320, 2201760, 2203200, 2204640, 2206080, 2207520, 2208960, 2210400, 2211840, 2213280, 2214720, 2216160, 2217600, 2219040, 2220480, 2221920, 2223360, 2224800, 2226240, 2227680, 2229120, 2230560, 2232000, 2233440, 2234880, 2236320, 2237760, 2239200, 2240640, 2242080, 2243520, 2244960, 2246400, 2247840, 2249280, 2250720, 2252160, 2253600, 2255040, 2256480, 2257920, 2259360, 2260800, 2262240, 2263680, 2265120, 2266560, 2268000, 2269440, 2270880, 2272320, 2273760, 2275200, 2276640, 2278080, 2279520, 2280960, 2282400, 2283840, 2285280, 2286720, 2288160, 2289600, 2291040, 2292480, 2293920, 2295360, 2296800, 2298240, 2299680, 2301120, 2302560, 2304000, 2305440, 2306880, 2308320, 2309760, 2311200, 2312640, 2314080, 2315520, 2316960, 2318400, 2319840, 2321280, 2322720, 2324160, 2325600, 2327040, 2328480, 2329920, 2331360, 2332800, 2334240, 2335680, 2337120, 2338560, 2340000, 2341440, 2342880, 2344320, 2345760, 2347200, 2348640, 2350080, 2351520, 2352960, 2354400, 2355840, 2357280, 2358720, 2360160, 2361600, 2363040, 2364480, 2365920, 2367360, 2368800, 2370240, 2371680, 2373120, 2374560, 2376000, 2377440, 2378880, 2380320, 2381760, 2383200, 2384640, 2386080, 2387520, 2388960, 2390400, 2391840, 2393280, 2394720, 2396160, 2397600, 2399040, 2400480, 2401920, 2403360, 2404800, 2406240, 2407680, 2409120, 2410560, 2412000, 2413440, 2414880, 2416320, 2417760, 2419200, 2420640, 2422080, 2423520, 2424960, 2426400, 2427840, 2429280, 2430720, 2432160, 2433600, 2435040, 2436480, 2437920, 2439360, 2440800, 2442240, 2443680, 2445120, 2446560, 2448000, 2449440, 2450880, 2452320, 2453760, 2455200, 2456640, 2458080, 2459520, 2460960, 2462400, 2463840, 2465280, 2466720, 2468160, 2469600, 2471040, 2472480, 2473920, 2475360, 2476800, 2478240, 2479680, 2481120, 2482560, 2484000, 2485440, 2486880, 2488320, 2489760, 2491200, 2492640, 2494080, 2495520, 2496960, 2498400, 2499840, 2501280, 2502720, 2504160, 2505600, 2507040, 2508480, 2509920, 2511360, 2512800, 2514240, 2515680, 2517120, 2518560, 2520000, 2521440, 2522880, 2524320, 2525760, 2527200, 2528640, 2530080, 2531520, 2532960, 2534400, 2535840, 2537280, 2538720, 2540160, 2541600, 2543040, 2544480, 2545920, 2547360, 2548800, 2550240, 2551680, 2553120, 2554560, 2556000, 2557440, 2558880, 2560320, 2561760, 2563200, 2564640, 2566080, 2567520, 2568960, 2570400, 2571840, 2573280, 2574720, 2576160, 2577600, 2579040, 2580480, 2581920, 2583360, 2584800, 2586240, 2587680, 2589120, 2590560, 2592000, 2593440, 2594880, 2596320, 2597760, 2599200, 2600640, 2602080, 2603520, 2604960, 2606400, 2607840, 2609280, 2610720, 2612160, 2613600, 2615040, 2616480, 2617920, 2619360, 2620800, 2622240, 2623680, 2625120, 2626560, 2628000, 2629440, 2630880, 2632320, 2633760, 2635200, 2636640, 2638080, 2639520, 2640960, 2642400, 2643840, 2645280, 2646720, 2648160, 2649600, 2651040, 2652480, 2653920, 2655360, 2656800, 2658240, 2659680, 2661120, 2662560, 2664000, 2665440, 2666880, 2668320, 2669760, 2671200, 2672640, 2674080, 2675520, 2676960, 2678400, 2679840, 2681280, 2682720, 2684160, 2685600, 2687040, 2688480, 2689920, 2691360, 2692800, 2694240, 2695680, 2697120, 2698560, 2700000, 2701440, 2702880, 2704320, 2705760, 2707200, 2708640, 2710080, 2711520, 2712960, 2714400, 2715840, 2717280, 2718720, 2720160, 2721600, 2723040, 2724480, 2725920, 2727360, 2728800, 2730240, 2731680, 2733120, 2734560, 2736000, 2737440, 2738880, 2740320, 2741760, 2743200, 2744640, 2746080, 2747520, 2748960, 2750400, 2751840, 2753280, 2754720, 2756160, 2757600, 2759040, 2760480, 2761920, 2763360, 2764800, 2766240, 2767680, 2769120, 2770560, 2772000, 2773440, 2774880, 2776320, 2777760, 2779200, 2780640, 2782080, 2783520, 2784960, 2786400, 2787840, 2789280, 2790720, 2792160, 2793600, 2795040, 2796480, 2797920, 2799360, 2800800, 2802240, 2803680, 2805120, 2806560, 2808000, 2809440, 2810880, 2812320, 2813760, 2815200, 2816640, 2818080, 2819520, 2820960, 2822400, 2823840, 2825280, 2826720, 2828160, 2829600, 2831040, 2832480, 2833920, 2835360, 2836800, 2838240, 2839680, 2841120, 2842560, 2844000, 2845440, 2846880, 2848320, 2849760, 2851200, 2852640, 2854080, 2855520, 2856960, 2858400]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear un conjunto de datos de ejemplo\n",
        "dia = 1440\n",
        "\n",
        "df = df_completo.iloc[dias[:]]\n",
        "\n",
        "# Calcular el cambio de precio\n",
        "df['Price Change'] = df['Close'].diff()\n",
        "\n",
        "# Calcular los retornos positivos y negativos\n",
        "df['Gain'] = np.where(df['Price Change'] > 0, df['Price Change'], 0)\n",
        "df['Loss'] = np.where(df['Price Change'] < 0, abs(df['Price Change']), 0)\n",
        "\n",
        "# Calcular el promedio móvil exponencial de los retornos positivos y negativos\n",
        "rsi_period = 14\n",
        "df['Avg Gain'] = df['Gain'].rolling(window=rsi_period).mean()\n",
        "df['Avg Loss'] = df['Loss'].rolling(window=rsi_period).mean()\n",
        "\n",
        "# Calcular el RSI\n",
        "df['RS'] = df['Avg Gain'] / df['Avg Loss']\n",
        "df['RSI'] = 100 - (100 / (1 + df['RS']))\n",
        "\n",
        "# Graficar el RSI\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df.index, df['Close'], label='Precio', color='Blue')\n",
        "plt.scatter(df.index[df['RSI'] >= 70], df['Close'][df['RSI'] >=70], color='red', label='vender')\n",
        "plt.scatter(df.index[df['RSI'] <= 30], df['Close'][df['RSI'] <=30], color='green', label='comprar')\n",
        "#plt.axhline(70, linestyle='--', color='red')  # Línea de sobrecompra\n",
        "#plt.axhline(30, linestyle='--', color='green')  # Línea de sobreventa\n",
        "plt.title('Índice de Fuerza Relativa (RSI)')\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('RSI')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTTAzVp2vC-4",
        "outputId": "38427d7c-6eb8-4792-aaa0-881ed5e2c89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-e1249a6bc62e>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Price Change'] = df['Close'].diff()\n",
            "<ipython-input-41-e1249a6bc62e>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Gain'] = np.where(df['Price Change'] > 0, df['Price Change'], 0)\n",
            "<ipython-input-41-e1249a6bc62e>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Loss'] = np.where(df['Price Change'] < 0, abs(df['Price Change']), 0)\n",
            "<ipython-input-41-e1249a6bc62e>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Avg Gain'] = df['Gain'].rolling(window=rsi_period).mean()\n",
            "<ipython-input-41-e1249a6bc62e>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Avg Loss'] = df['Loss'].rolling(window=rsi_period).mean()\n",
            "<ipython-input-41-e1249a6bc62e>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['RS'] = df['Avg Gain'] / df['Avg Loss']\n",
            "<ipython-input-41-e1249a6bc62e>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['RSI'] = 100 - (100 / (1 + df['RS']))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "GOzHnmzWwJW9",
        "outputId": "3cf0bce8-1104-4bcc-c388-296b1c8f19ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Open      High       Low     Close     Volume  \\\n",
              "Time                                                                     \n",
              "2023-02-22 08:40:00  24051.91  24058.45  24044.59  24054.61  226.74420   \n",
              "2023-02-22 08:41:00  24054.61  24085.20  24051.62  24071.26  301.14797   \n",
              "2023-02-22 08:42:00  24069.75  24099.19  24059.89  24096.74  228.64026   \n",
              "2023-02-22 08:43:00  24096.74  24118.25  24092.55  24114.95  277.30101   \n",
              "2023-02-22 08:44:00  24116.15  24131.28  24113.24  24126.59  200.56591   \n",
              "\n",
              "                     Price Change   Gain  Loss  Avg Gain  Avg Loss   RS    RSI  \n",
              "Time                                                                            \n",
              "2023-02-22 08:40:00           NaN   0.00   0.0       NaN       NaN  NaN    NaN  \n",
              "2023-02-22 08:41:00         16.65  16.65   0.0       NaN       NaN  NaN    NaN  \n",
              "2023-02-22 08:42:00         25.48  25.48   0.0       NaN       NaN  NaN    NaN  \n",
              "2023-02-22 08:43:00         18.21  18.21   0.0       NaN       NaN  NaN    NaN  \n",
              "2023-02-22 08:44:00         11.64  11.64   0.0    14.396       0.0  inf  100.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-582c06e3-d829-4f54-bbb1-e198b9b1cfee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Price Change</th>\n",
              "      <th>Gain</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Avg Gain</th>\n",
              "      <th>Avg Loss</th>\n",
              "      <th>RS</th>\n",
              "      <th>RSI</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-02-22 08:40:00</th>\n",
              "      <td>24051.91</td>\n",
              "      <td>24058.45</td>\n",
              "      <td>24044.59</td>\n",
              "      <td>24054.61</td>\n",
              "      <td>226.74420</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-22 08:41:00</th>\n",
              "      <td>24054.61</td>\n",
              "      <td>24085.20</td>\n",
              "      <td>24051.62</td>\n",
              "      <td>24071.26</td>\n",
              "      <td>301.14797</td>\n",
              "      <td>16.65</td>\n",
              "      <td>16.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-22 08:42:00</th>\n",
              "      <td>24069.75</td>\n",
              "      <td>24099.19</td>\n",
              "      <td>24059.89</td>\n",
              "      <td>24096.74</td>\n",
              "      <td>228.64026</td>\n",
              "      <td>25.48</td>\n",
              "      <td>25.48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-22 08:43:00</th>\n",
              "      <td>24096.74</td>\n",
              "      <td>24118.25</td>\n",
              "      <td>24092.55</td>\n",
              "      <td>24114.95</td>\n",
              "      <td>277.30101</td>\n",
              "      <td>18.21</td>\n",
              "      <td>18.21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-22 08:44:00</th>\n",
              "      <td>24116.15</td>\n",
              "      <td>24131.28</td>\n",
              "      <td>24113.24</td>\n",
              "      <td>24126.59</td>\n",
              "      <td>200.56591</td>\n",
              "      <td>11.64</td>\n",
              "      <td>11.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.396</td>\n",
              "      <td>0.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-582c06e3-d829-4f54-bbb1-e198b9b1cfee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-582c06e3-d829-4f54-bbb1-e198b9b1cfee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-582c06e3-d829-4f54-bbb1-e198b9b1cfee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71ecac39-df6c-4f98-8a19-16c95e046efe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71ecac39-df6c-4f98-8a19-16c95e046efe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71ecac39-df6c-4f98-8a19-16c95e046efe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: inf"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xYZrtajnBrvW",
        "QY1jqm_Fd7nE"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1oFhgUUBPahzRP5fGnhMlKTyMNFTWohq8",
      "authorship_tag": "ABX9TyM3xKddaY9/djkWhjsBJEvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}